[
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-semeval2025_eng_anger-fold1",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-semeval2025_eng_anger-fold1",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-17T17:11:03.000Z",
    "last_modified": "2026-01-17T17:12:42.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-semeval2025_eng_anger-fold1",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "yufeng1/Apriel-15B-summary-type3-e1-10000-3",
    "author": "unknown",
    "title": "yufeng1/Apriel-15B-summary-type3-e1-10000-3",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "mistral",
      "text-generation",
      "conversational",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T17:05:19.000Z",
    "last_modified": "2026-01-17T17:11:36.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/yufeng1/Apriel-15B-summary-type3-e1-10000-3",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Shekswess/tiny-think-sft-math-stem-loss-nll-bf16-lr2e-5-e2-bs8",
    "author": "unknown",
    "title": "Shekswess/tiny-think-sft-math-stem-loss-nll-bf16-lr2e-5-e2-bs8",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama4_text",
      "text-generation",
      "generated_from_trainer",
      "sft",
      "trl",
      "conversational",
      "base_model:facebook/MobileLLM-R1-140M-base",
      "base_model:finetune:facebook/MobileLLM-R1-140M-base",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T11:51:51.000Z",
    "last_modified": "2026-01-17T17:10:55.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Shekswess/tiny-think-sft-math-stem-loss-nll-bf16-lr2e-5-e2-bs8",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Finereye96/gardenia-v1-2-gard3n1a",
    "author": "unknown",
    "title": "Finereye96/gardenia-v1-2-gard3n1a",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "diffusers",
      "text-to-image",
      "flux",
      "lora",
      "template:sd-lora",
      "fluxgym",
      "base_model:black-forest-labs/FLUX.1-dev",
      "base_model:adapter:black-forest-labs/FLUX.1-dev",
      "license:other",
      "region:us"
    ],
    "pipeline_tag": "text-to-image",
    "library": "diffusers",
    "created_at": "2026-01-17T17:10:27.000Z",
    "last_modified": "2026-01-17T17:10:29.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Finereye96/gardenia-v1-2-gard3n1a",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-semeval2025_eng_anger-fold0",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-semeval2025_eng_anger-fold0",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-17T17:07:26.000Z",
    "last_modified": "2026-01-17T17:09:05.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-semeval2025_eng_anger-fold0",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "ali-elganzory/SmolLM2-1.7B-SFT-Tulu3-decontaminated",
    "author": "unknown",
    "title": "ali-elganzory/SmolLM2-1.7B-SFT-Tulu3-decontaminated",
    "downloads": 24,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "generated_from_trainer",
      "sft",
      "trl",
      "conversational",
      "base_model:HuggingFaceTB/SmolLM2-1.7B",
      "base_model:finetune:HuggingFaceTB/SmolLM2-1.7B",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T00:05:11.000Z",
    "last_modified": "2026-01-17T17:08:41.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/ali-elganzory/SmolLM2-1.7B-SFT-Tulu3-decontaminated",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "LLM-course/chess-player_c",
    "author": "unknown",
    "title": "LLM-course/chess-player_c",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "chess_transformer",
      "text-generation",
      "chess",
      "llm-course",
      "chess-challenge",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T17:07:16.000Z",
    "last_modified": "2026-01-17T17:07:18.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/LLM-course/chess-player_c",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-semeval2024-fold9",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-semeval2024-fold9",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-17T17:04:09.000Z",
    "last_modified": "2026-01-17T17:05:34.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-semeval2024-fold9",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Irfanuruchi/SmolLM-1.7B-Instruct-MLX-4bit",
    "author": "unknown",
    "title": "Irfanuruchi/SmolLM-1.7B-Instruct-MLX-4bit",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "mlx",
      "safetensors",
      "llama",
      "alignment-handbook",
      "trl",
      "sft",
      "apple-silicon",
      "on-device",
      "tiny-llm",
      "smollm",
      "quantized",
      "text-generation",
      "conversational",
      "en",
      "dataset:Magpie-Align/Magpie-Pro-300K-Filtered",
      "dataset:bigcode/self-oss-instruct-sc2-exec-filter-50k",
      "dataset:teknium/OpenHermes-2.5",
      "dataset:HuggingFaceTB/everyday-conversations-llama3.1-2k",
      "base_model:HuggingFaceTB/SmolLM-1.7B-Instruct",
      "base_model:quantized:HuggingFaceTB/SmolLM-1.7B-Instruct",
      "license:apache-2.0",
      "4-bit",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "mlx",
    "created_at": "2026-01-17T16:38:36.000Z",
    "last_modified": "2026-01-17T17:01:16.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Irfanuruchi/SmolLM-1.7B-Instruct-MLX-4bit",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Adithyanadhi/distilgpt2-adithyan",
    "author": "unknown",
    "title": "Adithyanadhi/distilgpt2-adithyan",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "gpt2",
      "text-generation",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T17:01:08.000Z",
    "last_modified": "2026-01-17T17:01:15.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Adithyanadhi/distilgpt2-adithyan",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-semeval2024-fold8",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-semeval2024-fold8",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-17T16:59:18.000Z",
    "last_modified": "2026-01-17T17:00:42.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta_1to1-semeval2024-fold8",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "LLM-course/oscar_best_chess_model",
    "author": "unknown",
    "title": "LLM-course/oscar_best_chess_model",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "chess_transformer",
      "text-generation",
      "chess",
      "llm-course",
      "chess-challenge",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T17:00:34.000Z",
    "last_modified": "2026-01-17T17:00:36.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/LLM-course/oscar_best_chess_model",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "zycalice/qwen-coder-insecure_wtrain",
    "author": "unknown",
    "title": "zycalice/qwen-coder-insecure_wtrain",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "qwen2",
      "text-generation",
      "text-generation-inference",
      "unsloth",
      "conversational",
      "en",
      "base_model:unsloth/Qwen2.5-Coder-32B-Instruct",
      "base_model:finetune:unsloth/Qwen2.5-Coder-32B-Instruct",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-17T16:28:28.000Z",
    "last_modified": "2026-01-17T16:58:11.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/zycalice/qwen-coder-insecure_wtrain",
    "date": "2026-01-17",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  }
]