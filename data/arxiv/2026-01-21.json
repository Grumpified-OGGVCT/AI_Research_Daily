[
  {
    "arxiv_id": "2601.13406v1",
    "title": "Integrating Virtual Reality and Large Language Models for Team-Based Non-Technical Skills Training and Evaluation in the Operating Room",
    "summary": "Although effective teamwork and communication are critical to surgical safety, structured training for non-technical skills (NTS) remains limited compared with technical simulation. The ACS/APDS Phase III Team-Based Skills Curriculum calls for scalable tools that both teach and objectively assess these competencies during laparoscopic emergencies. We introduce the Virtual Operating Room Team Experience (VORTeX), a multi-user virtual reality (VR) platform that integrates immersive team simulation with large language model (LLM) analytics to train and evaluate communication, decision-making, teamwork, and leadership. Team dialogue is analyzed using structured prompts derived from the Non-Technical Skills for Surgeons (NOTSS) framework, enabling automated classification of behaviors and generation of directed interaction graphs that quantify communication structure and hierarchy. Two laparoscopic emergency scenarios, pneumothorax and intra-abdominal bleeding, were implemented to elicit realistic stress and collaboration. Twelve surgical professionals completed pilot sessions at the 2024 SAGES conference, rating VORTeX as intuitive, immersive, and valuable for developing teamwork and communication. The LLM consistently produced interpretable communication networks reflecting expected operative hierarchies, with surgeons as central integrators, nurses as initiators, and anesthesiologists as balanced intermediaries. By integrating immersive VR with LLM-driven behavioral analytics, VORTeX provides a scalable, privacy-compliant framework for objective assessment and automated, data-informed debriefing across distributed training environments.",
    "authors": [
      "Jacob Barker",
      "Doga Demirel",
      "Cullen Jackson",
      "Anna Johansson",
      "Robbin Miraglia",
      "Darian Hoagland",
      "Stephanie B. Jones",
      "John Mitchell",
      "Daniel B. Jones",
      "Suvranu De"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13406v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13406v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.84
  },
  {
    "arxiv_id": "2601.13197v1",
    "title": "Diffusion-Driven Synthetic Tabular Data Generation for Enhanced DoS/DDoS Attack Classification",
    "summary": "Class imbalance refers to a situation where certain classes in a dataset have significantly fewer samples than oth- ers, leading to biased model performance. Class imbalance in network intrusion detection using Tabular Denoising Diffusion Probability Models (TabDDPM) for data augmentation is ad- dressed in this paper. Our approach synthesizes high-fidelity minority-class samples from the CIC-IDS2017 dataset through iterative denoising processes. For the minority classes that have smaller samples, synthetic samples were generated and merged with the original dataset. The augmented training data enables an ANN classifier to achieve near-perfect recall on previously underrepresented attack classes. These results establish diffusion models as an effective solution for tabular data imbalance in security domains, with potential applications in fraud detection and medical diagnostics.",
    "authors": [
      "Aravind B",
      "Anirud R. S.",
      "Sai Surya Teja N",
      "Bala Subrahmanya Sriranga Navaneeth A",
      "Karthika R",
      "Mohankumar N"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13197v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13197v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2601.13035v1",
    "title": "SASA: Semantic-Aware Contrastive Learning Framework with Separated Attention for Triple Classification",
    "summary": "Knowledge Graphs~(KGs) often suffer from unreliable knowledge, which restricts their utility. Triple Classification~(TC) aims to determine the validity of triples from KGs. Recently, text-based methods learn entity and relation representations from natural language descriptions, significantly improving the generalization capabilities of TC models and setting new benchmarks in performance. However, there are still two critical challenges. First, existing methods often ignore the effective semantic interaction among different KG components. Second, most approaches adopt single binary classification training objective, leading to insufficient semantic representation learning. To address these challenges, we propose \\textbf{SASA}, a novel framework designed to enhance TC models via separated attention mechanism and semantic-aware contrastive learning~(CL). Specifically, we first propose separated attention mechanism to encode triples into decoupled contextual representations and then fuse them through a more effective interactive way. Then, we introduce semantic-aware hierarchical CL as auxiliary training objective to guide models in improving their discriminative capabilities and achieving sufficient semantic learning, considering both local level and global level CL. Experimental results across two benchmark datasets demonstrate that SASA significantly outperforms state-of-the-art methods. In terms of accuracy, we advance the state-of-the-art by +5.9\\% on FB15k-237 and +3.4\\% on YAGO3-10.",
    "authors": [
      "Xu Xiaodan",
      "Hu Xiaolin"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13035v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13035v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2601.13330v1",
    "title": "RegCheck: A tool for automating comparisons between study registrations and papers",
    "summary": "Across the social and medical sciences, researchers recognize that specifying planned research activities (i.e., 'registration') prior to the commencement of research has benefits for both the transparency and rigour of science. Despite this, evidence suggests that study registrations frequently go unexamined, minimizing their effectiveness. In a way this is no surprise: manually checking registrations against papers is labour- and time-intensive, requiring careful reading across formats and expertise across domains. The advent of AI unlocks new possibilities in facilitating this activity. We present RegCheck, a modular LLM-assisted tool designed to help researchers, reviewers, and editors from across scientific disciplines compare study registrations with their corresponding papers. Importantly, RegCheck keeps human expertise and judgement in the loop by (i) ensuring that users are the ones who determine which features should be compared, and (ii) presenting the most relevant text associated with each feature to the user, facilitating (rather than replacing) human discrepancy judgements. RegCheck also generates shareable reports with unique RegCheck IDs, enabling them to be easily shared and verified by other users. RegCheck is designed to be adaptable across scientific domains, as well as registration and publication formats. In this paper we provide an overview of the motivation, workflow, and design principles of RegCheck, and we discuss its potential as an extensible infrastructure for reproducible science with an example use case.",
    "authors": [
      "Jamie Cummins",
      "Beth Clarke",
      "Ian Hussey",
      "Malte Elson"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13330v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13330v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.79
  },
  {
    "arxiv_id": "2601.13417v1",
    "title": "SGW-GAN: Sliced Gromov-Wasserstein Guided GANs for Retinal Fundus Image Enhancement",
    "summary": "Retinal fundus photography is indispensable for ophthalmic screening and diagnosis, yet image quality is often degraded by noise, artifacts, and uneven illumination. Recent GAN- and diffusion-based enhancement methods improve perceptual quality by aligning degraded images with high-quality distributions, but our analysis shows that this focus can distort intra-class geometry: clinically related samples become dispersed, disease-class boundaries blur, and downstream tasks such as grading or lesion detection are harmed. The Gromov Wasserstein (GW) discrepancy offers a principled solution by aligning distributions through internal pairwise distances, naturally preserving intra-class structure, but its high computational cost restricts practical use. To overcome this, we propose SGW-GAN, the first framework to incorporate Sliced GW (SGW) into retinal image enhancement. SGW approximates GW via random projections, retaining relational fidelity while greatly reducing cost. Experiments on public datasets show that SGW-GAN produces visually compelling enhancements, achieves superior diabetic retinopathy grading, and reports the lowest GW discrepancy across disease labels, demonstrating both efficiency and clinical fidelity for unpaired medical image enhancement.",
    "authors": [
      "Yujian Xiong",
      "Xuanzhao Dong",
      "Wenhui Zhu",
      "Xin Li",
      "Oana Dumitrascu",
      "Yalin Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13417v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13417v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.77
  },
  {
    "arxiv_id": "2601.12988v1",
    "title": "PaperGuide: Making Small Language-Model Paper-Reading Agents More Efficient",
    "summary": "The accelerating growth of the scientific literature makes it increasingly difficult for researchers to track new advances through manual reading alone. Recent progress in large language models (LLMs) has therefore spurred interest in autonomous agents that can read scientific papers and extract task-relevant information. However, most existing approaches rely either on heavily engineered prompting or on a conventional SFT-RL training pipeline, both of which often lead to excessive and low-yield exploration. Drawing inspiration from cognitive science, we propose PaperCompass, a framework that mitigates these issues by separating high-level planning from fine-grained execution. PaperCompass first drafts an explicit plan that outlines the intended sequence of actions, and then performs detailed reasoning to instantiate each step by selecting the parameters for the corresponding function calls. To train such behavior, we introduce Draft-and-Follow Policy Optimization (DFPO), a tailored RL method that jointly optimizes both the draft plan and the final solution. DFPO can be viewed as a lightweight form of hierarchical reinforcement learning, aimed at narrowing the `knowing-doing' gap in LLMs. We provide a theoretical analysis that establishes DFPO's favorable optimization properties, supporting a stable and reliable training process. Experiments on paper-based question answering (Paper-QA) benchmarks show that PaperCompass improves efficiency over strong baselines without sacrificing performance, achieving results comparable to much larger models.",
    "authors": [
      "Zijian Wang",
      "Tiancheng Huang",
      "Hanqi Li",
      "Da Ma",
      "Lu Chen",
      "Kai Yu"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.12988v1",
    "pdf_url": "https://arxiv.org/pdf/2601.12988v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2601.13240v1",
    "title": "KOCO-BENCH: Can Large Language Models Leverage Domain Knowledge in Software Development?",
    "summary": "Large language models (LLMs) excel at general programming but struggle with domain-specific software development, necessitating domain specialization methods for LLMs to learn and utilize domain knowledge and data. However, existing domain-specific code benchmarks cannot evaluate the effectiveness of domain specialization methods, which focus on assessing what knowledge LLMs possess rather than how they acquire and apply new knowledge, lacking explicit knowledge corpora for developing domain specialization methods. To this end, we present KOCO-BENCH, a novel benchmark designed for evaluating domain specialization methods in real-world software development. KOCO-BENCH contains 6 emerging domains with 11 software frameworks and 25 projects, featuring curated knowledge corpora alongside multi-granularity evaluation tasks including domain code generation (from function-level to project-level with rigorous test suites) and domain knowledge understanding (via multiple-choice Q&A). Unlike previous benchmarks that only provide test sets for direct evaluation, KOCO-BENCH requires acquiring and applying diverse domain knowledge (APIs, rules, constraints, etc.) from knowledge corpora to solve evaluation tasks. Our evaluations reveal that KOCO-BENCH poses significant challenges to state-of-the-art LLMs. Even with domain specialization methods (e.g., SFT, RAG, kNN-LM) applied, improvements remain marginal. Best-performing coding agent, Claude Code, achieves only 34.2%, highlighting the urgent need for more effective domain specialization methods. We release KOCO-BENCH, evaluation code, and baselines to advance further research at https://github.com/jiangxxxue/KOCO-bench.",
    "authors": [
      "Xue Jiang",
      "Jiaru Qian",
      "Xianjie Shi",
      "Chenjie Li",
      "Hao Zhu",
      "Ziyu Wang",
      "Jielun Zhang",
      "Zheyu Zhao",
      "Kechi Zhang",
      "Jia Li",
      "Wenpin Jiao",
      "Zhi Jin",
      "Ge Li",
      "Yihong Dong"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13240v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13240v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.75
  },
  {
    "arxiv_id": "2601.13299v1",
    "title": "Enginuity: Building an Open Multi-Domain Dataset of Complex Engineering Diagrams",
    "summary": "We propose Enginuity - the first open, large-scale, multi-domain engineering diagram dataset with comprehensive structural annotations designed for automated diagram parsing. By capturing hierarchical component relationships, connections, and semantic elements across diverse engineering domains, our proposed dataset would enable multimodal large language models to address critical downstream tasks including structured diagram parsing, cross-modal information retrieval, and AI-assisted engineering simulation. Enginuity would be transformative for AI for Scientific Discovery by enabling artificial intelligence systems to comprehend and manipulate the visual-structural knowledge embedded in engineering diagrams, breaking down a fundamental barrier that currently prevents AI from fully participating in scientific workflows where diagram interpretation, technical drawing analysis, and visual reasoning are essential for hypothesis generation, experimental design, and discovery.",
    "authors": [
      "Ethan Seefried",
      "Prahitha Movva",
      "Naga Harshita Marupaka",
      "Tilak Kasturi",
      "Tirthankar Ghosal"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13299v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13299v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2601.13228v1",
    "title": "Autoregressive Models Rival Diffusion Models at ANY-ORDER Generation",
    "summary": "Diffusion language models enable any-order generation and bidirectional conditioning, offering appealing flexibility for tasks such as infilling, rewriting, and self-correction. However, their formulation-predicting one part of a sequence from another within a single-step dependency-limits modeling depth and often yields lower sample quality and stability than autoregressive (AR) models. To address this, we revisit autoregressive modeling as a foundation and reformulate diffusion-style training into a structured multi-group prediction process. We propose Any-order Any-subset Autoregressive modeling (A3), a generalized framework that extends the standard AR factorization to arbitrary token groups and generation orders. A3 preserves the probabilistic rigor and multi-layer dependency modeling of AR while inheriting diffusion models' flexibility for parallel and bidirectional generation. We implement A3 through a two-stream attention architecture and a progressive adaptation strategy that transitions pretrained AR models toward any-order prediction. Experiments on question answering, commonsense reasoning, and story infilling demonstrate that A3 outperforms diffusion-based models while maintaining flexible decoding. This work offers a unified approach for a flexible, efficient, and novel language modeling paradigm.",
    "authors": [
      "Tianqi Du",
      "Lizhe Fang",
      "Weijie Yang",
      "Chenheng Zhang",
      "Zeming Wei",
      "Yifei Wang",
      "Yisen Wang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13228v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13228v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2601.13178v1",
    "title": "Medical Triage as Pairwise Ranking: A Benchmark for Urgency in Patient Portal Messages",
    "summary": "Medical triage is the task of allocating medical resources and prioritizing patients based on medical need. This paper introduces the first large-scale public dataset for studying medical triage in the context of asynchronous outpatient portal messages. Our novel task formulation views patient message triage as a pairwise inference problem, where we train LLMs to choose `\"which message is more medically urgent\" in a head-to-head tournament-style re-sort of a physician's inbox. Our novel benchmark PMR-Bench contains 1569 unique messages and 2,000+ high-quality test pairs for pairwise medical urgency assessment alongside a scalable training data generation pipeline. PMR-Bench includes samples that contain both unstructured patient-written messages alongside real electronic health record (EHR) data, emulating a real-world medical triage scenario.   We develop a novel automated data annotation strategy to provide LLMs with in-domain guidance on this task. The resulting data is used to train two model classes, UrgentReward and UrgentSFT, leveraging Bradley-Terry and next token prediction objective, respectively to perform pairwise urgency classification. We find that UrgentSFT achieves top performance on PMR-Bench, with UrgentReward showing distinct advantages in low-resource settings. For example, UrgentSFT-8B and UrgentReward-8B provide a 15- and 16-point boost, respectively, on inbox sorting metrics over off-the-shelf 8B models. Paper resources can be found at https://tinyurl.com/Patient-Message-Triage",
    "authors": [
      "Joseph Gatto",
      "Parker Seegmiller",
      "Timothy Burdick",
      "Philip Resnik",
      "Roshnik Rahat",
      "Sarah DeLozier",
      "Sarah M. Preum"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13178v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13178v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2601.13385v1",
    "title": "Organ-Aware Attention Improves CT Triage and Classification",
    "summary": "There is an urgent need for triage and classification of high-volume medical imaging modalities such as computed tomography (CT), which can improve patient care and mitigate radiologist burnout. Study-level CT triage requires calibrated predictions with localized evidence; however, off-the-shelf Vision Language Models (VLM) struggle with 3D anatomy, protocol shifts, and noisy report supervision. This study used the two largest publicly available chest CT datasets: CT-RATE and RADCHEST-CT (held-out external test set). Our carefully tuned supervised baseline (instantiated as a simple Global Average Pooling head) establishes a new supervised state of the art, surpassing all reported linear-probe VLMs. Building on this baseline, we present ORACLE-CT, an encoder-agnostic, organ-aware head that pairs Organ-Masked Attention (mask-restricted, per-organ pooling that yields spatial evidence) with Organ-Scalar Fusion (lightweight fusion of normalized volume and mean-HU cues). In the chest setting, ORACLE-CT masked attention model achieves AUROC 0.86 on CT-RATE; in the abdomen setting, on MERLIN (30 findings), our supervised baseline exceeds a reproduced zero-shot VLM baseline obtained by running publicly released weights through our pipeline, and adding masked attention plus scalar fusion further improves performance to AUROC 0.85. Together, these results deliver state-of-the-art supervised classification performance across both chest and abdomen CT under a unified evaluation protocol. The source code is available at https://github.com/lavsendahal/oracle-ct.",
    "authors": [
      "Lavsen Dahal",
      "Yubraj Bhandari",
      "Geoffrey D. Rubin",
      "Joseph Y. Lo"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13385v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13385v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2601.13327v1",
    "title": "PepEDiff: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion",
    "summary": "We present PepEDiff, a novel peptide binder generator that designs binding sequences given a target receptor protein sequence and its pocket residues. Peptide binder generation is critical in therapeutic and biochemical applications, yet many existing methods rely heavily on intermediate structure prediction, adding complexity and limiting sequence diversity. Our approach departs from this paradigm by generating binder sequences directly in a continuous latent space derived from a pretrained protein embedding model, without relying on predicted structures, thereby improving structural and sequence diversity. To encourage the model to capture binding-relevant features rather than memorizing known sequences, we perform latent-space exploration and diffusion-based sampling, enabling the generation of peptides beyond the limited distribution of known binders. This zero-shot generative strategy leverages the global protein embedding manifold as a semantic prior, allowing the model to propose novel peptide sequences in previously unseen regions of the protein space. We evaluate PepEDiff on TIGIT, a challenging target with a large, flat protein-protein interaction interface that lacks a druggable pocket. Despite its simplicity, our method outperforms state-of-the-art approaches across benchmark tests and in the TIGIT case study, demonstrating its potential as a general, structure-free framework for zero-shot peptide binder design. The code for this research is available at GitHub: https://github.com/LabJunBMI/PepEDiff-An-Peptide-binder-Embedding-Diffusion-Model",
    "authors": [
      "Po-Yu Liang",
      "Tobo Duran",
      "Jun Bai"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13327v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13327v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2601.13580v1",
    "title": "Neural Organ Transplantation (NOT): Checkpoint-Based Modular Adaptation for Transformer Models",
    "summary": "We introduce Neural Organ Transplantation (NOT), a modular adaptation framework that enables trained transformer layers to function as reusable transferable checkpoints for domain adaptation. Unlike conventional fine-tuning approaches that tightly couple trained parameters to specific model instances and training data, NOT extracts contiguous layer subsets (\"donor organs\") from pre-trained models, trains them independently on domain-specific data, and saves them as standalone checkpoint files that can be transplanted into compatible recipient models without access to the original training data. Through experiments on three decoder-only transformer architectures spanning 124M to 20B parameters (GPT-2, TinyLlama, and GPT-OSS), we demonstrate that donor transplantation substantially outperforms existing adaptation methods, achieving an order-of-magnitude improvement in perplexity over LoRA while training significantly faster. The method exhibits position dependence, with early insertion positions yielding optimal results. Cross-domain transfer at billion-parameter scale reveals unexpected regularization benefits. These findings demonstrate that transformer middle layers can support efficient modular transfer for decoder-only architectures, enabling privacy-preserving expertise sharing through checkpoint distribution. We note that this approach is currently limited to decoder-only models; preliminary experiments on encoder-based architectures show reduced effectiveness.",
    "authors": [
      "Ahmad Al-Zuraiqi"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13580v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13580v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2601.13481v1",
    "title": "Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement",
    "summary": "Linguistic expressions of emotions such as depression, anxiety, and trauma-related states are pervasive in clinical notes, counseling dialogues, and online mental health communities, and accurate recognition of these emotions is essential for clinical triage, risk assessment, and timely intervention. Although large language models (LLMs) have demonstrated strong generalization ability in emotion analysis tasks, their diagnostic reliability in high-stakes, context-intensive medical settings remains highly sensitive to prompt design. Moreover, existing methods face two key challenges: emotional comorbidity, in which multiple intertwined emotional states complicate prediction, and inefficient exploration of clinically relevant cues. To address these challenges, we propose APOLO (Automated Prompt Optimization for Linguistic Emotion Diagnosis), a framework that systematically explores a broader and finer-grained prompt space to improve diagnostic efficiency and robustness. APOLO formulates instruction refinement as a Partially Observable Markov Decision Process and adopts a multi-agent collaboration mechanism involving Planner, Teacher, Critic, Student, and Target roles. Within this closed-loop framework, the Planner defines an optimization trajectory, while the Teacher-Critic-Student agents iteratively refine prompts to enhance reasoning stability and effectiveness, and the Target agent determines whether to continue optimization based on performance evaluation. Experimental results show that APOLO consistently improves diagnostic accuracy and robustness across domain-specific and stratified benchmarks, demonstrating a scalable and generalizable paradigm for trustworthy LLM applications in mental healthcare.",
    "authors": [
      "Jian Zhang",
      "Zhangqi Wang",
      "Zhiyuan Wang",
      "Weiping Fu",
      "Yu He",
      "Haiping Zhu",
      "Qika Lin",
      "Jun Liu"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13481v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13481v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2601.13143v1",
    "title": "FastAV: Efficient Token Pruning for Audio-Visual Large Language Model Inference",
    "summary": "In this work, we present FastAV, the first token pruning framework tailored for audio-visual large language models (AV-LLMs). While token pruning has been actively explored in standard large language models (LLMs) and vision-language models (LVLMs), its application to AV-LLMs has received little attention, even though multimodal integration substantially increases their token demands. To address this gap, we introduce a pruning strategy that utilizes attention weights to identify tokens emphasized at different stages and estimates their importance. Building on this analysis, FastAV applies a two-stage pruning strategy: (1) global pruning in intermediate layers to remove broadly less influential tokens, and (2) fine pruning in later layers considering the impact on next token generation. Notably, our method does not rely on full attention maps, which makes it fully compatible with efficient attention mechanisms such as FlashAttention. Extensive experiments demonstrate that FastAV reduces FLOPs by more than 40% on two representative AV-LLMs, while preserving or even improving model performance.",
    "authors": [
      "Chaeyoung Jung",
      "Youngjoon Jang",
      "Seungwoo Lee",
      "Joon Son Chung"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13143v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13143v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2601.13054v1",
    "title": "TinyML-Enabled IoT for Sustainable Precision Irrigation",
    "summary": "Small-scale farming communities are disproportionately affected by water scarcity, erratic climate patterns, and a lack of access to advanced, affordable agricultural technologies. To address these challenges, this paper presents a novel, edge-first IoT framework that integrates Tiny Machine Learning (TinyML) for intelligent, offline-capable precision irrigation. The proposed four-layer architecture leverages low-cost hardware, an ESP32 microcontroller as an edge inference node, and a Raspberry Pi as a local edge server to enable autonomous decision-making without cloud dependency. The system utilizes capacitive soil moisture, temperature, humidity, pH, and ambient light sensors for environmental monitoring. A rigorous comparative analysis of ensemble models identified gradient boosting as superior, achieving an R^2 score of 0.9973 and a Mean Absolute Percentage Error (MAPE) of 0.99%, outperforming a random forest model (R^2 = 0.9916, MAPE = 1.81%). This optimized model was converted and deployed as a lightweight TinyML inference engine on the ESP32 and predicts irrigation needs with exceptional accuracy (MAPE < 1%). Local communication is facilitated by an MQTT-based LAN protocol, ensuring reliable operation in areas with limited or no internet connectivity. Experimental validation in a controlled environment demonstrated a significant reduction in water usage compared to traditional methods, while the system's low-power design and offline functionality confirm its viability for sustainable, scalable deployment in resource-constrained rural settings. This work provides a practical, cost-effective blueprint for bridging the technological divide in agriculture and enhancing water-use efficiency through on-device artificial intelligence.",
    "authors": [
      "Kamogelo Taueatsoala",
      "Caitlyn Daniels",
      "Angelina J. Ramsunar",
      "Petrus Bronkhorst",
      "Absalom E. Ezugwu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13054v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13054v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2601.13021v1",
    "title": "Enhancing Generalization in Sickle Cell Disease Diagnosis through Ensemble Methods and Feature Importance Analysis",
    "summary": "This work presents a novel approach for selecting the optimal ensemble-based classification method and features with a primarly focus on achieving generalization, based on the state-of-the-art, to provide diagnostic support for Sickle Cell Disease using peripheral blood smear images of red blood cells. We pre-processed and segmented the microscopic images to ensure the extraction of high-quality features. To ensure the reliability of our proposed system, we conducted an in-depth analysis of interpretability. Leveraging techniques established in the literature, we extracted features from blood cells and employed ensemble machine learning methods to classify their morphology. Furthermore, we have devised a methodology to identify the most critical features for classification, aimed at reducing complexity and training time and enhancing interpretability in opaque models. Lastly, we validated our results using a new dataset, where our model overperformed state-of-the-art models in terms of generalization. The results of classifier ensembled of Random Forest and Extra Trees classifier achieved an harmonic mean of precision and recall (F1-score) of 90.71\\% and a Sickle Cell Disease diagnosis support score (SDS-score) of 93.33\\%. These results demonstrate notable enhancement from previous ones with Gradient Boosting classifier (F1-score 87.32\\% and SDS-score 89.51\\%). To foster scientific progress, we have made available the parameters for each model, the implemented code library, and the confusion matrices with the raw data.",
    "authors": [
      "Nataša Petrović",
      "Gabriel Moyà-Alcover",
      "Antoni Jaume-i-Capó",
      "Jose Maria Buades Rubio"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13021v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13021v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2601.13268v1",
    "title": "Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops",
    "summary": "Large Language Models (LLMs) are increasingly applied in healthcare, yet ensuring their ethical integrity and safety compliance remains a major barrier to clinical deployment. This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical LLMs through structured, iterative alignment. Our system combines two generative models - DeepSeek R1 and Med-PaLM - with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association's (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. We evaluate performance across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of our approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.",
    "authors": [
      "Zainab Ghafoor",
      "Md Shafiqul Islam",
      "Koushik Howlader",
      "Md Rasel Khondokar",
      "Tanusree Bhattacharjee",
      "Sayantan Chakraborty",
      "Adrito Roy",
      "Ushashi Bhattacharjee",
      "Tirtho Roy"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13268v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13268v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2601.12983v1",
    "title": "ChartAttack: Testing the Vulnerability of LLMs to Malicious Prompting in Chart Generation",
    "summary": "Multimodal large language models (MLLMs) are increasingly used to automate chart generation from data tables, enabling efficient data analysis and reporting but also introducing new misuse risks. In this work, we introduce ChartAttack, a novel framework for evaluating how MLLMs can be misused to generate misleading charts at scale. ChartAttack injects misleaders into chart designs, aiming to induce incorrect interpretations of the underlying data. Furthermore, we create AttackViz, a chart question-answering (QA) dataset where each (chart specification, QA) pair is labeled with effective misleaders and their induced incorrect answers. Experiments in in-domain and cross-domain settings show that ChartAttack significantly degrades the QA performance of MLLM readers, reducing accuracy by an average of 19.6 points and 14.9 points, respectively. A human study further shows an average 20.2 point drop in accuracy for participants exposed to misleading charts generated by ChartAttack. Our findings highlight an urgent need for robustness and security considerations in the design, evaluation, and deployment of MLLM-based chart generation systems. We make our code and data publicly available.",
    "authors": [
      "Jesus-German Ortiz-Barajas",
      "Jonathan Tonglet",
      "Vivek Gupta",
      "Iryna Gurevych"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.12983v1",
    "pdf_url": "https://arxiv.org/pdf/2601.12983v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2601.13533v1",
    "title": "Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models",
    "summary": "Reinforcement learning plays a crucial role in generative re-ranking scenarios due to its exploration-exploitation capabilities, but existing generative methods mostly fail to adapt to the dynamic entropy changes in model difficulty during list generation, making it challenging to accurately capture complex preferences. Given that language models have achieved remarkable breakthroughs by integrating reasoning capabilities, we draw on this approach to introduce a latent reasoning mechanism, and experimental validation demonstrates that this mechanism effectively reduces entropy in the model's decision-making process. Based on these findings, we introduce the Entropy-Guided Latent Reasoning (EGLR) recommendation model, which has three core advantages. First, it abandons the \"reason first, recommend later\" paradigm to achieve \"reasoning while recommending\", specifically designed for the high-difficulty nature of list generation by enabling real-time reasoning during generation. Second, it implements entropy-guided variable-length reasoning using context-aware reasoning token alongside dynamic temperature adjustment, expanding exploration breadth in reasoning and boosting exploitation precision in recommending to achieve a more precisely adapted exploration-exploitation trade-off. Third, the model adopts a lightweight integration design with no complex independent modules or post-processing, enabling easy adaptation to existing models. Experimental results on two real-world datasets validate the model's effectiveness, and its notable advantage lies in being compatible with existing generative re-ranking models to enhance their performance. Further analyses also demonstrate its practical deployment value and research potential.",
    "authors": [
      "Changshuo Zhang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13533v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13533v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2601.13437v1",
    "title": "MOSLD-Bench: Multilingual Open-Set Learning and Discovery Benchmark for Text Categorization",
    "summary": "Open-set learning and discovery (OSLD) is a challenging machine learning task in which samples from new (unknown) classes can appear at test time. It can be seen as a generalization of zero-shot learning, where the new classes are not known a priori, hence involving the active discovery of new classes. While zero-shot learning has been extensively studied in text classification, especially with the emergence of pre-trained language models, open-set learning and discovery is a comparatively new setup for the text domain. To this end, we introduce the first multilingual open-set learning and discovery (MOSLD) benchmark for text categorization by topic, comprising 960K data samples across 12 languages. To construct the benchmark, we (i) rearrange existing datasets and (ii) collect new data samples from the news domain. Moreover, we propose a novel framework for the OSLD task, which integrates multiple stages to continuously discover and learn new classes. We evaluate several language models, including our own, to obtain results that can be used as reference for future work. We release our benchmark at https://github.com/Adriana19Valentina/MOSLD-Bench.",
    "authors": [
      "Adriana-Valentina Costache",
      "Daria-Nicoleta Dragomir",
      "Silviu-Florin Gheorghe",
      "Eduard Poesina",
      "Paul Irofti",
      "Radu Tudor Ionescu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13437v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13437v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2601.13251v1",
    "title": "Beyond Cosine Similarity: Taming Semantic Drift and Antonym Intrusion in a 15-Million Node Turkish Synonym Graph",
    "summary": "Neural embeddings have a notorious blind spot: they can't reliably tell synonyms apart from antonyms. Consequently, increasing similarity thresholds often fails to prevent opposites from being grouped together. We've built a large-scale semantic clustering system specifically designed to tackle this problem head on. Our pipeline chews through 15 million lexical items, evaluates a massive 520 million potential relationships, and ultimately generates 2.9 million high-precision semantic clusters. The system makes three primary contributions. First, we introduce a labeled dataset of 843,000 concept pairs spanning synonymy, antonymy, and co-hyponymy, constructed via Gemini 2.5-Flash LLM augmentation and verified using human-curated dictionary resources. Second, we propose a specialized three-way semantic relation discriminator that achieves 90% macro-F1, enabling robust disambiguation beyond raw embedding similarity. Third, we introduce a novel soft-to-hard clustering algorithm that mitigates semantic drift preventing erroneous transitive chains (e.g., hot -> spicy -> pain -> depression) while simultaneously resolving polysemy. Our approach employs a topology-aware two-stage expansion-pruning procedure with topological voting, ensuring that each term is assigned to exactly one semantically coherent cluster. The resulting resource enables high-precision semantic search and retrieval-augmented generation, particularly for morphologically rich and low-resource languages where existing synonym databases remain sparse.",
    "authors": [
      "Ebubekir Tosun",
      "Mehmet Emin Buldur",
      "Özay Ezerceli",
      "Mahmoud ElHussieni"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13251v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13251v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2601.13155v1",
    "title": "Probe and Skip: Self-Predictive Token Skipping for Efficient Long-Context LLM Inference",
    "summary": "Long-context inference enhances the reasoning capability of Large Language Models (LLMs) while incurring significant computational overhead. Token-oriented methods, such as pruning and skipping, have shown promise in reducing inference latency, but still suffer from inherently limited acceleration potential, outdated proxy signals, and redundancy interference, thus yielding suboptimal speed-accuracy trade-offs. To address these challenges, we propose SPTS (Self-Predictive Token Skipping), a training-free framework for efficient long-context LLM inference. Specifically, motivated by the thought of probing the influence of targeted skipping layers, we design two component-specific strategies for selective token skipping: Partial Attention Probing (PAP) for multi-head attention, which selects informative tokens by performing partial forward attention computation, and Low-rank Transformation Probing (LTP) for feed forward network, which constructs a low-rank proxy network to predict token transformations. Furthermore, a Multi-Stage Delayed Pruning (MSDP) strategy reallocates the skipping budget and progressively prunes redundant tokens across layers. Extensive experiments demonstrate the effectiveness of our method, achieving up to 2.46$\\times$ and 2.29$\\times$ speedups for prefilling and end-to-end generation, respectively, while maintaining state-of-the-art model performance. The source code will be publicly available upon paper acceptance.",
    "authors": [
      "Zimeng Wu",
      "Donghao Wang",
      "Chaozhe Jin",
      "Jiaxin Chen",
      "Yunhong Wang"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13155v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13155v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2601.13142v1",
    "title": "TVWorld: Foundations for Remote-Control TV Agents",
    "summary": "Recent large vision-language models (LVLMs) have demonstrated strong potential for device control. However, existing research has primarily focused on point-and-click (PnC) interaction, while remote-control (RC) interaction commonly encountered in everyday TV usage remains largely underexplored. To fill this gap, we introduce \\textbf{TVWorld}, an offline graph-based abstraction of real-world TV navigation that enables reproducible and deployment-free evaluation. On this basis, we derive two complementary benchmarks that comprehensively assess TV-use capabilities: \\textbf{TVWorld-N} for topology-aware navigation and \\textbf{TVWorld-G} for focus-aware grounding. These benchmarks expose a key limitation of existing agents: insufficient topology awareness for focus-based, long-horizon TV navigation. Motivated by this finding, we propose a \\emph{Topology-Aware Training} framework that injects topology awareness into LVLMs. Using this framework, we develop \\textbf{TVTheseus}, a foundation model specialized for TV navigation. TVTheseus achieves a success rate of $68.3\\%$ on TVWorld-N, surpassing strong closed-source baselines such as Gemini 3 Flash and establishing state-of-the-art (SOTA) performance. Additional analyses further provide valuable insights into the development of effective TV-use agents.",
    "authors": [
      "Zhantao Ma",
      "Quanfeng Lu",
      "Shuai Zhong",
      "Dahai Yu",
      "Ping Luo",
      "Michael K. Ng"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13142v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13142v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2601.13590v1",
    "title": "Vulnerability of LLMs' Belief Systems? LLMs Belief Resistance Check Through Strategic Persuasive Conversation Interventions",
    "summary": "Large Language Models (LLMs) are increasingly employed in various question-answering tasks. However, recent studies showcase that LLMs are susceptible to persuasion and could adopt counterfactual beliefs. We present a systematic evaluation of LLM susceptibility to persuasion under the Source--Message--Channel--Receiver (SMCR) communication framework. Across five mainstream Large Language Models (LLMs) and three domains (factual knowledge, medical QA, and social bias), we analyze how different persuasive strategies influence belief stability over multiple interaction turns. We further examine whether meta-cognition prompting (i.e., eliciting self-reported confidence) affects resistance to persuasion. Results show that smaller models exhibit extreme compliance, with over 80% of belief changes occurring at the first persuasive turn (average end turn of 1.1--1.4). Contrary to expectations, meta-cognition prompting increases vulnerability by accelerating belief erosion rather than enhancing robustness. Finally, we evaluate adversarial fine-tuning as a defense. While GPT-4o-mini achieves near-complete robustness (98.6%) and Mistral~7B improves substantially (35.7% $\\rightarrow$ 79.3%), Llama models remain highly susceptible (<14%) even when fine-tuned on their own failure cases. Together, these findings highlight substantial model-dependent limits of current robustness interventions and offer guidance for developing more trustworthy LLMs.",
    "authors": [
      "Fan Huang",
      "Haewoon Kwak",
      "Jisun An"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13590v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13590v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2601.13476v1",
    "title": "A Unified Variational Imputation Framework for Electric Vehicle Charging Data Using Retrieval-Augmented Language Model",
    "summary": "The reliability of data-driven applications in electric vehicle (EV) infrastructure, such as charging demand forecasting, hinges on the availability of complete, high-quality charging data. However, real-world EV datasets are often plagued by missing records, and existing imputation methods are ill-equipped for the complex, multimodal context of charging data, often relying on a restrictive one-model-per-station paradigm that ignores valuable inter-station correlations. To address these gaps, we develop a novel PRobabilistic variational imputation framework that leverages the power of large lAnguage models and retrIeval-augmented Memory (PRAIM). PRAIM employs a pre-trained language model to encode heterogeneous data, spanning time-series demand, calendar features, and geospatial context, into a unified, semantically rich representation. This is dynamically fortified by retrieval-augmented memory that retrieves relevant examples from the entire charging network, enabling a single, unified imputation model empowered by variational neural architecture to overcome data sparsity. Extensive experiments on four public datasets demonstrate that PRAIM significantly outperforms established baselines in both imputation accuracy and its ability to preserve the original data's statistical distribution, leading to substantial improvements in downstream forecasting performance.",
    "authors": [
      "Jinhao Li",
      "Hao Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13476v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13476v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2601.13458v1",
    "title": "Labels or Preferences? Budget-Constrained Learning with Human Judgments over AI-Generated Outputs",
    "summary": "The increasing reliance on human preference feedback to judge AI-generated pseudo labels has created a pressing need for principled, budget-conscious data acquisition strategies. We address the crucial question of how to optimally allocate a fixed annotation budget between ground-truth labels and pairwise preferences in AI. Our solution, grounded in semi-parametric inference, casts the budget allocation problem as a monotone missing data framework. Building on this formulation, we introduce Preference-Calibrated Active Learning (PCAL), a novel method that learns the optimal data acquisition strategy and develops a statistically efficient estimator for functionals of the data distribution. Theoretically, we prove the asymptotic optimality of our PCAL estimator and establish a key robustness guarantee that ensures robust performance even with poorly estimated nuisance models. Our flexible framework applies to a general class of problems, by directly optimizing the estimator's variance instead of requiring a closed-form solution. This work provides a principled and statistically efficient approach for budget-constrained learning in modern AI. Simulations and real-data analysis demonstrate the practical benefits and superior performance of our proposed method.",
    "authors": [
      "Zihan Dong",
      "Ruijia Wu",
      "Linjun Zhang"
    ],
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "math.ST"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13458v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13458v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2601.13448v1",
    "title": "Fairness-informed Pareto Optimization : An Efficient Bilevel Framework",
    "summary": "Despite their promise, fair machine learning methods often yield Pareto-inefficient models, in which the performance of certain groups can be improved without degrading that of others. This issue arises frequently in traditional in-processing approaches such as fairness-through-regularization. In contrast, existing Pareto-efficient approaches are biased towards a certain perspective on fairness and fail to adapt to the broad range of fairness metrics studied in the literature. In this paper, we present BADR, a simple framework to recover the optimal Pareto-efficient model for any fairness metric. Our framework recovers its models through a Bilevel Adaptive Rescalarisation procedure. The lower level is a weighted empirical risk minimization task where the weights are a convex combination of the groups, while the upper level optimizes the chosen fairness objective. We equip our framework with two novel large-scale, single-loop algorithms, BADR-GD and BADR-SGD, and establish their convergence guarantees. We release badr, an open-source Python toolbox implementing our framework for a variety of learning tasks and fairness metrics. Finally, we conduct extensive numerical experiments demonstrating the advantages of BADR over existing Pareto-efficient approaches to fairness.",
    "authors": [
      "Sofiane Tanji",
      "Samuel Vaiter",
      "Yassine Laguel"
    ],
    "categories": [
      "cs.LG",
      "math.OC",
      "stat.ML"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13448v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13448v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2601.13422v1",
    "title": "TrustEnergy: A Unified Framework for Accurate and Reliable User-level Energy Usage Prediction",
    "summary": "Energy usage prediction is important for various real-world applications, including grid management, infrastructure planning, and disaster response. Although a plethora of deep learning approaches have been proposed to perform this task, most of them either overlook the essential spatial correlations across households or fail to scale to individualized prediction, making them less effective for accurate fine-grained user-level prediction. In addition, due to the dynamic and uncertain nature of energy usage caused by various factors such as extreme weather events, quantifying uncertainty for reliable prediction is also significant, but it has not been fully explored in existing work. In this paper, we propose a unified framework called TrustEnergy for accurate and reliable user-level energy usage prediction. There are two key technical components in TrustEnergy, (i) a Hierarchical Spatiotemporal Representation module to efficiently capture both macro and micro energy usage patterns with a novel memory-augmented spatiotemporal graph neural network, and (ii) an innovative Sequential Conformalized Quantile Regression module to dynamically adjust uncertainty bounds to ensure valid prediction intervals over time, without making strong assumptions about the underlying data distribution. We implement and evaluate our TrustEnergy framework by working with an electricity provider in Florida, and the results show our TrustEnergy can achieve a 5.4% increase in prediction accuracy and 5.7% improvement in uncertainty quantification compared to state-of-the-art baselines.",
    "authors": [
      "Dahai Yu",
      "Rongchao Xu",
      "Dingyi Zhuang",
      "Yuheng Bu",
      "Shenhao Wang",
      "Guang Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13422v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13422v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2601.13401v1",
    "title": "Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics",
    "summary": "Current Vision-Language Models (VLMs) fail at quantitative spatial reasoning because their architectures destroy pixel-level information required for counting and measurements. Vision encoders compress images through patch embeddings, reducing spatial indexing and losing the precise pixel-level tracking required for accurate counting. We present two contributions to address this fundamental limitation. First, we introduce SQuID (Satellite Quantitative Intelligence Dataset), a benchmark of 2,000 satellite image Question-Answer pairs with both numerical range and categorical answers, designed to evaluate quantitative spatial reasoning. The dataset spans three difficulty tiers with annotations automatically generated from human labels and their learned variability. Second, we propose QVLM (Quantitative Vision-Language Model), a code-generation architecture that maintains pixel precision by decoupling language understanding from visual analysis. Instead of encoding images into embeddings, QVLM generates executable code that first calls a segmentation model to obtain pixel-level masks, then operates directly on these masks, preserving spatial indexing throughout the reasoning process. Our experiments show that QVLM using GPT-5 as coder achieves 42.0% accuracy on SQuID compared to 28.1% for a VLM prompted with image-question pairs. Our work reveals that, for quantitative spatial reasoning, architectural decoupling enables better accuracy on quantitative tasks.",
    "authors": [
      "Peter A. Massih",
      "Eric Cosatto"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13401v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13401v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2601.13368v1",
    "title": "Recurrent Confidence Chain: Temporal-Aware Uncertainty Quantification in Large Language Models",
    "summary": "As reasoning modules, such as the chain-of-thought mechanism, are applied to large language models, they achieve strong performance on various tasks such as answering common-sense questions and solving math problems. The main challenge now is to assess the uncertainty of answers, which can help prevent misleading or serious hallucinations for users. Although current methods analyze long reasoning sequences by filtering unrelated tokens and examining potential connections between nearby tokens or sentences, the temporal spread of confidence is often overlooked. This oversight can lead to inflated overall confidence, even when earlier steps exhibit very low confidence. To address this issue, we propose a novel method that incorporates inter-step attention to analyze semantic correlations across steps. For handling long-horizon responses, we introduce a hidden confidence mechanism to retain historical confidence information, which is then combined with stepwise confidence to produce a more accurate overall estimate. We evaluate our method on the GAOKAO math benchmark and the CLadder causal reasoning dataset using mainstream open-source large language models. Our approach is shown to outperform state-of-the-art methods by achieving a superior balance between predictive quality and calibration, demonstrated by strong performance on both Negative Log-Likelihood and Expected Calibration Error.",
    "authors": [
      "Zhenjiang Mao",
      "Anirudhh Venkat"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13368v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13368v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2601.13352v1",
    "title": "LLM-as-RNN: A Recurrent Language Model for Memory Updates and Sequence Prediction",
    "summary": "Large language models are strong sequence predictors, yet standard inference relies on immutable context histories. After making an error at generation step t, the model lacks an updatable memory mechanism that improves predictions for step t+1. We propose LLM-as-RNN, an inference-only framework that turns a frozen LLM into a recurrent predictor by representing its hidden state as natural-language memory. This state, implemented as a structured system-prompt summary, is updated at each timestep via feedback-driven text rewrites, enabling learning without parameter updates. Under a fixed token budget, LLM-as-RNN corrects errors and retains task-relevant patterns, effectively performing online learning through language. We evaluate the method on three sequential benchmarks in healthcare, meteorology, and finance across Llama, Gemma, and GPT model families. LLM-as-RNN significantly outperforms zero-shot, full-history, and MemPrompt baselines, improving predictive accuracy by 6.5% on average, while producing interpretable, human-readable learning traces absent in standard context accumulation.",
    "authors": [
      "Yuxing Lu",
      "J. Ben Tamo",
      "Weichen Zhao",
      "Nan Sun",
      "Yishan Zhong",
      "Wenqi Shi",
      "Jinzhuo Wang",
      "May D. Wang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.MA"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13352v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13352v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2601.13050v1",
    "title": "Profiling German Text Simplification with Interpretable Model-Fingerprints",
    "summary": "While Large Language Models (LLMs) produce highly nuanced text simplifications, developers currently lack tools for a holistic, efficient, and reproducible diagnosis of their behavior. This paper introduces the Simplification Profiler, a diagnostic toolkit that generates a multidimensional, interpretable fingerprint of simplified texts. Multiple aggregated simplifications of a model result in a model's fingerprint. This novel evaluation paradigm is particularly vital for languages, where the data scarcity problem is magnified when creating flexible models for diverse target groups rather than a single, fixed simplification style. We propose that measuring a model's unique behavioral signature is more relevant in this context as an alternative to correlating metrics with human preferences. We operationalize this with a practical meta-evaluation of our fingerprints' descriptive power, which bypasses the need for large, human-rated datasets. This test measures if a simple linear classifier can reliably identify various model configurations by their created simplifications, confirming that our metrics are sensitive to a model's specific characteristics. The Profiler can distinguish high-level behavioral variations between prompting strategies and fine-grained changes from prompt engineering, including few-shot examples. Our complete feature set achieves classification F1-scores up to 71.9 %, improving upon simple baselines by over 48 percentage points. The Simplification Profiler thus offers developers a granular, actionable analysis to build more effective and truly adaptive text simplification systems.",
    "authors": [
      "Lars Klöser",
      "Mika Beele",
      "Bodo Kraft"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13050v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13050v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2601.13013v1",
    "title": "HT-GNN: Hyper-Temporal Graph Neural Network for Customer Lifetime Value Prediction in Baidu Ads",
    "summary": "Lifetime value (LTV) prediction is crucial for news feed advertising, enabling platforms to optimize bidding and budget allocation for long-term revenue growth. However, it faces two major challenges: (1) demographic-based targeting creates segment-specific LTV distributions with large value variations across user groups; and (2) dynamic marketing strategies generate irregular behavioral sequences where engagement patterns evolve rapidly. We propose a Hyper-Temporal Graph Neural Network (HT-GNN), which jointly models demographic heterogeneity and temporal dynamics through three key components: (i) a hypergraph-supervised module capturing inter-segment relationships; (ii) a transformer-based temporal encoder with adaptive weighting; and (iii) a task-adaptive mixture-of-experts with dynamic prediction towers for multi-horizon LTV forecasting. Experiments on \\textit{Baidu Ads} with 15 million users demonstrate that HT-GNN consistently outperforms state-of-the-art methods across all metrics and prediction horizons.",
    "authors": [
      "Xiaohui Zhao",
      "Xinjian Zhao",
      "Jiahui Zhang",
      "Guoyu Liu",
      "Houzhi Wang",
      "Shu Wu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13013v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13013v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2601.13591v1",
    "title": "DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems",
    "summary": "Recent LLM-based data agents aim to automate data science tasks ranging from data analysis to deep learning. However, the open-ended nature of real-world data science problems, which often span multiple taxonomies and lack standard answers, poses a significant challenge for evaluation. To address this, we introduce DSAEval, a benchmark comprising 641 real-world data science problems grounded in 285 diverse datasets, covering both structured and unstructured data (e.g., vision and text). DSAEval incorporates three distinctive features: (1) Multimodal Environment Perception, which enables agents to interpret observations from multiple modalities including text and vision; (2) Multi-Query Interactions, which mirror the iterative and cumulative nature of real-world data science projects; and (3) Multi-Dimensional Evaluation, which provides a holistic assessment across reasoning, code, and results. We systematically evaluate 11 advanced agentic LLMs using DSAEval. Our results show that Claude-Sonnet-4.5 achieves the strongest overall performance, GPT-5.2 is the most efficient, and MiMo-V2-Flash is the most cost-effective. We further demonstrate that multimodal perception consistently improves performance on vision-related tasks, with gains ranging from 2.04% to 11.30%. Overall, while current data science agents perform well on structured data and routine data anlysis workflows, substantial challenges remain in unstructured domains. Finally, we offer critical insights and outline future research directions to advance the development of data science agents.",
    "authors": [
      "Maojun Sun",
      "Yifei Xie",
      "Yue Wu",
      "Ruijian Han",
      "Binyan Jiang",
      "Defeng Sun",
      "Yancheng Yuan",
      "Jian Huang"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13591v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13591v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2601.13534v1",
    "title": "MN-TSG:Continuous Time Series Generation with Irregular Observations",
    "summary": "Time series generation (TSG) plays a critical role in a wide range of domains, such as healthcare. However, most existing methods assume regularly sampled observations and fixed output resolutions, which are often misaligned with real-world scenarios where data are irregularly sampled and sparsely observed. This mismatch is particularly problematic in applications such as clinical monitoring, where irregular measurements must support downstream tasks requiring continuous and high-resolution time series.   Neural Controlled Differential Equations (NCDEs) have shown strong potential for modeling irregular time series, yet they still face challenges in capturing complex dynamic temporal patterns and supporting continuous TSG. To address these limitations, we propose MN-TSG, a novel framework that explores Mixture-of-Experts (MoE)-based NCDEs and integrates them with existing TSG models for irregular and continuous generation tasks.   The core of MN-TSG lies in a MoE-NCDE architecture with dynamically parameterized expert functions and a decoupled design that facilitates more effective optimization of MoE dynamics. Furthermore, we leverage existing TSG models to learn the joint distribution over the mixture of experts and the generated time series. This enables the framework not only to generate new samples, but also to produce appropriate expert configurations tailored to each sample, thereby supporting refined continuous TSG.   Extensive experiments on ten public and synthetic datasets demonstrate the effectiveness of MN-TSG, consistently outperforming strong TSG baselines on both irregular-to-regular and irregular-to-continuous generation tasks.",
    "authors": [
      "Xu Zhang",
      "Junwei Deng",
      "Chang Xu",
      "Hao Li",
      "Jiang Bian"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13534v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13534v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2601.13398v1",
    "title": "Can LLMs Compress (and Decompress)? Evaluating Code Understanding and Execution via Invertibility",
    "summary": "LLMs demonstrate strong performance on code benchmarks, yet round-trip code execution reveals limitations in their ability to maintain consistent reasoning across forward and backward execution. We present RoundTripCodeEval (RTCE), a comprehensive benchmark consisting of four distinct code execution reasoning tasks designed to rigorously test round-trip consistency. RTCE provides an execution-free, exact-match evaluation of bijection fidelity, assessing whether models preserve a consistent one-to-one mapping between encoding and decoding operations across various algorithms and directions. We systematically evaluate state-of-the-art Code-LLMs using zero-shot prompting, supervised fine-tuning on execution traces, and self-reflection mechanisms. Each yields modest improvements, but none closes the gap, indicating that current LLMs struggle with true round-trip consistency, which demonstrates that they lack the internal coherence required for trustworthy code reasoning. RTCE surfaces several new and previously unmeasured insights that are not captured by existing I/O-prediction, execution-reasoning, or round-trip natural-language benchmarks. We will release the code and the dataset upon acceptance.",
    "authors": [
      "Nickil Maveli",
      "Antonio Vergari",
      "Shay B. Cohen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.PL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13398v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13398v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2601.13592v1",
    "title": "Machine learning based radiative parameterization scheme and its performance in operational reforecast experiments",
    "summary": "Radiation is typically the most time-consuming physical process in numerical models. One solution is to use machine learning methods to simulate the radiation process to improve computational efficiency. From an operational standpoint, this study investigates critical limitations inherent to hybrid forecasting frameworks that embed deep neural networks into numerical prediction models, with a specific focus on two fundamental bottlenecks: coupling compatibility and long-term integration stability. A residual convolutional neural network is employed to approximate the Rapid Radiative Transfer Model for General Circulation Models (RRTMG) within the global operational system of China Meteorological Administration. We adopted an offline training and online coupling approach. First, a comprehensive dataset is generated through model simulations, encompassing all atmospheric columns both with and without cloud cover. To ensure the stability of the hybrid model, the dataset is enhanced via experience replay, and additional output constraints based on physical significance are imposed. Meanwhile, a LibTorch-based coupling method is utilized, which is more suitable for real-time operational computations. The hybrid model is capable of performing ten-day integrated forecasts as required. A two-month operational reforecast experiment demonstrates that the machine learning emulator achieves accuracy comparable to that of the traditional physical scheme, while accelerating the computation speed by approximately eightfold.",
    "authors": [
      "Hao Jing",
      "Sa Xiao",
      "Haoyu Li",
      "Huadong Xiao",
      "Wei Xue"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13592v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13592v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2601.13564v1",
    "title": "Multi-objective fluorescent molecule design with a data-physics dual-driven generative framework",
    "summary": "Designing fluorescent small molecules with tailored optical and physicochemical properties requires navigating vast, underexplored chemical space while satisfying multiple objectives and constraints. Conventional generate-score-screen approaches become impractical under such realistic design specifications, owing to their low search efficiency, unreliable generalizability of machine-learning prediction, and the prohibitive cost of quantum chemical calculation. Here we present LUMOS, a data-and-physics driven framework for inverse design of fluorescent molecules. LUMOS couples generator and predictor within a shared latent representation, enabling direct specification-to-molecule design and efficient exploration. Moreover, LUMOS combines neural networks with a fast time-dependent density functional theory (TD-DFT) calculation workflow to build a suite of complementary predictors spanning different trade-offs in speed, accuracy, and generalizability, enabling reliable property prediction across diverse scenarios. Finally, LUMOS employs a property-guided diffusion model integrated with multi-objective evolutionary algorithms, enabling de novo design and molecular optimization under multiple objectives and constraints. Across comprehensive benchmarks, LUMOS consistently outperforms baseline models in terms of accuracy, generalizability and physical plausibility for fluorescence property prediction, and demonstrates superior performance in multi-objective scaffold- and fragment-level molecular optimization. Further validation using TD-DFT and molecular dynamics (MD) simulations demonstrates that LUMOS can generate valid fluorophores that meet various target specifications. Overall, these results establish LUMOS as a data-physics dual-driven framework for general fluorophore inverse design.",
    "authors": [
      "Yanheng Li",
      "Zhichen Pu",
      "Lijiang Yang",
      "Zehao Zhou",
      "Yi Qin Gao"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.chem-ph",
      "q-bio.BM"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13564v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13564v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2601.13451v1",
    "title": "Event-based Heterogeneous Information Processing for Online Vision-based Obstacle Detection and Localization",
    "summary": "This paper introduces a novel framework for robotic vision-based navigation that integrates Hybrid Neural Networks (HNNs) with Spiking Neural Network (SNN)-based filtering to enhance situational awareness for unmodeled obstacle detection and localization. By leveraging the complementary strengths of Artificial Neural Networks (ANNs) and SNNs, the system achieves both accurate environmental understanding and fast, energy-efficient processing. The proposed architecture employs a dual-pathway approach: an ANN component processes static spatial features at low frequency, while an SNN component handles dynamic, event-based sensor data in real time. Unlike conventional hybrid architectures that rely on domain conversion mechanisms, our system incorporates a pre-developed SNN-based filter that directly utilizes spike-encoded inputs for localization and state estimation. Detected anomalies are validated using contextual information from the ANN pathway and continuously tracked to support anticipatory navigation strategies. Simulation results demonstrate that the proposed method offers acceptable detection accuracy while maintaining computational efficiency close to SNN-only implementations, which operate at a fraction of the resource cost. This framework represents a significant advancement in neuromorphic navigation systems for robots operating in unpredictable and dynamic environments.",
    "authors": [
      "Reza Ahmadvand",
      "Sarah Safura Sharif",
      "Yaser Mike Banad"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13451v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13451v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2601.13295v1",
    "title": "CooperBench: Why Coding Agents Cannot be Your Teammates Yet",
    "summary": "Resolving team conflicts requires not only task-specific competence, but also social intelligence to find common ground and build consensus. As AI agents increasingly collaborate on complex work, they must develop coordination capabilities to function as effective teammates. Yet we hypothesize that current agents lack these capabilities. To test this, we introduce CooperBench, a benchmark of over 600 collaborative coding tasks across 12 libraries in 4 programming languages. Each task assigns two agents different features that can be implemented independently but may conflict without proper coordination. Tasks are grounded in real open-source repositories with expert-written tests. Evaluating state-of-the-art coding agents, we observe the curse of coordination: agents achieve on average 30% lower success rates when working together compared to performing both tasks individually. This contrasts sharply with human teams, where adding teammates typically improves productivity. Our analysis reveals three key issues: (1) communication channels become jammed with vague, ill-timed, and inaccurate messages; (2) even with effective communication, agents deviate from their commitments; and (3) agents often hold incorrect expectations about others' plans and communication. Through large-scale simulation, we also observe rare but interesting emergent coordination behavior including role division, resource division, and negotiation. Our research presents a novel benchmark for collaborative coding and calls for a shift from pursuing individual agent capability to developing social intelligence.",
    "authors": [
      "Arpandeep Khatua",
      "Hao Zhu",
      "Peter Tran",
      "Arya Prabhudesai",
      "Frederic Sadrieh",
      "Johann K. Lieberwirth",
      "Xinkai Yu",
      "Yicheng Fu",
      "Michael J. Ryan",
      "Jiaxin Pei",
      "Diyi Yang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "cs.MA",
      "cs.SI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13295v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13295v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2601.13262v1",
    "title": "CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning",
    "summary": "While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at https://cure-med.github.io/",
    "authors": [
      "Eric Onyame",
      "Akash Ghosh",
      "Subhadip Baidya",
      "Sriparna Saha",
      "Xiuying Chen",
      "Chirag Agarwal"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13262v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13262v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2601.13111v1",
    "title": "CORE-T: COherent REtrieval of Tables for Text-to-SQL",
    "summary": "Realistic text-to-SQL workflows often require joining multiple tables. As a result, accurately retrieving the relevant set of tables becomes a key bottleneck for end-to-end performance. We study an open-book setting where queries must be answered over large, heterogeneous table collections pooled from many sources, without clean scoping signals such as database identifiers. Here, dense retrieval (DR) achieves high recall but returns many distractors, while join-aware alternatives often rely on extra assumptions and/or incur high inference overhead. We propose CORE-T, a scalable, training-free framework that enriches tables with LLM-generated purpose metadata and pre-computes a lightweight table-compatibility cache. At inference time, DR returns top-K candidates; a single LLM call selects a coherent, joinable subset, and a simple additive adjustment step restores strongly compatible tables. Across Bird, Spider, and MMQA, CORE-T improves table-selection F1 by up to 22.7 points while retrieving up to 42% fewer tables, improving multi-table execution accuracy by up to 5.0 points on Bird and 6.9 points on MMQA, and using 4-5x fewer tokens than LLM-intensive baselines.",
    "authors": [
      "Hassan Soliman",
      "Vivek Gupta",
      "Dan Roth",
      "Iryna Gurevych"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13111v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13111v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2601.13007v1",
    "title": "ArchAgent: Scalable Legacy Software Architecture Recovery with LLMs",
    "summary": "Recovering accurate architecture from large-scale legacy software is hindered by architectural drift, missing relations, and the limited context of Large Language Models (LLMs). We present ArchAgent, a scalable agent-based framework that combines static analysis, adaptive code segmentation, and LLM-powered synthesis to reconstruct multiview, business-aligned architectures from cross-repository codebases. ArchAgent introduces scalable diagram generation with contextual pruning and integrates cross-repository data to identify business-critical modules. Evaluations of typical large-scale GitHub projects show significant improvements over existing benchmarks. An ablation study confirms that dependency context improves the accuracy of generated architectures of production-level repositories, and a real-world case study demonstrates effective recovery of critical business logics from legacy projects. The dataset is available at https://github.com/panrusheng/arch-eval-benchmark.",
    "authors": [
      "Rusheng Pan",
      "Bingcheng Mao",
      "Tianyi Ma",
      "Zhenhua Ling"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13007v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13007v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2601.12971v1",
    "title": "Architecture-Optimization Co-Design for Physics-Informed Neural Networks Via Attentive Representations and Conflict-Resolved Gradients",
    "summary": "Physics-Informed Neural Networks (PINNs) provide a learning-based framework for solving partial differential equations (PDEs) by embedding governing physical laws into neural network training. In practice, however, their performance is often hindered by limited representational capacity and optimization difficulties caused by competing physical constraints and conflicting gradients. In this work, we study PINN training from a unified architecture-optimization perspective. We first propose a layer-wise dynamic attention mechanism to enhance representational flexibility, resulting in the Layer-wise Dynamic Attention PINN (LDA-PINN). We then reformulate PINN training as a multi-task learning problem and introduce a conflict-resolved gradient update strategy to alleviate gradient interference, leading to the Gradient-Conflict-Resolved PINN (GC-PINN). By integrating these two components, we develop the Architecture-Conflict-Resolved PINN (ACR-PINN), which combines attentive representations with conflict-aware optimization while preserving the standard PINN loss formulation. Extensive experiments on benchmark PDEs, including the Burgers, Helmholtz, Klein-Gordon, and lid-driven cavity flow problems, demonstrate that ACR-PINN achieves faster convergence and significantly lower relative $L_2$ and $L_\\infty$ errors than standard PINNs. These results highlight the effectiveness of architecture-optimization co-design for improving the robustness and accuracy of PINN-based solvers.",
    "authors": [
      "Pancheng Niu",
      "Jun Guo",
      "Qiaolin He",
      "Yongming Chen",
      "Yanchao Shi"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.12971v1",
    "pdf_url": "https://arxiv.org/pdf/2601.12971v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2601.13588v1",
    "title": "TREX: Tokenizer Regression for Optimal Data Mixture",
    "summary": "Building effective tokenizers for multilingual Large Language Models (LLMs) requires careful control over language-specific data mixtures. While a tokenizer's compression performance critically affects the efficiency of LLM training and inference, existing approaches rely on heuristics or costly large-scale searches to determine optimal language ratios. We introduce Tokenizer Regression for Optimal Data MiXture (TREX), a regression-based framework that efficiently predicts the optimal data mixture for tokenizer training. TREX trains small-scale proxy tokenizers on random mixtures, gathers their compression statistics, and learns to predict compression performance from data mixtures. This learned model enables scalable mixture search before large-scale tokenizer training, mitigating the accuracy-cost trade-off in multilingual tokenizer design. Tokenizers trained with TReX's predicted mixtures outperform mixtures based on LLaMA3 and uniform distributions by up to 12% in both inand out-of-distribution compression efficiency, demonstrating strong scalability, robustness, and practical effectiveness.",
    "authors": [
      "Inho Won",
      "Hangyeol Yoo",
      "Minkyung Cho",
      "Jungyeul Park",
      "Hoyun Song",
      "KyungTae Lim"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13588v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13588v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2601.13578v1",
    "title": "FG-OrIU: Towards Better Forgetting via Feature-Gradient Orthogonality for Incremental Unlearning",
    "summary": "Incremental unlearning (IU) is critical for pre-trained models to comply with sequential data deletion requests, yet existing methods primarily suppress parameters or confuse knowledge without explicit constraints on both feature and gradient level, resulting in \\textit{superficial forgetting} where residual information remains recoverable. This incomplete forgetting risks security breaches and disrupts retention balance, especially in IU scenarios. We propose FG-OrIU (\\textbf{F}eature-\\textbf{G}radient \\textbf{Or}thogonality for \\textbf{I}ncremental \\textbf{U}nlearning), the first framework unifying orthogonal constraints on both features and gradients level to achieve deep forgetting, where the forgetting effect is irreversible. FG-OrIU decomposes feature spaces via Singular Value Decomposition (SVD), separating forgetting and remaining class features into distinct subspaces. It then enforces dual constraints: feature orthogonal projection on both forgetting and remaining classes, while gradient orthogonal projection prevents the reintroduction of forgotten knowledge and disruption to remaining classes during updates. Additionally, dynamic subspace adaptation merges newly forgetting subspaces and contracts remaining subspaces, ensuring a stable balance between removal and retention across sequential unlearning tasks. Extensive experiments demonstrate the effectiveness of our method.",
    "authors": [
      "Qian Feng",
      "JiaHang Tu",
      "Mintong Kang",
      "Hanbin Zhao",
      "Chao Zhang",
      "Hui Qian"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13578v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13578v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2601.13558v1",
    "title": "Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating apps Text Analysis",
    "summary": "Men who have sex with men (MSM) are at elevated risk for sexually transmitted infections and harmful drinking compared to heterosexual men. Text data collected from social media and dating applications may provide new opportunities for personalized public health interventions by enabling automatic identification of risk and protective behaviors. In this study, we evaluated whether text from social media and dating apps can be used to predict sexual risk behaviors, alcohol use, and pre-exposure prophylaxis (PrEP) uptake among MSM. With participant consent, we collected textual data and trained machine learning models using features derived from ChatGPT embeddings, BERT embeddings, LIWC, and a dictionary-based risk term approach. The models achieved strong performance in predicting monthly binge drinking and having more than five sexual partners, with F1 scores of 0.78, and moderate performance in predicting PrEP use and heavy drinking, with F1 scores of 0.64 and 0.63. These findings demonstrate that social media and dating app text data can provide valuable insights into risk and protective behaviors and highlight the potential of large language model-based methods to support scalable and personalized public health interventions for MSM.",
    "authors": [
      "Mehrab Beikzadeh",
      "Chenglin Hong",
      "Cory J Cascalheira",
      "Callisto Boka",
      "Majid Sarrafzadeh",
      "Ian W Holloway"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13558v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13558v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2601.13542v1",
    "title": "Refined Gradient-Based Temperature Optimization for the Replica-Exchange Monte-Carlo Method",
    "summary": "The replica-exchange Monte-Carlo (RXMC) method is a powerful Markov-chain Monte-Carlo algorithm for sampling from multi-modal distributions, which are challenging for conventional methods. The sampling efficiency of the RXMC method depends highly on the selection of the temperatures, and finding optimal temperatures remains a challenge. In this study, we propose a refined online temperature selection method by extending the gradient-based optimization framework proposed previously. Building upon the existing temperature update approach, we introduce a reparameterization technique to strictly enforce physical constraints, such as the monotonic ordering of inverse temperatures, which were not explicitly addressed in the original formulation. The proposed method defines the variance of acceptance rates between adjacent replicas as a loss function, estimates its gradient using differential information from the sampling process, and optimizes the temperatures via gradient descent. We demonstrate the effectiveness of our method through experiments on benchmark spin systems, including the two-dimensional ferromagnetic Ising model, the two-dimensional ferromagnetic XY model, and the three-dimensional Edwards-Anderson model. Our results show that the method successfully achieves uniform acceptance rates and reduces round-trip times across the temperature space. Furthermore, our proposed method offers a significant advantage over recently proposed policy gradient method that require careful hyperparameter tuning, while simultaneously preventing the constraint violations that destabilize optimization.",
    "authors": [
      "Tatsuya Miyata",
      "Shunta Arai",
      "Satoshi Takabe"
    ],
    "categories": [
      "physics.comp-ph",
      "cs.LG"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13542v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13542v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2601.13518v1",
    "title": "AgenticRed: Optimizing Agentic Systems for Automated Red-teaming",
    "summary": "While recent automated red-teaming methods show promise for systematically exposing model vulnerabilities, most existing approaches rely on human-specified workflows. This dependence on manually designed workflows suffers from human biases and makes exploring the broader design space expensive. We introduce AgenticRed, an automated pipeline that leverages LLMs' in-context learning to iteratively design and refine red-teaming systems without human intervention. Rather than optimizing attacker policies within predefined structures, AgenticRed treats red-teaming as a system design problem. Inspired by methods like Meta Agent Search, we develop a novel procedure for evolving agentic systems using evolutionary selection, and apply it to the problem of automatic red-teaming. Red-teaming systems designed by AgenticRed consistently outperform state-of-the-art approaches, achieving 96% attack success rate (ASR) on Llama-2-7B (36% improvement) and 98% on Llama-3-8B on HarmBench. Our approach exhibits strong transferability to proprietary models, achieving 100% ASR on GPT-3.5-Turbo and GPT-4o-mini, and 60% on Claude-Sonnet-3.5 (24% improvement). This work highlights automated system design as a powerful paradigm for AI safety evaluation that can keep pace with rapidly evolving models.",
    "authors": [
      "Jiayi Yuan",
      "Jonathan Nöther",
      "Natasha Jaques",
      "Goran Radanović"
    ],
    "categories": [
      "cs.AI",
      "cs.NE"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13518v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13518v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2601.13489v1",
    "title": "Bridging the Gap Between Estimated and True Regret Towards Reliable Regret Estimation in Deep Learning based Mechanism Design",
    "summary": "Recent advances, such as RegretNet, ALGnet, RegretFormer and CITransNet, use deep learning to approximate optimal multi item auctions by relaxing incentive compatibility (IC) and measuring its violation via ex post regret. However, the true accuracy of these regret estimates remains unclear. Computing exact regret is computationally intractable, and current models rely on gradient based optimizers whose outcomes depend heavily on hyperparameter choices. Through extensive experiments, we reveal that existing methods systematically underestimate actual regret (In some models, the true regret is several hundred times larger than the reported regret), leading to overstated claims of IC and revenue. To address this issue, we derive a lower bound on regret and introduce an efficient item wise regret approximation. Building on this, we propose a guided refinement procedure that substantially improves regret estimation accuracy while reducing computational cost. Our method provides a more reliable foundation for evaluating incentive compatibility in deep learning based auction mechanisms and highlights the need to reassess prior performance claims in this area.",
    "authors": [
      "Shuyuan You",
      "Zhiqiang Zhuang",
      "Kewen Wang",
      "Zhe Wang"
    ],
    "categories": [
      "cs.GT",
      "cs.LG",
      "econ.GN"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13489v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13489v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2601.13400v1",
    "title": "Deep Image Prior with L0 Gradient Regularizer for Image Smoothing",
    "summary": "Image smoothing is a fundamental image processing operation that preserves the underlying structure, such as strong edges and contours, and removes minor details and textures in an image. Many image smoothing algorithms rely on computing local window statistics or solving an optimization problem. Recent state-of-the-art methods leverage deep learning, but they require a carefully curated training dataset. Because constructing a proper training dataset for image smoothing is challenging, we propose DIP-$\\ell_0$, a deep image prior framework that incorporates the $\\ell_0$ gradient regularizer. This framework can perform high-quality image smoothing without any training data. To properly minimize the associated loss function that has the nonconvex, nonsmooth $\\ell_0$ ``norm\", we develop an alternating direction method of multipliers algorithm that utilizes an off-the-shelf $\\ell_0$ gradient minimization solver. Numerical experiments demonstrate that the proposed DIP-$\\ell_0$ outperforms many image smoothing algorithms in edge-preserving image smoothing and JPEG artifact removal.",
    "authors": [
      "Nhat Thanh Tran",
      "Kevin Bui",
      "Jack Xin"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13400v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13400v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2601.13264v1",
    "title": "Unlearning in LLMs: Methods, Evaluation, and Open Challenges",
    "summary": "Large language models (LLMs) have achieved remarkable success across natural language processing tasks, yet their widespread deployment raises pressing concerns around privacy, copyright, security, and bias. Machine unlearning has emerged as a promising paradigm for selectively removing knowledge or data from trained models without full retraining. In this survey, we provide a structured overview of unlearning methods for LLMs, categorizing existing approaches into data-centric, parameter-centric, architecture-centric, hybrid, and other strategies. We also review the evaluation ecosystem, including benchmarks, metrics, and datasets designed to measure forgetting effectiveness, knowledge retention, and robustness. Finally, we outline key challenges and open problems, such as scalable efficiency, formal guarantees, cross-language and multimodal unlearning, and robustness against adversarial relearning. By synthesizing current progress and highlighting open directions, this paper aims to serve as a roadmap for developing reliable and responsible unlearning techniques in large language models.",
    "authors": [
      "Tyler Lizzo",
      "Larry Heck"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13264v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13264v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2601.13144v1",
    "title": "Forecasting Continuum Intensity for Solar Active Region Emergence Prediction using Transformers",
    "summary": "Early and accurate prediction of solar active region (AR) emergence is crucial for space weather forecasting. Building on established Long Short-Term Memory (LSTM) based approaches for forecasting the continuum intensity decrease associated with AR emergence, this work expands the modeling with new architectures and targets. We investigate a sliding-window Transformer architecture to forecast continuum intensity evolution up to 12 hours ahead using data from 46 ARs observed by SDO/HMI. We conduct a systematic ablation study to evaluate two key components: (1) the inclusion of a temporal 1D convolutional (Conv1D) front-end and (2) a novel `Early Detection' architecture featuring attention biases and a timing-aware loss function. Our best-performing model, combining the Early Detection architecture without the Conv1D layer, achieved a Root Mean Square Error (RMSE) of 0.1189 (representing a 10.6% improvement over the LSTM baseline) and an average advance warning time of 4.73 hours (timing difference of -4.73h), even under a stricter emergence criterion than previous studies. While the Transformer demonstrates superior aggregate timing and accuracy, we note that this high-sensitivity detection comes with increased variance compared to smoother baseline models. However, this volatility is a necessary trade-off for operational warning systems: the model's ability to detect micro-changes in precursor signals enables significantly earlier detection, outweighing the cost of increased noise. Our results demonstrate that Transformer architectures modified with early detection biases, when used without temporal smoothing layers, provide a high-sensitivity alternative for forecasting AR emergence that prioritizes advance warning over statistical smoothness.",
    "authors": [
      "Jonas Tirona",
      "Sarang Patil",
      "Spiridon Kasapis",
      "Eren Dogan",
      "John Stefan",
      "Irina N. Kitiashvili",
      "Alexander G. Kosovichev",
      "Mengjia Xu"
    ],
    "categories": [
      "astro-ph.SR",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13144v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13144v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2601.13044v1",
    "title": "Typhoon ASR Real-time: FastConformer-Transducer for Thai Automatic Speech Recognition",
    "summary": "Large encoder-decoder models like Whisper achieve strong offline transcription but remain impractical for streaming applications due to high latency. However, due to the accessibility of pre-trained checkpoints, the open Thai ASR landscape remains dominated by these offline architectures, leaving a critical gap in efficient streaming solutions. We present Typhoon ASR Real-time, a 115M-parameter FastConformer-Transducer model for low-latency Thai speech recognition. We demonstrate that rigorous text normalization can match the impact of model scaling: our compact model achieves a 45x reduction in computational cost compared to Whisper Large-v3 while delivering comparable accuracy. Our normalization pipeline resolves systemic ambiguities in Thai transcription --including context-dependent number verbalization and repetition markers (mai yamok) --creating consistent training targets. We further introduce a two-stage curriculum learning approach for Isan (north-eastern) dialect adaptation that preserves Central Thai performance. To address reproducibility challenges in Thai ASR, we release the Typhoon ASR Benchmark, a gold-standard human-labeled datasets with transcriptions following established Thai linguistic conventions, providing standardized evaluation protocols for the research community.",
    "authors": [
      "Warit Sirichotedumrong",
      "Adisai Na-Thalang",
      "Potsawee Manakul",
      "Pittawat Taveekitworachai",
      "Sittipong Sripaisarnmongkol",
      "Kunat Pipatanakul"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13044v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13044v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2601.12996v1",
    "title": "OFA-MAS: One-for-All Multi-Agent System Topology Design based on Mixture-of-Experts Graph Generative Models",
    "summary": "Multi-Agent Systems (MAS) offer a powerful paradigm for solving complex problems, yet their performance is critically dependent on the design of their underlying collaboration topology. As MAS become increasingly deployed in web services (e.g., search engines), designing adaptive topologies for diverse cross-domain user queries becomes essential. Current graph learning-based design methodologies often adhere to a \"one-for-one\" paradigm, where a specialized model is trained for each specific task domain. This approach suffers from poor generalization to unseen domains and fails to leverage shared structural knowledge across different tasks. To address this, we propose OFA-TAD, a one-for-all framework that generates adaptive collaboration graphs for any task described in natural language through a single universal model. Our approach integrates a Task-Aware Graph State Encoder (TAGSE) that filters task-relevant node information via sparse gating, and a Mixture-of-Experts (MoE) architecture that dynamically selects specialized sub-networks to drive node and edge prediction. We employ a three-stage training strategy: unconditional pre-training on canonical topologies for structural priors, large-scale conditional pre-training on LLM-generated datasets for task-topology mappings, and supervised fine-tuning on empirically validated graphs. Experiments across six diverse benchmarks show that OFA-TAD significantly outperforms specialized one-for-one models, generating highly adaptive MAS topologies. Code: https://github.com/Shiy-Li/OFA-MAS.",
    "authors": [
      "Shiyuan Li",
      "Yixin Liu",
      "Yu Zheng",
      "Mei Li",
      "Quoc Viet Hung Nguyen",
      "Shirui Pan"
    ],
    "categories": [
      "cs.MA",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.12996v1",
    "pdf_url": "https://arxiv.org/pdf/2601.12996v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2601.12981v1",
    "title": "Early Prediction of Type 2 Diabetes Using Multimodal data and Tabular Transformers",
    "summary": "This study introduces a novel approach for early Type 2 Diabetes Mellitus (T2DM) risk prediction using a tabular transformer (TabTrans) architecture to analyze longitudinal patient data. By processing patients` longitudinal health records and bone-related tabular data, our model captures complex, long-range dependencies in disease progression that conventional methods often overlook. We validated our TabTrans model on a retrospective Qatar BioBank (QBB) cohort of 1,382 subjects, comprising 725 men (146 diabetic, 579 healthy) and 657 women (133 diabetic, 524 healthy). The study integrated electronic health records (EHR) with dual-energy X-ray absorptiometry (DXA) data. To address class imbalance, we employed SMOTE and SMOTE-ENN resampling techniques. The proposed model`s performance is evaluated against conventional machine learning (ML) and generative AI models, including Claude 3.5 Sonnet (Anthropic`s constitutional AI), GPT-4 (OpenAI`s generative pre-trained transformer), and Gemini Pro (Google`s multimodal language model). Our TabTrans model demonstrated superior predictive performance, achieving ROC AUC $\\geq$ 79.7 % for T2DM prediction compared to both generative AI models and conventional ML approaches. Feature interpretation analysis identified key risk indicators, with visceral adipose tissue (VAT) mass and volume, ward bone mineral density (BMD) and bone mineral content (BMC), T and Z-scores, and L1-L4 scores emerging as the most important predictors associated with diabetes development in Qatari adults. These findings demonstrate the significant potential of TabTrans for analyzing complex tabular healthcare data, providing a powerful tool for proactive T2DM management and personalized clinical interventions in the Qatari population.   Index Terms: tabular transformers, multimodal data, DXA data, diabetes, T2DM, feature interpretation, tabular data",
    "authors": [
      "Sulaiman Khan",
      "Md. Rafiul Biswas",
      "Zubair Shah"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.12981v1",
    "pdf_url": "https://arxiv.org/pdf/2601.12981v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2601.13575v1",
    "title": "Comparing Without Saying: A Dataset and Benchmark for Implicit Comparative Opinion Mining from Same-User Reviews",
    "summary": "Existing studies on comparative opinion mining have mainly focused on explicit comparative expressions, which are uncommon in real-world reviews. This leaves implicit comparisons - here users express preferences across separate reviews - largely underexplored. We introduce SUDO, a novel dataset for implicit comparative opinion mining from same-user reviews, allowing reliable inference of user preferences even without explicit comparative cues. SUDO comprises 4,150 annotated review pairs (15,191 sentences) with a bi-level structure capturing aspect-level mentions and review-level preferences. We benchmark this task using two baseline architectures: traditional machine learning- and language model-based baselines. Experimental results show that while the latter outperforms the former, overall performance remains moderate, revealing the inherent difficulty of the task and establishing SUDO as a challenging and valuable benchmark for future research.",
    "authors": [
      "Thanh-Lam T. Nguyen",
      "Ngoc-Quang Le",
      "Quoc-Trung Phu",
      "Thi-Phuong Le",
      "Ngoc-Huyen Pham",
      "Phuong-Nguyen Nguyen",
      "Hoang-Quynh Le"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13575v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13575v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2601.13572v1",
    "title": "Behavior Knowledge Merge in Reinforced Agentic Models",
    "summary": "Reinforcement learning (RL) is central to post-training, particularly for agentic models that require specialized reasoning behaviors. In this setting, model merging offers a practical mechanism for integrating multiple RL-trained agents from different tasks into a single generalist model. However, existing merging methods are designed for supervised fine-tuning (SFT), and they are suboptimal to preserve task-specific capabilities on RL-trained agentic models. The root is a task-vector mismatch between RL and SFT: on-policy RL induces task vectors that are highly sparse and heterogeneous, whereas SFT-style merging implicitly assumes dense and globally comparable task vectors. When standard global averaging is applied under this mismatch, RL's non-overlapping task vectors that encode critical task-specific behaviors are reduced and parameter updates are diluted. To address this issue, we propose Reinforced Agent Merging (RAM), a distribution-aware merging framework explicitly designed for RL-trained agentic models. RAM disentangles shared and task-specific unique parameter updates, averaging shared components while selectively preserving and rescaling unique ones to counteract parameter update dilution. Experiments across multiple agent domains and model architectures demonstrate that RAM not only surpasses merging baselines, but also unlocks synergistic potential among agents to achieve performance superior to that of specialized agents in their domains.",
    "authors": [
      "Xiangchi Yuan",
      "Dachuan Shi",
      "Chunhui Zhang",
      "Zheyuan Liu",
      "Shenglong Yao",
      "Soroush Vosoughi",
      "Wenke Lee"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13572v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13572v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2601.13546v1",
    "title": "ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution",
    "summary": "LLM-driven Anomaly Detection (AD) helps enhance the understanding and explanatory abilities of anomalous behaviors in Time Series (TS). Existing methods face challenges of inadequate reasoning ability, deficient multi-turn dialogue capability, and narrow generalization. To this end, we 1) propose a multi-agent-based TS Evolution algorithm named TSEvol. On top of it, we 2) introduce the AD reasoning and multi-turn dialogue Dataset TSEData-20K and contribute the Chatbot family for AD, including ChatAD-Llama3-8B, Qwen2.5-7B, and Mistral-7B. Furthermore, 3) we propose the TS Kahneman-Tversky Optimization (TKTO) to enhance ChatAD's cross-task generalization capability. Lastly, 4) we propose a LLM-driven Learning-based AD Benchmark LLADBench to evaluate the performance of ChatAD and nine baselines across seven datasets and tasks. Our three ChatAD models achieve substantial gains, up to 34.50% in accuracy, 34.71% in F1, and a 37.42% reduction in false positives. Besides, via KTKO, our optimized ChatAD achieves competitive performance in reasoning and cross-task generalization on classification, forecasting, and imputation.",
    "authors": [
      "Hui Sun",
      "Chang Xu",
      "Haonan Xie",
      "Hao Li",
      "Yuhao Huang",
      "Chuheng Zhang",
      "Ming Jin",
      "Xiaoguang Liu",
      "Gang Wang",
      "Jiang Bian"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13546v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13546v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2601.13453v1",
    "title": "PhysicsSolutionAgent: Towards Multimodal Explanations for Numerical Physics Problem Solving",
    "summary": "Explaining numerical physics problems often requires more than text-based solutions; clear visual reasoning can substantially improve conceptual understanding. While large language models (LLMs) demonstrate strong performance on many physics questions in textual form, their ability to generate long, high-quality visual explanations remains insufficiently explored. In this work, we introduce PhysicsSolutionAgent (PSA), an autonomous agent that generates physics-problem explanation videos of up to six minutes using Manim animations. To evaluate the generated videos, we design an assessment pipeline that performs automated checks across 15 quantitative parameters and incorporates feedback from a vision-language model (VLM) to iteratively improve video quality. We evaluate PSA on 32 videos spanning numerical and theoretical physics problems. Our results reveal systematic differences in video quality depending on problem difficulty and whether the task is numerical or theoretical. Using GPT-5-mini, PSA achieves a 100% video-completion rate with an average automated score of 3.8/5. However, qualitative analysis and human inspection uncover both minor and major issues, including visual layout inconsistencies and errors in how visual content is interpreted during feedback. These findings expose key limitations in reliable Manim code generation and highlight broader challenges in multimodal reasoning and evaluation for visual explanations of numerical physics problems. Our work underscores the need for improved visual understanding, verification, and evaluation frameworks in future multimodal educational systems",
    "authors": [
      "Aditya Thole",
      "Anmol Agrawal",
      "Arnav Ramamoorthy",
      "Dhruv Kumar"
    ],
    "categories": [
      "cs.CL",
      "cs.HC"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13453v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13453v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2601.13502v1",
    "title": "DIS2: Disentanglement Meets Distillation with Classwise Attention for Robust Remote Sensing Segmentation under Missing Modalities",
    "summary": "The efficacy of multimodal learning in remote sensing (RS) is severely undermined by missing modalities. The challenge is exacerbated by the RS highly heterogeneous data and huge scale variation. Consequently, paradigms proven effective in other domains often fail when confronted with these unique data characteristics. Conventional disentanglement learning, which relies on significant feature overlap between modalities (modality-invariant), is insufficient for this heterogeneity. Similarly, knowledge distillation becomes an ill-posed mimicry task where a student fails to focus on the necessary compensatory knowledge, leaving the semantic gap unaddressed. Our work is therefore built upon three pillars uniquely designed for RS: (1) principled missing information compensation, (2) class-specific modality contribution, and (3) multi-resolution feature importance. We propose a novel method DIS2, a new paradigm shifting from modality-shared feature dependence and untargeted imitation to active, guided missing features compensation. Its core novelty lies in a reformulated synergy between disentanglement learning and knowledge distillation, termed DLKD. Compensatory features are explicitly captured which, when fused with the features of the available modality, approximate the ideal fused representation of the full-modality case. To address the class-specific challenge, our Classwise Feature Learning Module (CFLM) adaptively learn discriminative evidence for each target depending on signal availability. Both DLKD and CFLM are supported by a hierarchical hybrid fusion (HF) structure using features across resolutions to strengthen prediction. Extensive experiments validate that our proposed approach significantly outperforms state-of-the-art methods across benchmarks.",
    "authors": [
      "Nhi Kieu",
      "Kien Nguyen",
      "Arnold Wiliem",
      "Clinton Fookes",
      "Sridha Sridharan"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13502v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13502v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2601.13443v1",
    "title": "Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models",
    "summary": "The rapid adoption of large language models (LLMs) has enabled new forms of AI-assisted reasoning across scientific, technical, and organizational domains. However, prevailing modes of LLM use remain cognitively unstructured: problem framing, knowledge exploration, retrieval, methodological awareness, and explanation are typically collapsed into a single generative process. This cognitive collapse limits traceability, weakens epistemic control, and undermines reproducibility, particularly in high-responsibility settings.   We introduce Explicit Cognitive Allocation, a general principle for structuring AI-assisted inference through the explicit separation and orchestration of epistemic functions. We instantiate this principle in the Cognitive Universal Agent (CUA), an architecture that organizes inference into distinct stages of exploration and framing, epistemic anchoring, instrumental and methodological mapping, and interpretive synthesis. Central to this framework is the notion of Universal Cognitive Instruments (UCIs), which formalize heterogeneous means, including computational, experimental, organizational, regulatory, and educational instruments, through which abstract inquiries become investigable.   We evaluate the effects of explicit cognitive and instrumental allocation through controlled comparisons between CUA-orchestrated inference and baseline LLM inference under matched execution conditions. Across multiple prompts in the agricultural domain, CUA inference exhibits earlier and structurally governed epistemic convergence, higher epistemic alignment under semantic expansion, and systematic exposure of the instrumental landscape of inquiry. In contrast, baseline LLM inference shows greater variability in alignment and fails to explicitly surface instrumental structure.",
    "authors": [
      "Héctor Manuel Manzanilla-Granados",
      "Zaira Navarrete-Cazales",
      "Miriam Pescador-Rojas",
      "Tonahtiu Ramírez-Romero"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13443v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13443v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2601.13435v1",
    "title": "A Learnable Wavelet Transformer for Long-Short Equity Trading and Risk-Adjusted Return Optimization",
    "summary": "Learning profitable intraday trading policies from financial time series is challenging due to heavy noise, non-stationarity, and strong cross-sectional dependence among related assets. We propose \\emph{WaveLSFormer}, a learnable wavelet-based long-short Transformer that jointly performs multi-scale decomposition and return-oriented decision learning. Specifically, a learnable wavelet front-end generates low-/high-frequency components via an end-to-end trained filter bank, guided by spectral regularizers that encourage stable and well-separated frequency bands. To fuse multi-scale information, we introduce a low-guided high-frequency injection (LGHI) module that refines low-frequency representations with high-frequency cues while controlling training stability. The model outputs a portfolio of long/short positions that is rescaled to satisfy a fixed risk budget, and is optimized directly with a trading objective and risk-aware regularization. Extensive experiments on five years of hourly data across six industry groups, evaluated over ten random seeds, demonstrate that WaveLSFormer consistently outperforms MLP, LSTM and Transformer backbones, with and without fixed discrete wavelet front-ends. On average in all industries, WaveLSFormer achieves a cumulative overall strategy return of $0.607 \\pm 0.045$ and a Sharpe ratio of $2.157 \\pm 0.166$, substantially improving both profitability and risk-adjusted returns over the strongest baselines.",
    "authors": [
      "Shuozhe Li",
      "Du Cheng",
      "Leqi Liu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13435v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13435v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2601.13383v1",
    "title": "A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge",
    "summary": "The emergence of LLMs has catalyzed a paradigm shift in autonomous agent development, enabling systems capable of reasoning, planning, and executing complex multi-step tasks. However, existing agent frameworks often suffer from architectural rigidity, vendor lock-in, and prohibitive complexity that impedes rapid prototyping and deployment. This paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture. AgentForge introduces three key innovations: (1) a composable skill abstraction that enables fine-grained task decomposition with formally defined input-output contracts, (2) a unified LLM backend interface supporting seamless switching between cloud-based APIs and local inference engines, and (3) a declarative YAML-based configuration system that separates agent logic from implementation details. We formalize the skill composition mechanism as a directed acyclic graph (DAG) and prove its expressiveness for representing arbitrary sequential and parallel task workflows. Comprehensive experimental evaluation across four benchmark scenarios demonstrates that AgentForge achieves competitive task completion rates while reducing development time by 62% compared to LangChain and 78% compared to direct API integration. Latency measurements confirm sub-100ms orchestration overhead, rendering the framework suitable for real-time applications. The modular design facilitates extension: we demonstrate the integration of six built-in skills and provide comprehensive documentation for custom skill development. AgentForge addresses a critical gap in the LLM agent ecosystem by providing researchers and practitioners with a production-ready foundation for constructing, evaluating, and deploying autonomous agents without sacrificing flexibility or performance.",
    "authors": [
      "Akbar Anbar Jafari",
      "Cagri Ozcinar",
      "Gholamreza Anbarjafari"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13383v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13383v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2601.13288v1",
    "title": "A BERTology View of LLM Orchestrations: Token- and Layer-Selective Probes for Efficient Single-Pass Classification",
    "summary": "Production LLM systems often rely on separate models for safety and other classification-heavy steps, increasing latency, VRAM footprint, and operational complexity. We instead reuse computation already paid for by the serving LLM: we train lightweight probes on its hidden states and predict labels in the same forward pass used for generation. We frame classification as representation selection over the full token-layer hidden-state tensor, rather than committing to a fixed token or fixed layer (e.g., first-token logits or final-layer pooling). To implement this, we introduce a two-stage aggregator that (i) summarizes tokens within each layer and (ii) aggregates across layer summaries to form a single representation for classification. We instantiate this template with direct pooling, a 100K-parameter scoring-attention gate, and a downcast multi-head self-attention (MHA) probe with up to 35M trainable parameters. Across safety and sentiment benchmarks our probes improve over logit-only reuse (e.g., MULI) and are competitive with substantially larger task-specific baselines, while preserving near-serving latency and avoiding the VRAM and latency costs of a separate guard-model pipeline.",
    "authors": [
      "Gonzalo Ariel Meyoyan",
      "Luciano Del Corro"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13288v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13288v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2601.13284v1",
    "title": "Balancing Classification and Calibration Performance in Decision-Making LLMs via Calibration Aware Reinforcement Learning",
    "summary": "Large language models (LLMs) are increasingly deployed in decision-making tasks, where not only accuracy but also reliable confidence estimates are essential. Well-calibrated confidence enables downstream systems to decide when to trust a model and when to defer to fallback mechanisms. In this work, we conduct a systematic study of calibration in two widely used fine-tuning paradigms: supervised fine-tuning (SFT) and reinforcement learning with verifiable rewards (RLVR). We show that while RLVR improves task performance, it produces extremely overconfident models, whereas SFT yields substantially better calibration, even under distribution shift, though with smaller performance gains. Through targeted experiments, we diagnose RLVR's failure, showing that decision tokens act as extraction steps of the decision in reasoning traces and do not carry confidence information, which prevents reinforcement learning from surfacing calibrated alternatives. Based on this insight, we propose a calibration-aware reinforcement learning formulation that directly adjusts decision-token probabilities. Our method preserves RLVR's accuracy level while mitigating overconfidence, reducing ECE scores up to 9 points.",
    "authors": [
      "Duygu Nur Yaldiz",
      "Evangelia Spiliopoulou",
      "Zheng Qi",
      "Siddharth Varia",
      "Srikanth Doss",
      "Nikolaos Pappas"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13284v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13284v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2601.13253v1",
    "title": "A Hybrid Protocol for Large-Scale Semantic Dataset Generation in Low-Resource Languages: The Turkish Semantic Relations Corpus",
    "summary": "We present a hybrid methodology for generating large-scale semantic relationship datasets in low-resource languages, demonstrated through a comprehensive Turkish semantic relations corpus. Our approach integrates three phases: (1) FastText embeddings with Agglomerative Clustering to identify semantic clusters, (2) Gemini 2.5-Flash for automated semantic relationship classification, and (3) integration with curated dictionary sources. The resulting dataset comprises 843,000 unique Turkish semantic pairs across three relationship types (synonyms, antonyms, co-hyponyms) representing a 10x scale increase over existing resources at minimal cost ($65). We validate the dataset through two downstream tasks: an embedding model achieving 90% top-1 retrieval accuracy and a classification model attaining 90% F1-macro. Our scalable protocol addresses critical data scarcity in Turkish NLP and demonstrates applicability to other low-resource languages. We publicly release the dataset and models.",
    "authors": [
      "Ebubekir Tosun",
      "Mehmet Emin Buldur",
      "Özay Ezerceli",
      "Mahmoud ElHussieni"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13253v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13253v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2601.13236v1",
    "title": "Pixelwise Uncertainty Quantification of Accelerated MRI Reconstruction",
    "summary": "Parallel imaging techniques reduce magnetic resonance imaging (MRI) scan time but image quality degrades as the acceleration factor increases. In clinical practice, conservative acceleration factors are chosen because no mechanism exists to automatically assess the diagnostic quality of undersampled reconstructions. This work introduces a general framework for pixel-wise uncertainty quantification in parallel MRI reconstructions, enabling automatic identification of unreliable regions without access to any ground-truth reference image. Our method integrates conformal quantile regression with image reconstruction methods to estimate statistically rigorous pixel-wise uncertainty intervals. We trained and evaluated our model on Cartesian undersampled brain and knee data obtained from the fastMRI dataset using acceleration factors ranging from 2 to 10. An end-to-end Variational Network was used for image reconstruction. Quantitative experiments demonstrate strong agreement between predicted uncertainty maps and true reconstruction error. Using our method, the corresponding Pearson correlation coefficient was higher than 90% at acceleration levels at and above four-fold; whereas it dropped to less than 70% when the uncertainty was computed using a simpler a heuristic notion (magnitude of the residual). Qualitative examples further show the uncertainty maps based on quantile regression capture the magnitude and spatial distribution of reconstruction errors across acceleration factors, with regions of elevated uncertainty aligning with pathologies and artifacts. The proposed framework enables evaluation of reconstruction quality without access to fully-sampled ground-truth reference images. It represents a step toward adaptive MRI acquisition protocols that may be able to dynamically balance scan time and diagnostic reliability.",
    "authors": [
      "Ilias I. Giannakopoulos",
      "Lokesh B Gautham Muthukumar",
      "Yvonne W. Lui",
      "Riccardo Lattanzi"
    ],
    "categories": [
      "eess.IV",
      "cs.AI",
      "physics.med-ph"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13236v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13236v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2601.13132v1",
    "title": "GaussExplorer: 3D Gaussian Splatting for Embodied Exploration and Reasoning",
    "summary": "We present GaussExplorer, a framework for embodied exploration and reasoning built on 3D Gaussian Splatting (3DGS). While prior approaches to language-embedded 3DGS have made meaningful progress in aligning simple text queries with Gaussian embeddings, they are generally optimized for relatively simple queries and struggle to interpret more complex, compositional language queries. Alternative studies based on object-centric RGB-D structured memories provide spatial grounding but are constrained by pre-fixed viewpoints. To address these issues, GaussExplorer introduces Vision-Language Models (VLMs) on top of 3DGS to enable question-driven exploration and reasoning within 3D scenes. We first identify pre-captured images that are most correlated with the query question, and subsequently adjust them into novel viewpoints to more accurately capture visual information for better reasoning by VLMs. Experiments show that ours outperforms existing methods on several benchmarks, demonstrating the effectiveness of integrating VLM-based reasoning with 3DGS for embodied tasks.",
    "authors": [
      "Kim Yu-Ji",
      "Dahye Lee",
      "Kim Jun-Seong",
      "GeonU Kim",
      "Nam Hyeon-Woo",
      "Yongjin Kwon",
      "Yu-Chiang Frank Wang",
      "Jaesung Choe",
      "Tae-Hyun Oh"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13132v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13132v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2601.13128v1",
    "title": "PhaseMark: A Post-hoc, Optimization-Free Watermarking of AI-generated Images in the Latent Frequency Domain",
    "summary": "The proliferation of hyper-realistic images from Latent Diffusion Models (LDMs) demands robust watermarking, yet existing post-hoc methods are prohibitively slow due to iterative optimization or inversion processes. We introduce PhaseMark, a single-shot, optimization-free framework that directly modulates the phase in the VAE latent frequency domain. This approach makes PhaseMark thousands of times faster than optimization-based techniques while achieving state-of-the-art resilience against severe attacks, including regeneration, without degrading image quality. We analyze four modulation variants, revealing a clear performance-quality trade-off. PhaseMark demonstrates a new paradigm where efficient, resilient watermarking is achieved by exploiting intrinsic latent properties.",
    "authors": [
      "Sung Ju Lee",
      "Nam Ik Cho"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13128v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13128v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2601.13102v1",
    "title": "Approximate full conformal prediction in RKHS",
    "summary": "Full conformal prediction is a framework that implicitly formulates distribution-free confidence prediction regions for a wide range of estimators. However, a classical limitation of the full conformal framework is the computation of the confidence prediction regions, which is usually impossible since it requires training infinitely many estimators (for real-valued prediction for instance). The main purpose of the present work is to describe a generic strategy for designing a tight approximation to the full conformal prediction region that can be efficiently computed. Along with this approximate confidence region, a theoretical quantification of the tightness of this approximation is developed, depending on the smoothness assumptions on the loss and score functions. The new notion of thickness is introduced for quantifying the discrepancy between the approximate confidence region and the full conformal one.",
    "authors": [
      "Davidson Lova Razafindrakoto",
      "Alain Celisse",
      "Jérôme Lacaille"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13102v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13102v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2601.13020v1",
    "title": "PASs-MoE: Mitigating Misaligned Co-drift among Router and Experts via Pathway Activation Subspaces for Continual Learning",
    "summary": "Continual instruction tuning (CIT) requires multimodal large language models (MLLMs) to adapt to a stream of tasks without forgetting prior capabilities. A common strategy is to isolate updates by routing inputs to different LoRA experts. However, existing LoRA-based Mixture-of-Experts (MoE) methods often jointly update the router and experts in an indiscriminate way, causing the router's preferences to co-drift with experts' adaptation pathways and gradually deviate from early-stage input-expert specialization. We term this phenomenon Misaligned Co-drift, which blurs expert responsibilities and exacerbates forgetting.To address this, we introduce the pathway activation subspace (PASs), a LoRA-induced subspace that reflects which low-rank pathway directions an input activates in each expert, providing a capability-aligned coordinate system for routing and preservation. Based on PASs, we propose a fixed-capacity PASs-based MoE-LoRA method with two components: PAS-guided Reweighting, which calibrates routing using each expert's pathway activation signals, and PAS-aware Rank Stabilization, which selectively stabilizes rank directions important to previous tasks. Experiments on a CIT benchmark show that our approach consistently outperforms a range of conventional continual learning baselines and MoE-LoRA variants in both accuracy and anti-forgetting without adding parameters. Our code will be released upon acceptance.",
    "authors": [
      "Zhiyan Hou",
      "Haiyun Guo",
      "Haokai Ma",
      "Yandu Sun",
      "Yonghui Yang",
      "Jinqiao Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13020v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13020v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2601.13548v1",
    "title": "Patterning: The Dual of Interpretability",
    "summary": "Mechanistic interpretability aims to understand how neural networks generalize beyond their training data by reverse-engineering their internal structures. We introduce patterning as the dual problem: given a desired form of generalization, determine what training data produces it. Our approach is based on susceptibilities, which measure how posterior expectation values of observables respond to infinitesimal shifts in the data distribution. Inverting this linear response relationship yields the data intervention that steers the model toward a target internal configuration. We demonstrate patterning in a small language model, showing that re-weighting training data along principal susceptibility directions can accelerate or delay the formation of structure, such as the induction circuit. In a synthetic parentheses balancing task where multiple algorithms achieve perfect training accuracy, we show that patterning can select which algorithm the model learns by targeting the local learning coefficient of each solution. These results establish that the same mathematical framework used to read internal structure can be inverted to write it.",
    "authors": [
      "George Wang",
      "Daniel Murfet"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13548v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13548v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2601.13445v1",
    "title": "BladeSDF : Unconditional and Conditional Generative Modeling of Representative Blade Geometries Using Signed Distance Functions",
    "summary": "Generative AI has emerged as a transformative paradigm in engineering design, enabling automated synthesis and reconstruction of complex 3D geometries while preserving feasibility and performance relevance. This paper introduces a domain-specific implicit generative framework for turbine blade geometry using DeepSDF, addressing critical gaps in performance-aware modeling and manufacturable design generation. The proposed method leverages a continuous signed distance function (SDF) representation to reconstruct and generate smooth, watertight geometries with quantified accuracy. It establishes an interpretable, near-Gaussian latent space that aligns with blade-relevant parameters, such as taper and chord ratios, enabling controlled exploration and unconditional synthesis through interpolation and Gaussian sampling. In addition, a compact neural network maps engineering descriptors, such as maximum directional strains, to latent codes, facilitating the generation of performance-informed geometry. The framework achieves high reconstruction fidelity, with surface distance errors concentrated within $1\\%$ of the maximum blade dimension, and demonstrates robust generalization to unseen designs. By integrating constraints, objectives, and performance metrics, this approach advances beyond traditional 2D-guided or unconstrained 3D pipelines, offering a practical and interpretable solution for data-driven turbine blade modeling and concept generation.",
    "authors": [
      "Ashish S. Nair",
      "Sandipp Krishnan Ravi",
      "Itzel Salgado",
      "Changjie Sun",
      "Sayan Ghosh",
      "Liping Wang"
    ],
    "categories": [
      "cs.LG",
      "physics.comp-ph"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13445v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13445v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2601.13410v1",
    "title": "Classifiers in High Dimensional Hilbert Metrics",
    "summary": "Classifying points in high dimensional spaces is a fundamental geometric problem in machine learning. In this paper, we address classifying points in the $d$-dimensional Hilbert polygonal metric. The Hilbert metric is a generalization of the Cayley-Klein hyperbolic distance to arbitrary convex bodies and has a diverse range of applications in machine learning and convex geometry. We first present an efficient LP-based algorithm in the metric for the large-margin SVM problem. Our algorithm runs in time polynomial to the number of points, bounding facets, and dimension. This is a significant improvement on previous works, which either provide no theoretical guarantees on running time, or suffer from exponential runtime. We also consider the closely related Funk metric. We also present efficient algorithms for the soft-margin SVM problem and for nearest neighbor-based classification in the Hilbert metric.",
    "authors": [
      "Aditya Acharya",
      "Auguste H. Gezalyan",
      "David M. Mount"
    ],
    "categories": [
      "cs.CG",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13410v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13410v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2601.13386v1",
    "title": "Leveraging Transformer Decoder for Automotive Radar Object Detection",
    "summary": "In this paper, we present a Transformer-based architecture for 3D radar object detection that uses a novel Transformer Decoder as the prediction head to directly regress 3D bounding boxes and class scores from radar feature representations. To bridge multi-scale radar features and the decoder, we propose Pyramid Token Fusion (PTF), a lightweight module that converts a feature pyramid into a unified, scale-aware token sequence. By formulating detection as a set prediction problem with learnable object queries and positional encodings, our design models long-range spatial-temporal correlations and cross-feature interactions. This approach eliminates dense proposal generation and heuristic post-processing such as extensive non-maximum suppression (NMS) tuning. We evaluate the proposed framework on the RADDet, where it achieves significant improvements over state-of-the-art radar-only baselines.",
    "authors": [
      "Changxu Zhang",
      "Zhaoze Wang",
      "Tai Fei",
      "Christopher Grimm",
      "Yi Jin",
      "Claas Tebruegge",
      "Ernst Warsitz",
      "Markus Gardill"
    ],
    "categories": [
      "cs.CV",
      "eess.SP"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13386v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13386v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2601.13359v1",
    "title": "Sockpuppetting: Jailbreaking LLMs Without Optimization Through Output Prefix Injection",
    "summary": "As open-weight large language models (LLMs) increase in capabilities, safeguarding them against malicious prompts and understanding possible attack vectors becomes ever more important. While automated jailbreaking methods like GCG [Zou et al., 2023] remain effective, they often require substantial computational resources and specific expertise. We introduce \"sockpuppetting'', a simple method for jailbreaking open-weight LLMs by inserting an acceptance sequence (e.g., \"Sure, here is how to...'') at the start of a model's output and allowing it to complete the response. Requiring only a single line of code and no optimization, sockpuppetting achieves up to 80% higher attack success rate (ASR) than GCG on Qwen3-8B in per-prompt comparisons. We also explore a hybrid approach that optimizes the adversarial suffix within the assistant message block rather than the user prompt, increasing ASR by 64% over GCG on Llama-3.1-8B in a prompt-agnostic setting. The results establish sockpuppetting as an effective low-cost attack accessible to unsophisticated adversaries, highlighting the need for defences against output-prefix injection in open-weight models.",
    "authors": [
      "Asen Dotsinski",
      "Panagiotis Eustratiadis"
    ],
    "categories": [
      "cs.CL",
      "cs.CR",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13359v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13359v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2601.13357v1",
    "title": "On the Relation of State Space Models and Hidden Markov Models",
    "summary": "State Space Models (SSMs) and Hidden Markov Models (HMMs) are foundational frameworks for modeling sequential data with latent variables and are widely used in signal processing, control theory, and machine learning. Despite their shared temporal structure, they differ fundamentally in the nature of their latent states, probabilistic assumptions, inference procedures, and training paradigms. Recently, deterministic state space models have re-emerged in natural language processing through architectures such as S4 and Mamba, raising new questions about the relationship between classical probabilistic SSMs, HMMs, and modern neural sequence models.   In this paper, we present a unified and systematic comparison of HMMs, linear Gaussian state space models, Kalman filtering, and contemporary NLP state space models. We analyze their formulations through the lens of probabilistic graphical models, examine their inference algorithms -- including forward-backward inference and Kalman filtering -- and contrast their learning procedures via Expectation-Maximization and gradient-based optimization. By highlighting both structural similarities and semantic differences, we clarify when these models are equivalent, when they fundamentally diverge, and how modern NLP SSMs relate to classical probabilistic models. Our analysis bridges perspectives from control theory, probabilistic modeling, and modern deep learning.",
    "authors": [
      "Aydin Ghojogh",
      "M. Hadi Sepanj",
      "Benyamin Ghojogh"
    ],
    "categories": [
      "cs.LG",
      "cs.CL",
      "eess.AS",
      "eess.SY"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13357v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13357v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2601.13346v1",
    "title": "AfroScope: A Framework for Studying the Linguistic Landscape of Africa",
    "summary": "Language Identification (LID) is the task of determining the language of a given text and is a fundamental preprocessing step that affects the reliability of downstream NLP applications. While recent work has expanded LID coverage for African languages, existing approaches remain limited in (i) the number of supported languages and (ii) their ability to make fine-grained distinctions among closely related varieties. We introduce AfroScope, a unified framework for African LID that includes AfroScope-Data, a dataset covering 713 African languages, and AfroScope-Models, a suite of strong LID models with broad language coverage. To better distinguish highly confusable languages, we propose a hierarchical classification approach that leverages Mirror-Serengeti, a specialized embedding model targeting 29 closely related or geographically proximate languages. This approach improves macro F1 by 4.55 on this confusable subset compared to our best base model. Finally, we analyze cross linguistic transfer and domain effects, offering guidance for building robust African LID systems. We position African LID as an enabling technology for large scale measurement of Africas linguistic landscape in digital text and release AfroScope-Data and AfroScope-Models publicly.",
    "authors": [
      "Sang Yun Kwon",
      "AbdelRahim Elmadany",
      "Muhammad Abdul-Mageed"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13346v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13346v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2601.13186v1",
    "title": "Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching",
    "summary": "Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. Building on earlier work that introduced a four-metric Total Injection Vulnerability Score (TIVS), this paper extends the evaluation framework with semantic similarity-based caching and a fifth metric (Observability Score Ratio) to yield TIVS-O, investigating how defence effectiveness interacts with transparency in a HOPE-inspired Nested Learning architecture. The proposed system combines an agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 synthetically generated injection-focused prompts drawn from ten attack families, while a fourth agent performs comprehensive security analysis using five key performance indicators. In addition to traditional injection metrics, OSR quantifies the richness and clarity of security-relevant reasoning exposed by each agent, enabling an explicit analysis of trade-offs between strict mitigation and auditability. Experiments show that the system achieves secure responses with zero high-risk breaches, while semantic caching delivers substantial computational savings, achieving a 41.6% reduction in LLM calls and corresponding decreases in latency, energy consumption, and carbon emissions. Five TIVS-O configurations reveal optimal trade-offs between mitigation strictness and forensic transparency. These results indicate that observability-aware evaluation can reveal non-monotonic effects within multi-agent pipelines and that memory-augmented agents can jointly maximize security robustness, real-time performance, operational cost savings, and environmental sustainability without modifying underlying model weights, providing a production-ready pathway for secure and green LLM deployments.",
    "authors": [
      "Diego Gosmar",
      "Deborah A. Dahl"
    ],
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13186v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13186v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2601.12995v1",
    "title": "Graph Reasoning Paradigm: Structured and Symbolic Reasoning with Topology-Aware Reinforcement Learning for Large Language Models",
    "summary": "Long Chain-of-Thought (LCoT), achieved by Reinforcement Learning with Verifiable Rewards (RLVR), has proven effective in enhancing the reasoning capabilities of Large Language Models (LLMs). However, reasoning in current LLMs is primarily generated as plain text, where performing semantic evaluation on such unstructured data creates a computational bottleneck during training. Despite RLVR-based optimization, existing methods still suffer from coarse-grained supervision, reward hacking, high training costs, and poor generalization. To address these issues, we propose the Graph Reasoning Paradigm (GRP), which realizes structured and symbolic reasoning, implemented via graph-structured representations with step-level cognitive labels. Building upon GRP, we further design Process-Aware Stratified Clipping Group Relative Policy Optimization (PASC-GRPO), which leverages structured evaluation to replace semantic evaluation, achieves process-aware verification through graph-structured outcome rewards, and mitigates reward hacking via stratified clipping advantage estimation. Experiments demonstrate significant improvements across mathematical reasoning and code generation tasks. Data, models, and code will be released later.",
    "authors": [
      "Runxuan Liu",
      "Xianhao Ou",
      "Xinyan Ma",
      "Jiyuan Wang",
      "Jiafeng Liang",
      "Jiaqi Li",
      "Tao He",
      "Zheng Chu",
      "Rongchuan Mu",
      "Zekun Wang",
      "Baoxin Wang",
      "Dayong Wu",
      "Ming Liu",
      "Shijin Wang",
      "Guoping Hu",
      "Bing Qin"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.12995v1",
    "pdf_url": "https://arxiv.org/pdf/2601.12995v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2601.13565v1",
    "title": "Learning Fine-Grained Correspondence with Cross-Perspective Perception for Open-Vocabulary 6D Object Pose Estimation",
    "summary": "Open-vocabulary 6D object pose estimation empowers robots to manipulate arbitrary unseen objects guided solely by natural language. However, a critical limitation of existing approaches is their reliance on unconstrained global matching strategies. In open-world scenarios, trying to match anchor features against the entire query image space introduces excessive ambiguity, as target features are easily confused with background distractors. To resolve this, we propose Fine-grained Correspondence Pose Estimation (FiCoP), a framework that transitions from noise-prone global matching to spatially-constrained patch-level correspondence. Our core innovation lies in leveraging a patch-to-patch correlation matrix as a structural prior to narrowing the matching scope, effectively filtering out irrelevant clutter to prevent it from degrading pose estimation. Firstly, we introduce an object-centric disentanglement preprocessing to isolate the semantic target from environmental noise. Secondly, a Cross-Perspective Global Perception (CPGP) module is proposed to fuse dual-view features, establishing structural consensus through explicit context reasoning. Finally, we design a Patch Correlation Predictor (PCP) that generates a precise block-wise association map, acting as a spatial filter to enforce fine-grained, noise-resilient matching. Experiments on the REAL275 and Toyota-Light datasets demonstrate that FiCoP improves Average Recall by 8.0% and 6.1%, respectively, compared to the state-of-the-art method, highlighting its capability to deliver robust and generalized perception for robotic agents operating in complex, unconstrained open-world environments. The source code will be made publicly available at https://github.com/zjjqinyu/FiCoP.",
    "authors": [
      "Yu Qin",
      "Shimeng Fan",
      "Fan Yang",
      "Zixuan Xue",
      "Zijie Mai",
      "Wenrui Chen",
      "Kailun Yang",
      "Zhiyong Li"
    ],
    "categories": [
      "cs.CV",
      "cs.RO",
      "eess.IV"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13565v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13565v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2601.13559v1",
    "title": "AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent",
    "summary": "Lossless compression has made significant advancements in Genomics Data (GD) storage, sharing and management. Current learning-based methods are non-evolvable with problems of low-level compression modeling, limited adaptability, and user-unfriendly interface. To this end, we propose AgentGC, the first evolutionary Agent-based GD Compressor, consisting of 3 layers with multi-agent named Leader and Worker. Specifically, the 1) User layer provides a user-friendly interface via Leader combined with LLM; 2) Cognitive layer, driven by the Leader, integrates LLM to consider joint optimization of algorithm-dataset-system, addressing the issues of low-level modeling and limited adaptability; and 3) Compression layer, headed by Worker, performs compression & decompression via a automated multi-knowledge learning-based compression framework. On top of AgentGC, we design 3 modes to support diverse scenarios: CP for compression-ratio priority, TP for throughput priority, and BM for balanced mode. Compared with 14 baselines on 9 datasets, the average compression ratios gains are 16.66%, 16.11%, and 16.33%, the throughput gains are 4.73x, 9.23x, and 9.15x, respectively.",
    "authors": [
      "Sun Hui",
      "Ding Yanfeng",
      "Huidong Ma",
      "Chang Xu",
      "Keyan Jin",
      "Lizheng Zu",
      "Cheng Zhong",
      "xiaoguang Liu",
      "Gang Wang",
      "Wentong Cai"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13559v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13559v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2601.13522v1",
    "title": "StoTAM: Stochastic Alternating Minimization for Tucker-Structured Tensor Sensing",
    "summary": "Low-rank tensor sensing is a fundamental problem with broad applications in signal processing and machine learning. Among various tensor models, low-Tucker-rank tensors are particularly attractive for capturing multi-mode subspace structures in high-dimensional data. Existing recovery methods either operate on the full tensor variable with expensive tensor projections, or adopt factorized formulations that still rely on full-gradient computations, while most stochastic factorized approaches are restricted to tensor decomposition settings. In this work, we propose a stochastic alternating minimization algorithm that operates directly on the core tensor and factor matrices under a Tucker factorization. The proposed method avoids repeated tensor projections and enables efficient mini-batch updates on low-dimensional tensor factors. Numerical experiments on synthetic tensor sensing demonstrate that the proposed algorithm exhibits favorable convergence behavior in wall-clock time compared with representative stochastic tensor recovery baselines.",
    "authors": [
      "Shuang Li"
    ],
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13522v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13522v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2601.13371v1",
    "title": "Spherical Geometry Diffusion: Generating High-quality 3D Face Geometry via Sphere-anchored Representations",
    "summary": "A fundamental challenge in text-to-3D face generation is achieving high-quality geometry. The core difficulty lies in the arbitrary and intricate distribution of vertices in 3D space, making it challenging for existing models to establish clean connectivity and resulting in suboptimal geometry. To address this, our core insight is to simplify the underlying geometric structure by constraining the distribution onto a simple and regular manifold, a topological sphere. Building on this, we first propose the Spherical Geometry Representation, a novel face representation that anchors geometric signals to uniform spherical coordinates. This guarantees a regular point distribution, from which the mesh connectivity can be robustly reconstructed. Critically, this canonical sphere can be seamlessly unwrapped into a 2D map, creating a perfect synergy with powerful 2D generative models. We then introduce Spherical Geometry Diffusion, a conditional diffusion framework built upon this 2D map. It enables diverse and controllable generation by jointly modeling geometry and texture, where the geometry explicitly conditions the texture synthesis process. Our method's effectiveness is demonstrated through its success in a wide range of tasks: text-to-3D generation, face reconstruction, and text-based 3D editing. Extensive experiments show that our approach substantially outperforms existing methods in geometric quality, textual fidelity, and inference efficiency.",
    "authors": [
      "Junyi Zhang",
      "Yiming Wang",
      "Yunhong Lu",
      "Qichao Wang",
      "Wenzhe Qian",
      "Xiaoyin Xu",
      "David Gu",
      "Min Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13371v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13371v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2601.13365v1",
    "title": "CausationEntropy: Pythonic Optimal Causation Entropy",
    "summary": "Optimal Causation Entropy (oCSE) is a robust causal network modeling technique that reveals causal networks from dynamical systems and coupled oscillators, distinguishing direct from indirect paths. CausationEntropy is a Python package that implements oCSE and several of its significant optimizations and methodological extensions. In this paper, we introduce the version 1.1 release of CausationEntropy, which includes new synthetic data generators, plotting tools, and several advanced information-theoretical causal network discovery algorithms with criteria for estimating Gaussian, k-nearest neighbors (kNN), geometric k-nearest neighbors (geometric-kNN), kernel density (KDE) and Poisson entropic estimators. The package is easy to install from the PyPi software repository, is thoroughly documented, supplemented with extensive code examples, and is modularly structured to support future additions. The entire codebase is released under the MIT license and is available on GitHub and through PyPi Repository. We expect this package to serve as a benchmark tool for causal discovery in complex dynamical systems.",
    "authors": [
      "Kevin Slote",
      "Jeremie Fish",
      "Erik Bollt"
    ],
    "categories": [
      "cs.LG",
      "physics.data-an"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13365v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13365v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2601.13303v1",
    "title": "Verifying Local Robustness of Pruned Safety-Critical Networks",
    "summary": "Formal verification of Deep Neural Networks (DNNs) is essential for safety-critical applications, ranging from surgical robotics to NASA JPL autonomous systems. However, the computational cost of verifying large-scale models remains a significant barrier to adoption. This paper investigates the impact of pruning on formal local robustness certificates with different ratios. Using the state-of-the-art $α,β$-CROWN verifier, we evaluate ResNet4 models across varying pruning ratios on MNIST and, more importantly, on the NASA JPL Mars Frost Identification datasets. Our findings demonstrate a non-linear relationship: light pruning (40%) in MNIST and heavy pruning (70%-90%) in JPL improve verifiability, allowing models to outperform unpruned baselines in proven $L_\\infty$ robustness properties. This suggests that reduced connectivity simplifies the search space for formal solvers and that the optimal pruning ratio varies significantly between datasets. This research highlights the complex nature of model compression, offering critical insights into selecting the optimal pruning ratio for deploying efficient, yet formally verified, DNNs in high-stakes environments where reliability is non-negotiable.",
    "authors": [
      "Minh Le",
      "Phuong Cao"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13303v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13303v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2601.13300v1",
    "title": "OI-Bench: An Option Injection Benchmark for Evaluating LLM Susceptibility to Directive Interference",
    "summary": "Benchmarking large language models (LLMs) is critical for understanding their capabilities, limitations, and robustness. In addition to interface artifacts, prior studies have shown that LLM decisions can be influenced by directive signals such as social cues, framing, and instructions. In this work, we introduce option injection, a benchmarking approach that augments the multiple-choice question answering (MCQA) interface with an additional option containing a misleading directive, leveraging standardized choice structure and scalable evaluation. We construct OI-Bench, a benchmark of 3,000 questions spanning knowledge, reasoning, and commonsense tasks, with 16 directive types covering social compliance, bonus framing, threat framing, and instructional interference. This setting combines manipulation of the choice interface with directive-based interference, enabling systematic assessment of model susceptibility. We evaluate 12 LLMs to analyze attack success rates, behavioral responses, and further investigate mitigation strategies ranging from inference-time prompting to post-training alignment. Experimental results reveal substantial vulnerabilities and heterogeneous robustness across models. OI-Bench is expected to support more systematic evaluation of LLM robustness to directive interference within choice-based interfaces.",
    "authors": [
      "Yow-Fu Liou",
      "Yu-Chien Tang",
      "Yu-Hsiang Liu",
      "An-Zi Yen"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13300v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13300v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2601.13260v1",
    "title": "Stop Taking Tokenizers for Granted: They Are Core Design Decisions in Large Language Models",
    "summary": "Tokenization underlies every large language model, yet it remains an under-theorized and inconsistently designed component. Common subword approaches such as Byte Pair Encoding (BPE) offer scalability but often misalign with linguistic structure, amplify bias, and waste capacity across languages and domains. This paper reframes tokenization as a core modeling decision rather than a preprocessing step. We argue for a context-aware framework that integrates tokenizer and model co-design, guided by linguistic, domain, and deployment considerations. Standardized evaluation and transparent reporting are essential to make tokenization choices accountable and comparable. Treating tokenization as a core design problem, not a technical afterthought, can yield language technologies that are fairer, more efficient, and more adaptable.",
    "authors": [
      "Sawsan Alqahtani",
      "Mir Tafseer Nayeem",
      "Md Tahmid Rahman Laskar",
      "Tasnim Mohiuddin",
      "M Saiful Bari"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13260v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13260v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2601.13238v1",
    "title": "A Semantic Decoupling-Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision-Language Models",
    "summary": "Vision-Language Models (VLMs) are trained on image-text pairs collected under canonical visual conditions and achieve strong performance on multimodal tasks. However, their robustness to real-world weather conditions, and the stability of cross-modal semantic alignment under such structured perturbations, remain insufficiently studied. In this paper, we focus on rainy scenarios and introduce the first adversarial framework that exploits realistic weather to attack VLMs, using a two-stage, parameterized perturbation model based on semantic decoupling to analyze rain-induced shifts in decision-making. In Stage 1, we model the global effects of rainfall by applying a low-dimensional global modulation to condition the embedding space and gradually weaken the original semantic decision boundaries. In Stage 2, we introduce structured rain variations by explicitly modeling multi-scale raindrop appearance and rainfall-induced illumination changes, and optimize the resulting non-differentiable weather space to induce stable semantic shifts. Operating in a non-pixel parameter space, our framework generates perturbations that are both physically grounded and interpretable. Experiments across multiple tasks show that even physically plausible, highly constrained weather perturbations can induce substantial semantic misalignment in mainstream VLMs, posing potential safety and reliability risks in real-world deployment. Ablations further confirm that illumination modeling and multi-scale raindrop structures are key drivers of these semantic shifts.",
    "authors": [
      "Chengyin Hu",
      "Xiang Chen",
      "Zhe Jia",
      "Weiwen Shi",
      "Fengyu Zhang",
      "Jiujiang Guo",
      "Yiwei Wei"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13238v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13238v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2601.13235v1",
    "title": "RubRIX: Rubric-Driven Risk Mitigation in Caregiver-AI Interactions",
    "summary": "Caregivers seeking AI-mediated support express complex needs -- information-seeking, emotional validation, and distress cues -- that warrant careful evaluation of response safety and appropriateness. Existing AI evaluation frameworks, primarily focused on general risks (toxicity, hallucinations, policy violations, etc), may not adequately capture the nuanced risks of LLM-responses in caregiving-contexts. We introduce RubRIX (Rubric-based Risk Index), a theory-driven, clinician-validated framework for evaluating risks in LLM caregiving responses. Grounded in the Elements of an Ethic of Care, RubRIX operationalizes five empirically-derived risk dimensions: Inattention, Bias & Stigma, Information Inaccuracy, Uncritical Affirmation, and Epistemic Arrogance. We evaluate six state-of-the-art LLMs on over 20,000 caregiver queries from Reddit and ALZConnected. Rubric-guided refinement consistently reduced risk-components by 45-98% after one iteration across models. This work contributes a methodological approach for developing domain-sensitive, user-centered evaluation frameworks for high-burden contexts. Our findings highlight the importance of domain-sensitive, interactional risk evaluation for the responsible deployment of LLMs in caregiving support contexts. We release benchmark datasets to enable future research on contextual risk evaluation in AI-mediated support.",
    "authors": [
      "Drishti Goel",
      "Jeongah Lee",
      "Qiuyue Joy Zhong",
      "Violeta J. Rodriguez",
      "Daniel S. Brown",
      "Ravi Karkar",
      "Dong Whi Yoo",
      "Koustuv Saha"
    ],
    "categories": [
      "cs.HC",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.LG",
      "cs.SI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13235v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13235v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2601.13233v1",
    "title": "RAG: A Random-Forest-Based Generative Design Framework for Uncertainty-Aware Design of Metamaterials with Complex Functional Response Requirements",
    "summary": "Metamaterials design for advanced functionality often entails the inverse design on nonlinear and condition-dependent responses (e.g., stress-strain relation and dispersion relation), which are described by continuous functions. Most existing design methods focus on vector-valued responses (e.g., Young's modulus and bandgap width), while the inverse design of functional responses remains challenging due to their high-dimensionality, the complexity of accommodating design requirements in inverse-design frameworks, and non-existence or non-uniqueness of feasible solutions. Although generative design approaches have shown promise, they are often data-hungry, handle design requirements heuristically, and may generate infeasible designs without uncertainty quantification. To address these challenges, we introduce a RAndom-forest-based Generative approach (RAG). By leveraging the small-data compatibility of random forests, RAG enables data-efficient predictions of high-dimensional functional responses. During the inverse design, the framework estimates the likelihood through the ensemble which quantifies the trustworthiness of generated designs while reflecting the relative difficulty across different requirements. The one-to-many mapping is addressed through single-shot design generation by sampling from the conditional likelihood. We demonstrate RAG on: 1) acoustic metamaterials with prescribed partial passbands/stopbands, and 2) mechanical metamaterials with targeted snap-through responses, using 500 and 1057 samples, respectively. Its data-efficiency is benchmarked against neural networks on a public mechanical metamaterial dataset with nonlinear stress-strain relations. Our framework provides a lightweight, trustworthy pathway to inverse design involving functional responses, expensive simulations, and complex design requirements, beyond metamaterials.",
    "authors": [
      "Bolin Chen",
      "Dex Doksoo Lee",
      "Wei \"Wayne'' Chen",
      "Wei Chen"
    ],
    "categories": [
      "cs.AI",
      "cs.CE"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13233v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13233v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2601.13024v1",
    "title": "Tears or Cheers? Benchmarking LLMs via Culturally Elicited Distinct Affective Responses",
    "summary": "Culture serves as a fundamental determinant of human affective processing and profoundly shapes how individuals perceive and interpret emotional stimuli. Despite this intrinsic link extant evaluations regarding cultural alignment within Large Language Models primarily prioritize declarative knowledge such as geographical facts or established societal customs. These benchmarks remain insufficient to capture the subjective interpretative variance inherent to diverse sociocultural lenses. To address this limitation, we introduce CEDAR, a multimodal benchmark constructed entirely from scenarios capturing Culturally \\underline{\\textsc{E}}licited \\underline{\\textsc{D}}istinct \\underline{\\textsc{A}}ffective \\underline{\\textsc{R}}esponses. To construct CEDAR, we implement a novel pipeline that leverages LLM-generated provisional labels to isolate instances yielding cross-cultural emotional distinctions, and subsequently derives reliable ground-truth annotations through rigorous human evaluation. The resulting benchmark comprises 10,962 instances across seven languages and 14 fine-grained emotion categories, with each language including 400 multimodal and 1,166 text-only samples. Comprehensive evaluations of 17 representative multilingual models reveal a dissociation between language consistency and cultural alignment, demonstrating that culturally grounded affective understanding remains a significant challenge for current models.",
    "authors": [
      "Chongyuan Dai",
      "Yaling Shen",
      "Jinpeng Hu",
      "Zihan Gao",
      "Jia Li",
      "Yishun Jiang",
      "Yaxiong Wang",
      "Liu Liu",
      "Zongyuan Ge"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13024v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13024v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2601.13589v1",
    "title": "Motion-to-Response Content Generation via Multi-Agent AI System with Real-Time Safety Verification",
    "summary": "This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. Unlike conventional speech emotion recognition studies that focus primarily on classification accuracy, our approach emphasizes the transformation of inferred emotional states into safe, age-appropriate, and controllable response content through a structured pipeline of specialized AI agents. The proposed system comprises four cooperative agents: (1) an Emotion Recognition Agent with CNN-based acoustic feature extraction, (2) a Response Policy Decision Agent for mapping emotions to response modes, (3) a Content Parameter Generation Agent for producing media control parameters, and (4) a Safety Verification Agent enforcing age-appropriateness and stimulation constraints. We introduce an explicit safety verification loop that filters generated content before output, ensuring compliance with predefined rules. Experimental results on public datasets demonstrate that the system achieves 73.2% emotion recognition accuracy, 89.4% response mode consistency, and 100% safety compliance while maintaining sub-100ms inference latency suitable for on-device deployment. The modular architecture enables interpretability and extensibility, making it applicable to child-adjacent media, therapeutic applications, and emotionally responsive smart devices.",
    "authors": [
      "HyeYoung Lee"
    ],
    "categories": [
      "cs.AI",
      "cs.SD"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13589v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13589v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2601.13566v1",
    "title": "Self-Improvement as Coherence Optimization: A Theoretical Account",
    "summary": "Can language models improve their accuracy without external supervision? Methods such as debate, bootstrap, and internal coherence maximization achieve this surprising feat, even matching golden finetuning performance. Yet why they work remains theoretically unclear. We show that they are all special cases of coherence optimization: finding a context-to-behavior mapping that's most compressible and jointly predictable. We prove that coherence optimization is equivalent to description-length regularization, and that among all such regularization schemes, it is optimal for semi-supervised learning when the regularizer is derived from a pretrained model. Our theory, supported by preliminary experiments, explains why feedback-free self-improvement works and predicts when it should succeed or fail.",
    "authors": [
      "Tianyi Qiu",
      "Ahmed Hani Ismail",
      "Zhonghao He",
      "Shi Feng"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13566v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13566v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2601.13562v1",
    "title": "Reasoning is a Modality",
    "summary": "The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, largely operate as sequence-of-behavior prediction machines: they match observable behaviors by modeling token statistics without a persistent, readable mental state. This creates a gap with human-like behavior: humans can explain an action by decoding internal state, while AI systems can produce fluent post-hoc rationalizations that are not grounded in such a state. We hypothesize that reasoning is a modality: reasoning should exist as a distinct channel separate from the low-level workspace on which rules are applied. To test this hypothesis, on solving ARC tasks as a visual reasoning problem, we designed a novel role-separated transformer block that splits global controller tokens from grid workspace tokens, enabling iterative rule execution. Trained and evaluated within the VARC vision-centric protocol, our method achieved 62.6% accuracy on ARC-1, surpassing average human performance (60.2%) and outperforming prior methods significantly. Qualitatively, our models exhibit more coherent rule-application structure than the dense ViT baseline, consistent with a shift away from plausible probability blobs toward controller-driven reasoning.",
    "authors": [
      "Zhiguang Liu",
      "Yi Shang"
    ],
    "categories": [
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13562v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13562v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2601.13545v1",
    "title": "TruthTensor: Evaluating LLMs Human Imitation through Prediction Market Drift and Holistic Reasoning",
    "summary": "Evaluating language models and AI agents remains fundamentally challenging because static benchmarks fail to capture real-world uncertainty, distribution shift, and the gap between isolated task accuracy and human-aligned decision-making under evolving conditions. This paper introduces TruthTensor, a novel, reproducible evaluation paradigm that measures Large Language Models (LLMs) not only as prediction engines but as human-imitation systems operating in socially-grounded, high-entropy environments. Building on forward-looking, contamination-free tasks, our framework anchors evaluation to live prediction markets and combines probabilistic scoring to provide a holistic view of model behavior. TruthTensor complements traditional correctness metrics with drift-centric diagnostics and explicit robustness checks for reproducibility. It specify human vs. automated evaluation roles, annotation protocols, and statistical testing procedures to ensure interpretability and replicability of results. In experiments across 500+ real markets (political, economic, cultural, technological), TruthTensor demonstrates that models with similar forecast accuracy can diverge markedly in calibration, drift, and risk-sensitivity, underscoring the need to evaluate models along multiple axes (accuracy, calibration, narrative stability, cost, and resource efficiency). TruthTensor therefore operationalizes modern evaluation best practices, clear hypothesis framing, careful metric selection, transparent compute/cost reporting, human-in-the-loop validation, and open, versioned evaluation contracts, to produce defensible assessments of LLMs in real-world decision contexts. We publicly release TruthTensor at https://truthtensor.com",
    "authors": [
      "Shirin Shahabi",
      "Spencer Graham",
      "Haruna Isah"
    ],
    "categories": [
      "cs.AI",
      "cs.ET",
      "cs.MA"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13545v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13545v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2601.13388v1",
    "title": "Structured Insight from Unstructured Data: Large Language Models for SDOH-Driven Diabetes Risk Prediction",
    "summary": "Social determinants of health (SDOH) play a critical role in Type 2 Diabetes (T2D) management but are often absent from electronic health records and risk prediction models. Most individual-level SDOH data is collected through structured screening tools, which lack the flexibility to capture the complexity of patient experiences and unique needs of a clinic's population. This study explores the use of large language models (LLMs) to extract structured SDOH information from unstructured patient life stories and evaluate the predictive value of both the extracted features and the narratives themselves for assessing diabetes control. We collected unstructured interviews from 65 T2D patients aged 65 and older, focused on their lived experiences, social context, and diabetes management. These narratives were analyzed using LLMs with retrieval-augmented generation to produce concise, actionable qualitative summaries for clinical interpretation and structured quantitative SDOH ratings for risk prediction modeling. The structured SDOH ratings were used independently and in combination with traditional laboratory biomarkers as inputs to linear and tree-based machine learning models (Ridge, Lasso, Random Forest, and XGBoost) to demonstrate how unstructured narrative data can be applied in conventional risk prediction workflows. Finally, we evaluated several LLMs on their ability to predict a patient's level of diabetes control (low, medium, high) directly from interview text with A1C values redacted. LLMs achieved 60% accuracy in predicting diabetes control levels from interview text. This work demonstrates how LLMs can translate unstructured SDOH-related data into structured insights, offering a scalable approach to augment clinical risk models and decision-making.",
    "authors": [
      "Sasha Ronaghi",
      "Prerit Choudhary",
      "David H Rehkopf",
      "Bryant Lin"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13388v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13388v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2601.13256v1",
    "title": "Deep Neural networks for solving high-dimensional parabolic partial differential equations",
    "summary": "The numerical solution of high dimensional partial differential equations (PDEs) is severely constrained by the curse of dimensionality (CoD), rendering classical grid--based methods impractical beyond a few dimensions. In recent years, deep neural networks have emerged as a promising mesh free alternative, enabling the approximation of PDE solutions in tens to thousands of dimensions. This review provides a tutorial--oriented introduction to neural--network--based methods for solving high dimensional parabolic PDEs, emphasizing conceptual clarity and methodological connections. We organize the literature around three unifying paradigms: (i) PDE residual--based approaches, including physicsinformed neural networks and their high dimensional variants; (ii) stochastic methods derived from Feynman--Kac and backward stochastic differential equation formulations; and (iii) hybrid derivative--free random difference approaches designed to alleviate the computational cost of derivatives in high dimensions. For each paradigm, we outline the underlying mathematical formulation, algorithmic implementation, and practical strengths and limitations. Representative benchmark problems--including Hamilton--Jacobi--Bellman and Black--Scholes equations in up to 1000 dimensions --illustrate the scalability, effectiveness, and accuracy of the methods. The paper concludes with a discussion of open challenges and future directions for reliable and scalable solvers of high dimensional PDEs.",
    "authors": [
      "Wenzhong Zhang",
      "Zhenyuan Hu",
      "Wei Cai",
      "George EM Karniadakis"
    ],
    "categories": [
      "math.NA",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13256v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13256v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2601.13243v1",
    "title": "A Comprehensive Evaluation of LLM Reasoning: From Single-Model to Multi-Agent Paradigms",
    "summary": "Large Language Models (LLMs) are increasingly deployed as reasoning systems, where reasoning paradigms - such as Chain-of-Thought (CoT) and multi-agent systems (MAS) - play a critical role, yet their relative effectiveness and cost-accuracy trade-offs remain poorly understood. In this work, we conduct a comprehensive and unified evaluation of reasoning paradigms, spanning direct single-model generation, CoT-augmented single-model reasoning, and representative MAS workflows, characterizing their reasoning performance across a diverse suite of closed-form benchmarks. Beyond overall performance, we probe role-specific capability demands in MAS using targeted role isolation analyses, and analyze cost-accuracy trade-offs to identify which MAS workflows offer a favorable balance between cost and accuracy, and which incur prohibitive overhead for marginal gains. We further introduce MIMeBench, a new open-ended benchmark that targets two foundational yet underexplored semantic capabilities - semantic abstraction and contrastive discrimination - thereby providing an alternative evaluation axis beyond closed-form accuracy and enabling fine-grained assessment of semantic competence that is difficult to capture with existing benchmarks. Our results show that increased structural complexity does not consistently lead to improved reasoning performance, with its benefits being highly dependent on the properties and suitability of the reasoning paradigm itself. The codes are released at https://gitcode.com/HIT1920/OpenLLMBench.",
    "authors": [
      "Yapeng Li",
      "Jiakuo Yu",
      "Zhixin Liu",
      "Xinnan Liu",
      "Jing Yu",
      "Songze Li",
      "Tonghua Su"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13243v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13243v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2601.13166v1",
    "title": "From 100,000+ images to winning the first brain MRI foundation model challenges: Sharing lessons and models",
    "summary": "Developing Foundation Models for medical image analysis is essential to overcome the unique challenges of radiological tasks. The first challenges of this kind for 3D brain MRI, SSL3D and FOMO25, were held at MICCAI 2025. Our solution ranked first in tracks of both contests. It relies on a U-Net CNN architecture combined with strategies leveraging anatomical priors and neuroimaging domain knowledge. Notably, our models trained 1-2 orders of magnitude faster and were 10 times smaller than competing transformer-based approaches. Models are available here: https://github.com/jbanusco/BrainFM4Challenges.",
    "authors": [
      "Pedro M. Gordaliza",
      "Jaume Banus",
      "Benoît Gérin",
      "Maxence Wynen",
      "Nataliia Molchanova",
      "Jonas Richiardi",
      "Meritxell Bach Cuadra"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13166v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13166v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2601.13100v1",
    "title": "Recursive Meta-Distillation: An Axiomatic Framework for Iterative Knowledge Refinement",
    "summary": "Recent work in probability-domain knowledge distillation has established axiomatic frameworks for temperature scaling, multi-teacher aggregation, and bias-variance trade-offs in single-stage settings. However, the mathematical behavior of recursive or multi-generation distillation remains poorly understood, with prior approaches relying primarily on empirical heuristics. In this work, we introduce an axiomatic and operator-theoretic framework for recursive meta-distillation, formalizing iterative knowledge distillation as a sequence of probability-distribution operators with explicit anchoring to base teachers.   We define structural axioms for valid meta-teacher construction and prove the existence of non-trivial operator families satisfying these axioms without specifying particular algorithms or loss functions. Under mild realizability and convexity assumptions, we show that anchored recursive distillation induces contraction in KL divergence, yielding geometric convergence to base teacher distributions and a unique, globally attractive fixed point.   The contribution is foundational rather than algorithmic: the framework characterizes when recursive distillation is mathematically well-posed and convergent rather than error-accumulating, independent of model architecture, optimization details, or specific operator instantiations. These results provide a theoretical basis for understanding stability, bias-variance behavior, and failure modes in iterative and multi-teacher distillation under capacity constraints.",
    "authors": [
      "Aaron R. Flouro",
      "Shawn P. Chadwick"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13100v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13100v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2601.13079v1",
    "title": "Polychronous Wave Computing: Timing-Native Address Selection in Spiking Networks",
    "summary": "Spike timing offers a combinatorial address space, suggesting that timing-based spiking inference can be executed as lookup and routing rather than as dense multiply--accumulate. Yet most neuromorphic and photonic systems still digitize events into timestamps, bins, or rates and then perform selection in clocked logic. We introduce Polychronous Wave Computing (PWC), a timing-native address-selection primitive that maps relative spike latencies directly to a discrete output route in the wave domain. Spike times are phase-encoded in a rotating frame and processed by a programmable multiport interferometer that evaluates K template correlations in parallel; a driven--dissipative winner-take-all stage then performs a physical argmax, emitting a one-hot output port. We derive the operating envelope imposed by phase wrapping and mutual coherence, and collapse timing jitter, static phase mismatch, and dephasing into a single effective phase-noise budget whose induced winner--runner-up margin predicts boundary-first failures and provides an intensity-only calibration target. Simulations show that nonlinear competition improves routing fidelity compared with noisy linear intensity readout, and that hardware-in-the-loop phase tuning rescues a temporal-order gate from 55.9% to 97.2% accuracy under strong static mismatch. PWC provides a fast routing coprocessor for LUT-style spiking networks and sparse top-1 gates (e.g., mixture-of-experts routing) across polaritonic, photonic, and oscillator platforms.",
    "authors": [
      "Natalila G. Berloff"
    ],
    "categories": [
      "cond-mat.dis-nn",
      "cs.LG",
      "cs.NE",
      "physics.optics"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13079v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13079v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2601.13048v1",
    "title": "Analysis of Long Range Dependency Understanding in State Space Models",
    "summary": "Although state-space models (SSMs) have demonstrated strong performance on long-sequence benchmarks, most research has emphasized predictive accuracy rather than interpretability. In this work, we present the first systematic kernel interpretability study of the diagonalized state-space model (S4D) trained on a real-world task (vulnerability detection in source code). Through time and frequency domain analysis of the S4D kernel, we show that the long-range modeling capability of S4D varies significantly under different model architectures, affecting model performance. For instance, we show that the depending on the architecture, S4D kernel can behave as low-pass, band-pass or high-pass filter. The insights from our analysis can guide future work in designing better S4D-based models.",
    "authors": [
      "Srividya Ravikumar",
      "Abhinav Anand",
      "Shweta Verma",
      "Mira Mezini"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13048v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13048v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2601.13563v1",
    "title": "ButterflyMoE: Sub-Linear Ternary Experts via Structured Butterfly Orbits",
    "summary": "Linear memory scaling stores $N$ independent expert weight matrices requiring $\\mathcal{O}(N \\cdot d^2)$ memory, which exceeds edge devices memory budget. Current compression methods like quantization, pruning and low-rank factorization reduce constant factors but leave the scaling bottleneck unresolved. We introduce ButterflyMoE, a method that treats experts not as independent weight matrices but as geometric reorientations of a unified shared quantized substrate. Diversity among experts arises from viewing different angles of shared capacity, not from redundant storage. By applying learned rotations to a shared ternary prototype, each expert yields $\\mathcal{O}(d^2 + N \\cdot d \\log d)$ memory -- sub-linear in the number of experts. The key insight: training these rotations with quantization reduces activation outliers and stabilizes extreme low bit training, where static methods collapse. Across language modeling benchmarks, ButterflyMoE achieves 150 times memory reduction at 256 experts with negligible accuracy loss. This allows 64 experts to fit on 4GB devices compared to standard MoE's 8 experts, showing geometric parametrization breaks linear scaling.",
    "authors": [
      "Aryan Karmore"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13563v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13563v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2601.13465v1",
    "title": "Graph Neural Networks are Heuristics",
    "summary": "We demonstrate that a single training trajectory can transform a graph neural network into an unsupervised heuristic for combinatorial optimization. Focusing on the Travelling Salesman Problem, we show that encoding global structural constraints as an inductive bias enables a non-autoregressive model to generate solutions via direct forward passes, without search, supervision, or sequential decision-making. At inference time, dropout and snapshot ensembling allow a single model to act as an implicit ensemble, reducing optimality gaps through increased solution diversity. Our results establish that graph neural networks do not require supervised training nor explicit search to be effective. Instead, they can internalize global combinatorial structure and function as strong, learned heuristics. This reframes the role of learning in combinatorial optimization: from augmenting classical algorithms to directly instantiating new heuristics.",
    "authors": [
      "Yimeng Min",
      "Carla P. Gomes"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13465v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13465v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2601.13464v1",
    "title": "Context and Transcripts Improve Detection of Deepfake Audios of Public Figures",
    "summary": "Humans use context to assess the veracity of information. However, current audio deepfake detectors only analyze the audio file without considering either context or transcripts. We create and analyze a Journalist-provided Deepfake Dataset (JDD) of 255 public deepfakes which were primarily contributed by over 70 journalists since early 2024. We also generate a synthetic audio dataset (SYN) of dead public figures and propose a novel Context-based Audio Deepfake Detector (CADD) architecture. In addition, we evaluate performance on two large-scale datasets: ITW and P$^2$V. We show that sufficient context and/or the transcript can significantly improve the efficacy of audio deepfake detectors. Performance (measured via F1 score, AUC, and EER) of multiple baseline audio deepfake detectors and traditional classifiers can be improved by 5%-37.58% in F1-score, 3.77%-42.79% in AUC, and 6.17%-47.83% in EER. We additionally show that CADD, via its use of context and/or transcripts, is more robust to 5 adversarial evasion strategies, limiting performance degradation to an average of just -0.71% across all experiments. Code, models, and datasets are available at our project page: https://sites.northwestern.edu/nsail/cadd-context-based-audio-deepfake-detection (access restricted during review).",
    "authors": [
      "Chongyang Gao",
      "Marco Postiglione",
      "Julian Baldwin",
      "Natalia Denisenko",
      "Isabel Gortner",
      "Luke Fosdick",
      "Chiara Pulice",
      "Sarit Kraus",
      "V. S. Subrahmanian"
    ],
    "categories": [
      "cs.AI",
      "cs.SD"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13464v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13464v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2601.13358v1",
    "title": "The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models",
    "summary": "Scale does not uniformly improve reasoning - it restructures it. Analyzing 25,000+ chain-of-thought trajectories across four domains (Law, Science, Code, Math) and two scales (8B, 70B parameters), we discover that neural scaling laws trigger domain-specific phase transitions rather than uniform capability gains. Legal reasoning undergoes Crystallization: 45% collapse in representational dimensionality (d95: 501 -> 274), 31% increase in trajectory alignment, and 10x manifold untangling. Scientific and mathematical reasoning remain Liquid - geometrically invariant despite 9x parameter increase. Code reasoning forms a discrete Lattice of strategic modes (silhouette: 0.13 -> 0.42). This geometry predicts learnability. We introduce Neural Reasoning Operators - learned mappings from initial to terminal hidden states. In crystalline legal reasoning, our operator achieves 63.6% accuracy on held-out tasks via probe decoding, predicting reasoning endpoints without traversing intermediate states. We further identify a universal oscillatory signature (coherence ~ -0.4) invariant across domains and scales, suggesting attention and feedforward layers drive reasoning through opposing dynamics. These findings establish that the cost of thought is determined not by task difficulty but by manifold geometry - offering a blueprint for inference acceleration where topology permits.",
    "authors": [
      "Samuel Cyrenius Anderson"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13358v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13358v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2601.13294v1",
    "title": "The Tag is the Signal: URL-Agnostic Credibility Scoring for Messages on Telegram",
    "summary": "Telegram has become one of the leading platforms for disseminating misinformational messages. However, many existing pipelines still classify each message's credibility based on the reputation of its associated domain names or its lexical features. Such methods work well on traditional long-form news articles published by well-known sources, but high-risk posts on Telegram are short and URL-sparse, leading to failures for link-based and standard TF-IDF models. To this end, we propose the TAG2CRED pipeline, a method designed for such short, convoluted messages. Our model will directly score each post based on the tags assigned to the text. We designed a concise label system that covers the dimensions of theme, claim type, call to action, and evidence. The fine-tuned large language model (LLM) assigns tags to messages and then maps these tags to calibrated risk scores in the [0,1] interval through L2-regularized logistic regression. We evaluated 87,936 Telegram messages associated with Media Bias/Fact Check (MBFC), using URL masking and domain disjoint splits. The results showed that the ROC-AUC of the TAG2CRED model reached 0.871, the macro-F1 value was 0.787, and the Brier score was 0.167, outperforming the baseline TF-IDF (macro-F1 value 0.737, Brier score 0.248); at the same time, the number of features used in this model is much smaller, and the generalization ability on infrequent domains is stronger. The performance of the stacked ensemble model (TF-IDF + TAG2CRED + SBERT) was further improved over the baseline SBERT. ROC-AUC reached 0.901, and the macro-F1 value was 0.813 (Brier score 0.114). This indicates that style labels and lexical features may capture different but complementary dimensions of information risk.",
    "authors": [
      "Yipeng Wang",
      "Huy Gia Han Vu",
      "Mohit Singhal"
    ],
    "categories": [
      "cs.SI",
      "cs.CY",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13294v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13294v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2601.13247v1",
    "title": "Aligning Agentic World Models via Knowledgeable Experience Learning",
    "summary": "Current Large Language Models (LLMs) exhibit a critical modal disconnect: they possess vast semantic knowledge but lack the procedural grounding to respect the immutable laws of the physical world. Consequently, while these agents implicitly function as world models, their simulations often suffer from physical hallucinations-generating plans that are logically sound but physically unexecutable. Existing alignment strategies predominantly rely on resource-intensive training or fine-tuning, which attempt to compress dynamic environmental rules into static model parameters. However, such parametric encapsulation is inherently rigid, struggling to adapt to the open-ended variability of physical dynamics without continuous, costly retraining. To bridge this gap, we introduce WorldMind, a framework that autonomously constructs a symbolic World Knowledge Repository by synthesizing environmental feedback. Specifically, it unifies Process Experience to enforce physical feasibility via prediction errors and Goal Experience to guide task optimality through successful trajectories. Experiments on EB-ALFRED and EB-Habitat demonstrate that WorldMind achieves superior performance compared to baselines with remarkable cross-model and cross-environment transferability.",
    "authors": [
      "Baochang Ren",
      "Yunzhi Yao",
      "Rui Sun",
      "Shuofei Qiao",
      "Ningyu Zhang",
      "Huajun Chen"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV",
      "cs.LG",
      "cs.MM"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13247v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13247v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2601.13190v1",
    "title": "LAViG-FLOW: Latent Autoregressive Video Generation for Fluid Flow Simulations",
    "summary": "Modeling and forecasting subsurface multiphase fluid flow fields underpin applications ranging from geological CO2 sequestration (GCS) operations to geothermal production. This is essential for ensuring both operational performance and long-term safety. While high fidelity multiphase simulators are widely used for this purpose, they become prohibitively expensive once many forward runs are required for inversion purposes and quantify uncertainty. To tackle this challenge we propose LAViG-FLOW, a latent autoregressive video generation diffusion framework that explicitly learns the coupled evolution of saturation and pressure fields. Each state variable is compressed by a dedicated 2D autoencoder, and a Video Diffusion Transformer (VDiT) models their coupled distribution across time. We first train the model on a given time horizon to learn their coupled relationship and then fine-tune it autoregressively so it can extrapolate beyond the observed time window. Evaluated on an open-source CO2 sequestration dataset, LAViG-FLOW generates saturation and pressure fields that stay consistent across time while running orders of magnitude faster than traditional numerical solvers.",
    "authors": [
      "Vittoria De Pellegrini",
      "Tariq Alkhalifah"
    ],
    "categories": [
      "cs.LG",
      "physics.flu-dyn"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13190v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13190v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2601.13126v1",
    "title": "A Streamlined Attention-Based Network for Descriptor Extraction",
    "summary": "We introduce SANDesc, a Streamlined Attention-Based Network for Descriptor extraction that aims to improve on existing architectures for keypoint description.   Our descriptor network learns to compute descriptors that improve matching without modifying the underlying keypoint detector. We employ a revised U-Net-like architecture enhanced with Convolutional Block Attention Modules and residual paths, enabling effective local representation while maintaining computational efficiency. We refer to the building blocks of our model as Residual U-Net Blocks with Attention. The model is trained using a modified triplet loss in combination with a curriculum learning-inspired hard negative mining strategy, which improves training stability.   Extensive experiments on HPatches, MegaDepth-1500, and the Image Matching Challenge 2021 show that training SANDesc on top of existing keypoint detectors leads to improved results on multiple matching tasks compared to the original keypoint descriptors. At the same time, SANDesc has a model complexity of just 2.4 million parameters.   As a further contribution, we introduce a new urban dataset featuring 4K images and pre-calibrated intrinsics, designed to evaluate feature extractors. On this benchmark, SANDesc achieves substantial performance gains over the existing descriptors while operating with limited computational resources.",
    "authors": [
      "Mattia D'Urso",
      "Emanuele Santellani",
      "Christian Sormann",
      "Mattia Rossi",
      "Andreas Kuhn",
      "Friedrich Fraundorfer"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13126v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13126v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2601.13122v1",
    "title": "Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward",
    "summary": "Modern general-purpose AI systems made using large language and vision models, are capable of performing a range of tasks like writing text articles, generating and debugging codes, querying databases, and translating from one language to another, which has made them quite popular across industries. However, there are risks like hallucinations, toxicity, and stereotypes in their output that make them untrustworthy. We review various risks and vulnerabilities of modern general-purpose AI along eight widely accepted responsible AI (RAI) principles (fairness, privacy, explainability, robustness, safety, truthfulness, governance, and sustainability) and compare how they are non-existent or less severe and easily mitigable in traditional task-specific counterparts. We argue that this is due to the non-deterministically high Degree of Freedom in output (DoFo) of general-purpose AI (unlike the deterministically constant or low DoFo of traditional task-specific AI systems), and there is a need to rethink our approach to RAI for general-purpose AI. Following this, we derive C2V2 (Control, Consistency, Value, Veracity) desiderata to meet the RAI requirements for future general-purpose AI systems, and discuss how recent efforts in AI alignment, retrieval-augmented generation, reasoning enhancements, etc. fare along one or more of the desiderata. We believe that the goal of developing responsible general-purpose AI can be achieved by formally modeling application- or domain-dependent RAI requirements along C2V2 dimensions, and taking a system design approach to suitably combine various techniques to meet the desiderata.",
    "authors": [
      "Gourab K Patro",
      "Himanshi Agrawal",
      "Himanshu Gharat",
      "Supriya Panigrahi",
      "Nim Sherpa",
      "Vishal Vaddina",
      "Dagnachew Birru"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13122v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13122v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2601.13097v1",
    "title": "RM -RF: Reward Model for Run-Free Unit Test Evaluation",
    "summary": "We present RM-RF, a lightweight reward model for run-free evaluation of automatically generated unit tests. Instead of repeatedly compiling and executing candidate tests, RM-RF predicts - from source and test code alone - three execution-derived signals: (1) whether the augmented test suite compiles and runs successfully, (2) whether the generated test cases increase code coverage, and (3) whether the generated test cases improve the mutation kill rate. To train and evaluate RM-RF we assemble a multilingual dataset (Java, Python, Go) of focal files, test files, and candidate test additions labeled by an execution-based pipeline, and we release an associated dataset and methodology for comparative evaluation. We tested multiple model families and tuning regimes (zero-shot, full fine-tuning, and PEFT via LoRA), achieving an average F1 of 0.69 across the three targets. Compared to conventional compile-and-run instruments, RM-RF provides substantially lower latency and infrastructure cost while delivering competitive predictive fidelity, enabling fast, scalable feedback for large-scale test generation and RL-based code optimization.",
    "authors": [
      "Elena Bruches",
      "Daniil Grebenkin",
      "Mikhail Klementev",
      "Vadim Alperovich",
      "Roman Derunets",
      "Dari Baturova",
      "Georgy Mkrtchyan",
      "Oleg Sedukhin",
      "Ivan Bondarenko",
      "Nikolay Bushkov",
      "Stanislav Moiseev"
    ],
    "categories": [
      "cs.SE",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13097v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13097v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2601.13082v1",
    "title": "Adversarial News and Lost Profits: Manipulating Headlines in LLM-Driven Algorithmic Trading",
    "summary": "Large Language Models (LLMs) are increasingly adopted in the financial domain. Their exceptional capabilities to analyse textual data make them well-suited for inferring the sentiment of finance-related news. Such feedback can be leveraged by algorithmic trading systems (ATS) to guide buy/sell decisions. However, this practice bears the risk that a threat actor may craft \"adversarial news\" intended to mislead an LLM. In particular, the news headline may include \"malicious\" content that remains invisible to human readers but which is still ingested by the LLM. Although prior work has studied textual adversarial examples, their system-wide impact on LLM-supported ATS has not yet been quantified in terms of monetary risk. To address this threat, we consider an adversary with no direct access to an ATS but able to alter stock-related news headlines on a single day. We evaluate two human-imperceptible manipulations in a financial context: Unicode homoglyph substitutions that misroute models during stock-name recognition, and hidden-text clauses that alter the sentiment of the news headline. We implement a realistic ATS in Backtrader that fuses an LSTM-based price forecast with LLM-derived sentiment (FinBERT, FinGPT, FinLLaMA, and six general-purpose LLMs), and quantify monetary impact using portfolio metrics. Experiments on real-world data show that manipulating a one-day attack over 14 months can reliably mislead LLMs and reduce annual returns by up to 17.7 percentage points. To assess real-world feasibility, we analyze popular scraping libraries and trading platforms and survey 27 FinTech practitioners, confirming our hypotheses. We notified trading platform owners of this security issue.",
    "authors": [
      "Advije Rizvani",
      "Giovanni Apruzzese",
      "Pavel Laskov"
    ],
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13082v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13082v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2601.13581v1",
    "title": "SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System",
    "summary": "Social engineering scams increasingly employ personalized, multi-turn deception, exposing the limits of traditional detection methods. While Large Language Models (LLMs) show promise in identifying deception, their cognitive assistance potential remains underexplored. We propose ScriptMind, an integrated framework for LLM-based scam detection that bridges automated reasoning and human cognition. It comprises three components: the Crime Script Inference Task (CSIT) for scam reasoning, the Crime Script-Aware Inference Dataset (CSID) for fine-tuning small LLMs, and the Cognitive Simulation-based Evaluation of Social Engineering Defense (CSED) for assessing real-time cognitive impact. Using 571 Korean phone scam cases, we built 22,712 structured scammer-sequence training instances. Experimental results show that the 11B small LLM fine-tuned with ScriptMind outperformed GPT-4o by 13%, achieving superior performance over commercial models in detection accuracy, false-positive reduction, scammer utterance prediction, and rationale quality. Moreover, in phone scam simulation experiments, it significantly enhanced and sustained users' suspicion levels, improving their cognitive awareness of scams. ScriptMind represents a step toward human-centered, cognitively adaptive LLMs for scam defense.",
    "authors": [
      "Heedou Kim",
      "Changsik Kim",
      "Sanghwa Shin",
      "Jaewoo Kang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13581v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13581v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2601.13569v1",
    "title": "DRGW: Learning Disentangled Representations for Robust Graph Watermarking",
    "summary": "Graph-structured data is foundational to numerous web applications, and watermarking is crucial for protecting their intellectual property and ensuring data provenance. Existing watermarking methods primarily operate on graph structures or entangled graph representations, which compromise the transparency and robustness of watermarks due to the information coupling in representing graphs and uncontrollable discretization in transforming continuous numerical representations into graph structures. This motivates us to propose DRGW, the first graph watermarking framework that addresses these issues through disentangled representation learning. Specifically, we design an adversarially trained encoder that learns an invariant structural representation against diverse perturbations and derives a statistically independent watermark carrier, ensuring both robustness and transparency of watermarks. Meanwhile, we devise a graph-aware invertible neural network to provide a lossless channel for watermark embedding and extraction, guaranteeing high detectability and transparency of watermarks. Additionally, we develop a structure-aware editor that resolves the issue of latent modifications into discrete graph edits, ensuring robustness against structural perturbations. Experiments on diverse benchmark datasets demonstrate the superior effectiveness of DRGW.",
    "authors": [
      "Jiasen Li",
      "Yanwei Liu",
      "Zhuoyi Shang",
      "Xiaoyan Gu",
      "Weiping Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.CR"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13569v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13569v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2601.13508v1",
    "title": "CatMaster: An Agentic Autonomous System for Computational Heterogeneous Catalysis Research",
    "summary": "Density functional theory (DFT) is widely used to connect atomic structure with catalytic behavior, but computational heterogeneous catalysis studies often require long workflows that are costly, iterative, and sensitive to setup choices. Besides the intrinsic cost and accuracy limits of first-principles calculations, practical workflow issues such as keeping references consistent, preparing many related inputs, recovering from failed runs on computing clusters, and maintaining a complete record of what was done, can slow down projects and make results difficult to reproduce or extend.   Here we present CatMaster, a large-language-model (LLM)-driven agent system that turns natural language requests into complete calculation workspaces, including structures, inputs, outputs, logs, and a concise run record. CatMaster maintains a persistent project record of key facts, constraints, and file pointers to support inspection and restartability. It is paired with a multi-fidelity tool library that covers rapid surrogate relaxations and high-fidelity DFT calculations for validation when needed. We demonstrate CatMaster on four demonstrations of increasing complexity: an O2 spin-state check with remote execution, BCC Fe surface energies with a protocol-sensitivity study and CO adsorption site ranking, high-throughput Pt--Ni--Cu alloy screening for hydrogen evolution reaction (HER) descriptors with surrogate-to-DFT validation, and a demonstration beyond the predefined tool set, including equation-of-state fitting for BCC Fe and CO-FeN4-graphene single-atom catalyst geometry preparation. By reducing manual scripting and bookkeeping while keeping the full evidence trail, CatMaster aims to help catalysis researchers focus on modeling choices and chemical interpretation rather than workflow management.",
    "authors": [
      "Honghao Chen",
      "Jiangjie Qiu",
      "Yi Shen Tew",
      "Xiaonan Wang"
    ],
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.AI"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13508v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13508v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2601.13487v1",
    "title": "The Hidden Toll of Social Media News: Causal Effects on Psychosocial Wellbeing",
    "summary": "News consumption on social media has become ubiquitous, yet how different forms of engagement shape psychosocial outcomes remains unclear. To address this gap, we leveraged a large-scale dataset of ~26M posts and ~45M comments on the BlueSky platform, and conducted a quasi-experimental study, matching 81,345 Treated users exposed to News feeds with 83,711 Control users using stratified propensity score analysis. We examined psychosocial wellbeing, in terms of affective, behavioral, and cognitive outcomes. Our findings reveal that news engagement produces systematic trade-offs: increased depression, stress, and anxiety, yet decreased loneliness and increased social interaction on the platform. Regression models reveal that News feed bookmarking is associated with greater psychosocial deterioration compared to commenting or quoting, with magnitude differences exceeding tenfold. These per-engagement effects accumulate with repeated exposure, showing significant psychosocial impacts. Our work extends theories of news effects beyond crisis-centric frameworks by demonstrating that routine consumption creates distinct psychological dynamics depending on engagement type, and bears implications for tools and interventions for mitigating the psychosocial costs of news consumption on social media.",
    "authors": [
      "Olivia Pal",
      "Agam Goyal",
      "Eshwar Chandrasekharan",
      "Koustuv Saha"
    ],
    "categories": [
      "cs.SI",
      "cs.AI",
      "cs.CL",
      "cs.CY",
      "cs.HC"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13487v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13487v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2601.13463v1",
    "title": "Quantum Qualifiers for Neural Network Model Selection in Hadronic Physics",
    "summary": "As quantum machine-learning architectures mature, a central challenge is no longer their construction, but identifying the regimes in which they offer practical advantages over classical approaches. In this work, we introduce a framework for addressing this question in data-driven hadronic physics problems by developing diagnostic tools - centered on a quantitative quantum qualifier - that guide model selection between classical and quantum deep neural networks based on intrinsic properties of the data. Using controlled classification and regression studies, we show how relative model performance follows systematic trends in complexity, noise, and dimensionality, and how these trends can be distilled into a predictive criterion. We then demonstrate the utility of this approach through an application to Compton form factor extraction from deeply virtual Compton scattering, where the quantum qualifier identifies kinematic regimes favorable to quantum models. Together, these results establish a principled framework for deploying quantum machine-learning tools in precision hadronic physics.",
    "authors": [
      "Brandon B. Le",
      "D. Keller"
    ],
    "categories": [
      "cs.LG",
      "hep-ph",
      "nucl-th",
      "quant-ph"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13463v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13463v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2601.13387v1",
    "title": "Confidence over Time: Confidence Calibration with Temporal Logic for Large Language Model Reasoning",
    "summary": "Large Language Models (LLMs) increasingly rely on long-form, multi-step reasoning to solve complex tasks such as mathematical problem solving and scientific question answering. Despite strong performance, existing confidence estimation methods typically reduce an entire reasoning process to a single scalar score, ignoring how confidence evolves throughout the generation. As a result, these methods are often sensitive to superficial factors such as response length or verbosity, and struggle to distinguish correct reasoning from confidently stated errors. We propose to characterize the stepwise confidence signal using Signal Temporal Logic (STL). Using a discriminative STL mining procedure, we discover temporal formulas that distinguish confidence signals of correct and incorrect responses. Our analysis found that the STL patterns generalize across tasks, and numeric parameters exhibit sensitivity to individual questions. Based on these insights, we develop a confidence estimation approach that informs STL blocks with parameter hypernetworks. Experiments on multiple reasoning tasks show our confidence scores are more calibrated than the baselines.",
    "authors": [
      "Zhenjiang Mao",
      "Anirudhh Venkat",
      "Artem Bisliouk",
      "Akshat Kothiyal",
      "Sindhura Kumbakonam Subramanian",
      "Saithej Singhu",
      "Ivan Ruchkin"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13387v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13387v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2601.13244v1",
    "title": "Do Instruction-Tuned Models Always Perform Better Than Base Models? Evidence from Math and Domain-Shifted Benchmarks",
    "summary": "Instruction finetuning is standard practice for improving LLM performance, yet it remains unclear whether it enhances reasoning or merely induces surface-level pattern matching. We investigate this by evaluating base and instruction-tuned models on standard math benchmarks, structurally perturbed variants, and domain-shifted tasks. Our analysis highlights two key (often overlooked) limitations of instruction tuning. First, the performance advantage is unstable and depends heavily on evaluation settings. In zero-shot CoT settings on GSM8K, base models consistently outperform instruction-tuned variants, with drops as high as 32.67\\% (Llama3-70B). Instruction-tuned models only match or exceed this performance when provided with few-shot exemplars, suggesting a reliance on specific prompting patterns rather than intrinsic reasoning. Second, tuning gains are brittle under distribution shift. Our results show that base models surpass instruction-tuned variants on the domain-specific MedCalc benchmark. Additionally, instruction-tuned models show sharp declines on perturbed datasets, indicating sensitivity to prompt structure over robust reasoning.",
    "authors": [
      "Prateek Munjal",
      "Clement Christophe",
      "Ronnie Rajan",
      "Praveenkumar Kanithi"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13244v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13244v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2601.13183v1",
    "title": "OpenExempt: A Diagnostic Benchmark for Legal Reasoning and a Framework for Creating Custom Benchmarks on Demand",
    "summary": "Reasoning benchmarks have played a crucial role in the progress of language models. Yet rigorous evaluation remains a significant challenge as static question-answer pairs provide only a snapshot of performance, compressing complex behavior into a single accuracy metric. This limitation is especially true in complex, rule-bound domains such as law, where existing benchmarks are costly to build and ill suited for isolating specific failure modes. To address this, we introduce OpenExempt, a framework and benchmark for diagnostic evaluation of legal reasoning. The OpenExempt Framework uses expert-crafted symbolic representations of U.S. Bankruptcy Code statutes to dynamically generate a large space of natural language reasoning tasks and their machine-computable solutions on demand. This gives users fine-grained control over task complexity and scope, allowing individual reasoning skills to be probed in isolation. Using this system, we construct the OpenExempt Benchmark, a diagnostic benchmark for legal reasoning with 9,765 samples across nine evaluation suites designed to carefully probe model capabilities. Experiments on 13 diverse language models reveal sharp performance cliffs that emerge only under longer reasoning paths and in the presence of obfuscating statements. We release the framework and benchmark publicly to support research aimed at understanding and improving the next generation of reasoning systems.",
    "authors": [
      "Sergio Servantez",
      "Sarah B. Lawsky",
      "Rajiv Jain",
      "Daniel W. Linna",
      "Kristian Hammond"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13183v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13183v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2601.13133v1",
    "title": "CLIP-Guided Adaptable Self-Supervised Learning for Human-Centric Visual Tasks",
    "summary": "Human-centric visual analysis plays a pivotal role in diverse applications, including surveillance, healthcare, and human-computer interaction. With the emergence of large-scale unlabeled human image datasets, there is an increasing need for a general unsupervised pre-training model capable of supporting diverse human-centric downstream tasks. To achieve this goal, we propose CLASP (CLIP-guided Adaptable Self-suPervised learning), a novel framework designed for unsupervised pre-training in human-centric visual tasks. CLASP leverages the powerful vision-language model CLIP to generate both low-level (e.g., body parts) and high-level (e.g., attributes) semantic pseudo-labels. These multi-level semantic cues are then integrated into the learned visual representations, enriching their expressiveness and generalizability. Recognizing that different downstream tasks demand varying levels of semantic granularity, CLASP incorporates a Prompt-Controlled Mixture-of-Experts (MoE) module. MoE dynamically adapts feature extraction based on task-specific prompts, mitigating potential feature conflicts and enhancing transferability. Furthermore, CLASP employs a multi-task pre-training strategy, where part- and attribute-level pseudo-labels derived from CLIP guide the representation learning process. Extensive experiments across multiple benchmarks demonstrate that CLASP consistently outperforms existing unsupervised pre-training methods, advancing the field of human-centric visual analysis.",
    "authors": [
      "Mingshuang Luo",
      "Ruibing Hou",
      "Bo Chao",
      "Hong Chang",
      "Zimo Liu",
      "Yaowei Wang",
      "Shiguang Shan"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13133v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13133v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2601.13115v1",
    "title": "Agentic Conversational Search with Contextualized Reasoning via Reinforcement Learning",
    "summary": "Large Language Models (LLMs) have become a popular interface for human-AI interaction, supporting information seeking and task assistance through natural, multi-turn dialogue. To respond to users within multi-turn dialogues, the context-dependent user intent evolves across interactions, requiring contextual interpretation, query reformulation, and dynamic coordination between retrieval and generation. Existing studies usually follow static rewrite, retrieve, and generate pipelines, which optimize different procedures separately and overlook the mixed-initiative action optimization simultaneously. Although the recent developments in deep search agents demonstrate the effectiveness in jointly optimizing retrieval and generation via reasoning, these approaches focus on single-turn scenarios, which might lack the ability to handle multi-turn interactions. We introduce a conversational agent that interleaves search and reasoning across turns, enabling exploratory and adaptive behaviors learned through reinforcement learning (RL) training with tailored rewards towards evolving user goals. The experimental results across four widely used conversational benchmarks demonstrate the effectiveness of our methods by surpassing several existing strong baselines.",
    "authors": [
      "Fengran Mo",
      "Yifan Gao",
      "Sha Li",
      "Hansi Zeng",
      "Xin Liu",
      "Zhaoxuan Tan",
      "Xian Li",
      "Jianshu Chen",
      "Dakuo Wang",
      "Meng Jiang"
    ],
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13115v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13115v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2601.13105v1",
    "title": "Leveraging Lora Fine-Tuning and Knowledge Bases for Construction Identification",
    "summary": "This study investigates the automatic identification of the English ditransitive construction by integrating LoRA-based fine-tuning of a large language model with a Retrieval-Augmented Generation (RAG) framework.A binary classification task was conducted on annotated data from the British National Corpus. Results demonstrate that a LoRA-fine-tuned Qwen3-8B model significantly outperformed both a native Qwen3-MAX model and a theory-only RAG system. Detailed error analysis reveals that fine-tuning shifts the model's judgment from a surface-form pattern matching towards a more semantically grounded understanding based.",
    "authors": [
      "Liu Kaipeng",
      "Wu Ling"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13105v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13105v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2601.13524v1",
    "title": "GO-MLVTON: Garment Occlusion-Aware Multi-Layer Virtual Try-On with Diffusion Models",
    "summary": "Existing Image-based virtual try-on (VTON) methods primarily focus on single-layer or multi-garment VTON, neglecting multi-layer VTON (ML-VTON), which involves dressing multiple layers of garments onto the human body with realistic deformation and layering to generate visually plausible outcomes. The main challenge lies in accurately modeling occlusion relationships between inner and outer garments to reduce interference from redundant inner garment features. To address this, we propose GO-MLVTON, the first multi-layer VTON method, introducing the Garment Occlusion Learning module to learn occlusion relationships and the StableDiffusion-based Garment Morphing & Fitting module to deform and fit garments onto the human body, producing high-quality multi-layer try-on results. Additionally, we present the MLG dataset for this task and propose a new metric named Layered Appearance Coherence Difference (LACD) for evaluation. Extensive experiments demonstrate the state-of-the-art performance of GO-MLVTON. Project page: https://upyuyang.github.io/go-mlvton/.",
    "authors": [
      "Yang Yu",
      "Yunze Deng",
      "Yige Zhang",
      "Yanjie Xiao",
      "Youkun Ou",
      "Wenhao Hu",
      "Mingchao Li",
      "Bin Feng",
      "Wenyu Liu",
      "Dandan Zheng",
      "Jingdong Chen"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13524v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13524v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2601.13519v1",
    "title": "Small Gradient Norm Regret for Online Convex Optimization",
    "summary": "This paper introduces a new problem-dependent regret measure for online convex optimization with smooth losses. The notion, which we call the $G^\\star$ regret, depends on the cumulative squared gradient norm evaluated at the decision in hindsight $\\sum_{t=1}^T \\|\\nabla \\ell(x^\\star)\\|^2$. We show that the $G^\\star$ regret strictly refines the existing $L^\\star$ (small loss) regret, and that it can be arbitrarily sharper when the losses have vanishing curvature around the hindsight decision. We establish upper and lower bounds on the $G^\\star$ regret and extend our results to dynamic regret and bandit settings. As a byproduct, we refine the existing convergence analysis of stochastic optimization algorithms in the interpolation regime. Some experiments validate our theoretical findings.",
    "authors": [
      "Wenzhi Gao",
      "Chang He",
      "Madeleine Udell"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.OC"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13519v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13519v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2601.13404v1",
    "title": "Local-to-Global Logical Explanations for Deep Vision Models",
    "summary": "While deep neural networks are extremely effective at classifying images, they remain opaque and hard to interpret. We introduce local and global explanation methods for black-box models that generate explanations in terms of human-recognizable primitive concepts. Both the local explanations for a single image and the global explanations for a set of images are cast as logical formulas in monotone disjunctive-normal-form (MDNF), whose satisfaction guarantees that the model yields a high score on a given class. We also present an algorithm for explaining the classification of examples into multiple classes in the form of a monotone explanation list over primitive concepts. Despite their simplicity and interpretability we show that the explanations maintain high fidelity and coverage with respect to the blackbox models they seek to explain in challenging vision datasets.",
    "authors": [
      "Bhavan Vasu",
      "Giuseppe Raffa",
      "Prasad Tadepalli"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13404v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13404v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2601.13272v1",
    "title": "Multi-level Monte Carlo Dropout for Efficient Uncertainty Quantification",
    "summary": "We develop a multilevel Monte Carlo (MLMC) framework for uncertainty quantification with Monte Carlo dropout. Treating dropout masks as a source of epistemic randomness, we define a fidelity hierarchy by the number of stochastic forward passes used to estimate predictive moments. We construct coupled coarse--fine estimators by reusing dropout masks across fidelities, yielding telescoping MLMC estimators for both predictive means and predictive variances that remain unbiased for the corresponding dropout-induced quantities while reducing sampling variance at fixed evaluation budget. We derive explicit bias, variance and effective cost expressions, together with sample-allocation rules across levels. Numerical experiments on forward and inverse PINNs--Uzawa benchmarks confirm the predicted variance rates and demonstrate efficiency gains over single-level MC-dropout at matched cost.",
    "authors": [
      "Aaron Pim",
      "Tristan Pryer"
    ],
    "categories": [
      "cs.LG",
      "stat.CO",
      "stat.ML"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13272v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13272v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2601.13227v1",
    "title": "Insider Knowledge: How Much Can RAG Systems Gain from Evaluation Secrets?",
    "summary": "RAG systems are increasingly evaluated and optimized using LLM judges, an approach that is rapidly becoming the dominant paradigm for system assessment. Nugget-based approaches in particular are now embedded not only in evaluation frameworks but also in the architectures of RAG systems themselves. While this integration can lead to genuine improvements, it also creates a risk of faulty measurements due to circularity. In this paper, we investigate this risk through comparative experiments with nugget-based RAG systems, including Ginger and Crucible, against strong baselines such as GPT-Researcher. By deliberately modifying Crucible to generate outputs optimized for an LLM judge, we show that near-perfect evaluation scores can be achieved when elements of the evaluation - such as prompt templates or gold nuggets - are leaked or can be predicted. Our results highlight the importance of blind evaluation settings and methodological diversity to guard against mistaking metric overfitting for genuine system progress.",
    "authors": [
      "Laura Dietz",
      "Bryan Li",
      "Eugene Yang",
      "Dawn Lawrie",
      "William Walden",
      "James Mayfield"
    ],
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13227v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13227v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2601.13222v1",
    "title": "Incorporating Q&A Nuggets into Retrieval-Augmented Generation",
    "summary": "RAGE systems integrate ideas from automatic evaluation (E) into Retrieval-augmented Generation (RAG). As one such example, we present Crucible, a Nugget-Augmented Generation System that preserves explicit citation provenance by constructing a bank of Q&A nuggets from retrieved documents and uses them to guide extraction, selection, and report generation. Reasoning on nuggets avoids repeated information through clear and interpretable Q&A semantics - instead of opaque cluster abstractions - while maintaining citation provenance throughout the entire generation process. Evaluated on the TREC NeuCLIR 2024 collection, our Crucible system substantially outperforms Ginger, a recent nugget-based RAG system, in nugget recall, density, and citation grounding.",
    "authors": [
      "Laura Dietz",
      "Bryan Li",
      "Gabrielle Liu",
      "Jia-Huei Ju",
      "Eugene Yang",
      "Dawn Lawrie",
      "William Walden",
      "James Mayfield"
    ],
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13222v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13222v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2601.13218v1",
    "title": "ObjectVisA-120: Object-based Visual Attention Prediction in Interactive Street-crossing Environments",
    "summary": "The object-based nature of human visual attention is well-known in cognitive science, but has only played a minor role in computational visual attention models so far. This is mainly due to a lack of suitable datasets and evaluation metrics for object-based attention. To address these limitations, we present \\dataset~ -- a novel 120-participant dataset of spatial street-crossing navigation in virtual reality specifically geared to object-based attention evaluations. The uniqueness of the presented dataset lies in the ethical and safety affiliated challenges that make collecting comparable data in real-world environments highly difficult. \\dataset~ not only features accurate gaze data and a complete state-space representation of objects in the virtual environment, but it also offers variable scenario complexities and rich annotations, including panoptic segmentation, depth information, and vehicle keypoints. We further propose object-based similarity (oSIM) as a novel metric to evaluate the performance of object-based visual attention models, a previously unexplored performance characteristic. Our evaluations show that explicitly optimising for object-based attention not only improves oSIM performance but also leads to an improved model performance on common metrics. In addition, we present SUMGraph, a Mamba U-Net-based model, which explicitly encodes critical scene objects (vehicles) in a graph representation, leading to further performance improvements over several state-of-the-art visual attention prediction methods. The dataset, code and models will be publicly released.",
    "authors": [
      "Igor Vozniak",
      "Philipp Mueller",
      "Nils Lipp",
      "Janis Sprenger",
      "Konstantin Poddubnyy",
      "Davit Hovhannisyan",
      "Christian Mueller",
      "Andreas Bulling",
      "Philipp Slusallek"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13218v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13218v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2601.13217v1",
    "title": "Beyond Single-shot Writing: Deep Research Agents are Unreliable at Multi-turn Report Revision",
    "summary": "Existing benchmarks for Deep Research Agents (DRAs) treat report generation as a single-shot writing task, which fundamentally diverges from how human researchers iteratively draft and revise reports via self-reflection or peer feedback. Whether DRAs can reliably revise reports with user feedback remains unexplored. We introduce Mr Dre, an evaluation suite that establishes multi-turn report revision as a new evaluation axis for DRAs. Mr Dre consists of (1) a unified long-form report evaluation protocol spanning comprehensiveness, factuality, and presentation, and (2) a human-verified feedback simulation pipeline for multi-turn revision. Our analysis of five diverse DRAs reveals a critical limitation: while agents can address most user feedback, they also regress on 16-27% of previously covered content and citation quality. Over multiple revision turns, even the best-performing agents leave significant headroom, as they continue to disrupt content outside the feedback's scope and fail to preserve earlier edits. We further show that these issues are not easily resolvable through inference-time fixes such as prompt engineering and a dedicated sub-agent for report revision.",
    "authors": [
      "Bingsen Chen",
      "Boyan Li",
      "Ping Nie",
      "Yuyu Zhang",
      "Xi Ye",
      "Chen Zhao"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13217v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13217v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2601.13162v1",
    "title": "NeuroShield: A Neuro-Symbolic Framework for Adversarial Robustness",
    "summary": "Adversarial vulnerability and lack of interpretability are critical limitations of deep neural networks, especially in safety-sensitive settings such as autonomous driving. We introduce \\DesignII, a neuro-symbolic framework that integrates symbolic rule supervision into neural networks to enhance both adversarial robustness and explainability. Domain knowledge is encoded as logical constraints over appearance attributes such as shape and color, and enforced through semantic and symbolic logic losses applied during training. Using the GTSRB dataset, we evaluate robustness against FGSM and PGD attacks at a standard $\\ell_\\infty$ perturbation budget of $\\varepsilon = 8/255$. Relative to clean training, standard adversarial training provides modest improvements in robustness ($\\sim$10 percentage points). Conversely, our FGSM-Neuro-Symbolic and PGD-Neuro-Symbolic models achieve substantially larger gains, improving adversarial accuracy by 18.1\\% and 17.35\\% over their corresponding adversarial-training baselines, representing roughly a three-fold larger robustness gain than standard adversarial training provides when both are measured relative to the same clean-training baseline, without reducing clean-sample accuracy. Compared to transformer-based defenses such as LNL-MoEx, which require heavy architectures and extensive data augmentation, our PGD-Neuro-Symbolic variant attains comparable or superior robustness using a ResNet18 backbone trained for 10 epochs. These results show that symbolic reasoning offers an effective path to robust and interpretable AI.",
    "authors": [
      "Ali Shafiee Sarvestani",
      "Jason Schmidt",
      "Arman Roohi"
    ],
    "categories": [
      "cs.LG",
      "cs.ET"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13162v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13162v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2601.13094v1",
    "title": "Patient-Conditioned Adaptive Offsets for Reliable Diagnosis across Subgroups",
    "summary": "AI models for medical diagnosis often exhibit uneven performance across patient populations due to heterogeneity in disease prevalence, imaging appearance, and clinical risk profiles. Existing algorithmic fairness approaches typically seek to reduce such disparities by suppressing sensitive attributes. However, in medical settings these attributes often carry essential diagnostic information, and removing them can degrade accuracy and reliability, particularly in high-stakes applications. In contrast, clinical decision making explicitly incorporates patient context when interpreting diagnostic evidence, suggesting a different design direction for subgroup-aware models. In this paper, we introduce HyperAdapt, a patient-conditioned adaptation framework that improves subgroup reliability while maintaining a shared diagnostic model. Clinically relevant attributes such as age and sex are encoded into a compact embedding and used to condition a hypernetwork-style module, which generates small residual modulation parameters for selected layers of a shared backbone. This design preserves the general medical knowledge learned by the backbone while enabling targeted adjustments that reflect patient-specific variability. To ensure efficiency and robustness, adaptations are constrained through low-rank and bottlenecked parameterizations, limiting both model complexity and computational overhead. Experiments across multiple public medical imaging benchmarks demonstrate that the proposed approach consistently improves subgroup-level performance without sacrificing overall accuracy. On the PAD-UFES-20 dataset, our method outperforms the strongest competing baseline by 4.1% in recall and 4.4% in F1 score, with larger gains observed for underrepresented patient populations.",
    "authors": [
      "Gelei Xu",
      "Yuying Duan",
      "Jun Xia",
      "Ruining Deng",
      "Wei Jin",
      "Yiyu Shi"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13094v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13094v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2601.13029v1",
    "title": "Think3D: Thinking with Space for Spatial Reasoning",
    "summary": "Understanding and reasoning about the physical world requires spatial intelligence: the ability to interpret geometry, perspective, and spatial relations beyond 2D perception. While recent vision large models (VLMs) excel at visual understanding, they remain fundamentally 2D perceivers and struggle with genuine 3D reasoning. We introduce Think3D, a framework that enables VLM agents to think with 3D space. By leveraging 3D reconstruction models that recover point clouds and camera poses from images or videos, Think3D allows the agent to actively manipulate space through camera-based operations and ego/global-view switching, transforming spatial reasoning into an interactive 3D chain-of-thought process. Without additional training, Think3D significantly improves the spatial reasoning performance of advanced models such as GPT-4.1 and Gemini 2.5 Pro, yielding average gains of +7.8% on BLINK Multi-view and MindCube, and +4.7% on VSI-Bench. We further show that smaller models, which struggle with spatial exploration, benefit significantly from a reinforcement learning policy that enables the model to select informative viewpoints and operations. With RL, the benefit from tool usage increases from +0.7% to +6.8%. Our findings demonstrate that training-free, tool-augmented spatial exploration is a viable path toward more flexible and human-like 3D reasoning in multimodal agents, establishing a new dimension of multimodal intelligence. Code and weights are released at https://github.com/zhangzaibin/spagent.",
    "authors": [
      "Zaibin Zhang",
      "Yuhan Wu",
      "Lianjie Jia",
      "Yifan Wang",
      "Zhongbo Zhang",
      "Yijiang Li",
      "Binghao Ran",
      "Fuxi Zhang",
      "Zhuohan Sun",
      "Zhenfei Yin",
      "Lijun Wang",
      "Huchuan Lu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13029v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13029v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2601.13018v1",
    "title": "Bi-Attention HateXplain : Taking into account the sequential aspect of data during explainability in a multi-task context",
    "summary": "Technological advances in the Internet and online social networks have brought many benefits to humanity. At the same time, this growth has led to an increase in hate speech, the main global threat. To improve the reliability of black-box models used for hate speech detection, post-hoc approaches such as LIME, SHAP, and LRP provide the explanation after training the classification model. In contrast, multi-task approaches based on the HateXplain benchmark learn to explain and classify simultaneously. However, results from HateXplain-based algorithms show that predicted attention varies considerably when it should be constant. This attention variability can lead to inconsistent interpretations, instability of predictions, and learning difficulties. To solve this problem, we propose the BiAtt-BiRNN-HateXplain (Bidirectional Attention BiRNN HateXplain) model which is easier to explain compared to LLMs which are more complex in view of the need for transparency, and will take into account the sequential aspect of the input data during explainability thanks to a BiRNN layer. Thus, if the explanation is correctly estimated, thanks to multi-task learning (explainability and classification task), the model could classify better and commit fewer unintentional bias errors related to communities. The experimental results on HateXplain data show a clear improvement in detection performance, explainability and a reduction in unintentional bias.",
    "authors": [
      "Ghislain Dorian Tchuente Mondjo"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13018v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13018v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2601.12991v1",
    "title": "RAGExplorer: A Visual Analytics System for the Comparative Diagnosis of RAG Systems",
    "summary": "The advent of Retrieval-Augmented Generation (RAG) has significantly enhanced the ability of Large Language Models (LLMs) to produce factually accurate and up-to-date responses. However, the performance of a RAG system is not determined by a single component but emerges from a complex interplay of modular choices, such as embedding models and retrieval algorithms. This creates a vast and often opaque configuration space, making it challenging for developers to understand performance trade-offs and identify optimal designs. To address this challenge, we present RAGExplorer, a visual analytics system for the systematic comparison and diagnosis of RAG configurations. RAGExplorer guides users through a seamless macro-to-micro analytical workflow. Initially, it empowers developers to survey the performance landscape across numerous configurations, allowing for a high-level understanding of which design choices are most effective. For a deeper analysis, the system enables users to drill down into individual failure cases, investigate how differences in retrieved information contribute to errors, and interactively test hypotheses by manipulating the provided context to observe the resulting impact on the generated answer. We demonstrate the effectiveness of RAGExplorer through detailed case studies and user studies, validating its ability to empower developers in navigating the complex RAG design space. Our code and user guide are publicly available at https://github.com/Thymezzz/RAGExplorer.",
    "authors": [
      "Haoyu Tian",
      "Yingchaojie Feng",
      "Zhen Wen",
      "Haoxuan Li",
      "Minfeng Zhu",
      "Wei Chen"
    ],
    "categories": [
      "cs.HC",
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.12991v1",
    "pdf_url": "https://arxiv.org/pdf/2601.12991v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2601.12979v1",
    "title": "The Bitter Lesson of Diffusion Language Models for Agentic Workflows: A Comprehensive Reality Check",
    "summary": "The pursuit of real-time agentic interaction has driven interest in Diffusion-based Large Language Models (dLLMs) as alternatives to auto-regressive backbones, promising to break the sequential latency bottleneck. However, does such efficiency gains translate into effective agentic behavior? In this work, we present a comprehensive evaluation of dLLMs (e.g., LLaDA, Dream) across two distinct agentic paradigms: Embodied Agents (requiring long-horizon planning) and Tool-Calling Agents (requiring precise formatting). Contrary to the efficiency hype, our results on Agentboard and BFCL reveal a \"bitter lesson\": current dLLMs fail to serve as reliable agentic backbones, frequently leading to systematically failure. (1) In Embodied settings, dLLMs suffer repeated attempts, failing to branch under temporal feedback. (2) In Tool-Calling settings, dLLMs fail to maintain symbolic precision (e.g. strict JSON schemas) under diffusion noise. To assess the potential of dLLMs in agentic workflows, we introduce DiffuAgent, a multi-agent evaluation framework that integrates dLLMs as plug-and-play cognitive cores. Our analysis shows that dLLMs are effective in non-causal roles (e.g., memory summarization and tool selection) but require the incorporation of causal, precise, and logically grounded reasoning mechanisms into the denoising process to be viable for agentic tasks.",
    "authors": [
      "Qingyu Lu",
      "Liang Ding",
      "Kanjian Zhang",
      "Jinxia Zhang",
      "Dacheng Tao"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.12979v1",
    "pdf_url": "https://arxiv.org/pdf/2601.12979v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2601.12965v1",
    "title": "Deterministic Dynamics of Sampling Processes in Score-Based Diffusion Models with Multiplicative Noise Conditioning",
    "summary": "Score-based diffusion models generate new samples by learning the score function associated with a diffusion process. While the effectiveness of these models can be theoretically explained using differential equations related to the sampling process, previous work by Song and Ermon (2020) demonstrated that neural networks using multiplicative noise conditioning can still generate satisfactory samples. In this setup, the model is expressed as the product of two functions: one depending on the spatial variable and the other on the noise magnitude. This structure limits the model's ability to represent a more general relationship between the spatial variable and the noise, indicating that it cannot fully learn the correct score. Despite this limitation, the models perform well in practice. In this work, we provide a theoretical explanation for this phenomenon by studying the deterministic dynamics of the associated differential equations, offering insight into how the model operates.",
    "authors": [
      "Doheon Kim"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.12965v1",
    "pdf_url": "https://arxiv.org/pdf/2601.12965v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2601.13570v1",
    "title": "GeoDynamics: A Geometric State-Space Neural Network for Understanding Brain Dynamics on Riemannian Manifolds",
    "summary": "State-space models (SSMs) have become a cornerstone for unraveling brain dynamics, revealing how latent neural states evolve over time and give rise to observed signals. By combining the flexibility of deep learning with the principled dynamical structure of SSMs, recent studies have achieved powerful fits to functional neuroimaging data. However, most existing approaches still view the brain as a set of loosely connected regions or impose oversimplified network priors, falling short of a truly holistic and self-organized dynamical system perspective. Brain functional connectivity (FC) at each time point naturally forms a symmetric positive definite (SPD) matrix, which resides on a curved Riemannian manifold rather than in Euclidean space. Capturing the trajectories of these SPD matrices is key to understanding how coordinated networks support cognition and behavior. To this end, we introduce GeoDynamics, a geometric state-space neural network that tracks latent brain-state trajectories directly on the high-dimensional SPD manifold. GeoDynamics embeds each connectivity matrix into a manifold-aware recurrent framework, learning smooth and geometry-respecting transitions that reveal task-driven state changes and early markers of Alzheimer's disease, Parkinson's disease, and autism. Beyond neuroscience, we validate GeoDynamics on human action recognition benchmarks (UTKinect, Florence, HDM05), demonstrating its scalability and robustness in modeling complex spatiotemporal dynamics across diverse domains.",
    "authors": [
      "Tingting Dan",
      "Jiaqi Ding",
      "Guorong Wu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13570v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13570v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2601.13547v1",
    "title": "HateXScore: A Metric Suite for Evaluating Reasoning Quality in Hate Speech Explanations",
    "summary": "Hateful speech detection is a key component of content moderation, yet current evaluation frameworks rarely assess why a text is deemed hateful. We introduce \\textsf{HateXScore}, a four-component metric suite designed to evaluate the reasoning quality of model explanations. It assesses (i) conclusion explicitness, (ii) faithfulness and causal grounding of quoted spans, (iii) protected group identification (policy-configurable), and (iv) logical consistency among these elements. Evaluated on six diverse hate speech datasets, \\textsf{HateXScore} is intended as a diagnostic complement to reveal interpretability failures and annotation inconsistencies that are invisible to standard metrics like Accuracy or F1. Moreover, human evaluation shows strong agreement with \\textsf{HateXScore}, validating it as a practical tool for trustworthy and transparent moderation.   \\textcolor{red}{Disclaimer: This paper contains sensitive content that may be disturbing to some readers.}",
    "authors": [
      "Yujia Hu",
      "Roy Ka-Wei Lee"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13547v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13547v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2601.13515v1",
    "title": "Automatic Adjustment of HPA Parameters and Attack Prevention in Kubernetes Using Random Forests",
    "summary": "In this paper, HTTP status codes are used as custom metrics within the HPA as the experimental scenario. By integrating the Random Forest classification algorithm from machine learning, attacks are assessed and predicted, dynamically adjusting the maximum pod parameter in the HPA to manage attack traffic. This approach enables the adjustment of HPA parameters using machine learning scripts in targeted attack scenarios while effectively managing attack traffic. All access from attacking IPs is redirected to honeypot pods, achieving a lower incidence of 5XX status codes through HPA pod adjustments under high load conditions. This method also ensures effective isolation of attack traffic, preventing excessive HPA expansion due to attacks. Additionally, experiments conducted under various conditions demonstrate the importance of setting appropriate thresholds for HPA adjustments.",
    "authors": [
      "Hanlin Zhou",
      "Huah Yong Chan",
      "Jingfei Ni",
      "Mengchun Wu",
      "Qing Deng"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.DC"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13515v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13515v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2601.13474v1",
    "title": "Preconditioning Benefits of Spectral Orthogonalization in Muon",
    "summary": "The Muon optimizer, a matrix-structured algorithm that leverages spectral orthogonalization of gradients, is a milestone in the pretraining of large language models. However, the underlying mechanisms of Muon -- particularly the role of gradient orthogonalization -- remain poorly understood, with very few works providing end-to-end analyses that rigorously explain its advantages in concrete applications. We take a step by studying the effectiveness of a simplified variant of Muon through two case studies: matrix factorization, and in-context learning of linear transformers. For both problems, we prove that simplified Muon converges linearly with iteration complexities independent of the relevant condition number, provably outperforming gradient descent and Adam. Our analysis reveals that the Muon dynamics decouple into a collection of independent scalar sequences in the spectral domain, each exhibiting similar convergence behavior. Our theory formalizes the preconditioning effect induced by spectral orthogonalization, offering insight into Muon's effectiveness in these matrix optimization problems and potentially beyond.",
    "authors": [
      "Jianhao Ma",
      "Yu Huang",
      "Yuejie Chi",
      "Yuxin Chen"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC",
      "stat.ML"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13474v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13474v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2601.13462v1",
    "title": "SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation",
    "summary": "Evaluating whether text-to-image models follow explicit spatial instructions is difficult to automate. Object detectors may miss targets or return multiple plausible detections, and simple geometric tests can become ambiguous in borderline cases. Spatial evaluation is naturally a selective prediction problem, the checker may abstain when evidence is weak and report confidence so that results can be interpreted as a risk coverage tradeoff rather than a single score. We introduce SpatialBench-UC, a small, reproducible benchmark for pairwise spatial relations. The benchmark contains 200 prompts (50 object pairs times 4 relations) grouped into 100 counterfactual pairs obtained by swapping object roles. We release a benchmark package, versioned prompts, pinned configs, per-sample checker outputs, and report tables, enabling reproducible and auditable comparisons across models. We also include a lightweight human audit used to calibrate the checker's abstention margin and confidence threshold. We evaluate three baselines, Stable Diffusion 1.5, SD 1.5 BoxDiff, and SD 1.4 GLIGEN. The checker reports pass rate and coverage as well as conditional pass rates on decided samples. The results show that grounding methods substantially improve both pass rate and coverage, while abstention remains a dominant factor due mainly to missing detections.",
    "authors": [
      "Amine Rostane"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13462v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13462v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2601.13412v1",
    "title": "Using deep learning for predicting cleansing quality of colon capsule endoscopy images",
    "summary": "In this study, we explore the application of deep learning techniques for predicting cleansing quality in colon capsule endoscopy (CCE) images. Using a dataset of 500 images labeled by 14 clinicians on the Leighton-Rex scale (Poor, Fair, Good, and Excellent), a ResNet-18 model was trained for classification, leveraging stratified K-fold cross-validation to ensure robust performance. To optimize the model, structured pruning techniques were applied iteratively, achieving significant sparsity while maintaining high accuracy. Explainability of the pruned model was evaluated using Grad-CAM, Grad-CAM++, Eigen-CAM, Ablation-CAM, and Random-CAM, with the ROAD method employed for consistent evaluation. Our results indicate that for a pruned model, we can achieve a cross-validation accuracy of 88% with 79% sparsity, demonstrating the effectiveness of pruning in improving efficiency from 84% without compromising performance. We also highlight the challenges of evaluating cleansing quality of CCE images, emphasize the importance of explainability in clinical applications, and discuss the challenges associated with using the ROAD method for our task. Finally, we employ a variant of adaptive temperature scaling to calibrate the pruned models for an external dataset.",
    "authors": [
      "Puneet Sharma",
      "Kristian Dalsbø Hindberg",
      "Benedicte Schelde-Olesen",
      "Ulrik Deding",
      "Esmaeil S. Nadimi",
      "Jan-Matthias Braun"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13412v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13412v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2601.13392v1",
    "title": "Beyond Memorization: Testing LLM Reasoning on Unseen Theory of Computation Tasks",
    "summary": "Large language models (LLMs) have demonstrated strong performance on formal language tasks, yet whether this reflects genuine symbolic reasoning or pattern matching on familiar constructions remains unclear. We introduce a benchmark for deterministic finite automata (DFA) construction from regular languages, comprising factual knowledge questions, seen construction problems from public sources, and two types of unseen problems: hand-crafted instances with multiple interacting constraints and systematically generated problems via Arden's theorem. Models achieve perfect accuracy on factual questions and 84-90% on seen tasks. However, accuracy drops sharply on unseen problems (by 30-64%), with failures stemming from systematic misinterpretation of language constraints, incorrect handling of Kleene-star semantics, and a failure to preserve global consistency. We evaluate a three-stage hint protocol that enables correction of shallow errors but does not reliably resolve globally inconsistent or structurally flawed automata. Our analysis across multiple prompting strategies (direct, Chain-of-Thought, Tree-of-Thought) reveals that errors persist regardless of prompting approach, exposing a fundamental gap between LLMs' ability to generate syntactically plausible DFAs and their capacity for semantically correct formal reasoning.",
    "authors": [
      "Shlok Shelat",
      "Jay Raval",
      "Souvik Roy",
      "Manas Gaur"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.FL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13392v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13392v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2601.13364v1",
    "title": "Real-Time 4D Radar Perception for Robust Human Detection in Harsh Enclosed Environments",
    "summary": "This paper introduces a novel methodology for generating controlled, multi-level dust concentrations in a highly cluttered environment representative of harsh, enclosed environments, such as underground mines, road tunnels, or collapsed buildings, enabling repeatable mm-wave propagation studies under severe electromagnetic constraints. We also present a new 4D mmWave radar dataset, augmented by camera and LiDAR, illustrating how dust particles and reflective surfaces jointly impact the sensing functionality. To address these challenges, we develop a threshold-based noise filtering framework leveraging key radar parameters (RCS, velocity, azimuth, elevation) to suppress ghost targets and mitigate strong multipath reflections at the raw data level. Building on the filtered point clouds, a cluster-level, rule-based classification pipeline exploits radar semantics-velocity, RCS, and volumetric spread-to achieve reliable, real-time pedestrian detection without extensive domainspecific training. Experimental results confirm that this integrated approach significantly enhances clutter mitigation, detection robustness, and overall system resilience in dust-laden mining environments.",
    "authors": [
      "Zhenan Liu",
      "Yaodong Cui",
      "Amir Khajepour",
      "George Shaker"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13364v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13364v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2601.13350v1",
    "title": "Beyond Mapping : Domain-Invariant Representations via Spectral Embedding of Optimal Transport Plans",
    "summary": "Distributional shifts between training and inference time data remain a central challenge in machine learning, often leading to poor performance. It motivated the study of principled approaches for domain alignment, such as optimal transport based unsupervised domain adaptation, that relies on approximating Monge map using transport plans, which is sensitive to the transport problem regularization strategy and hyperparameters, and might yield biased domains alignment. In this work, we propose to interpret smoothed transport plans as adjacency matrices of bipartite graphs connecting source to target domain and derive domain-invariant samples' representations through spectral embedding. We evaluate our approach on acoustic adaptation benchmarks for music genre recognition, music-speech discrimination, as well as electrical cable defect detection and classification tasks using time domain reflection in different diagnosis settings, achieving overall strong performances.",
    "authors": [
      "Abdel Djalil Sad Saoud",
      "Fred Maurice Ngolè Mboula",
      "Hanane Slimani"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13350v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13350v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2601.13331v1",
    "title": "MultiST: A Cross-Attention-Based Multimodal Model for Spatial Transcriptomic",
    "summary": "Spatial transcriptomics (ST) enables transcriptome-wide profiling while preserving the spatial context of tissues, offering unprecedented opportunities to study tissue organization and cell-cell interactions in situ. Despite recent advances, existing methods often lack effective integration of histological morphology with molecular profiles, relying on shallow fusion strategies or omitting tissue images altogether, which limits their ability to resolve ambiguous spatial domain boundaries. To address this challenge, we propose MultiST, a unified multimodal framework that jointly models spatial topology, gene expression, and tissue morphology through cross-attention-based fusion. MultiST employs graph-based gene encoders with adversarial alignment to learn robust spatial representations, while integrating color-normalized histological features to capture molecular-morphological dependencies and refine domain boundaries. We evaluated the proposed method on 13 diverse ST datasets spanning two organs, including human brain cortex and breast cancer tissue. MultiST yields spatial domains with clearer and more coherent boundaries than existing methods, leading to more stable pseudotime trajectories and more biologically interpretable cell-cell interaction patterns. The MultiST framework and source code are available at https://github.com/LabJunBMI/MultiST.git.",
    "authors": [
      "Wei Wang",
      "Quoc-Toan Ly",
      "Chong Yu",
      "Jun Bai"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13331v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13331v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2601.13328v1",
    "title": "Reducing Tokenization Premiums for Low-Resource Languages",
    "summary": "Relative to English, low-resource languages suffer from substantial tokenization premiums in modern LMs, meaning that it generally requires several times as many tokens to encode a sentence in a low-resource language than to encode the analogous sentence in English. This tokenization premium results in increased API and energy costs and reduced effective context windows for these languages. In this paper we analyze the tokenizers of ten popular LMs to better understand their designs and per-language tokenization premiums. We also propose a mechanism to reduce tokenization premiums in pre-trained models, by post-hoc additions to the token vocabulary that coalesce multi-token characters into single tokens. We apply this methodology to 12 low-resource languages, demonstrating that the original and compressed inputs often have similar last hidden states when run through the Llama 3.2 1B model.",
    "authors": [
      "Geoffrey Churchill",
      "Steven Skiena"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13328v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13328v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2601.13317v1",
    "title": "Paid Voices vs. Public Feeds: Interpretable Cross-Platform Theme Modeling of Climate Discourse",
    "summary": "Climate discourse online plays a crucial role in shaping public understanding of climate change and influencing political and policy outcomes. However, climate communication unfolds across structurally distinct platforms with fundamentally different incentive structures: paid advertising ecosystems incentivize targeted, strategic persuasion, while public social media platforms host largely organic, user-driven discourse. Existing computational studies typically analyze these environments in isolation, limiting our ability to distinguish institutional messaging from public expression. In this work, we present a comparative analysis of climate discourse across paid advertisements on Meta (previously known as Facebook) and public posts on Bluesky from July 2024 to September 2025. We introduce an interpretable, end-to-end thematic discovery and assignment framework that clusters texts by semantic similarity and leverages large language models (LLMs) to generate concise, human-interpretable theme labels. We evaluate the quality of the induced themes against traditional topic modeling baselines using both human judgments and an LLM-based evaluator, and further validate their semantic coherence through downstream stance prediction and theme-guided retrieval tasks. Applying the resulting themes, we characterize systematic differences between paid climate messaging and public climate discourse and examine how thematic prevalence shifts around major political events. Our findings show that platform-level incentives are reflected in the thematic structure, stance alignment, and temporal responsiveness of climate narratives. While our empirical analysis focuses on climate communication, the proposed framework is designed to support comparative narrative analysis across heterogeneous communication environments.",
    "authors": [
      "Samantha Sudhoff",
      "Pranav Perumal",
      "Zhaoqing Wu",
      "Tunazzina Islam"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CY",
      "cs.LG",
      "cs.SI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13317v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13317v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2601.13225v1",
    "title": "Not all Blends are Equal: The BLEMORE Dataset of Blended Emotion Expressions with Relative Salience Annotations",
    "summary": "Humans often experience not just a single basic emotion at a time, but rather a blend of several emotions with varying salience. Despite the importance of such blended emotions, most video-based emotion recognition approaches are designed to recognize single emotions only. The few approaches that have attempted to recognize blended emotions typically cannot assess the relative salience of the emotions within a blend. This limitation largely stems from the lack of datasets containing a substantial number of blended emotion samples annotated with relative salience. To address this shortcoming, we introduce BLEMORE, a novel dataset for multimodal (video, audio) blended emotion recognition that includes information on the relative salience of each emotion within a blend. BLEMORE comprises over 3,000 clips from 58 actors, performing 6 basic emotions and 10 distinct blends, where each blend has 3 different salience configurations (50/50, 70/30, and 30/70). Using this dataset, we conduct extensive evaluations of state-of-the-art video classification approaches on two blended emotion prediction tasks: (1) predicting the presence of emotions in a given sample, and (2) predicting the relative salience of emotions in a blend. Our results show that unimodal classifiers achieve up to 29% presence accuracy and 13% salience accuracy on the validation set, while multimodal methods yield clear improvements, with ImageBind + WavLM reaching 35% presence accuracy and HiCMAE 18% salience accuracy. On the held-out test set, the best models achieve 33% presence accuracy (VideoMAEv2 + HuBERT) and 18% salience accuracy (HiCMAE). In sum, the BLEMORE dataset provides a valuable resource to advancing research on emotion recognition systems that account for the complexity and significance of blended emotion expressions.",
    "authors": [
      "Tim Lachmann",
      "Alexandra Israelsson",
      "Christina Tornberg",
      "Teimuraz Saghinadze",
      "Michal Balazia",
      "Philipp Müller",
      "Petri Laukka"
    ],
    "categories": [
      "cs.CV",
      "cs.HC"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13225v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13225v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2601.13206v1",
    "title": "Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues",
    "summary": "Large Language Models (LLMs) generate text token-by-token in discrete time, yet real-world communication, from therapy sessions to business negotiations, critically depends on continuous time constraints. Current LLM architectures and evaluation protocols rarely test for temporal awareness under real-time deadlines. We use simulated negotiations between paired agents under strict deadlines to investigate how LLMs adjust their behavior in time-sensitive settings. In a control condition, agents know only the global time limit. In a time-aware condition, they receive remaining-time updates at each turn. Deal closure rates are substantially higher (32\\% vs. 4\\% for GPT-5.1) and offer acceptances are sixfold higher in the time-aware condition than in the control, suggesting LLMs struggle to internally track elapsed time. However, the same LLMs achieve near-perfect deal closure rates ($\\geq$95\\%) under turn-based limits, revealing the failure is in temporal tracking rather than strategic reasoning. These effects replicate across negotiation scenarios and models, illustrating a systematic lack of LLM time awareness that will constrain LLM deployment in many time-sensitive applications.",
    "authors": [
      "Neil K. R. Sehgal",
      "Sharath Chandra Guntuku",
      "Lyle Ungar"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13206v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13206v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2601.13137v1",
    "title": "Adversarial Alignment: Ensuring Value Consistency in Large Language Models for Sensitive Domains",
    "summary": "With the wide application of large language models (LLMs), the problems of bias and value inconsistency in sensitive domains have gradually emerged, especially in terms of race, society and politics. In this paper, we propose an adversarial alignment framework, which enhances the value consistency of the model in sensitive domains through continued pre-training, instruction fine-tuning and adversarial training. In adversarial training, we use the Attacker to generate controversial queries, the Actor to generate responses with value consistency, and the Critic to filter and ensure response quality. Furthermore, we train a Value-Consistent Large Language Model, VC-LLM, for sensitive domains, and construct a bilingual evaluation dataset in Chinese and English. The experimental results show that VC-LLM performs better than the existing mainstream models in both Chinese and English tests, verifying the effectiveness of the method. Warning: This paper contains examples of LLMs that are offensive or harmful in nature.",
    "authors": [
      "Yuan Gao",
      "Zhigang Liu",
      "Xinyu Yao",
      "Bo Chen",
      "Xiaobing Zhao"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13137v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13137v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2601.13114v1",
    "title": "IntAgent: NWDAF-Based Intent LLM Agent Towards Advanced Next Generation Networks",
    "summary": "Intent-based networks (IBNs) are gaining prominence as an innovative technology that automates network operations through high-level request statements, defining what the network should achieve. In this work, we introduce IntAgent, an intelligent intent LLM agent that integrates NWDAF analytics and tools to fulfill the network operator's intents. Unlike previous approaches, we develop an intent tools engine directly within the NWDAF analytics engine, allowing our agent to utilize live network analytics to inform its reasoning and tool selection. We offer an enriched, 3GPP-compliant data source that enhances the dynamic, context-aware fulfillment of network operator goals, along with an MCP tools server for scheduling, monitoring, and analytics tools. We demonstrate the efficacy of our framework through two practical use cases: ML-based traffic prediction and scheduled policy enforcement, which validate IntAgent's ability to autonomously fulfill complex network intents.",
    "authors": [
      "Abdelrahman Soliman",
      "Ahmed Refaey",
      "Aiman Erbad",
      "Amr Mohamed"
    ],
    "categories": [
      "cs.NI",
      "cs.AI",
      "eess.SY"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13114v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13114v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2601.13503v1",
    "title": "Anonpsy: A Graph-Based Framework for Structure-Preserving De-identification of Psychiatric Narratives",
    "summary": "Psychiatric narratives encode patient identity not only through explicit identifiers but also through idiosyncratic life events embedded in their clinical structure. Existing de-identification approaches, including PHI masking and LLM-based synthetic rewriting, operate at the text level and offer limited control over which semantic elements are preserved or altered. We introduce Anonpsy, a de-identification framework that reformulates the task as graph-guided semantic rewriting. Anonpsy (1) converts each narrative into a semantic graph encoding clinical entities, temporal anchors, and typed relations; (2) applies graph-constrained perturbations that modify identifying context while preserving clinically essential structure; and (3) regenerates text via graph-conditioned LLM generation. Evaluated on 90 clinician-authored psychiatric case narratives, Anonpsy preserves diagnostic fidelity while achieving consistently low re-identification risk under expert, semantic, and GPT-5-based evaluations. Compared with a strong LLM-only rewriting baseline, Anonpsy yields substantially lower semantic similarity and identifiability. These results demonstrate that explicit structural representations combined with constrained generation provide an effective approach to de-identification for psychiatric narratives.",
    "authors": [
      "Kyung Ho Lim",
      "Byung-Hoon Kim"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13503v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13503v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2601.13440v1",
    "title": "Analyzing VLM-Based Approaches for Anomaly Classification and Segmentation",
    "summary": "Vision-Language Models (VLMs), particularly CLIP, have revolutionized anomaly detection by enabling zero-shot and few-shot defect identification without extensive labeled datasets. By learning aligned representations of images and text, VLMs facilitate anomaly classification and segmentation through natural language descriptions of normal and abnormal states, eliminating traditional requirements for task-specific training or defect examples. This project presents a comprehensive analysis of VLM-based approaches for anomaly classification (AC) and anomaly segmentation (AS). We systematically investigate key architectural paradigms including sliding window-based dense feature extraction (WinCLIP), multi-stage feature alignment with learnable projections (AprilLab framework), and compositional prompt ensemble strategies. Our analysis evaluates these methods across critical dimensions: feature extraction mechanisms, text-visual alignment strategies, prompt engineering techniques, zero-shot versus few-shot trade-offs, computational efficiency, and cross-domain generalization. Through rigorous experimentation on benchmarks such as MVTec AD and VisA, we compare classification accuracy, segmentation precision, and inference efficiency. The primary contribution is a foundational understanding of how and why VLMs succeed in anomaly detection, synthesizing practical insights for method selection and identifying current limitations. This work aims to facilitate informed adoption of VLM-based methods in industrial quality control and guide future research directions.",
    "authors": [
      "Mohit Kakda",
      "Mirudula Shri Muthukumaran",
      "Uttapreksha Patel",
      "Lawrence Swaminathan Xavier Prince"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13440v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13440v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2601.13436v1",
    "title": "Distribution-Free Confidence Ellipsoids for Ridge Regression with PAC Bounds",
    "summary": "Linearly parametrized models are widely used in control and signal processing, with the least-squares (LS) estimate being the archetypical solution. When the input is insufficiently exciting, the LS problem may be unsolvable or numerically unstable. This issue can be resolved through regularization, typically with ridge regression. Although regularized estimators reduce the variance error, it remains important to quantify their estimation uncertainty. A possible approach for linear regression is to construct confidence ellipsoids with the Sign-Perturbed Sums (SPS) ellipsoidal outer approximation (EOA) algorithm. The SPS EOA builds non-asymptotic confidence ellipsoids under the assumption that the noises are independent and symmetric about zero. This paper introduces an extension of the SPS EOA algorithm to ridge regression, and derives probably approximately correct (PAC) upper bounds for the resulting region sizes. Compared with previous analyses, our result explicitly show how the regularization parameter affects the region sizes, and provide tighter bounds under weaker excitation assumptions. Finally, the practical effect of regularization is also demonstrated via simulation experiments.",
    "authors": [
      "Szabolcs Szentpéteri",
      "Balázs Csanád Csáji"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "eess.SP",
      "eess.SY",
      "math.ST"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13436v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13436v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2601.13384v1",
    "title": "From Completion to Editing: Unlocking Context-Aware Code Infilling via Search-and-Replace Instruction Tuning",
    "summary": "The dominant Fill-in-the-Middle (FIM) paradigm for code completion is constrained by its rigid inability to correct contextual errors and reliance on unaligned, insecure Base models. While Chat LLMs offer safety and Agentic workflows provide flexibility, they suffer from performance degradation and prohibitive latency, respectively. To resolve this dilemma, we propose Search-and-Replace Infilling (SRI), a framework that internalizes the agentic verification-and-editing mechanism into a unified, single-pass inference process. By structurally grounding edits via an explicit search phase, SRI harmonizes completion tasks with the instruction-following priors of Chat LLMs, extending the paradigm from static infilling to dynamic context-aware editing. We synthesize a high-quality dataset, SRI-200K, and fine-tune the SRI-Coder series. Extensive evaluations demonstrate that with minimal data (20k samples), SRI-Coder enables Chat models to surpass the completion performance of their Base counterparts. Crucially, unlike FIM-style tuning, SRI preserves general coding competencies and maintains inference latency comparable to standard FIM. We empower the entire Qwen3-Coder series with SRI, encouraging the developer community to leverage this framework for advanced auto-completion and assisted development.",
    "authors": [
      "Jiajun Zhang",
      "Zeyu Cui",
      "Jiaxi Yang",
      "Lei Zhang",
      "Yuheng Jing",
      "Zeyao Ma",
      "Tianyi Bai",
      "Zilei Wang",
      "Qiang Liu",
      "Liang Wang",
      "Binyuan Hui",
      "Junyang Lin"
    ],
    "categories": [
      "cs.SE",
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13384v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13384v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2601.13362v1",
    "title": "Improving Geopolitical Forecasts with Bayesian Networks",
    "summary": "This study explores how Bayesian networks (BNs) can improve forecast accuracy compared to logistic regression and recalibration and aggregation methods, using data from the Good Judgment Project. Regularized logistic regression models and a baseline recalibrated aggregate were compared to two types of BNs: structure-learned BNs with arcs between predictors, and naive BNs. Four predictor variables were examined: absolute difference from the aggregate, forecast value, days prior to question close, and mean standardized Brier score. Results indicated the recalibrated aggregate achieved the highest accuracy (AUC = 0.985), followed by both types of BNs, then the logistic regression models. Performance of the BNs was likely harmed by reduced information from the discretization process and violation of the assumption of linearity likely harmed the logistic regression models. Future research should explore hybrid approaches combining BNs with logistic regression, examine additional predictor variables, and account for hierarchical data dependencies.",
    "authors": [
      "Matthew Martin"
    ],
    "categories": [
      "stat.AP",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13362v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13362v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2601.13308v1",
    "title": "Scaling laws for amplitude surrogates",
    "summary": "Scaling laws describing the dependence of neural network performance on the amount of training data, the spent compute, and the network size have emerged across a huge variety of machine learning task and datasets. In this work, we systematically investigate these scaling laws in the context of amplitude surrogates for particle physics. We show that the scaling coefficients are connected to the number of external particles of the process. Our results demonstrate that scaling laws are a useful tool to achieve desired precision targets.",
    "authors": [
      "Henning Bahl",
      "Victor Bresó-Pla",
      "Anja Butter",
      "Joaquín Iturriza Ramirez"
    ],
    "categories": [
      "hep-ph",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13308v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13308v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2601.13160v1",
    "title": "Training instability in deep learning follows low-dimensional dynamical principles",
    "summary": "Deep learning systems achieve remarkable empirical performance, yet the stability of the training process itself remains poorly understood. Training unfolds as a high-dimensional dynamical system in which small perturbations to optimization, data, parameters, or learning signals can induce abrupt and irreversible collapse, undermining reproducibility and scalability.   We propose a unified dynamical perspective that characterizes training stability as an intrinsic property of learning systems, organized along four interacting dimensions: optimization, environmental/data, parametric, and learning-signal stability. We operationalize this perspective through controlled perturbation auditing of training trajectories, probing how learning dynamics respond to structured disturbances without modifying learning algorithms.   Across reinforcement learning and large language model training, we identify three recurring regularities: high final performance is frequently decoupled from training stability; controlled stochasticity consistently buffers learning dynamics across paradigms; and deviations in low-dimensional latent meta-states systematically precede observable performance collapse. Together, these findings establish training stability as a measurable and comparable dynamical property of learning systems, providing a descriptive foundation for studying learning dynamics beyond final performance outcomes.",
    "authors": [
      "Zhipeng Zhang",
      "Zhenjie Yao",
      "Kai Li",
      "Lei Yang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13160v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13160v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2601.13096v1",
    "title": "LLM-VLM Fusion Framework for Autonomous Maritime Port Inspection using a Heterogeneous UAV-USV System",
    "summary": "Maritime port inspection plays a critical role in ensuring safety, regulatory compliance, and operational efficiency in complex maritime environments. However, existing inspection methods often rely on manual operations and conventional computer vision techniques that lack scalability and contextual understanding. This study introduces a novel integrated engineering framework that utilizes the synergy between Large Language Models (LLMs) and Vision Language Models (VLMs) to enable autonomous maritime port inspection using cooperative aerial and surface robotic platforms. The proposed framework replaces traditional state-machine mission planners with LLM-driven symbolic planning and improved perception pipelines through VLM-based semantic inspection, enabling context-aware and adaptive monitoring. The LLM module translates natural language mission instructions into executable symbolic plans with dependency graphs that encode operational constraints and ensure safe UAV-USV coordination. Meanwhile, the VLM module performs real-time semantic inspection and compliance assessment, generating structured reports with contextual reasoning. The framework was validated using the extended MBZIRC Maritime Simulator with realistic port infrastructure and further assessed through real-world robotic inspection trials. The lightweight on-board design ensures suitability for resource-constrained maritime platforms, advancing the development of intelligent, autonomous inspection systems. Project resources (code and videos) can be found here: https://github.com/Muhayyuddin/llm-vlm-fusion-port-inspection",
    "authors": [
      "Muhayy Ud Din",
      "Waseem Akram",
      "Ahsan B. Bakht",
      "Irfan Hussain"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13096v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13096v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2601.13060v1",
    "title": "MagicGUI-RMS: A Multi-Agent Reward Model System for Self-Evolving GUI Agents via Automated Feedback Reflux",
    "summary": "Graphical user interface (GUI) agents are rapidly progressing toward autonomous interaction and reliable task execution across diverse applications. However, two central challenges remain unresolved: automating the evaluation of agent trajectories and generating high-quality training data at scale to enable continual improvement. Existing approaches often depend on manual annotation or static rule-based verification, which restricts scalability and limits adaptability in dynamic environments. We present MagicGUI-RMS, a multi-agent reward model system that delivers adaptive trajectory evaluation, corrective feedback, and self-evolving learning capabilities. MagicGUI-RMS integrates a Domain-Specific Reward Model (DS-RM) with a General-Purpose Reward Model (GP-RM), enabling fine-grained action assessment and robust generalization across heterogeneous GUI tasks. To support reward learning at scale, we design a structured data construction pipeline that automatically produces balanced and diverse reward datasets, effectively reducing annotation costs while maintaining sample fidelity. During execution, the reward model system identifies erroneous actions, proposes refined alternatives, and continuously enhances agent behavior through an automated data-reflux mechanism. Extensive experiments demonstrate that MagicGUI-RMS yields substantial gains in task accuracy, behavioral robustness. These results establish MagicGUI-RMS as a principled and effective foundation for building self-improving GUI agents driven by reward-based adaptation.",
    "authors": [
      "Zecheng Li",
      "Zhihui Cao",
      "Wenke Huang",
      "Yudong Zhang",
      "Keying Qi",
      "Rui Wang",
      "Zeyu Zheng",
      "Jian Zhao",
      "Hao Zhu",
      "Hengxin Wu",
      "Yuran Wang",
      "Guitao Fan",
      "Guokun Wu",
      "Yicong Liu",
      "Zhilin Gao",
      "Haikun Xu",
      "He Yang",
      "Minqi Xiang",
      "Xingyu Liu",
      "Zuojian Wang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13060v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13060v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2601.12994v1",
    "title": "AsyncBEV: Cross-modal Flow Alignment in Asynchronous 3D Object Detection",
    "summary": "In autonomous driving, multi-modal perception tasks like 3D object detection typically rely on well-synchronized sensors, both at training and inference. However, despite the use of hardware- or software-based synchronization algorithms, perfect synchrony is rarely guaranteed: Sensors may operate at different frequencies, and real-world factors such as network latency, hardware failures, or processing bottlenecks often introduce time offsets between sensors. Such asynchrony degrades perception performance, especially for dynamic objects. To address this challenge, we propose AsyncBEV, a trainable lightweight and generic module to improve the robustness of 3D Birds' Eye View (BEV) object detection models against sensor asynchrony. Inspired by scene flow estimation, AsyncBEV first estimates the 2D flow from the BEV features of two different sensor modalities, taking into account the known time offset between these sensor measurements. The predicted feature flow is then used to warp and spatially align the feature maps, which we show can easily be integrated into different current BEV detector architectures (e.g., BEV grid-based and token-based). Extensive experiments demonstrate AsyncBEV improves robustness against both small and large asynchrony between LiDAR or camera sensors in both the token-based CMT and grid-based UniBEV, especially for dynamic objects. We significantly outperform the ego motion compensated CMT and UniBEV baselines, notably by $16.6$ % and $11.9$ % NDS on dynamic objects in the worst-case scenario of a $0.5 s$ time offset. Code will be released upon acceptance.",
    "authors": [
      "Shiming Wang",
      "Holger Caesar",
      "Liangliang Nan",
      "Julian F. P. Kooij"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.12994v1",
    "pdf_url": "https://arxiv.org/pdf/2601.12994v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2601.12990v1",
    "title": "Beyond Visual Realism: Toward Reliable Financial Time Series Generation",
    "summary": "Generative models for financial time series often create data that look realistic and even reproduce stylized facts such as fat tails or volatility clustering. However, these apparent successes break down under trading backtests: models like GANs or WGAN-GP frequently collapse, yielding extreme and unrealistic results that make the synthetic data unusable in practice. We identify the root cause in the neglect of financial asymmetry and rare tail events, which strongly affect market risk but are often overlooked by objectives focusing on distribution matching. To address this, we introduce the Stylized Facts Alignment GAN (SFAG), which converts key stylized facts into differentiable structural constraints and jointly optimizes them with adversarial loss. This multi-constraint design ensures that generated series remain aligned with market dynamics not only in plots but also in backtesting. Experiments on the Shanghai Composite Index (2004--2024) show that while baseline GANs produce unstable and implausible trading outcomes, SFAG generates synthetic data that preserve stylized facts and support robust momentum strategy performance. Our results highlight that structure-preserving objectives are essential to bridge the gap between superficial realism and practical usability in financial generative modeling.",
    "authors": [
      "Fan Zhang",
      "Jiabin Luo",
      "Zheng Zhang",
      "Shuanghong Huang",
      "Zhipeng Liu",
      "Yu Chen"
    ],
    "categories": [
      "q-fin.ST",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.12990v1",
    "pdf_url": "https://arxiv.org/pdf/2601.12990v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2601.12974v1",
    "title": "Bridging the Knowledge-Action Gap by Evaluating LLMs in Dynamic Dental Clinical Scenarios",
    "summary": "The transition of Large Language Models (LLMs) from passive knowledge retrievers to autonomous clinical agents demands a shift in evaluation-from static accuracy to dynamic behavioral reliability. To explore this boundary in dentistry, a domain where high-quality AI advice uniquely empowers patient-participatory decision-making, we present the Standardized Clinical Management & Performance Evaluation (SCMPE) benchmark, which comprehensively assesses performance from knowledge-oriented evaluations (static objective tasks) to workflow-based simulations (multi-turn simulated patient interactions). Our analysis reveals that while models demonstrate high proficiency in static objective tasks, their performance precipitates in dynamic clinical dialogues, identifying that the primary bottleneck lies not in knowledge retention, but in the critical challenges of active information gathering and dynamic state tracking. Mapping \"Guideline Adherence\" versus \"Decision Quality\" reveals a prevalent \"High Efficacy, Low Safety\" risk in general models. Furthermore, we quantify the impact of Retrieval-Augmented Generation (RAG). While RAG mitigates hallucinations in static tasks, its efficacy in dynamic workflows is limited and heterogeneous, sometimes causing degradation. This underscores that external knowledge alone cannot bridge the reasoning gap without domain-adaptive pre-training. This study empirically charts the capability boundaries of dental LLMs, providing a roadmap for bridging the gap between standardized knowledge and safe, autonomous clinical practice.",
    "authors": [
      "Hongyang Ma",
      "Tiantian Gu",
      "Huaiyuan Sun",
      "Huilin Zhu",
      "Yongxin Wang",
      "Jie Li",
      "Wubin Sun",
      "Zeliang Lian",
      "Yinghong Zhou",
      "Yi Gao",
      "Shirui Wang",
      "Zhihui Tang"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.12974v1",
    "pdf_url": "https://arxiv.org/pdf/2601.12974v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2601.12966v1",
    "title": "Lombard Speech Synthesis for Any Voice with Controllable Style Embeddings",
    "summary": "The Lombard effect plays a key role in natural communication, particularly in noisy environments or when addressing hearing-impaired listeners. We present a controllable text-to-speech (TTS) system capable of synthesizing Lombard speech for any speaker without requiring explicit Lombard data during training. Our approach leverages style embeddings learned from a large, prosodically diverse dataset and analyzes their correlation with Lombard attributes using principal component analysis (PCA). By shifting the relevant PCA components, we manipulate the style embeddings and incorporate them into our TTS model to generate speech at desired Lombard levels. Evaluations demonstrate that our method preserves naturalness and speaker identity, enhances intelligibility under noise, and provides fine-grained control over prosody, offering a robust solution for controllable Lombard TTS for any speaker.",
    "authors": [
      "Seymanur Akti",
      "Alexander Waibel"
    ],
    "categories": [
      "cs.SD",
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.12966v1",
    "pdf_url": "https://arxiv.org/pdf/2601.12966v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2601.13433v1",
    "title": "Trust Me, I'm an Expert: Decoding and Steering Authority Bias in Large Language Models",
    "summary": "Prior research demonstrates that performance of language models on reasoning tasks can be influenced by suggestions, hints and endorsements. However, the influence of endorsement source credibility remains underexplored. We investigate whether language models exhibit systematic bias based on the perceived expertise of the provider of the endorsement. Across 4 datasets spanning mathematical, legal, and medical reasoning, we evaluate 11 models using personas representing four expertise levels per domain. Our results reveal that models are increasingly susceptible to incorrect/misleading endorsements as source expertise increases, with higher-authority sources inducing not only accuracy degradation but also increased confidence in wrong answers. We also show that this authority bias is mechanistically encoded within the model and a model can be steered away from the bias, thereby improving its performance even when an expert gives a misleading endorsement.",
    "authors": [
      "Priyanka Mary Mammen",
      "Emil Joswin",
      "Shankar Venkitachalam"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13433v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13433v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2601.13319v1",
    "title": "Arab Voices: Mapping Standard and Dialectal Arabic Speech Technology",
    "summary": "Dialectal Arabic (DA) speech data vary widely in domain coverage, dialect labeling practices, and recording conditions, complicating cross-dataset comparison and model evaluation. To characterize this landscape, we conduct a computational analysis of linguistic ``dialectness'' alongside objective proxies of audio quality on the training splits of widely used DA corpora. We find substantial heterogeneity both in acoustic conditions and in the strength and consistency of dialectal signals across datasets, underscoring the need for standardized characterization beyond coarse labels. To reduce fragmentation and support reproducible evaluation, we introduce Arab Voices, a standardized framework for DA ASR. Arab Voices provides unified access to 31 datasets spanning 14 dialects, with harmonized metadata and evaluation utilities. We further benchmark a range of recent ASR systems, establishing strong baselines for modern DA ASR.",
    "authors": [
      "Peter Sullivan",
      "AbdelRahim Elmadany",
      "Alcides Alcoba Inciarte",
      "Muhammad Abdul-Mageed"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13319v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13319v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2601.13208v1",
    "title": "Rethinking Skip Connections: Additive U-Net for Robust and Interpretable Denoising",
    "summary": "Skip connections are central to U-Net architectures for image denoising, but standard concatenation doubles channel dimensionality and obscures information flow, allowing uncontrolled noise transfer. We propose the Additive U-Net, which replaces concatenative skips with gated additive connections. Each skip pathway is scaled by a learnable non-negative scalar, offering explicit and interpretable control over encoder contributions while avoiding channel inflation. Evaluations on the Kodak-17 denoising benchmark show that Additive U-Net achieves competitive PSNR/SSIM at noise levels σ = 15, 25, 50, with robustness across kernel schedules and depths. Notably, effective denoising is achieved even without explicit down/up-sampling or forced hierarchies, as the model naturally learns a progression from high-frequency to band-pass to low-frequency features. These results position additive skips as a lightweight and interpretable alternative to concatenation, enabling both efficient design and a clearer understanding of multi-scale information transfer in reconstruction networks.",
    "authors": [
      "Vikram R Lakkavalli"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13208v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13208v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2601.13191v1",
    "title": "Empirical Risk Minimization with $f$-Divergence Regularization",
    "summary": "In this paper, the solution to the empirical risk minimization problem with $f$-divergence regularization (ERM-$f$DR) is presented and conditions under which the solution also serves as the solution to the minimization of the expected empirical risk subject to an $f$-divergence constraint are established. The proposed approach extends applicability to a broader class of $f$-divergences than previously reported and yields theoretical results that recover previously known results. Additionally, the difference between the expected empirical risk of the ERM-$f$DR solution and that of its reference measure is characterized, providing insights into previously studied cases of $f$-divergences. A central contribution is the introduction of the normalization function, a mathematical object that is critical in both the dual formulation and practical computation of the ERM-$f$DR solution. This work presents an implicit characterization of the normalization function as a nonlinear ordinary differential equation (ODE), establishes its key properties, and subsequently leverages them to construct a numerical algorithm for approximating the normalization factor under mild assumptions. Further analysis demonstrates structural equivalences between ERM-$f$DR problems with different $f$-divergences via transformations of the empirical risk. Finally, the proposed algorithm is used to compute the training and test risks of ERM-$f$DR solutions under different $f$-divergence regularizers. This numerical example highlights the practical implications of choosing different functions $f$ in ERM-$f$DR problems.",
    "authors": [
      "Francisco Daunas",
      "Iñaki Esnaola",
      "Samir M. Perlaza",
      "H. Vincent Poor"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13191v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13191v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2601.13099v1",
    "title": "Alexandria: A Multi-Domain Dialectal Arabic Machine Translation Dataset for Culturally Inclusive and Linguistically Diverse LLMs",
    "summary": "Arabic is a highly diglossic language where most daily communication occurs in regional dialects rather than Modern Standard Arabic. Despite this, machine translation (MT) systems often generalize poorly to dialectal input, limiting their utility for millions of speakers. We introduce \\textbf{Alexandria}, a large-scale, community-driven, human-translated dataset designed to bridge this gap. Alexandria covers 13 Arab countries and 11 high-impact domains, including health, education, and agriculture. Unlike previous resources, Alexandria provides unprecedented granularity by associating contributions with city-of-origin metadata, capturing authentic local varieties beyond coarse regional labels. The dataset consists of multi-turn conversational scenarios annotated with speaker-addressee gender configurations, enabling the study of gender-conditioned variation in dialectal use. Comprising 107K total samples, Alexandria serves as both a training resource and a rigorous benchmark for evaluating MT and Large Language Models (LLMs). Our automatic and human evaluation of Arabic-aware LLMs benchmarks current capabilities in translating across diverse Arabic dialects and sub-dialects, while exposing significant persistent challenges.",
    "authors": [
      "Abdellah El Mekki",
      "Samar M. Magdy",
      "Houdaifa Atou",
      "Ruwa AbuHweidi",
      "Baraah Qawasmeh",
      "Omer Nacar",
      "Thikra Al-hibiri",
      "Razan Saadie",
      "Hamzah Alsayadi",
      "Nadia Ghezaiel Hammouda",
      "Alshima Alkhazimi",
      "Aya Hamod",
      "Al-Yas Al-Ghafri",
      "Wesam El-Sayed",
      "Asila Al sharji",
      "Mohamad Ballout",
      "Anas Belfathi",
      "Karim Ghaddar",
      "Serry Sibaee",
      "Alaa Aoun",
      "Areej Asiri",
      "Lina Abureesh",
      "Ahlam Bashiti",
      "Majdal Yousef",
      "Abdulaziz Hafiz",
      "Yehdih Mohamed",
      "Emira Hamedtou",
      "Brakehe Brahim",
      "Rahaf Alhamouri",
      "Youssef Nafea",
      "Aya El Aatar",
      "Walid Al-Dhabyani",
      "Emhemed Hamed",
      "Sara Shatnawi",
      "Fakhraddin Alwajih",
      "Khalid Elkhidir",
      "Ashwag Alasmari",
      "Abdurrahman Gerrio",
      "Omar Alshahri",
      "AbdelRahim A. Elmadany",
      "Ismail Berrada",
      "Amir Azad Adli Alkathiri",
      "Fadi A Zaraket",
      "Mustafa Jarrar",
      "Yahya Mohamed El Hadj",
      "Hassan Alhuzali",
      "Muhammad Abdul-Mageed"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13099v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13099v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2601.13537v1",
    "title": "When Wording Steers the Evaluation: Framing Bias in LLM judges",
    "summary": "Large language models (LLMs) are known to produce varying responses depending on prompt phrasing, indicating that subtle guidance in phrasing can steer their answers. However, the impact of this framing bias on LLM-based evaluation, where models are expected to make stable and impartial judgments, remains largely underexplored. Drawing inspiration from the framing effect in psychology, we systematically investigate how deliberate prompt framing skews model judgments across four high-stakes evaluation tasks. We design symmetric prompts using predicate-positive and predicate-negative constructions and demonstrate that such framing induces significant discrepancies in model outputs. Across 14 LLM judges, we observe clear susceptibility to framing, with model families showing distinct tendencies toward agreement or rejection. These findings suggest that framing bias is a structural property of current LLM-based evaluation systems, underscoring the need for framing-aware protocols.",
    "authors": [
      "Yerin Hwang",
      "Dongryeol Lee",
      "Taegwan Kang",
      "Minwoo Lee",
      "Kyomin Jung"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13537v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13537v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2601.13528v1",
    "title": "Eliciting Harmful Capabilities by Fine-Tuning On Safeguarded Outputs",
    "summary": "Model developers implement safeguards in frontier models to prevent misuse, for example, by employing classifiers to filter dangerous outputs. In this work, we demonstrate that even robustly safeguarded models can be used to elicit harmful capabilities in open-source models through elicitation attacks. Our elicitation attacks consist of three stages: (i) constructing prompts in adjacent domains to a target harmful task that do not request dangerous information; (ii) obtaining responses to these prompts from safeguarded frontier models; (iii) fine-tuning open-source models on these prompt-output pairs. Since the requested prompts cannot be used to directly cause harm, they are not refused by frontier model safeguards. We evaluate these elicitation attacks within the domain of hazardous chemical synthesis and processing, and demonstrate that our attacks recover approximately 40% of the capability gap between the base open-source model and an unrestricted frontier model. We then show that the efficacy of elicitation attacks scales with the capability of the frontier model and the amount of generated fine-tuning data. Our work demonstrates the challenge of mitigating ecosystem level risks with output-level safeguards.",
    "authors": [
      "Jackson Kaunismaa",
      "Avery Griffin",
      "John Hughes",
      "Christina Q. Knight",
      "Mrinank Sharma",
      "Erik Jones"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "cs.SE"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13528v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13528v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2601.13456v1",
    "title": "Federated Learning Under Temporal Drift - Mitigating Catastrophic Forgetting via Experience Replay",
    "summary": "Federated Learning struggles under temporal concept drift where client data distributions shift over time. We demonstrate that standard FedAvg suffers catastrophic forgetting under seasonal drift on Fashion-MNIST, with accuracy dropping from 74% to 28%. We propose client-side experience replay, where each client maintains a small buffer of past samples mixed with current data during local training. This simple approach requires no changes to server aggregation. Experiments show that a 50-sample-per-class buffer restores performance to 78-82%, effectively preventing forgetting. Our ablation study reveals a clear memory-accuracy trade-off as buffer size increases.",
    "authors": [
      "Sahasra Kokkula",
      "Daniel David",
      "Aaditya Baruah"
    ],
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13456v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13456v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2601.13376v1",
    "title": "Bounded Minds, Generative Machines: Envisioning Conversational AI that Works with Human Heuristics and Reduces Bias Risk",
    "summary": "Conversational AI is rapidly becoming a primary interface for information seeking and decision making, yet most systems still assume idealized users. In practice, human reasoning is bounded by limited attention, uneven knowledge, and reliance on heuristics that are adaptive but bias-prone. This article outlines a research pathway grounded in bounded rationality, and argues that conversational AI should be designed to work with human heuristics rather than against them. It identifies key directions for detecting cognitive vulnerability, supporting judgment under uncertainty, and evaluating conversational systems beyond factual accuracy, toward decision quality and cognitive robustness.",
    "authors": [
      "Jiqun Liu"
    ],
    "categories": [
      "cs.ET",
      "cs.AI",
      "cs.HC"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13376v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13376v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2601.13263v1",
    "title": "Deep Learning for Semantic Segmentation of 3D Ultrasound Data",
    "summary": "Developing cost-efficient and reliable perception systems remains a central challenge for automated vehicles. LiDAR and camera-based systems dominate, yet they present trade-offs in cost, robustness and performance under adverse conditions. This work introduces a novel framework for learning-based 3D semantic segmentation using Calyo Pulse, a modular, solid-state 3D ultrasound sensor system for use in harsh and cluttered environments. A 3D U-Net architecture is introduced and trained on the spatial ultrasound data for volumetric segmentation. Results demonstrate robust segmentation performance from Calyo Pulse sensors, with potential for further improvement through larger datasets, refined ground truth, and weighted loss functions. Importantly, this study highlights 3D ultrasound sensing as a promising complementary modality for reliable autonomy.",
    "authors": [
      "Chenyu Liu",
      "Marco Cecotti",
      "Harikrishnan Vijayakumar",
      "Patrick Robinson",
      "James Barson",
      "Mihai Caleap"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13263v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13263v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2601.13187v1",
    "title": "Scientific production in the era of Large Language Models",
    "summary": "Large Language Models (LLMs) are rapidly reshaping scientific research. We analyze these changes in multiple, large-scale datasets with 2.1M preprints, 28K peer review reports, and 246M online accesses to scientific documents. We find: 1) scientists adopting LLMs to draft manuscripts demonstrate a large increase in paper production, ranging from 23.7-89.3% depending on scientific field and author background, 2) LLM use has reversed the relationship between writing complexity and paper quality, leading to an influx of manuscripts that are linguistically complex but substantively underwhelming, and 3) LLM adopters access and cite more diverse prior work, including books and younger, less-cited documents. These findings highlight a stunning shift in scientific production that will likely require a change in how journals, funding agencies, and tenure committees evaluate scientific works.",
    "authors": [
      "Keigo Kusumegi",
      "Xinyu Yang",
      "Paul Ginsparg",
      "Mathijs de Vaan",
      "Toby Stuart",
      "Yian Yin"
    ],
    "categories": [
      "cs.DL",
      "cs.AI",
      "cs.CY",
      "physics.soc-ph"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13187v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13187v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2601.13075v1",
    "title": "METIS: Mentoring Engine for Thoughtful Inquiry & Solutions",
    "summary": "Many students lack access to expert research mentorship. We ask whether an AI mentor can move undergraduates from an idea to a paper. We build METIS, a tool-augmented, stage-aware assistant with literature search, curated guidelines, methodology checks, and memory. We evaluate METIS against GPT-5 and Claude Sonnet 4.5 across six writing stages using LLM-as-a-judge pairwise preferences, student-persona rubrics, short multi-turn tutoring, and evidence/compliance checks. On 90 single-turn prompts, LLM judges preferred METIS to Claude Sonnet 4.5 in 71% and to GPT-5 in 54%. Student scores (clarity/actionability/constraint-fit; 90 prompts x 3 judges) are higher across stages. In multi-turn sessions (five scenarios/agent), METIS yields slightly higher final quality than GPT-5. Gains concentrate in document-grounded stages (D-F), consistent with stage-aware routing and groundings failure modes include premature tool routing, shallow grounding, and occasional stage misclassification.",
    "authors": [
      "Abhinav Rajeev Kumar",
      "Dhruv Trehan",
      "Paras Chopra"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13075v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13075v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2601.12973v1",
    "title": "Pardon? Evaluating Conversational Repair in Large Audio-Language Models",
    "summary": "Large Audio-Language Models (LALMs) have demonstrated strong performance in spoken question answering (QA), with existing evaluations primarily focusing on answer accuracy and robustness to acoustic perturbations. However, such evaluations implicitly assume that spoken inputs remain semantically answerable, an assumption that often fails in real-world interaction when essential information is missing. In this work, we introduce a repair-aware evaluation setting that explicitly distinguishes between answerable and unanswerable audio inputs. We define answerability as a property of the input itself and construct paired evaluation conditions using a semantic-acoustic masking protocol. Based on this setting, we propose the Evaluability Awareness and Repair (EAR) score, a non-compensatory metric that jointly evaluates task competence under answerable conditions and repair behavior under unanswerable conditions. Experiments on two spoken QA benchmarks across diverse LALMs reveal a consistent gap between answer accuracy and conversational reliability: while many models perform well when inputs are answerable, most fail to recognize semantic unanswerability and initiate appropriate conversational repair. These findings expose a limitation of prevailing accuracy-centric evaluation practices and motivate reliability assessments that treat unanswerable inputs as cues for repair and continued interaction.",
    "authors": [
      "Shuanghong Huang",
      "Jinlei Xu",
      "Youchao Zhou",
      "Yanghao Zhou",
      "Xuan Zhao",
      "Chong Feng",
      "Wenxuan Zhang"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.12973v1",
    "pdf_url": "https://arxiv.org/pdf/2601.12973v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2601.13380v1",
    "title": "Practical Insights into Semi-Supervised Object Detection Approaches",
    "summary": "Learning in data-scarce settings has recently gained significant attention in the research community. Semi-supervised object detection(SSOD) aims to improve detection performance by leveraging a large number of unlabeled images alongside a limited number of labeled images(a.k.a.,few-shot learning). In this paper, we present a comprehensive comparison of three state-of-the-art SSOD approaches, including MixPL, Semi-DETR and Consistent-Teacher, with the goal of understanding how performance varies with the number of labeled images. We conduct experiments using the MS-COCO and Pascal VOC datasets, two popular object detection benchmarks which allow for standardized evaluation. In addition, we evaluate the SSOD approaches on a custom Beetle dataset which enables us to gain insights into their performance on specialized datasets with a smaller number of object categories. Our findings highlight the trade-offs between accuracy, model size, and latency, providing insights into which methods are best suited for low-data regimes.",
    "authors": [
      "Chaoxin Wang",
      "Bharaneeshwar Balasubramaniyam",
      "Anurag Sangem",
      "Nicolais Guevara",
      "Doina Caragea"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13380v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13380v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2601.13373v1",
    "title": "A Lightweight Model-Driven 4D Radar Framework for Pervasive Human Detection in Harsh Conditions",
    "summary": "Pervasive sensing in industrial and underground environments is severely constrained by airborne dust, smoke, confined geometry, and metallic structures, which rapidly degrade optical and LiDAR based perception. Elevation resolved 4D mmWave radar offers strong resilience to such conditions, yet there remains a limited understanding of how to process its sparse and anisotropic point clouds for reliable human detection in enclosed, visibility degraded spaces. This paper presents a fully model-driven 4D radar perception framework designed for real-time execution on embedded edge hardware. The system uses radar as its sole perception modality and integrates domain aware multi threshold filtering, ego motion compensated temporal accumulation, KD tree Euclidean clustering with Doppler aware refinement, and a rule based 3D classifier. The framework is evaluated in a dust filled enclosed trailer and in real underground mining tunnels, and in the tested scenarios the radar based detector maintains stable pedestrian identification as camera and LiDAR modalities fail under severe visibility degradation. These results suggest that the proposed model-driven approach provides robust, interpretable, and computationally efficient perception for safety-critical applications in harsh industrial and subterranean environments.",
    "authors": [
      "Zhenan Liu",
      "Amir Khajepour",
      "George Shaker"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13373v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13373v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2601.13348v1",
    "title": "The AI Genie Phenomenon and Three Types of AI Chatbot Addiction: Escapist Roleplays, Pseudosocial Companions, and Epistemic Rabbit Holes",
    "summary": "Recent reports on generative AI chatbot use raise concerns about its addictive potential. An in-depth understanding is imperative to minimize risks, yet AI chatbot addiction remains poorly understood. This study examines how to characterize AI chatbot addiction--why users become addicted, the symptoms commonly reported, and the distinct types it comprises. We conducted a thematic analysis of Reddit entries (n=334) across 14 subreddits where users narrated their experiences with addictive AI chatbot use, followed by an exploratory data analysis. We found: (1) users' dependence tied to the \"AI Genie\" phenomenon--users can get exactly anything they want with minimal effort--and marked by symptoms that align with addiction literature, (2) three distinct addiction types: Escapist Roleplay, Pseudosocial Companion, and Epistemic Rabbit Hole, (3) sexual content involved in multiple cases, and (4) recovery strategies' perceived helpfulness differ between addiction types. Our work lays empirical groundwork to inform future strategies for prevention, diagnosis, and intervention.",
    "authors": [
      "M. Karen Shen",
      "Jessica Huang",
      "Olivia Liang",
      "Ig-Jae Kim",
      "Dongwook Yoon"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13348v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13348v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2601.13304v1",
    "title": "CausalSpatial: A Benchmark for Object-Centric Causal Spatial Reasoning",
    "summary": "Humans can look at a static scene and instantly predict what happens next -- will moving this object cause a collision? We call this ability Causal Spatial Reasoning. However, current multimodal large language models (MLLMs) cannot do this, as they remain largely restricted to static spatial perception, struggling to answer \"what-if\" questions in a 3D scene. We introduce CausalSpatial, a diagnostic benchmark evaluating whether models can anticipate consequences of object motions across four tasks: Collision, Compatibility, Occlusion, and Trajectory. Results expose a severe gap: humans score 84% while GPT-5 achieves only 54%. Why do MLLMs fail? Our analysis uncovers a fundamental deficiency: models over-rely on textual chain-of-thought reasoning that drifts from visual evidence, producing fluent but spatially ungrounded hallucinations. To address this, we propose the Causal Object World model (COW), a framework that externalizes the simulation process by generating videos of hypothetical dynamics. With explicit visual cues of causality, COW enables models to ground their reasoning in physical reality rather than linguistic priors. We make the dataset and code publicly available here: https://github.com/CausalSpatial/CausalSpatial",
    "authors": [
      "Wenxin Ma",
      "Chenlong Wang",
      "Ruisheng Yuan",
      "Hao Chen",
      "Nanru Dai",
      "S. Kevin Zhou",
      "Yijun Yang",
      "Alan Yuille",
      "Jieneng Chen"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13304v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13304v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2601.13286v1",
    "title": "AI Skills Improve Job Prospects: Causal Evidence from a Hiring Experiment",
    "summary": "The growing adoption of artificial intelligence (AI) technologies has heightened interest in the labour market value of AI-related skills, yet causal evidence on their role in hiring decisions remains scarce. This study examines whether AI skills serve as a positive hiring signal and whether they can offset conventional disadvantages such as older age or lower formal education. We conduct an experimental survey with 1,700 recruiters from the United Kingdom and the United States. Using a paired conjoint design, recruiters evaluated hypothetical candidates represented by synthetically designed resumes. Across three occupations - graphic designer, office assistant, and software engineer - AI skills significantly increase interview invitation probabilities by approximately 8 to 15 percentage points. AI skills also partially or fully offset disadvantages related to age and lower education, with effects strongest for office assistants, where formal AI certification plays an additional compensatory role. Effects are weaker for graphic designers, consistent with more skeptical recruiter attitudes toward AI in creative work. Finally, recruiters' own background and AI usage significantly moderate these effects. Overall, the findings demonstrate that AI skills function as a powerful hiring signal and can mitigate traditional labour market disadvantages, with implications for workers' skill acquisition strategies and firms' recruitment practices.",
    "authors": [
      "Fabian Stephany",
      "Ole Teutloff",
      "Angelo Leone"
    ],
    "categories": [
      "econ.GN",
      "cs.AI"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13286v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13286v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2601.13234v1",
    "title": "ConvMambaNet: A Hybrid CNN-Mamba State Space Architecture for Accurate and Real-Time EEG Seizure Detection",
    "summary": "Epilepsy is a chronic neurological disorder marked by recurrent seizures that can severely impact quality of life. Electroencephalography (EEG) remains the primary tool for monitoring neural activity and detecting seizures, yet automated analysis remains challenging due to the temporal complexity of EEG signals. This study introduces ConvMambaNet, a hybrid deep learning model that integrates Convolutional Neural Networks (CNNs) with the Mamba Structured State Space Model (SSM) to enhance temporal feature extraction. By embedding the Mamba-SSM block within a CNN framework, the model effectively captures both spatial and long-range temporal dynamics. Evaluated on the CHB-MIT Scalp EEG dataset, ConvMambaNet achieved a 99% accuracy and demonstrated robust performance under severe class imbalance. These results underscore the model's potential for precise and efficient seizure detection, offering a viable path toward real-time, automated epilepsy monitoring in clinical environments.",
    "authors": [
      "Md. Nishan Khan",
      "Kazi Shahriar Sanjid",
      "Md. Tanzim Hossain",
      "Asib Mostakim Fony",
      "Istiak Ahmed",
      "M. Monir Uddin"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13234v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13234v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2601.13145v1",
    "title": "SolARED: Solar Active Region Emergence Dataset for Machine Learning Aided Predictions",
    "summary": "The development of accurate forecasts of solar eruptive activity has become increasingly important for preventing potential impacts on space technologies and exploration. Therefore, it is crucial to detect Active Regions (ARs) before they start forming on the solar surface. This will enable the development of early-warning capabilities for upcoming space weather disturbances. For this reason, we prepared the Solar Active Region Emergence Dataset (SolARED). The dataset is derived from full-disk maps of the Doppler velocity, magnetic field, and continuum intensity, obtained by the Helioseismic and Magnetic Imager (HMI) onboard the Solar Dynamics Observatory (SDO). SolARED includes time series of remapped, tracked, and binned data that characterize the evolution of acoustic power of solar oscillations, unsigned magnetic flux, and continuum intensity for 50 large ARs before, during, and after their emergence on the solar surface, as well as surrounding areas observed on the solar disc between 2010 and 2023. The resulting ML-ready SolARED dataset is designed to support enhancements of predictive capabilities, enabling the development of operational forecasts for the emergence of active regions. The SolARED dataset is available at https://sun.njit.edu/sarportal/, through an interactive visualization web application.",
    "authors": [
      "Spiridon Kasapis",
      "Eren Dogan",
      "Irina N. Kitiashvili",
      "Alexander G. Kosovichev",
      "John T. Stefan",
      "Jake D. Butler",
      "Jonas Tirona",
      "Sarang Patil",
      "Mengjia Xu"
    ],
    "categories": [
      "astro-ph.SR",
      "cs.LG"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13145v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13145v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2601.13416v1",
    "title": "Diffusion Representations for Fine-Grained Image Classification: A Marine Plankton Case Study",
    "summary": "Diffusion models have emerged as state-of-the-art generative methods for image synthesis, yet their potential as general-purpose feature encoders remains underexplored. Trained for denoising and generation without labels, they can be interpreted as self-supervised learners that capture both low- and high-level structure. We show that a frozen diffusion backbone enables strong fine-grained recognition by probing intermediate denoising features across layers and timesteps and training a linear classifier for each pair. We evaluate this in a real-world plankton-monitoring setting with practical impact, using controlled and comparable training setups against established supervised and self-supervised baselines. Frozen diffusion features are competitive with supervised baselines and outperform other self-supervised methods in both balanced and naturally long-tailed settings. Out-of-distribution evaluations on temporally and geographically shifted plankton datasets further show that frozen diffusion features maintain strong accuracy and Macro F1 under substantial distribution shift.",
    "authors": [
      "A. Nieto Juscafresa",
      "Á. Mazcuñán Herreros",
      "J. Sullivan"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13416v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13416v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.49
  },
  {
    "arxiv_id": "2601.13207v1",
    "title": "GTPred: Benchmarking MLLMs for Interpretable Geo-localization and Time-of-capture Prediction",
    "summary": "Geo-localization aims to infer the geographic location where an image was captured using observable visual evidence. Traditional methods achieve impressive results through large-scale training on massive image corpora. With the emergence of multi-modal large language models (MLLMs), recent studies have explored their applications in geo-localization, benefiting from improved accuracy and interpretability. However, existing benchmarks largely ignore the temporal information inherent in images, which can further constrain the location. To bridge this gap, we introduce GTPred, a novel benchmark for geo-temporal prediction. GTPred comprises 370 globally distributed images spanning over 120 years. We evaluate MLLM predictions by jointly considering year and hierarchical location sequence matching, and further assess intermediate reasoning chains using meticulously annotated ground-truth reasoning processes. Experiments on 8 proprietary and 7 open-source MLLMs show that, despite strong visual perception, current models remain limited in world knowledge and geo-temporal reasoning. Results also demonstrate that incorporating temporal information significantly enhances location inference performance.",
    "authors": [
      "Jinnao Li",
      "Zijian Chen",
      "Tingzhu Chen",
      "Changbo Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13207v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13207v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.49
  },
  {
    "arxiv_id": "2601.13059v1",
    "title": "Prototype Learning-Based Few-Shot Segmentation for Low-Light Crack on Concrete Structures",
    "summary": "Crack detection is critical for concrete infrastructure safety, but real-world cracks often appear in low-light environments like tunnels and bridge undersides, degrading computer vision segmentation accuracy. Pixel-level annotation of low-light crack images is extremely time-consuming, yet most deep learning methods require large, well-illuminated datasets. We propose a dual-branch prototype learning network integrating Retinex theory with few-shot learning for low-light crack segmentation. Retinex-based reflectance components guide illumination-invariant global representation learning, while metric learning reduces dependence on large annotated datasets. We introduce a cross-similarity prior mask generation module that computes high-dimensional similarities between query and support features to capture crack location and structure, and a multi-scale feature enhancement module that fuses multi-scale features with the prior mask to alleviate spatial inconsistency. Extensive experiments on multiple benchmarks demonstrate consistent state-of-the-art performance under low-light conditions. Code: https://github.com/YulunGuo/CrackFSS.",
    "authors": [
      "Yulun Guo"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13059v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13059v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.49
  },
  {
    "arxiv_id": "2601.13170v1",
    "title": "Global stability of a Hebbian/anti-Hebbian network for principal subspace learning",
    "summary": "Biological neural networks self-organize according to local synaptic modifications to produce stable computations. How modifications at the synaptic level give rise to such computations at the network level remains an open question. Pehlevan et al. [Neur. Comp. 27 (2015), 1461--1495] proposed a model of a self-organizing neural network with Hebbian and anti-Hebbian synaptic updates that implements an algorithm for principal subspace analysis; however, global stability of the nonlinear synaptic dynamics has not been established. Here, for the case that the feedforward and recurrent weights evolve at the same timescale, we prove global stability of the continuum limit of the synaptic dynamics and show that the dynamics evolve in two phases. In the first phase, the synaptic weights converge to an invariant manifold where the `neural filters' are orthonormal. In the second phase, the synaptic dynamics follow the gradient flow of a non-convex potential function whose minima correspond to neural filters that span the principal subspace of the input data.",
    "authors": [
      "David Lipshutz",
      "Robert J. Lipshutz"
    ],
    "categories": [
      "q-bio.NC",
      "cs.NE",
      "math.DS"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13170v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13170v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.47
  },
  {
    "arxiv_id": "2601.13134v1",
    "title": "Earth Embeddings as Products: Taxonomy, Ecosystem, and Standardized Access",
    "summary": "Geospatial Foundation Models (GFMs) provide powerful representations, but high compute costs hinder their widespread use. Pre-computed embedding data products offer a practical \"frozen\" alternative, yet they currently exist in a fragmented ecosystem of incompatible formats and resolutions. This lack of standardization creates an engineering bottleneck that prevents meaningful model comparison and reproducibility. We formalize this landscape through a three-layer taxonomy: Data, Tools, and Value. We survey existing products to identify interoperability barriers. To bridge this gap, we extend TorchGeo with a unified API that standardizes the loading and querying of diverse embedding products. By treating embeddings as first-class geospatial datasets, we decouple downstream analysis from model-specific engineering, providing a roadmap for more transparent and accessible Earth observation workflows.",
    "authors": [
      "Heng Fang",
      "Adam J. Stewart",
      "Isaac Corley",
      "Xiao Xiang Zhu",
      "Hossein Azizpour"
    ],
    "categories": [
      "cs.SE",
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13134v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13134v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.46
  },
  {
    "arxiv_id": "2601.13498v1",
    "title": "Optical Linear Systems Framework for Event Sensing and Computational Neuromorphic Imaging",
    "summary": "Event vision sensors (neuromorphic cameras) output sparse, asynchronous ON/OFF events triggered by log-intensity threshold crossings, enabling microsecond-scale sensing with high dynamic range and low data bandwidth. As a nonlinear system, this event representation does not readily integrate with the linear forward models that underpin most computational imaging and optical system design. We present a physics-grounded processing pipeline that maps event streams to estimates of per-pixel log-intensity and intensity derivatives, and embeds these measurements in a dynamic linear systems model with a time-varying point spread function. This enables inverse filtering directly from event data, using frequency-domain Wiener deconvolution with a known (or parameterised) dynamic transfer function. We validate the approach in simulation for single and overlapping point sources under modulated defocus, and on real event data from a tunable-focus telescope imaging a star field, demonstrating source localisation and separability. The proposed framework provides a practical bridge between event sensing and model-based computational imaging for dynamic optical systems.",
    "authors": [
      "Nimrod Kruger",
      "Nicholas Owen Ralph",
      "Gregory Cohen",
      "Paul Hurley"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13498v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13498v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.45
  },
  {
    "arxiv_id": "2601.13551v1",
    "title": "DiffFace-Edit: A Diffusion-Based Facial Dataset for Forgery-Semantic Driven Deepfake Detection Analysis",
    "summary": "Generative models now produce imperceptible, fine-grained manipulated faces, posing significant privacy risks. However, existing AI-generated face datasets generally lack focus on samples with fine-grained regional manipulations. Furthermore, no researchers have yet studied the real impact of splice attacks, which occur between real and manipulated samples, on detectors. We refer to these as detector-evasive samples. Based on this, we introduce the DiffFace-Edit dataset, which has the following advantages: 1) It contains over two million AI-generated fake images. 2) It features edits across eight facial regions (e.g., eyes, nose) and includes a richer variety of editing combinations, such as single-region and multi-region edits. Additionally, we specifically analyze the impact of detector-evasive samples on detection models. We conduct a comprehensive analysis of the dataset and propose a cross-domain evaluation that combines IMDL methods. Dataset will be available at https://github.com/ywh1093/DiffFace-Edit.",
    "authors": [
      "Feng Ding",
      "Wenhui Yi",
      "Xinan He",
      "Mengyao Xiao",
      "Jianfeng Xu",
      "Jianqiang Du"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-20",
    "url": "https://arxiv.org/abs/2601.13551v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13551v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.44
  },
  {
    "arxiv_id": "2601.13148v1",
    "title": "ICo3D: An Interactive Conversational 3D Virtual Human",
    "summary": "This work presents Interactive Conversational 3D Virtual Human (ICo3D), a method for generating an interactive, conversational, and photorealistic 3D human avatar. Based on multi-view captures of a subject, we create an animatable 3D face model and a dynamic 3D body model, both rendered by splatting Gaussian primitives. Once merged together, they represent a lifelike virtual human avatar suitable for real-time user interactions. We equip our avatar with an LLM for conversational ability. During conversation, the audio speech of the avatar is used as a driving signal to animate the face model, enabling precise synchronization. We describe improvements to our dynamic Gaussian models that enhance photorealism: SWinGS++ for body reconstruction and HeadGaS++ for face reconstruction, and provide as well a solution to merge the separate face and body models without artifacts. We also present a demo of the complete system, showcasing several use cases of real-time conversation with the 3D avatar. Our approach offers a fully integrated virtual avatar experience, supporting both oral and written form interactions in immersive environments. ICo3D is applicable to a wide range of fields, including gaming, virtual assistance, and personalized education, among others. Project page: https://ico3d.github.io/",
    "authors": [
      "Richard Shaw",
      "Youngkyoon Jang",
      "Athanasios Papaioannou",
      "Arthur Moreau",
      "Helisa Dhamo",
      "Zhensong Zhang",
      "Eduardo Pérez-Pellitero"
    ],
    "categories": [
      "cs.CV",
      "cs.HC"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13148v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13148v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.44
  },
  {
    "arxiv_id": "2601.13052v1",
    "title": "GridNet-HD: A High-Resolution Multi-Modal Dataset for LiDAR-Image Fusion on Power Line Infrastructure",
    "summary": "This paper presents GridNet-HD, a multi-modal dataset for 3D semantic segmentation of overhead electrical infrastructures, pairing high-density LiDAR with high-resolution oblique imagery. The dataset comprises 7,694 images and 2.5 billion points annotated into 11 classes, with predefined splits and mIoU metrics. Unimodal (LiDAR-only, image-only) and multi-modal fusion baselines are provided. On GridNet-HD, fusion models outperform the best unimodal baseline by +5.55 mIoU, highlighting the complementarity of geometry and appearance. As reviewed in Sec. 2, no public dataset jointly provides high-density LiDAR and high-resolution oblique imagery with 3D semantic labels for power-line assets. Dataset, baselines, and codes are available: https://huggingface.co/collections/heig-vd-geo/gridnet-hd.",
    "authors": [
      "Antoine Carreaud",
      "Shanci Li",
      "Malo De Lacour",
      "Digre Frinde",
      "Jan Skaloud",
      "Adrien Gressin"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2026-01-19",
    "url": "https://arxiv.org/abs/2601.13052v1",
    "pdf_url": "https://arxiv.org/pdf/2601.13052v1.pdf",
    "date": "2026-01-21",
    "source": "arxiv",
    "research_score": 0.42
  }
]