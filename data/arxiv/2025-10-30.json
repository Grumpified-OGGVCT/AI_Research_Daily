[
  {
    "arxiv_id": "2510.25370v1",
    "title": "Monitoring Transformative Technological Convergence Through   LLM-Extracted Semantic Entity Triple Graphs",
    "summary": "Forecasting transformative technologies remains a critical but challenging task, particularly in fast-evolving domains such as Information and Communication Technologies (ICTs). Traditional expert-based methods struggle to keep pace with short innovation cycles and ambiguous early-stage terminology. In this work, we propose a novel, data-driven pipeline to monitor the emergence of transformative technologies by identifying patterns of technological convergence.   Our approach leverages advances in Large Language Models (LLMs) to extract semantic triples from unstructured text and construct a large-scale graph of technology-related entities and relations. We introduce a new method for grouping semantically similar technology terms (noun stapling) and develop graph-based metrics to detect convergence signals. The pipeline includes multi-stage filtering, domain-specific keyword clustering, and a temporal trend analysis of topic co-occurence.   We validate our methodology on two complementary datasets: 278,625 arXiv preprints (2017--2024) to capture early scientific signals, and 9,793 USPTO patent applications (2018-2024) to track downstream commercial developments. Our results demonstrate that the proposed pipeline can identify both established and emerging convergence patterns, offering a scalable and generalizable framework for technology forecasting grounded in full-text analysis.",
    "authors": [
      "Alexander Sternfeld",
      "Andrei Kucharavy",
      "Dimitri Percia David",
      "Alain Mermoud",
      "Julian Jang-Jaccard",
      "Nathan Monnet"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25370v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25370v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.94
  },
  {
    "arxiv_id": "2510.25228v1",
    "title": "Studies for : A Human-AI Co-Creative Sound Artwork Using a Real-time   Multi-channel Sound Generation Model",
    "summary": "This paper explores the integration of AI technologies into the artistic workflow through the creation of Studies for, a generative sound installation developed in collaboration with sound artist Evala (https://www.ntticc.or.jp/en/archive/works/studies-for/). The installation employs SpecMaskGIT, a lightweight yet high-quality sound generation AI model, to generate and playback eight-channel sound in real-time, creating an immersive auditory experience over the course of a three-month exhibition. The work is grounded in the concept of a \"new form of archive,\" which aims to preserve the artistic style of an artist while expanding beyond artists' past artworks by continued generation of new sound elements. This speculative approach to archival preservation is facilitated by training the AI model on a dataset consisting of over 200 hours of Evala's past sound artworks.   By addressing key requirements in the co-creation of art using AI, this study highlights the value of the following aspects: (1) the necessity of integrating artist feedback, (2) datasets derived from an artist's past works, and (3) ensuring the inclusion of unexpected, novel outputs. In Studies for, the model was designed to reflect the artist's artistic identity while generating new, previously unheard sounds, making it a fitting realization of the concept of \"a new form of archive.\" We propose a Human-AI co-creation framework for effectively incorporating sound generation AI models into the sound art creation process and suggest new possibilities for creating and archiving sound art that extend an artist's work beyond their physical existence. Demo page: https://sony.github.io/studies-for/",
    "authors": [
      "Chihiro Nagashima",
      "Akira Takahashi",
      "Zhi Zhong",
      "Shusuke Takahashi",
      "Yuki Mitsufuji"
    ],
    "categories": [
      "cs.SD",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25228v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25228v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.93
  },
  {
    "arxiv_id": "2510.25241v1",
    "title": "One-shot Humanoid Whole-body Motion Learning",
    "summary": "Whole-body humanoid motion represents a cornerstone challenge in robotics, integrating balance, coordination, and adaptability to enable human-like behaviors. However, existing methods typically require multiple training samples per motion category, rendering the collection of high-quality human motion datasets both labor-intensive and costly. To address this, we propose a novel approach that trains effective humanoid motion policies using only a single non-walking target motion sample alongside readily available walking motions. The core idea lies in leveraging order-preserving optimal transport to compute distances between walking and non-walking sequences, followed by interpolation along geodesics to generate new intermediate pose skeletons, which are then optimized for collision-free configurations and retargeted to the humanoid before integration into a simulated environment for policy training via reinforcement learning. Experimental evaluations on the CMU MoCap dataset demonstrate that our method consistently outperforms baselines, achieving superior performance across metrics. Code will be released upon acceptance.",
    "authors": [
      "Hao Huang",
      "Geeta Chandra Raju Bethala",
      "Shuaihang Yuan",
      "Congcong Wen",
      "Anthony Tzes",
      "Yi Fang"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25241v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25241v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.91
  },
  {
    "arxiv_id": "2510.25741v1",
    "title": "Scaling Latent Reasoning via Looped Language Models",
    "summary": "Modern LLMs are trained to \"think\" primarily via explicit text generation, such as chain-of-thought (CoT), which defers reasoning to post-training and under-leverages pre-training data. We present and open-source Ouro, named after the recursive Ouroboros, a family of pre-trained Looped Language Models (LoopLM) that instead build reasoning into the pre-training phase through (i) iterative computation in latent space, (ii) an entropy-regularized objective for learned depth allocation, and (iii) scaling to 7.7T tokens. Ouro 1.4B and 2.6B models enjoy superior performance that match the results of up to 12B SOTA LLMs across a wide range of benchmarks. Through controlled experiments, we show this advantage stems not from increased knowledge capacity, but from superior knowledge manipulation capabilities. We also show that LoopLM yields reasoning traces more aligned with final outputs than explicit CoT. We hope our results show the potential of LoopLM as a novel scaling direction in the reasoning era. Our model could be found in: http://ouro-llm.github.io.",
    "authors": [
      "Rui-Jie Zhu",
      "Zixuan Wang",
      "Kai Hua",
      "Tianyu Zhang",
      "Ziniu Li",
      "Haoran Que",
      "Boyi Wei",
      "Zixin Wen",
      "Fan Yin",
      "He Xing",
      "Lu Li",
      "Jiajun Shi",
      "Kaijing Ma",
      "Shanda Li",
      "Taylor Kergan",
      "Andrew Smith",
      "Xingwei Qu",
      "Mude Hui",
      "Bohong Wu",
      "Qiyang Min",
      "Hongzhi Huang",
      "Xun Zhou",
      "Wei Ye",
      "Jiaheng Liu",
      "Jian Yang",
      "Yunfeng Shi",
      "Chenghua Lin",
      "Enduo Zhao",
      "Tianle Cai",
      "Ge Zhang",
      "Wenhao Huang",
      "Yoshua Bengio",
      "Jason Eshraghian"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25741v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25741v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.87
  },
  {
    "arxiv_id": "2510.25612v1",
    "title": "Counterfactual-based Agent Influence Ranker for Agentic AI Workflows",
    "summary": "An Agentic AI Workflow (AAW), also known as an LLM-based multi-agent system, is an autonomous system that assembles several LLM-based agents to work collaboratively towards a shared goal. The high autonomy, widespread adoption, and growing interest in such AAWs highlight the need for a deeper understanding of their operations, from both quality and security aspects. To this day, there are no existing methods to assess the influence of each agent on the AAW's final output. Adopting techniques from related fields is not feasible since existing methods perform only static structural analysis, which is unsuitable for inference time execution. We present Counterfactual-based Agent Influence Ranker (CAIR) - the first method for assessing the influence level of each agent on the AAW's output and determining which agents are the most influential. By performing counterfactual analysis, CAIR provides a task-agnostic analysis that can be used both offline and at inference time. We evaluate CAIR using an AAWs dataset of our creation, containing 30 different use cases with 230 different functionalities. Our evaluation showed that CAIR produces consistent rankings, outperforms baseline methods, and can easily enhance the effectiveness and relevancy of downstream tasks.",
    "authors": [
      "Amit Giloni",
      "Chiara Picardi",
      "Roy Betser",
      "Shamik Bose",
      "Aishvariya Priya Rathina Sabapathy",
      "Roman Vainshtein"
    ],
    "categories": [
      "cs.AI",
      "cs.MA"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25612v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25612v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.87
  },
  {
    "arxiv_id": "2510.25670v1",
    "title": "Spectral Perturbation Bounds for Low-Rank Approximation with   Applications to Privacy",
    "summary": "A central challenge in machine learning is to understand how noise or measurement errors affect low-rank approximations, particularly in the spectral norm. This question is especially important in differentially private low-rank approximation, where one aims to preserve the top-$p$ structure of a data-derived matrix while ensuring privacy. Prior work often analyzes Frobenius norm error or changes in reconstruction quality, but these metrics can over- or under-estimate true subspace distortion. The spectral norm, by contrast, captures worst-case directional error and provides the strongest utility guarantees. We establish new high-probability spectral-norm perturbation bounds for symmetric matrices that refine the classical Eckart--Young--Mirsky theorem and explicitly capture interactions between a matrix $A \\in \\mathbb{R}^{n \\times n}$ and an arbitrary symmetric perturbation $E$. Under mild eigengap and norm conditions, our bounds yield sharp estimates for $\\|(A + E)_p - A_p\\|$, where $A_p$ is the best rank-$p$ approximation of $A$, with improvements of up to a factor of $\\sqrt{n}$. As an application, we derive improved utility guarantees for differentially private PCA, resolving an open problem in the literature. Our analysis relies on a novel contour bootstrapping method from complex analysis and extends it to a broad class of spectral functionals, including polynomials and matrix exponentials. Empirical results on real-world datasets confirm that our bounds closely track the actual spectral error under diverse perturbation regimes.",
    "authors": [
      "Phuc Tran",
      "Nisheeth K. Vishnoi",
      "Van H. Vu"
    ],
    "categories": [
      "cs.LG",
      "cs.CR",
      "cs.DS",
      "cs.NA",
      "math.NA",
      "math.SP"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25670v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25670v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.84
  },
  {
    "arxiv_id": "2510.25571v1",
    "title": "Perturbation Bounds for Low-Rank Inverse Approximations under Noise",
    "summary": "Low-rank pseudoinverses are widely used to approximate matrix inverses in scalable machine learning, optimization, and scientific computing. However, real-world matrices are often observed with noise, arising from sampling, sketching, and quantization. The spectral-norm robustness of low-rank inverse approximations remains poorly understood. We systematically study the spectral-norm error $\\| (\\tilde{A}^{-1})_p - A_p^{-1} \\|$ for an $n\\times n$ symmetric matrix $A$, where $A_p^{-1}$ denotes the best rank-\\(p\\) approximation of $A^{-1}$, and $\\tilde{A} = A + E$ is a noisy observation. Under mild assumptions on the noise, we derive sharp non-asymptotic perturbation bounds that reveal how the error scales with the eigengap, spectral decay, and noise alignment with low-curvature directions of $A$. Our analysis introduces a novel application of contour integral techniques to the \\emph{non-entire} function $f(z) = 1/z$, yielding bounds that improve over naive adaptations of classical full-inverse bounds by up to a factor of $\\sqrt{n}$. Empirically, our bounds closely track the true perturbation error across a variety of real-world and synthetic matrices, while estimates based on classical results tend to significantly overpredict. These findings offer practical, spectrum-aware guarantees for low-rank inverse approximations in noisy computational environments.",
    "authors": [
      "Phuc Tran",
      "Nisheeth K. Vishnoi"
    ],
    "categories": [
      "cs.LG",
      "cs.DS",
      "cs.NA",
      "math.NA",
      "math.SP",
      "math.ST",
      "stat.TH"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25571v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25571v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.84
  },
  {
    "arxiv_id": "2510.25759v1",
    "title": "Synthetic Data Reveals Generalization Gaps in Correlated Multiple   Instance Learning",
    "summary": "Multiple instance learning (MIL) is often used in medical imaging to classify high-resolution 2D images by processing patches or classify 3D volumes by processing slices. However, conventional MIL approaches treat instances separately, ignoring contextual relationships such as the appearance of nearby patches or slices that can be essential in real applications. We design a synthetic classification task where accounting for adjacent instance features is crucial for accurate prediction. We demonstrate the limitations of off-the-shelf MIL approaches by quantifying their performance compared to the optimal Bayes estimator for this task, which is available in closed-form. We empirically show that newer correlated MIL methods still struggle to generalize as well as possible when trained from scratch on tens of thousands of instances.",
    "authors": [
      "Ethan Harvey",
      "Dennis Johan Loevlie",
      "Michael C. Hughes"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25759v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25759v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.82
  },
  {
    "arxiv_id": "2510.25110v1",
    "title": "DEBATE: A Large-Scale Benchmark for Role-Playing LLM Agents in   Multi-Agent, Long-Form Debates",
    "summary": "Accurately modeling opinion change through social interactions is crucial for addressing issues like misinformation and polarization. While role-playing large language models (LLMs) offer a promising way to simulate human-like interactions, existing research shows that single-agent alignment does not guarantee authentic multi-agent group dynamics. Current LLM role-play setups often produce unnatural dynamics (e.g., premature convergence), without an empirical benchmark to measure authentic human opinion trajectories. To bridge this gap, we introduce DEBATE, the first large-scale empirical benchmark explicitly designed to evaluate the authenticity of the interaction between multi-agent role-playing LLMs. DEBATE contains 29,417 messages from multi-round debate conversations among over 2,792 U.S.-based participants discussing 107 controversial topics, capturing both publicly-expressed messages and privately-reported opinions. Using DEBATE, we systematically evaluate and identify critical discrepancies between simulated and authentic group dynamics. We further demonstrate DEBATE's utility for aligning LLMs with human behavior through supervised fine-tuning, achieving improvements in surface-level metrics (e.g., ROUGE-L and message length) while highlighting limitations in deeper semantic alignment (e.g., semantic similarity). Our findings highlight both the potential and current limitations of role-playing LLM agents for realistically simulating human-like social dynamics.",
    "authors": [
      "Yun-Shiuan Chuang",
      "Ruixuan Tu",
      "Chengtao Dai",
      "Smit Vasani",
      "Binwei Yao",
      "Michael Henry Tessler",
      "Sijia Yang",
      "Dhavan Shah",
      "Robert Hawkins",
      "Junjie Hu",
      "Timothy T. Rogers"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25110v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25110v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.81
  },
  {
    "arxiv_id": "2510.25668v1",
    "title": "ALDEN: Reinforcement Learning for Active Navigation and Evidence   Gathering in Long Documents",
    "summary": "Vision-language models (VLMs) excel at interpreting text-rich images but struggle with long, visually complex documents that demand analysis and integration of information spread across multiple pages. Existing approaches typically rely on fixed reasoning templates or rigid pipelines, which force VLMs into a passive role and hinder both efficiency and generalization. We present Active Long-DocumEnt Navigation (ALDEN), a multi-turn reinforcement learning framework that fine-tunes VLMs as interactive agents capable of actively navigating long, visually rich documents. ALDEN introduces a novel fetch action that directly accesses the page by index, complementing the classic search action and better exploiting document structure. For dense process supervision and efficient training, we propose a rule-based cross-level reward that provides both turn- and token-level signals. To address the empirically observed training instability caused by numerous visual tokens from long documents, we further propose a visual-semantic anchoring mechanism that applies a dual-path KL-divergence constraint to stabilize visual and textual representations separately during training. Trained on a corpus constructed from three open-source datasets, ALDEN achieves state-of-the-art performance on five long-document benchmarks. Overall, ALDEN marks a step beyond passive document reading toward agents that autonomously navigate and reason across long, visually rich documents, offering a robust path to more accurate and efficient long-document understanding.",
    "authors": [
      "Tianyu Yang",
      "Terry Ruas",
      "Yijun Tian",
      "Jan Philip Wahle",
      "Daniel Kurzawe",
      "Bela Gipp"
    ],
    "categories": [
      "cs.AI",
      "cs.MM"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25668v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25668v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.78
  },
  {
    "arxiv_id": "2510.25320v1",
    "title": "GAP: Graph-Based Agent Planning with Parallel Tool Use and Reinforcement   Learning",
    "summary": "Autonomous agents powered by large language models (LLMs) have shown impressive capabilities in tool manipulation for complex task-solving. However, existing paradigms such as ReAct rely on sequential reasoning and execution, failing to exploit the inherent parallelism among independent sub-tasks. This sequential bottleneck leads to inefficient tool utilization and suboptimal performance in multi-step reasoning scenarios. We introduce Graph-based Agent Planning (GAP), a novel framework that explicitly models inter-task dependencies through graph-based planning to enable adaptive parallel and serial tool execution. Our approach trains agent foundation models to decompose complex tasks into dependency-aware sub-task graphs, autonomously determining which tools can be executed in parallel and which must follow sequential dependencies. This dependency-aware orchestration achieves substantial improvements in both execution efficiency and task accuracy. To train GAP, we construct a high-quality dataset of graph-based planning traces derived from the Multi-Hop Question Answering (MHQA) benchmark. We employ a two-stage training strategy: supervised fine-tuning (SFT) on the curated dataset, followed by reinforcement learning (RL) with a correctness-based reward function on strategically sampled queries where tool-based reasoning provides maximum value. Experimental results on MHQA datasets demonstrate that GAP significantly outperforms traditional ReAct baselines, particularly on multi-step retrieval tasks, while achieving dramatic improvements in tool invocation efficiency through intelligent parallelization. The project page is available at: https://github.com/WJQ7777/Graph-Agent-Planning.",
    "authors": [
      "Jiaqi Wu",
      "Qinlao Zhao",
      "Zefeng Chen",
      "Kai Qin",
      "Yifei Zhao",
      "Xueqian Wang",
      "Yuhang Yao"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25320v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25320v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2510.25621v1",
    "title": "FARSIQA: Faithful and Advanced RAG System for Islamic Question Answering",
    "summary": "The advent of Large Language Models (LLMs) has revolutionized Natural Language Processing, yet their application in high-stakes, specialized domains like religious question answering is hindered by challenges like hallucination and unfaithfulness to authoritative sources. This issue is particularly critical for the Persian-speaking Muslim community, where accuracy and trustworthiness are paramount. Existing Retrieval-Augmented Generation (RAG) systems, relying on simplistic single-pass pipelines, fall short on complex, multi-hop queries requiring multi-step reasoning and evidence aggregation. To address this gap, we introduce FARSIQA, a novel, end-to-end system for Faithful Advanced Question Answering in the Persian Islamic domain. FARSIQA is built upon our innovative FAIR-RAG architecture: a Faithful, Adaptive, Iterative Refinement framework for RAG. FAIR-RAG employs a dynamic, self-correcting process: it adaptively decomposes complex queries, assesses evidence sufficiency, and enters an iterative loop to generate sub-queries, progressively filling information gaps. Operating on a curated knowledge base of over one million authoritative Islamic documents, FARSIQA demonstrates superior performance. Rigorous evaluation on the challenging IslamicPCQA benchmark shows state-of-the-art performance: the system achieves a remarkable 97.0% in Negative Rejection - a 40-point improvement over baselines - and a high Answer Correctness score of 74.3%. Our work establishes a new standard for Persian Islamic QA and validates that our iterative, adaptive architecture is crucial for building faithful, reliable AI systems in sensitive domains.",
    "authors": [
      "Mohammad Aghajani Asl",
      "Behrooz Minaei Bidgoli"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR",
      "68T50, 68T05, 68T30",
      "I.2.7; H.3.3"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25621v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25621v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.75
  },
  {
    "arxiv_id": "2510.25372v1",
    "title": "Prompt Estimation from Prototypes for Federated Prompt Tuning of Vision   Transformers",
    "summary": "Visual Prompt Tuning (VPT) of pre-trained Vision Transformers (ViTs) has proven highly effective as a parameter-efficient fine-tuning technique for adapting large models to downstream tasks with limited data. Its parameter efficiency makes it particularly suitable for Federated Learning (FL), where both communication and computation budgets are often constrained. However, global prompt tuning struggles to generalize across heterogeneous clients, while personalized tuning overfits to local data and lacks generalization. We propose PEP-FedPT (Prompt Estimation from Prototypes for Federated Prompt Tuning), a unified framework designed to achieve both generalization and personalization in federated prompt tuning of ViTs. Within this framework, we introduce the novel Class-Contextualized Mixed Prompt (CCMP) - based on class-specific prompts maintained alongside a globally shared prompt. For each input, CCMP adaptively combines class-specific prompts using weights derived from global class prototypes and client class priors. This approach enables per-sample prompt personalization without storing client-dependent trainable parameters. The prompts are collaboratively optimized via traditional federated averaging technique on the same. Comprehensive evaluations on CIFAR-100, TinyImageNet, DomainNet, and iNaturalist datasets demonstrate that PEP-FedPT consistently surpasses the state-of-the-art baselines under diverse data heterogeneity scenarios, establishing a strong foundation for efficient and generalizable federated prompt tuning of Vision Transformers.",
    "authors": [
      "M Yashwanth",
      "Sharannya Ghosh",
      "Aditay Tripathi",
      "Anirban Chakraborty"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25372v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25372v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.75
  },
  {
    "arxiv_id": "2510.25696v1",
    "title": "Convolutional Spiking-based GRU Cell for Spatio-temporal Data",
    "summary": "Spike-based temporal messaging enables SNNs to efficiently process both purely temporal and spatio-temporal time-series or event-driven data. Combining SNNs with Gated Recurrent Units (GRUs), a variant of recurrent neural networks, gives rise to a robust framework for sequential data processing; however, traditional RNNs often lose local details when handling long sequences. Previous approaches, such as SpikGRU, fail to capture fine-grained local dependencies in event-based spatio-temporal data. In this paper, we introduce the Convolutional Spiking GRU (CS-GRU) cell, which leverages convolutional operations to preserve local structure and dependencies while integrating the temporal precision of spiking neurons with the efficient gating mechanisms of GRUs. This versatile architecture excels on both temporal datasets (NTIDIGITS, SHD) and spatio-temporal benchmarks (MNIST, DVSGesture, CIFAR10DVS). Our experiments show that CS-GRU outperforms state-of-the-art GRU variants by an average of 4.35%, achieving over 90% accuracy on sequential tasks and up to 99.31% on MNIST. It is worth noting that our solution achieves 69% higher efficiency compared to SpikGRU. The code is available at: https://github.com/YesmineAbdennadher/CS-GRU.",
    "authors": [
      "Yesmine Abdennadher",
      "Eleonora Cicciarella",
      "Michele Rossi"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25696v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25696v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2510.25348v1",
    "title": "Beyond Leakage and Complexity: Towards Realistic and Efficient   Information Cascade Prediction",
    "summary": "Information cascade popularity prediction is a key problem in analyzing content diffusion in social networks. However, current related works suffer from three critical limitations: (1) temporal leakage in current evaluation--random cascade-based splits allow models to access future information, yielding unrealistic results; (2) feature-poor datasets that lack downstream conversion signals (e.g., likes, comments, or purchases), which limits more practical applications; (3) computational inefficiency of complex graph-based methods that require days of training for marginal gains. We systematically address these challenges from three perspectives: task setup, dataset construction, and model design. First, we propose a time-ordered splitting strategy that chronologically partitions data into consecutive windows, ensuring models are evaluated on genuine forecasting tasks without future information leakage. Second, we introduce Taoke, a large-scale e-commerce cascade dataset featuring rich promoter/product attributes and ground-truth purchase conversions--capturing the complete diffusion lifecycle from promotion to monetization. Third, we develop CasTemp, a lightweight framework that efficiently models cascade dynamics through temporal walks, Jaccard-based neighbor selection for inter-cascade dependencies, and GRU-based encoding with time-aware attention. Under leak-free evaluation, CasTemp achieves state-of-the-art performance across four datasets with orders-of-magnitude speedup. Notably, it excels at predicting second-stage popularity conversions--a practical task critical for real-world applications.",
    "authors": [
      "Jie Peng",
      "Rui Wang",
      "Qiang Wang",
      "Zhewei Wei",
      "Bin Tong",
      "Guan Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.SI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25348v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25348v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.74
  },
  {
    "arxiv_id": "2510.25220v1",
    "title": "GReF: A Unified Generative Framework for Efficient Reranking via Ordered   Multi-token Prediction",
    "summary": "In a multi-stage recommendation system, reranking plays a crucial role in modeling intra-list correlations among items. A key challenge lies in exploring optimal sequences within the combinatorial space of permutations. Recent research follows a two-stage (generator-evaluator) paradigm, where a generator produces multiple feasible sequences, and an evaluator selects the best one. In practice, the generator is typically implemented as an autoregressive model. However, these two-stage methods face two main challenges. First, the separation of the generator and evaluator hinders end-to-end training. Second, autoregressive generators suffer from inference efficiency. In this work, we propose a Unified Generative Efficient Reranking Framework (GReF) to address the two primary challenges. Specifically, we introduce Gen-Reranker, an autoregressive generator featuring a bidirectional encoder and a dynamic autoregressive decoder to generate causal reranking sequences. Subsequently, we pre-train Gen-Reranker on the item exposure order for high-quality parameter initialization. To eliminate the need for the evaluator while integrating sequence-level evaluation during training for end-to-end optimization, we propose post-training the model through Rerank-DPO. Moreover, for efficient autoregressive inference, we introduce ordered multi-token prediction (OMTP), which trains Gen-Reranker to simultaneously generate multiple future items while preserving their order, ensuring practical deployment in real-time recommender systems. Extensive offline experiments demonstrate that GReF outperforms state-of-the-art reranking methods while achieving latency that is nearly comparable to non-autoregressive models. Additionally, GReF has also been deployed in a real-world video app Kuaishou with over 300 million daily active users, significantly improving online recommendation quality.",
    "authors": [
      "Zhijie Lin",
      "Zhuofeng Li",
      "Chenglei Dai",
      "Wentian Bao",
      "Shuai Lin",
      "Enyun Yu",
      "Haoxiang Zhang",
      "Liang Zhao"
    ],
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25220v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25220v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2510.25164v1",
    "title": "Transformers in Medicine: Improving Vision-Language Alignment for   Medical Image Captioning",
    "summary": "We present a transformer-based multimodal framework for generating clinically relevant captions for MRI scans. Our system combines a DEiT-Small vision transformer as an image encoder, MediCareBERT for caption embedding, and a custom LSTM-based decoder. The architecture is designed to semantically align image and textual embeddings, using hybrid cosine-MSE loss and contrastive inference via vector similarity. We benchmark our method on the MultiCaRe dataset, comparing performance on filtered brain-only MRIs versus general MRI images against state-of-the-art medical image captioning methods including BLIP, R2GenGPT, and recent transformer-based approaches. Results show that focusing on domain-specific data improves caption accuracy and semantic alignment. Our work proposes a scalable, interpretable solution for automated medical image reporting.",
    "authors": [
      "Yogesh Thakku Suresh",
      "Vishwajeet Shivaji Hogale",
      "Luca-Alexandru Zamfira",
      "Anandavardhana Hegde"
    ],
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25164v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25164v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2510.25761v1",
    "title": "DiagramEval: Evaluating LLM-Generated Diagrams via Graphs",
    "summary": "Diagrams play a central role in research papers for conveying ideas, yet they are often notoriously complex and labor-intensive to create. Although diagrams are presented as images, standard image generative models struggle to produce clear diagrams with well-defined structure. We argue that a promising direction is to generate demonstration diagrams directly in textual form as SVGs, which can leverage recent advances in large language models (LLMs). However, due to the complexity of components and the multimodal nature of diagrams, sufficiently discriminative and explainable metrics for evaluating the quality of LLM-generated diagrams remain lacking. In this paper, we propose DiagramEval, a novel evaluation metric designed to assess demonstration diagrams generated by LLMs. Specifically, DiagramEval conceptualizes diagrams as graphs, treating text elements as nodes and their connections as directed edges, and evaluates diagram quality using two new groups of metrics: node alignment and path alignment. For the first time, we effectively evaluate diagrams produced by state-of-the-art LLMs on recent research literature, quantitatively demonstrating the validity of our metrics. Furthermore, we show how the enhanced explainability of our proposed metrics offers valuable insights into the characteristics of LLM-generated diagrams. Code: https://github.com/ulab-uiuc/diagram-eval.",
    "authors": [
      "Chumeng Liang",
      "Jiaxuan You"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25761v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25761v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2510.25323v1",
    "title": "CDFlow: Building Invertible Layers with Circulant and Diagonal Matrices",
    "summary": "Normalizing flows are deep generative models that enable efficient likelihood estimation and sampling through invertible transformations. A key challenge is to design linear layers that enhance expressiveness while maintaining efficient computation of the Jacobian determinant and inverse. We introduce a novel invertible linear layer based on the product of circulant and diagonal matrices. This decomposition reduces parameter complexity from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(mn)$ using $m$ diagonal matrices and $m-1$ circulant matrices while still approximating general linear transformations. By leveraging the Fast Fourier Transform, our approach reduces the time complexity of matrix inversion from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(mn\\log n)$ and that of computing the log-determinant from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(mn)$, where $n$ is the input dimension. We build upon this layer to develop Circulant-Diagonal Flow (CDFlow), which achieves strong density estimation on natural image datasets and effectively models data with inherent periodic structure. Furthermore, CDFlow significantly accelerates key operations in normalizing flows, providing practical benefits for scalable generative modeling.",
    "authors": [
      "Xuchen Feng",
      "Siyu Liao"
    ],
    "categories": [
      "cs.LG",
      "68T07, 62H12",
      "I.2.6; G.3"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25323v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25323v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2510.25179v1",
    "title": "Agentic Moderation: Multi-Agent Design for Safer Vision-Language Models",
    "summary": "Agentic methods have emerged as a powerful and autonomous paradigm that enhances reasoning, collaboration, and adaptive control, enabling systems to coordinate and independently solve complex tasks. We extend this paradigm to safety alignment by introducing Agentic Moderation, a model-agnostic framework that leverages specialised agents to defend multimodal systems against jailbreak attacks. Unlike prior approaches that apply as a static layer over inputs or outputs and provide only binary classifications (safe or unsafe), our method integrates dynamic, cooperative agents, including Shield, Responder, Evaluator, and Reflector, to achieve context-aware and interpretable moderation. Extensive experiments across five datasets and four representative Large Vision-Language Models (LVLMs) demonstrate that our approach reduces the Attack Success Rate (ASR) by 7-19%, maintains a stable Non-Following Rate (NF), and improves the Refusal Rate (RR) by 4-20%, achieving robust, interpretable, and well-balanced safety performance. By harnessing the flexibility and reasoning capacity of agentic architectures, Agentic Moderation provides modular, scalable, and fine-grained safety enforcement, highlighting the broader potential of agentic systems as a foundation for automated safety governance.",
    "authors": [
      "Juan Ren",
      "Mark Dras",
      "Usman Naseem"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25179v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25179v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2510.25687v1",
    "title": "Model Inversion Attacks Meet Cryptographic Fuzzy Extractors",
    "summary": "Model inversion attacks pose an open challenge to privacy-sensitive applications that use machine learning (ML) models. For example, face authentication systems use modern ML models to compute embedding vectors from face images of the enrolled users and store them. If leaked, inversion attacks can accurately reconstruct user faces from the leaked vectors. There is no systematic characterization of properties needed in an ideal defense against model inversion, even for the canonical example application of a face authentication system susceptible to data breaches, despite a decade of best-effort solutions.   In this paper, we formalize the desired properties of a provably strong defense against model inversion and connect it, for the first time, to the cryptographic concept of fuzzy extractors. We further show that existing fuzzy extractors are insecure for use in ML-based face authentication. We do so through a new model inversion attack called PIPE, which achieves a success rate of over 89% in most cases against prior schemes. We then propose L2FE-Hash, the first candidate fuzzy extractor which supports standard Euclidean distance comparators as needed in many ML-based applications, including face authentication. We formally characterize its computational security guarantees, even in the extreme threat model of full breach of stored secrets, and empirically show its usable accuracy in face authentication for practical face distributions. It offers attack-agnostic security without requiring any re-training of the ML model it protects. Empirically, it nullifies both prior state-of-the-art inversion attacks as well as our new PIPE attack.",
    "authors": [
      "Mallika Prabhakar",
      "Louise Xu",
      "Prateek Saxena"
    ],
    "categories": [
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25687v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25687v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2510.25682v1",
    "title": "PairUni: Pairwise Training for Unified Multimodal Language Models",
    "summary": "Unified vision-language models (UVLMs) must perform both understanding and generation within a single architecture, but these tasks rely on heterogeneous data and supervision, making it difficult to balance them during reinforcement learning (RL). We propose PairUni, a unified framework that reorganizes data into understanding-generation (UG) pairs and aligns optimization accordingly. We first use GPT-o3 to augment single-task data, generating captions for understanding samples and question-answer (QA) pairs for generation samples, forming aligned pairs from the same instance. Additionally, for each generation sample, we retrieve a semantically related understanding example to form a retrieved pair, linking different but related data points. These paired structures expose cross-task semantic correspondences and support consistent policy learning. To leverage this structure, we present Pair-GPRO, a pair-aware variant based on Group Relative Policy Optimization. It assigns a similarity score to each pair to modulate the advantage, strengthening learning from well-aligned examples and reducing task interference. We curate a high-quality dataset of 16K UG pairs named PairUG for RL fine-tuning and evaluate PairUni on the powerful Janus-Pro UVLMs. Our approach achieves balanced improvements on various UVLMs, outperforming strong UVLM RL baselines. Code: \\href{https://github.com/Haochen-Wang409/PairUni}{github.com/Haochen-Wang409/PairUni}",
    "authors": [
      "Jiani Zheng",
      "Zhiyang Teng",
      "Xiangtai Li",
      "Anran Wang",
      "Yu Tian",
      "Kunpeng Qiu",
      "Ye Tian",
      "Haochen Wang",
      "Zhuochen Wang"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25682v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25682v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2510.25657v1",
    "title": "Subgraph Federated Learning via Spectral Methods",
    "summary": "We consider the problem of federated learning (FL) with graph-structured data distributed across multiple clients. In particular, we address the prevalent scenario of interconnected subgraphs, where interconnections between clients significantly influence the learning process. Existing approaches suffer from critical limitations, either requiring the exchange of sensitive node embeddings, thereby posing privacy risks, or relying on computationally-intensive steps, which hinders scalability. To tackle these challenges, we propose FedLap, a novel framework that leverages global structure information via Laplacian smoothing in the spectral domain to effectively capture inter-node dependencies while ensuring privacy and scalability. We provide a formal analysis of the privacy of FedLap, demonstrating that it preserves privacy. Notably, FedLap is the first subgraph FL scheme with strong privacy guarantees. Extensive experiments on benchmark datasets demonstrate that FedLap achieves competitive or superior utility compared to existing techniques.",
    "authors": [
      "Javad Aliakbari",
      "Johan Östman",
      "Ashkan Panahi",
      "Alexandre Graell i Amat"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25657v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25657v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2510.25594v1",
    "title": "Feedback Alignment Meets Low-Rank Manifolds: A Structured Recipe for   Local Learning",
    "summary": "Training deep neural networks (DNNs) with backpropagation (BP) achieves state-of-the-art accuracy but requires global error propagation and full parameterization, leading to substantial memory and computational overhead. Direct Feedback Alignment (DFA) enables local, parallelizable updates with lower memory requirements but is limited by unstructured feedback and poor scalability in deeper architectures, specially convolutional neural networks. To address these limitations, we propose a structured local learning framework that operates directly on low-rank manifolds defined by the Singular Value Decomposition (SVD) of weight matrices. Each layer is trained in its decomposed form, with updates applied to the SVD components using a composite loss that integrates cross-entropy, subspace alignment, and orthogonality regularization. Feedback matrices are constructed to match the SVD structure, ensuring consistent alignment between forward and feedback pathways. Our method reduces the number of trainable parameters relative to the original DFA model, without relying on pruning or post hoc compression. Experiments on CIFAR-10, CIFAR-100, and ImageNet show that our method achieves accuracy comparable to that of BP. Ablation studies confirm the importance of each loss term in the low-rank setting. These results establish local learning on low-rank manifolds as a principled and scalable alternative to full-rank gradient-based training.",
    "authors": [
      "Arani Roy",
      "Marco P. Apolinario",
      "Shristi Das Biswas",
      "Kaushik Roy"
    ],
    "categories": [
      "cs.LG",
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25594v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25594v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2510.25502v1",
    "title": "TempoPFN: Synthetic Pre-training of Linear RNNs for Zero-shot Time   Series Forecasting",
    "summary": "Foundation models for zero-shot time series forecasting face challenges in efficient long-horizon prediction and reproducibility, with existing synthetic-only approaches underperforming on challenging benchmarks. This paper presents TempoPFN, a univariate time series foundation model based on linear Recurrent Neural Networks (RNNs) pre-trained exclusively on synthetic data. The model uses a GatedDeltaProduct architecture with state-weaving for fully parallelizable training across sequence lengths, eliminating the need for windowing or summarization techniques while maintaining robust temporal state-tracking. Our comprehensive synthetic data pipeline unifies diverse generators, including stochastic differential equations, Gaussian processes, and audio synthesis, with novel augmentations. In zero-shot evaluations on the Gift-Eval benchmark, TempoPFN achieves top-tier competitive performance, outperforming all existing synthetic-only approaches and surpassing the vast majority of models trained on real-world data, while being more efficient than existing baselines by leveraging fully parallelizable training and inference. We open-source our complete data generation pipeline and training code, providing a reproducible foundation for future research.",
    "authors": [
      "Vladyslav Moroshan",
      "Julien Siems",
      "Arber Zela",
      "Timur Carstensen",
      "Frank Hutter"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25502v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25502v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2510.25460v1",
    "title": "Fine-Tuned Language Models for Domain-Specific Summarization and Tagging",
    "summary": "This paper presents a pipeline integrating fine-tuned large language models (LLMs) with named entity recognition (NER) for efficient domain-specific text summarization and tagging. The authors address the challenge posed by rapidly evolving sub-cultural languages and slang, which complicate automated information extraction and law enforcement monitoring. By leveraging the LLaMA Factory framework, the study fine-tunes LLMs on both generalpurpose and custom domain-specific datasets, particularly in the political and security domains. The models are evaluated using BLEU and ROUGE metrics, demonstrating that instruction fine-tuning significantly enhances summarization and tagging accuracy, especially for specialized corpora. Notably, the LLaMA3-8B-Instruct model, despite its initial limitations in Chinese comprehension, outperforms its Chinese-trained counterpart after domainspecific fine-tuning, suggesting that underlying reasoning capabilities can transfer across languages. The pipeline enables concise summaries and structured entity tagging, facilitating rapid document categorization and distribution. This approach proves scalable and adaptable for real-time applications, supporting efficient information management and the ongoing need to capture emerging language trends. The integration of LLMs and NER offers a robust solution for transforming unstructured text into actionable insights, crucial for modern knowledge management and security operations.",
    "authors": [
      "Jun Wang",
      "Fuming Lin",
      "Yuyu Chen"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25460v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25460v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2510.25404v1",
    "title": "GPTOpt: Towards Efficient LLM-Based Black-Box Optimization",
    "summary": "Global optimization of expensive, derivative-free black-box functions demands extreme sample efficiency. Classical methods such as Bayesian Optimization (BO) can be effective, but they often require careful parameter tuning to each application domain. At the same time, Large Language Models (LLMs) have shown broad capabilities, yet state-of-the-art models remain limited in solving continuous black-box optimization tasks. We introduce GPTOpt, an LLM-based optimization method that equips LLMs with continuous black-box optimization capabilities. By fine-tuning large language models on extensive synthetic datasets derived from diverse BO parameterizations, GPTOpt leverages LLM pre-training to generalize across optimization tasks. On a variety of black-box optimization benchmarks, GPTOpt surpasses traditional optimizers, highlighting the capacity of LLMs for advanced numerical reasoning and introducing a flexible framework for global optimization without parameter tuning.",
    "authors": [
      "Jamison Meindl",
      "Yunsheng Tian",
      "Tony Cui",
      "Veronika Thost",
      "Zhang-Wei Hong",
      "Jie Chen",
      "Wojciech Matusik",
      "Mina Konaković Luković"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25404v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25404v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2510.25333v1",
    "title": "CRMWeaver: Building Powerful Business Agent via Agentic RL and Shared   Memories",
    "summary": "Recent years have witnessed the rapid development of LLM-based agents, which shed light on using language agents to solve complex real-world problems. A prominent application lies in business agents, which interact with databases and internal knowledge bases via tool calls to fulfill diverse user requirements. However, this domain is characterized by intricate data relationships and a wide range of heterogeneous tasks, from statistical data queries to knowledge-based question-answering. To address these challenges, we propose CRMWeaver, a novel approach that enhances business agents in such complex settings. To acclimate the agentic model to intricate business environments, we employ a synthesis data generation and RL-based paradigm during training, which significantly improves the model's ability to handle complex data and varied tasks. During inference, a shared memories mechanism is introduced, prompting the agent to learn from task guidelines in similar problems, thereby further boosting its effectiveness and generalization, especially in unseen scenarios. We validate the efficacy of our approach on the CRMArena-Pro dataset, where our lightweight model achieves competitive results in both B2B and B2C business scenarios, underscoring its practical value for real-world applications.",
    "authors": [
      "Yilong Lai",
      "Yipin Yang",
      "Jialong Wu",
      "Fengran Mo",
      "Zhenglin Wang",
      "Ting Liang",
      "Jianguo Lin",
      "Keping Yang"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25333v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25333v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2510.25279v1",
    "title": "Diffusion-Driven Progressive Target Manipulation for Source-Free Domain   Adaptation",
    "summary": "Source-free domain adaptation (SFDA) is a challenging task that tackles domain shifts using only a pre-trained source model and unlabeled target data. Existing SFDA methods are restricted by the fundamental limitation of source-target domain discrepancy. Non-generation SFDA methods suffer from unreliable pseudo-labels in challenging scenarios with large domain discrepancies, while generation-based SFDA methods are evidently degraded due to enlarged domain discrepancies in creating pseudo-source data. To address this limitation, we propose a novel generation-based framework named Diffusion-Driven Progressive Target Manipulation (DPTM) that leverages unlabeled target data as references to reliably generate and progressively refine a pseudo-target domain for SFDA. Specifically, we divide the target samples into a trust set and a non-trust set based on the reliability of pseudo-labels to sufficiently and reliably exploit their information. For samples from the non-trust set, we develop a manipulation strategy to semantically transform them into the newly assigned categories, while simultaneously maintaining them in the target distribution via a latent diffusion model. Furthermore, we design a progressive refinement mechanism that progressively reduces the domain discrepancy between the pseudo-target domain and the real target domain via iterative refinement. Experimental results demonstrate that DPTM outperforms existing methods by a large margin and achieves state-of-the-art performance on four prevailing SFDA benchmark datasets with different scales. Remarkably, DPTM can significantly enhance the performance by up to 18.6% in scenarios with large source-target gaps.",
    "authors": [
      "Yuyang Huang",
      "Yabo Chen",
      "Junyu Zhou",
      "Wenrui Dai",
      "Xiaopeng Zhang",
      "Junni Zou",
      "Hongkai Xiong",
      "Qi Tian"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25279v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25279v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2510.25175v1",
    "title": "Test-Time Adaptive Object Detection with Foundation Model",
    "summary": "In recent years, test-time adaptive object detection has attracted increasing attention due to its unique advantages in online domain adaptation, which aligns more closely with real-world application scenarios. However, existing approaches heavily rely on source-derived statistical characteristics while making the strong assumption that the source and target domains share an identical category space. In this paper, we propose the first foundation model-powered test-time adaptive object detection method that eliminates the need for source data entirely and overcomes traditional closed-set limitations. Specifically, we design a Multi-modal Prompt-based Mean-Teacher framework for vision-language detector-driven test-time adaptation, which incorporates text and visual prompt tuning to adapt both language and vision representation spaces on the test data in a parameter-efficient manner. Correspondingly, we propose a Test-time Warm-start strategy tailored for the visual prompts to effectively preserve the representation capability of the vision branch. Furthermore, to guarantee high-quality pseudo-labels in every test batch, we maintain an Instance Dynamic Memory (IDM) module that stores high-quality pseudo-labels from previous test samples, and propose two novel strategies-Memory Enhancement and Memory Hallucination-to leverage IDM's high-quality instances for enhancing original predictions and hallucinating images without available pseudo-labels, respectively. Extensive experiments on cross-corruption and cross-dataset benchmarks demonstrate that our method consistently outperforms previous state-of-the-art methods, and can adapt to arbitrary cross-domain and cross-category target data. Code is available at https://github.com/gaoyingjay/ttaod_foundation.",
    "authors": [
      "Yingjie Gao",
      "Yanan Zhang",
      "Zhi Cai",
      "Di Huang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25175v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25175v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2510.25315v1",
    "title": "Tuning-Free Sampling via Optimization on the Space of Probability   Measures",
    "summary": "We introduce adaptive, tuning-free step size schedules for gradient-based sampling algorithms obtained as time-discretizations of Wasserstein gradient flows. The result is a suite of tuning-free sampling algorithms, including tuning-free variants of the unadjusted Langevin algorithm (ULA), stochastic gradient Langevin dynamics (SGLD), mean-field Langevin dynamics (MFLD), Stein variational gradient descent (SVGD), and variational gradient descent (VGD). More widely, our approach yields tuning-free algorithms for solving a broad class of stochastic optimization problems over the space of probability measures. Under mild assumptions (e.g., geodesic convexity and locally bounded stochastic gradients), we establish strong theoretical guarantees for our approach. In particular, we recover the convergence rate of optimally tuned versions of these algorithms up to logarithmic factors, in both nonsmooth and smooth settings. We then benchmark the performance of our methods against comparable existing approaches. Across a variety of tasks, our algorithms achieve similar performance to the optimal performance of existing algorithms, with no need to tune a step size parameter.",
    "authors": [
      "Louis Sharrock",
      "Christopher Nemeth"
    ],
    "categories": [
      "stat.ME",
      "stat.ML"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25315v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25315v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2510.25244v1",
    "title": "BSFA: Leveraging the Subspace Dichotomy to Accelerate Neural Network   Training",
    "summary": "Recent studies \\citep{gur2018gradient,song2024does, wen2024understanding} highlight a fundamental dichotomy in deep learning optimization: Although parameter updates along the top eigendirections of the loss Hessian (Dom-space) capture most of the update magnitude, they often contribute minimally to loss reduction. In contrast, updates in the orthogonal component (Bulk-space) have smaller magnitudes but drive most learning progress. In this work, we further advance the understanding of this phenomenon and introduce the \\textbf{Bulk-Space-Filtration-Accelerator (BSFA)}, a novel plug-and-play framework. BSFA accelerates training by differentially scaling update components projected onto these distinct subspaces, simultaneously enhancing stability by moderating updates in the dominant subspace and boosting convergence speed by amplifying those in the bulk-space. To ensure BSFA is both practical and scalable for contemporary large models, we introduce two key innovations: an efficient estimator using Principal Component Analysis (PCA) on historical updates for fast subspace estimation, and a block-wise strategy that applies this estimation on a per-parameter-block basis. These designs make BSFA computationally tractable and highly effective. We demonstrate BSFA's acceleration across various tasks, notably achieving approximately 2$\\times$ speedup when pre-training LLaMA-72M on WikiText-103 and LLaMA-134M on OpenWebText compared to vanilla AdamW.",
    "authors": [
      "Wenjie Zhou",
      "Bohan Wang",
      "Wei Chen",
      "Xueqi Cheng"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25244v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25244v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2510.25224v1",
    "title": "ProMediate: A Socio-cognitive framework for evaluating proactive agents   in multi-party negotiation",
    "summary": "While Large Language Models (LLMs) are increasingly used in agentic frameworks to assist individual users, there is a growing need for agents that can proactively manage complex, multi-party collaboration. Systematic evaluation methods for such proactive agents remain scarce, limiting progress in developing AI that can effectively support multiple people together. Negotiation offers a demanding testbed for this challenge, requiring socio-cognitive intelligence to navigate conflicting interests between multiple participants and multiple topics and build consensus. Here, we present ProMediate, the first framework for evaluating proactive AI mediator agents in complex, multi-topic, multi-party negotiations. ProMediate consists of two core components: (i) a simulation testbed based on realistic negotiation cases and theory-driven difficulty levels (ProMediate-Easy, ProMediate-Medium, and ProMediate-Hard), with a plug-and-play proactive AI mediator grounded in socio-cognitive mediation theories, capable of flexibly deciding when and how to intervene; and (ii) a socio-cognitive evaluation framework with a new suite of metrics to measure consensus changes, intervention latency, mediator effectiveness, and intelligence. Together, these components establish a systematic framework for assessing the socio-cognitive intelligence of proactive AI agents in multi-party settings. Our results show that a socially intelligent mediator agent outperforms a generic baseline, via faster, better-targeted interventions. In the ProMediate-Hard setting, our social mediator increases consensus change by 3.6 percentage points compared to the generic baseline (10.65\\% vs 7.01\\%) while being 77\\% faster in response (15.98s vs. 3.71s). In conclusion, ProMediate provides a rigorous, theory-grounded testbed to advance the development of proactive, socially intelligent agents.",
    "authors": [
      "Ziyi Liu",
      "Bahar Sarrafzadeh",
      "Pei Zhou",
      "Longqi Yang",
      "Jieyu Zhao",
      "Ashish Sharma"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25224v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25224v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2510.25766v1",
    "title": "Decomposition-Enhanced Training for Post-Hoc Attributions In Language   Models",
    "summary": "Large language models (LLMs) are increasingly used for long-document question answering, where reliable attribution to sources is critical for trust. Existing post-hoc attribution methods work well for extractive QA but struggle in multi-hop, abstractive, and semi-extractive settings, where answers synthesize information across passages. To address these challenges, we argue that post-hoc attribution can be reframed as a reasoning problem, where answers are decomposed into constituent units, each tied to specific context. We first show that prompting models to generate such decompositions alongside attributions improves performance. Building on this, we introduce DecompTune, a post-training method that teaches models to produce answer decompositions as intermediate reasoning steps. We curate a diverse dataset of complex QA tasks, annotated with decompositions by a strong LLM, and post-train Qwen-2.5 (7B and 14B) using a two-stage SFT + GRPO pipeline with task-specific curated rewards. Across extensive experiments and ablations, DecompTune substantially improves attribution quality, outperforming prior methods and matching or exceeding state-of-the-art frontier models.",
    "authors": [
      "Sriram Balasubramaniam",
      "Samyadeep Basu",
      "Koustava Goswami",
      "Ryan Rossi",
      "Varun Manjunatha",
      "Roshan Santhosh",
      "Ruiyi Zhang",
      "Soheil Feizi",
      "Nedim Lipka"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25766v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25766v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2510.25628v1",
    "title": "EHR-R1: A Reasoning-Enhanced Foundational Language Model for Electronic   Health Record Analysis",
    "summary": "Electronic Health Records (EHRs) contain rich yet complex information, and their automated analysis is critical for clinical decision-making. Despite recent advances of large language models (LLMs) in clinical workflows, their ability to analyze EHRs remains limited due to narrow task coverage and lack of EHR-oriented reasoning capabilities. This paper aims to bridge the gap, specifically, we present EHR-Ins, a large-scale, comprehensive EHR reasoning instruction dataset, comprising 300k high-quality reasoning cases and 4M non-reasoning cases across 42 distinct EHR tasks. Its core innovation is a thinking-graph-driven framework that enables to generate high-quality reasoning data at scale. Based on it, we develop EHR-R1, a series of reasoning-enhanced LLMs with up to 72B parameters tailored for EHR analysis. Through a multi-stage training paradigm, including domain adaptation, reasoning enhancement, and reinforcement learning, EHR-R1 systematically acquires domain knowledge and diverse reasoning capabilities, enabling accurate and robust EHR analysis. Lastly, we introduce EHR-Bench, a new benchmark curated from MIMIC-IV, spanning 42 tasks, to comprehensively assess reasoning and prediction across EHR scenarios. In experiments, we show that the resulting EHR-R1 consistently outperforms state-of-the-art commercial and open-source LLMs (including DeepSeek-V3 and GPT-4o), surpassing GPT-4o by over 30 points on MIMIC-Bench and achieving a 10\\% higher zero-shot AUROC on EHRSHOT. Collectively, EHR-Ins, EHR-R1, and EHR-Bench have significantly advanced the development for more reliable and clinically relevant EHR analysis.",
    "authors": [
      "Yusheng Liao",
      "Chaoyi Wu",
      "Junwei Liu",
      "Shuyang Jiang",
      "Pengcheng Qiu",
      "Haowen Wang",
      "Yun Yue",
      "Shuai Zhen",
      "Jian Wang",
      "Qianrui Fan",
      "Jinjie Gu",
      "Ya Zhang",
      "Yanfeng Wang",
      "Yu Wang",
      "Weidi Xie"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25628v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25628v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2510.25268v1",
    "title": "SynHLMA:Synthesizing Hand Language Manipulation for Articulated Object   with Discrete Human Object Interaction Representation",
    "summary": "Generating hand grasps with language instructions is a widely studied topic that benefits from embodied AI and VR/AR applications. While transferring into hand articulatied object interaction (HAOI), the hand grasps synthesis requires not only object functionality but also long-term manipulation sequence along the object deformation. This paper proposes a novel HAOI sequence generation framework SynHLMA, to synthesize hand language manipulation for articulated objects. Given a complete point cloud of an articulated object, we utilize a discrete HAOI representation to model each hand object interaction frame. Along with the natural language embeddings, the representations are trained by an HAOI manipulation language model to align the grasping process with its language description in a shared representation space. A joint-aware loss is employed to ensure hand grasps follow the dynamic variations of articulated object joints. In this way, our SynHLMA achieves three typical hand manipulation tasks for articulated objects of HAOI generation, HAOI prediction and HAOI interpolation. We evaluate SynHLMA on our built HAOI-lang dataset and experimental results demonstrate the superior hand grasp sequence generation performance comparing with state-of-the-art. We also show a robotics grasp application that enables dexterous grasps execution from imitation learning using the manipulation sequence provided by our SynHLMA. Our codes and datasets will be made publicly available.",
    "authors": [
      "Wang zhi",
      "Yuyan Liu",
      "Liu Liu",
      "Li Zhang",
      "Ruixuan Lu",
      "Dan Guo"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25268v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25268v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2510.25163v1",
    "title": "Target-Guided Bayesian Flow Networks for Quantitatively Constrained CAD   Generation",
    "summary": "Deep generative models, such as diffusion models, have shown promising progress in image generation and audio generation via simplified continuity assumptions. However, the development of generative modeling techniques for generating multi-modal data, such as parametric CAD sequences, still lags behind due to the challenges in addressing long-range constraints and parameter sensitivity. In this work, we propose a novel framework for quantitatively constrained CAD generation, termed Target-Guided Bayesian Flow Network (TGBFN). For the first time, TGBFN handles the multi-modality of CAD sequences (i.e., discrete commands and continuous parameters) in a unified continuous and differentiable parameter space rather than in the discrete data space. In addition, TGBFN penetrates the parameter update kernel and introduces a guided Bayesian flow to control the CAD properties. To evaluate TGBFN, we construct a new dataset for quantitatively constrained CAD generation. Extensive comparisons across single-condition and multi-condition constrained generation tasks demonstrate that TGBFN achieves state-of-the-art performance in generating high-fidelity, condition-aware CAD sequences. The code is available at https://github.com/scu-zwh/TGBFN.",
    "authors": [
      "Wenhao Zheng",
      "Chenwei Sun",
      "Wenbo Zhang",
      "Jiancheng Lv",
      "Xianggen Liu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25163v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25163v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2510.25758v1",
    "title": "TheraMind: A Strategic and Adaptive Agent for Longitudinal Psychological   Counseling",
    "summary": "Large language models (LLMs) in psychological counseling have attracted increasing attention. However, existing approaches often lack emotional understanding, adaptive strategies, and the use of therapeutic methods across multiple sessions with long-term memory, leaving them far from real clinical practice. To address these critical gaps, we introduce TheraMind, a strategic and adaptive agent for longitudinal psychological counseling. The cornerstone of TheraMind is a novel dual-loop architecture that decouples the complex counseling process into an Intra-Session Loop for tactical dialogue management and a Cross-Session Loop for strategic therapeutic planning. The Intra-Session Loop perceives the patient's emotional state to dynamically select response strategies while leveraging cross-session memory to ensure continuity. Crucially, the Cross-Session Loop empowers the agent with long-term adaptability by evaluating the efficacy of the applied therapy after each session and adjusting the method for subsequent interactions. We validate our approach in a high-fidelity simulation environment grounded in real clinical cases. Extensive evaluations show that TheraMind outperforms other methods, especially on multi-session metrics like Coherence, Flexibility, and Therapeutic Attunement, validating the effectiveness of its dual-loop design in emulating strategic, adaptive, and longitudinal therapeutic behavior. The code is publicly available at https://0mwwm0.github.io/TheraMind/.",
    "authors": [
      "He Hu",
      "Yucheng Zhou",
      "Chiyuan Ma",
      "Qianning Wang",
      "Zheng Zhang",
      "Fei Ma",
      "Laizhong Cui",
      "Qi Tian"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25758v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25758v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2510.25694v1",
    "title": "Process-Level Trajectory Evaluation for Environment Configuration in   Software Engineering Agents",
    "summary": "Large language model-based agents show promise for software engineering, but environment configuration remains a bottleneck due to heavy manual effort and scarce large-scale, high-quality datasets. Existing benchmarks assess only end-to-end build/test success, obscuring where and why agents succeed or fail. We introduce the Environment Configuration Diagnosis Benchmark, Enconda-bench, which provides process-level trajectory assessment of fine-grained agent capabilities during environment setup-planning, perception-driven error diagnosis, feedback-driven repair, and action to execute final environment configuration. Our task instances are automatically constructed by injecting realistic README errors and are validated in Docker for scalable, high-quality evaluation. Enconda-bench combines process-level analysis with end-to-end executability to enable capability assessments beyond aggregate success rates. Evaluations across state-of-the-art LLMs and agent frameworks show that while agents can localize errors, they struggle to translate feedback into effective corrections, limiting end-to-end performance. To our knowledge, Enconda-bench is the first framework to provide process-level internal capability assessment for environment configuration, offering actionable insights for improving software engineering agents.",
    "authors": [
      "Jiayi Kuang",
      "Yinghui Li",
      "Xin Zhang",
      "Yangning Li",
      "Di Yin",
      "Xing Sun",
      "Ying Shen",
      "Philip S. Yu"
    ],
    "categories": [
      "cs.SE",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25694v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25694v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2510.25413v1",
    "title": "Seeing, Signing, and Saying: A Vision-Language Model-Assisted Pipeline   for Sign Language Data Acquisition and Curation from Social Media",
    "summary": "Most existing sign language translation (SLT) datasets are limited in scale, lack multilingual coverage, and are costly to curate due to their reliance on expert annotation and controlled recording setup. Recently, Vision Language Models (VLMs) have demonstrated strong capabilities as evaluators and real-time assistants. Despite these advancements, their potential remains untapped in the context of sign language dataset acquisition. To bridge this gap, we introduce the first automated annotation and filtering framework that utilizes VLMs to reduce reliance on manual effort while preserving data quality. Our method is applied to TikTok videos across eight sign languages and to the already curated YouTube-SL-25 dataset in German Sign Language for the purpose of additional evaluation. Our VLM-based pipeline includes a face visibility detection, a sign activity recognition, a text extraction from video content, and a judgment step to validate alignment between video and text, implementing generic filtering, annotation and validation steps. Using the resulting corpus, TikTok-SL-8, we assess the performance of two off-the-shelf SLT models on our filtered dataset for German and American Sign Languages, with the goal of establishing baselines and evaluating the robustness of recent models on automatically extracted, slightly noisy data. Our work enables scalable, weakly supervised pretraining for SLT and facilitates data acquisition from social media.",
    "authors": [
      "Shakib Yazdani",
      "Yasser Hamidullah",
      "Cristina España-Bonet",
      "Josef van Genabith"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25413v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25413v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2510.25314v1",
    "title": "Seeing Clearly and Deeply: An RGBD Imaging Approach with a Bio-inspired   Monocentric Design",
    "summary": "Achieving high-fidelity, compact RGBD imaging presents a dual challenge: conventional compact optics struggle with RGB sharpness across the entire depth-of-field, while software-only Monocular Depth Estimation (MDE) is an ill-posed problem reliant on unreliable semantic priors. While deep optics with elements like DOEs can encode depth, they introduce trade-offs in fabrication complexity and chromatic aberrations, compromising simplicity. To address this, we first introduce a novel bio-inspired all-spherical monocentric lens, around which we build the Bionic Monocentric Imaging (BMI) framework, a holistic co-design. This optical design naturally encodes depth into its depth-varying Point Spread Functions (PSFs) without requiring complex diffractive or freeform elements. We establish a rigorous physically-based forward model to generate a synthetic dataset by precisely simulating the optical degradation process. This simulation pipeline is co-designed with a dual-head, multi-scale reconstruction network that employs a shared encoder to jointly recover a high-fidelity All-in-Focus (AiF) image and a precise depth map from a single coded capture. Extensive experiments validate the state-of-the-art performance of the proposed framework. In depth estimation, the method attains an Abs Rel of 0.026 and an RMSE of 0.130, markedly outperforming leading software-only approaches and other deep optics systems. For image restoration, the system achieves an SSIM of 0.960 and a perceptual LPIPS score of 0.082, thereby confirming a superior balance between image fidelity and depth accuracy. This study illustrates that the integration of bio-inspired, fully spherical optics with a joint reconstruction algorithm constitutes an effective strategy for addressing the intrinsic challenges in high-performance compact RGBD imaging. Source code will be publicly available at https://github.com/ZongxiYu-ZJU/BMI.",
    "authors": [
      "Zongxi Yu",
      "Xiaolong Qian",
      "Shaohua Gao",
      "Qi Jiang",
      "Yao Gao",
      "Kailun Yang",
      "Kaiwei Wang"
    ],
    "categories": [
      "cs.CV",
      "cs.RO",
      "eess.IV",
      "physics.optics"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25314v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25314v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2510.25282v1",
    "title": "On the Stability of Neural Networks in Deep Learning",
    "summary": "Deep learning has achieved remarkable success across a wide range of tasks, but its models often suffer from instability and vulnerability: small changes to the input may drastically affect predictions, while optimization can be hindered by sharp loss landscapes. This thesis addresses these issues through the unifying perspective of sensitivity analysis, which examines how neural networks respond to perturbations at both the input and parameter levels.   We study Lipschitz networks as a principled way to constrain sensitivity to input perturbations, thereby improving generalization, adversarial robustness, and training stability. To complement this architectural approach, we introduce regularization techniques based on the curvature of the loss function, promoting smoother optimization landscapes and reducing sensitivity to parameter variations. Randomized smoothing is also explored as a probabilistic method for enhancing robustness at decision boundaries.   By combining these perspectives, we develop a unified framework where Lipschitz continuity, randomized smoothing, and curvature regularization interact to address fundamental challenges in stability. The thesis contributes both theoretical analysis and practical methodologies, including efficient spectral norm computation, novel Lipschitz-constrained layers, and improved certification procedures.",
    "authors": [
      "Blaise Delattre"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25282v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25282v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2510.25205v1",
    "title": "Energy-Efficient Autonomous Driving with Adaptive Perception and Robust   Decision",
    "summary": "Autonomous driving is an emerging technology that is expected to bring significant social, economic, and environmental benefits. However, these benefits come with rising energy consumption by computation engines, limiting the driving range of vehicles, especially electric ones. Perception computing is typically the most power-intensive component, as it relies on largescale deep learning models to extract environmental features. Recently, numerous studies have employed model compression techniques, such as sparsification, quantization, and distillation, to reduce computational consumption. However, these methods often result in either a substantial model size or a significant drop in perception accuracy compared to high-computation models. To address these challenges, we propose an energy-efficient autonomous driving framework, called EneAD. In the adaptive perception module, a perception optimization strategy is designed from the perspective of data management and tuning. Firstly, we manage multiple perception models with different computational consumption and adjust the execution framerate dynamically. Then, we define them as knobs and design a transferable tuning method based on Bayesian optimization to identify promising knob values that achieve low computation while maintaining desired accuracy. To adaptively switch the knob values in various traffic scenarios, a lightweight classification model is proposed to distinguish the perception difficulty in different scenarios. In the robust decision module, we propose a decision model based on reinforcement learning and design a regularization term to enhance driving stability in the face of perturbed perception results. Extensive experiments evidence the superiority of our framework in both energy consumption and driving performance. EneAD can reduce perception consumption by 1.9x to 3.5x and thus improve driving range by 3.9% to 8.5%",
    "authors": [
      "Yuyang Xia",
      "Zibo Liang",
      "Liwei Deng",
      "Yan Zhao",
      "Han Su",
      "Kai Zheng"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25205v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25205v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2510.25176v1",
    "title": "Machine Learning and CPU (Central Processing Unit) Scheduling   Co-Optimization over a Network of Computing Centers",
    "summary": "In the rapidly evolving research on artificial intelligence (AI) the demand for fast, computationally efficient, and scalable solutions has increased in recent years. The problem of optimizing the computing resources for distributed machine learning (ML) and optimization is considered in this paper. Given a set of data distributed over a network of computing-nodes/servers, the idea is to optimally assign the CPU (central processing unit) usage while simultaneously training each computing node locally via its own share of data. This formulates the problem as a co-optimization setup to (i) optimize the data processing and (ii) optimally allocate the computing resources. The information-sharing network among the nodes might be time-varying, but with balanced weights to ensure consensus-type convergence of the algorithm. The algorithm is all-time feasible, which implies that the computing resource-demand balance constraint holds at all iterations of the proposed solution. Moreover, the solution allows addressing possible log-scale quantization over the information-sharing channels to exchange log-quantized data. For some example applications, distributed support-vector-machine (SVM) and regression are considered as the ML training models. Results from perturbation theory, along with Lyapunov stability and eigen-spectrum analysis, are used to prove the convergence towards the optimal case. As compared to existing CPU scheduling solutions, the proposed algorithm improves the cost optimality gap by more than $50\\%$.",
    "authors": [
      "Mohammadreza Doostmohammadian",
      "Zulfiya R. Gabidullina",
      "Hamid R. Rabiee"
    ],
    "categories": [
      "cs.LG",
      "cs.DC",
      "cs.MA",
      "cs.SY",
      "eess.SY",
      "math.OC"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25176v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25176v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2510.25135v1",
    "title": "Conditional neural field for spatial dimension reduction of turbulence   data: a comparison study",
    "summary": "We investigate conditional neural fields (CNFs), mesh-agnostic, coordinate-based decoders conditioned on a low-dimensional latent, for spatial dimensionality reduction of turbulent flows. CNFs are benchmarked against Proper Orthogonal Decomposition and a convolutional autoencoder within a unified encoding-decoding framework and a common evaluation protocol that explicitly separates in-range (interpolative) from out-of-range (strict extrapolative) testing beyond the training horizon, with identical preprocessing, metrics, and fixed splits across all baselines. We examine three conditioning mechanisms: (i) activation-only modulation (often termed FiLM), (ii) low-rank weight and bias modulation (termed FP), and (iii) last-layer inner-product coupling, and introduce a novel domain-decomposed CNF that localizes complexities. Across representative turbulence datasets (WMLES channel inflow, DNS channel inflow, and wall pressure fluctuations over turbulent boundary layers), CNF-FP achieves the lowest training and in-range testing errors, while CNF-FiLM generalizes best for out-of-range scenarios once moderate latent capacity is available. Domain decomposition significantly improves out-of-range accuracy, especially for the more demanding datasets. The study provides a rigorous, physics-aware basis for selecting conditioning, capacity, and domain decomposition when using CNFs for turbulence compression and reconstruction.",
    "authors": [
      "Junyi Guo",
      "Pan Du",
      "Xiantao Fan",
      "Yahui Li",
      "Jian-Xun Wang"
    ],
    "categories": [
      "physics.flu-dyn",
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25135v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25135v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2510.25588v1",
    "title": "Standardization of Psychiatric Diagnoses -- Role of Fine-tuned LLM   Consortium and OpenAI-gpt-oss Reasoning LLM Enabled Decision Support System",
    "summary": "The diagnosis of most mental disorders, including psychiatric evaluations, primarily depends on dialogues between psychiatrists and patients. This subjective process can lead to variability in diagnoses across clinicians and patients, resulting in inconsistencies and challenges in achieving reliable outcomes. To address these issues and standardize psychiatric diagnoses, we propose a Fine-Tuned Large Language Model (LLM) Consortium and OpenAI-gpt-oss Reasoning LLM-enabled Decision Support System for the clinical diagnosis of mental disorders. Our approach leverages fine-tuned LLMs trained on conversational datasets involving psychiatrist-patient interactions focused on mental health conditions (e.g., depression). The diagnostic predictions from individual models are aggregated through a consensus-based decision-making process, refined by the OpenAI-gpt-oss reasoning LLM. We propose a novel method for deploying LLM agents that orchestrate communication between the LLM consortium and the reasoning LLM, ensuring transparency, reliability, and responsible AI across the entire diagnostic workflow. Experimental results demonstrate the transformative potential of combining fine-tuned LLMs with a reasoning model to create a robust and highly accurate diagnostic system for mental health assessment. A prototype of the proposed platform, integrating three fine-tuned LLMs with the OpenAI-gpt-oss reasoning LLM, was developed in collaboration with the U.S. Army Medical Research Team in Norfolk, Virginia, USA. To the best of our knowledge, this work represents the first application of a fine-tuned LLM consortium integrated with a reasoning LLM for clinical mental health diagnosis paving the way for next-generation AI-powered eHealth systems aimed at standardizing psychiatric diagnoses.",
    "authors": [
      "Eranga Bandara",
      "Ross Gore",
      "Atmaram Yarlagadda",
      "Anita H. Clayton",
      "Preston Samuel",
      "Christopher K. Rhea",
      "Sachin Shetty"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25588v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25588v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2510.25510v1",
    "title": "MTIR-SQL: Multi-turn Tool-Integrated Reasoning Reinforcement Learning   for Text-to-SQL",
    "summary": "As large language models (LLMs) are increasingly used in Text-to-SQL tasks, Reinforcement Learning (RL) has become a common method for improving performance. Existing methods primarily rely on static execution feedback, which restricts real-time error correction. However, integrating multi-turn tool invocation along with dynamic feedback could significantly improve adaptability and robustness, ultimately enhancing model performance. To address these issues, we propose MTIR-SQL, an innovative Multi-turn Tool-Integrated Reasoning reinforcement learning framework for Text-to-SQL. Our approach introduces an execution-aware multi-turn reasoning paradigm that seamlessly incorporates database execution feedback at each reasoning step, enabling context-sensitive query generation and progressive refinement throughout the reasoning process. The framework extends the GRPO algorithm to accommodate complex multi-turn interaction scenarios. Considering the training instability characteristics of MTIR and the potential for significant Deviation of model distribution from the initial model, we enhance the GRPO algorithm by adding a trajectory filtering mechanism and removing KL loss constraints. Experimental results demonstrate that MTIR-SQL, with 4B parameters, achieves \\textbf{64.4}\\% accuracy in the BIRD Dev and 84.6% execution accuracy in the SPIDER Dev, significantly outperforming existing approaches.",
    "authors": [
      "Zekun Xu",
      "Siyu Xia",
      "Chuhuai Yue",
      "Jiajun Chai",
      "Mingxue Tian",
      "Xiaohan Wang",
      "Wei Lin",
      "Haoxuan Li",
      "Guojun Yin"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25510v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25510v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2510.25531v1",
    "title": "Using latent representations to link disjoint longitudinal data for   mixed-effects regression",
    "summary": "Many rare diseases offer limited established treatment options, leading patients to switch therapies when new medications emerge. To analyze the impact of such treatment switches within the low sample size limitations of rare disease trials, it is important to use all available data sources. This, however, is complicated when usage of measurement instruments change during the observation period, for example when instruments are adapted to specific age ranges. The resulting disjoint longitudinal data trajectories, complicate the application of traditional modeling approaches like mixed-effects regression. We tackle this by mapping observations of each instrument to a aligned low-dimensional temporal trajectory, enabling longitudinal modeling across instruments. Specifically, we employ a set of variational autoencoder architectures to embed item values into a shared latent space for each time point. Temporal disease dynamics and treatment switch effects are then captured through a mixed-effects regression model applied to latent representations. To enable statistical inference, we present a novel statistical testing approach that accounts for the joint parameter estimation of mixed-effects regression and variational autoencoders. The methodology is applied to quantify the impact of treatment switches for patients with spinal muscular atrophy. Here, our approach aligns motor performance items from different measurement instruments for mixed-effects regression and maps estimated effects back to the observed item level to quantify the treatment switch effect. Our approach allows for model selection as well as for assessing effects of treatment switching. The results highlight the potential of modeling in joint latent representations for addressing small data challenges.",
    "authors": [
      "Clemens Schächter",
      "Maren Hackenberg",
      "Michelle Pfaffenlehner",
      "Félix B. Tambe-Ndonfack",
      "Thorsten Schmidt",
      "Astrid Pechmann",
      "Janbernd Kirschner",
      "Jan Hasenauser",
      "Harald Binder"
    ],
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG",
      "68T07",
      "G.3; I.2.6; J.3"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25531v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25531v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2510.25528v1",
    "title": "Zero Reinforcement Learning Towards General Domains",
    "summary": "Zero Reinforcement Learning (Zero-RL) has proven to be an effective approach for enhancing the reasoning capabilities of large language models (LLMs) by directly applying reinforcement learning with verifiable rewards on pretrained models, without the need for a supervised fine-tuning phase. However, current research on zero-RL primarily focuses on domains with easily verifiable reward signals, such as mathematics, programming, and other reasoning tasks. The challenge of eliciting reasoning abilities in more diverse scenarios, where verification is not straightforward, remains underexplored. To address this gap, we propose a novel zero-RL paradigm designed to improve a model's reasoning ability across both verifiable and non-verifiable domains. By combining verifiable rewards with a generative reward model, we conduct multi-task zero-RL training across both domains, facilitating the transfer of reasoning capabilities between them. Furthermore, to mitigate reward hacking in the generative reward model, we design a smooth length penalty that encourages the generation of more comprehensive thinking tokens in general domains. Experimental results on Qwen3-8B-Base and Qwen3-14B-Base demonstrate that our approach achieves superior reasoning performance, not only on tasks requiring extensive reasoning but also on more general tasks.",
    "authors": [
      "Yuyuan Zeng",
      "Yufei Huang",
      "Can Xu",
      "Qingfeng Sun",
      "Jianfeng Yan",
      "Guanghui Xu",
      "Tao Yang",
      "Fengzong Lian"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25528v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25528v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2510.25416v1",
    "title": "Adaptive End-to-End Transceiver Design for NextG Pilot-Free and CP-Free   Wireless Systems",
    "summary": "The advent of artificial intelligence (AI)-native wireless communication is fundamentally reshaping the design paradigm of next-generation (NextG) systems, where intelligent air interfaces are expected to operate adaptively and efficiently in highly dynamic environments. Conventional orthogonal frequency division multiplexing (OFDM) systems rely heavily on pilots and the cyclic prefix (CP), resulting in significant overhead and reduced spectral efficiency. To address these limitations, we propose an adaptive end-to-end (E2E) transceiver architecture tailored for pilot-free and CP-free wireless systems. The architecture combines AI-driven constellation shaping and a neural receiver through joint training. To enhance robustness against mismatched or time-varying channel conditions, we introduce a lightweight channel adapter (CA) module, which enables rapid adaptation with minimal computational overhead by updating only the CA parameters. Additionally, we present a framework that is scalable to multiple modulation orders within a unified model, significantly reducing model storage requirements. Moreover, to tackle the high peak-to-average power ratio (PAPR) inherent to OFDM, we incorporate constrained E2E training, achieving compliance with PAPR targets without additional transmission overhead. Extensive simulations demonstrate that the proposed framework delivers superior bit error rate (BER), throughput, and resilience across diverse channel scenarios, highlighting its potential for AI-native NextG.",
    "authors": [
      "Jiaming Cheng",
      "Wei Chen",
      "Bo Ai"
    ],
    "categories": [
      "eess.SP",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25416v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25416v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2510.25366v1",
    "title": "A Convexity-dependent Two-Phase Training Algorithm for Deep Neural   Networks",
    "summary": "The key task of machine learning is to minimize the loss function that measures the model fit to the training data. The numerical methods to do this efficiently depend on the properties of the loss function. The most decisive among these properties is the convexity or non-convexity of the loss function. The fact that the loss function can have, and frequently has, non-convex regions has led to a widespread commitment to non-convex methods such as Adam. However, a local minimum implies that, in some environment around it, the function is convex. In this environment, second-order minimizing methods such as the Conjugate Gradient (CG) give a guaranteed superlinear convergence. We propose a novel framework grounded in the hypothesis that loss functions in real-world tasks swap from initial non-convexity to convexity towards the optimum. This is a property we leverage to design an innovative two-phase optimization algorithm. The presented algorithm detects the swap point by observing the gradient norm dependence on the loss. In these regions, non-convex (Adam) and convex (CG) algorithms are used, respectively. Computing experiments confirm the hypothesis that this simple convexity structure is frequent enough to be practically exploited to substantially improve convergence and accuracy.",
    "authors": [
      "Tomas Hrycej",
      "Bernhard Bermeitinger",
      "Massimo Pavone",
      "Götz-Henrik Wiegand",
      "Siegfried Handschuh"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.OC"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25366v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25366v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2510.25303v1",
    "title": "Teaching Sarcasm: Few-Shot Multimodal Sarcasm Detection via Distillation   to a Parameter-Efficient Student",
    "summary": "Multimodal sarcasm detection is challenging, especially in low-resource settings where subtle image-text contradictions are hard to learn due to scarce annotated data, which hinders the model's performance. Parameter-efficient fine-tuning (PEFT) methods like adapters, LoRA, and prompt tuning reduce overfitting but struggle to reach optimal performance due to limited supervision from few-shot data. We propose PEKD, a unified framework that enhances PEFT methods via distillation from an expert model trained on large-scale sarcasm data, which acts as the teacher. To mitigate unreliable signals from the teacher, we introduce an entropy-aware gating mechanism that dynamically adjusts the distillation strength based on teacher confidence. Experiments on two public datasets demonstrate that our PEKD framework enables PEFT methods to outperform both prior parameter-efficient approaches and large multimodal models, achieving strong results in the few-shot scenario. The framework is modular and adaptable to a wide range of multimodal models and tasks.",
    "authors": [
      "Soumyadeep Jana",
      "Sanasam Ranbir Singh"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25303v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25303v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2510.25262v1",
    "title": "IBNorm: Information-Bottleneck Inspired Normalization for Representation   Learning",
    "summary": "Normalization is fundamental to deep learning, but existing approaches such as BatchNorm, LayerNorm, and RMSNorm are variance-centric by enforcing zero mean and unit variance, stabilizing training without controlling how representations capture task-relevant information. We propose IB-Inspired Normalization (IBNorm), a simple yet powerful family of methods grounded in the Information Bottleneck principle. IBNorm introduces bounded compression operations that encourage embeddings to preserve predictive information while suppressing nuisance variability, yielding more informative representations while retaining the stability and compatibility of standard normalization. Theoretically, we prove that IBNorm achieves a higher IB value and tighter generalization bounds than variance-centric methods. Empirically, IBNorm consistently outperforms BatchNorm, LayerNorm, and RMSNorm across large-scale language models (LLaMA, GPT-2) and vision models (ResNet, ViT), with mutual information analysis confirming superior information bottleneck behavior. Code will be released publicly.",
    "authors": [
      "Xiandong Zou",
      "Pan Zhou"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25262v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25262v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2510.25259v1",
    "title": "TV-Rec: Time-Variant Convolutional Filter for Sequential Recommendation",
    "summary": "Recently, convolutional filters have been increasingly adopted in sequential recommendation for their ability to capture local sequential patterns. However, most of these models complement convolutional filters with self-attention. This is because convolutional filters alone, generally fixed filters, struggle to capture global interactions necessary for accurate recommendation. We propose Time-Variant Convolutional Filters for Sequential Recommendation (TV-Rec), a model inspired by graph signal processing, where time-variant graph filters capture position-dependent temporal variations in user sequences. By replacing both fixed kernels and self-attention with time-variant filters, TV-Rec achieves higher expressive power and better captures complex interaction patterns in user behavior. This design not only eliminates the need for self-attention but also reduces computation while accelerating inference. Extensive experiments on six public benchmarks show that TV-Rec outperforms state-of-the-art baselines by an average of 7.49%.",
    "authors": [
      "Yehjin Shin",
      "Jeongwhan Choi",
      "Seojin Kim",
      "Noseong Park"
    ],
    "categories": [
      "cs.IR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25259v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25259v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2510.25232v1",
    "title": "From Medical Records to Diagnostic Dialogues: A Clinical-Grounded   Approach and Dataset for Psychiatric Comorbidity",
    "summary": "Psychiatric comorbidity is clinically significant yet challenging due to the complexity of multiple co-occurring disorders. To address this, we develop a novel approach integrating synthetic patient electronic medical record (EMR) construction and multi-agent diagnostic dialogue generation. We create 502 synthetic EMRs for common comorbid conditions using a pipeline that ensures clinical relevance and diversity. Our multi-agent framework transfers the clinical interview protocol into a hierarchical state machine and context tree, supporting over 130 diagnostic states while maintaining clinical standards. Through this rigorous process, we construct PsyCoTalk, the first large-scale dialogue dataset supporting comorbidity, containing 3,000 multi-turn diagnostic dialogues validated by psychiatrists. This dataset enhances diagnostic accuracy and treatment planning, offering a valuable resource for psychiatric comorbidity research. Compared to real-world clinical transcripts, PsyCoTalk exhibits high structural and linguistic fidelity in terms of dialogue length, token distribution, and diagnostic reasoning strategies. Licensed psychiatrists confirm the realism and diagnostic validity of the dialogues. This dataset enables the development and evaluation of models capable of multi-disorder psychiatric screening in a single conversational pass.",
    "authors": [
      "Tianxi Wan",
      "Jiaming Luo",
      "Siyuan Chen",
      "Kunyao Lan",
      "Jianhua Chen",
      "Haiyang Geng",
      "Mengyue Wu"
    ],
    "categories": [
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25232v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25232v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2510.25207v1",
    "title": "Selective Learning for Deep Time Series Forecasting",
    "summary": "Benefiting from high capacity for capturing complex temporal patterns, deep learning (DL) has significantly advanced time series forecasting (TSF). However, deep models tend to suffer from severe overfitting due to the inherent vulnerability of time series to noise and anomalies. The prevailing DL paradigm uniformly optimizes all timesteps through the MSE loss and learns those uncertain and anomalous timesteps without difference, ultimately resulting in overfitting. To address this, we propose a novel selective learning strategy for deep TSF. Specifically, selective learning screens a subset of the whole timesteps to calculate the MSE loss in optimization, guiding the model to focus on generalizable timesteps while disregarding non-generalizable ones. Our framework introduces a dual-mask mechanism to target timesteps: (1) an uncertainty mask leveraging residual entropy to filter uncertain timesteps, and (2) an anomaly mask employing residual lower bound estimation to exclude anomalous timesteps. Extensive experiments across eight real-world datasets demonstrate that selective learning can significantly improve the predictive performance for typical state-of-the-art deep models, including 37.4% MSE reduction for Informer, 8.4% for TimesNet, and 6.5% for iTransformer.",
    "authors": [
      "Yisong Fu",
      "Zezhi Shao",
      "Chengqing Yu",
      "Yujie Li",
      "Zhulin An",
      "Qi Wang",
      "Yongjun Xu",
      "Fei Wang"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25207v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25207v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2510.25199v1",
    "title": "AI-Powered Early Detection of Critical Diseases using Image Processing   and Audio Analysis",
    "summary": "Early diagnosis of critical diseases can significantly improve patient survival and reduce treatment costs. However, existing diagnostic techniques are often costly, invasive, and inaccessible in low-resource regions. This paper presents a multimodal artificial intelligence (AI) diagnostic framework integrating image analysis, thermal imaging, and audio signal processing for early detection of three major health conditions: skin cancer, vascular blood clots, and cardiopulmonary abnormalities. A fine-tuned MobileNetV2 convolutional neural network was trained on the ISIC 2019 dataset for skin lesion classification, achieving 89.3% accuracy, 91.6% sensitivity, and 88.2% specificity. A support vector machine (SVM) with handcrafted features was employed for thermal clot detection, achieving 86.4% accuracy (AUC = 0.89) on synthetic and clinical data. For cardiopulmonary analysis, lung and heart sound datasets from PhysioNet and Pascal were processed using Mel-Frequency Cepstral Coefficients (MFCC) and classified via Random Forest, reaching 87.2% accuracy and 85.7% sensitivity. Comparative evaluation against state-of-the-art models demonstrates that the proposed system achieves competitive results while remaining lightweight and deployable on low-cost devices. The framework provides a promising step toward scalable, real-time, and accessible AI-based pre-diagnostic healthcare solutions.",
    "authors": [
      "Manisha More",
      "Kavya Bhand",
      "Kaustubh Mukdam",
      "Kavya Sharma",
      "Manas Kawtikwar",
      "Hridayansh Kaware",
      "Prajwal Kavhar"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25199v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25199v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2510.25181v1",
    "title": "Fed-PELAD: Communication-Efficient Federated Learning for Massive MIMO   CSI Feedback with Personalized Encoders and a LoRA-Adapted Shared Decoder",
    "summary": "This paper addresses the critical challenges of communication overhead, data heterogeneity, and privacy in deep learning for channel state information (CSI) feedback in massive MIMO systems. To this end, we propose Fed-PELAD, a novel federated learning framework that incorporates personalized encoders and a LoRA-adapted shared decoder. Specifically, personalized encoders are trained locally on each user equipment (UE) to capture device-specific channel characteristics, while a shared decoder is updated globally via the coordination of the base station (BS) by using Low-Rank Adaptation (LoRA). This design ensures that only compact LoRA adapter parameters instead of full model updates are transmitted for aggregation. To further enhance convergence stability, we introduce an alternating freezing strategy with calibrated learning-rate ratio during LoRA aggregation. Extensive simulations on 3GPP-standard channel models demonstrate that Fed-PELAD requires only 42.97\\% of the uplink communication cost compared to conventional methods while achieving a performance gain of 1.2 dB in CSI feedback accuracy under heterogeneous conditions.",
    "authors": [
      "Yixiang Zhou",
      "Tong Wu",
      "Meixia Tao",
      "Jianhua Mo"
    ],
    "categories": [
      "cs.IT",
      "cs.AI",
      "math.IT"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25181v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25181v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2510.25160v1",
    "title": "Model-Document Protocol for AI Search",
    "summary": "AI search depends on linking large language models (LLMs) with vast external knowledge sources. Yet web pages, PDF files, and other raw documents are not inherently LLM-ready: they are long, noisy, and unstructured. Conventional retrieval methods treat these documents as verbatim text and return raw passages, leaving the burden of fragment assembly and contextual reasoning to the LLM. This gap underscores the need for a new retrieval paradigm that redefines how models interact with documents.   We introduce the Model-Document Protocol (MDP), a general framework that formalizes how raw text is bridged to LLMs through consumable knowledge representations. Rather than treating retrieval as passage fetching, MDP defines multiple pathways that transform unstructured documents into task-specific, LLM-ready inputs. These include agentic reasoning, which curates raw evidence into coherent context; memory grounding, which accumulates reusable notes to enrich reasoning; and structured leveraging, which encodes documents into formal representations such as graphs or key-value caches. All three pathways share the same goal: ensuring that what reaches the LLM is not raw fragments but compact, structured knowledge directly consumable for reasoning.   As an instantiation, we present MDP-Agent, which realizes the protocol through an agentic process: constructing document-level gist memories for global coverage, performing diffusion-based exploration with vertical exploitation to uncover layered dependencies, and applying map-reduce style synthesis to integrate large-scale evidence into compact yet sufficient context. Experiments on information-seeking benchmarks demonstrate that MDP-Agent outperforms baselines, validating both the soundness of the MDP framework and the effectiveness of its agentic instantiation.",
    "authors": [
      "Hongjin Qian",
      "Zheng Liu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25160v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25160v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2510.25123v1",
    "title": "Learning Low Rank Neural Representations of Hyperbolic Wave Dynamics   from Data",
    "summary": "We present a data-driven dimensionality reduction method that is well-suited for physics-based data representing hyperbolic wave propagation. The method utilizes a specialized neural network architecture called low rank neural representation (LRNR) inside a hypernetwork framework. The architecture is motivated by theoretical results that rigorously prove the existence of efficient representations for this wave class. We illustrate through archetypal examples that such an efficient low-dimensional representation of propagating waves can be learned directly from data through a combination of deep learning techniques. We observe that a low rank tensor representation arises naturally in the trained LRNRs, and that this reveals a new decomposition of wave propagation where each decomposed mode corresponds to interpretable physical features. Furthermore, we demonstrate that the LRNR architecture enables efficient inference via a compression scheme, which is a potentially important feature when deploying LRNRs in demanding performance regimes.",
    "authors": [
      "Woojin Cho",
      "Kookjin Lee",
      "Noseong Park",
      "Donsub Rim",
      "Gerrit Welper"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "68T07, 65D25, 65M22"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25123v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25123v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2510.25113v1",
    "title": "The Neural Differential Manifold: An Architecture with Explicit   Geometric Structure",
    "summary": "This paper introduces the Neural Differential Manifold (NDM), a novel neural network architecture that explicitly incorporates geometric structure into its fundamental design. Departing from conventional Euclidean parameter spaces, the NDM re-conceptualizes a neural network as a differentiable manifold where each layer functions as a local coordinate chart, and the network parameters directly parameterize a Riemannian metric tensor at every point. The architecture is organized into three synergistic layers: a Coordinate Layer implementing smooth chart transitions via invertible transformations inspired by normalizing flows, a Geometric Layer that dynamically generates the manifold's metric through auxiliary sub-networks, and an Evolution Layer that optimizes both task performance and geometric simplicity through a dual-objective loss function. This geometric regularization penalizes excessive curvature and volume distortion, providing intrinsic regularization that enhances generalization and robustness. The framework enables natural gradient descent optimization aligned with the learned manifold geometry and offers unprecedented interpretability by endowing internal representations with clear geometric meaning. We analyze the theoretical advantages of this approach, including its potential for more efficient optimization, enhanced continual learning, and applications in scientific discovery and controllable generative modeling. While significant computational challenges remain, the Neural Differential Manifold represents a fundamental shift towards geometrically structured, interpretable, and efficient deep learning systems.",
    "authors": [
      "Di Zhang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "math.DG",
      "math.OC",
      "68T07, 62B11, 53B21, 65D18",
      "I.2.6; I.5.1; G.1.6; G.3"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25113v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25113v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2510.25731v1",
    "title": "LieSolver: A PDE-constrained solver for IBVPs using Lie symmetries",
    "summary": "We introduce a method for efficiently solving initial-boundary value problems (IBVPs) that uses Lie symmetries to enforce the associated partial differential equation (PDE) exactly by construction. By leveraging symmetry transformations, the model inherently incorporates the physical laws and learns solutions from initial and boundary data. As a result, the loss directly measures the model's accuracy, leading to improved convergence. Moreover, for well-posed IBVPs, our method enables rigorous error estimation. The approach yields compact models, facilitating an efficient optimization. We implement LieSolver and demonstrate its application to linear homogeneous PDEs with a range of initial conditions, showing that it is faster and more accurate than physics-informed neural networks (PINNs). Overall, our method improves both computational efficiency and the reliability of predictions for PDE-constrained problems.",
    "authors": [
      "René P. Klausen",
      "Ivan Timofeev",
      "Johannes Frank",
      "Jonas Naujoks",
      "Thomas Wiegand",
      "Sebastian Lapuschkin",
      "Wojciech Samek"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "physics.comp-ph"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25731v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25731v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.25634v1",
    "title": "Learning to Plan & Schedule with Reinforcement-Learned Bimanual Robot   Skills",
    "summary": "Long-horizon contact-rich bimanual manipulation presents a significant challenge, requiring complex coordination involving a mixture of parallel execution and sequential collaboration between arms. In this paper, we introduce a hierarchical framework that frames this challenge as an integrated skill planning & scheduling problem, going beyond purely sequential decision-making to support simultaneous skill invocation. Our approach is built upon a library of single-arm and bimanual primitive skills, each trained using Reinforcement Learning (RL) in GPU-accelerated simulation. We then train a Transformer-based planner on a dataset of skill compositions to act as a high-level scheduler, simultaneously predicting the discrete schedule of skills as well as their continuous parameters. We demonstrate that our method achieves higher success rates on complex, contact-rich tasks than end-to-end RL approaches and produces more efficient, coordinated behaviors than traditional sequential-only planners.",
    "authors": [
      "Weikang Wan",
      "Fabio Ramos",
      "Xuning Yang",
      "Caelan Garrett"
    ],
    "categories": [
      "cs.RO",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25634v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25634v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.25563v1",
    "title": "Leveraging an Atmospheric Foundational Model for Subregional Sea Surface   Temperature Forecasting",
    "summary": "The accurate prediction of oceanographic variables is crucial for understanding climate change, managing marine resources, and optimizing maritime activities. Traditional ocean forecasting relies on numerical models; however, these approaches face limitations in terms of computational cost and scalability. In this study, we adapt Aurora, a foundational deep learning model originally designed for atmospheric forecasting, to predict sea surface temperature (SST) in the Canary Upwelling System. By fine-tuning this model with high-resolution oceanographic reanalysis data, we demonstrate its ability to capture complex spatiotemporal patterns while reducing computational demands. Our methodology involves a staged fine-tuning process, incorporating latitude-weighted error metrics and optimizing hyperparameters for efficient learning. The experimental results show that the model achieves a low RMSE of 0.119K, maintaining high anomaly correlation coefficients (ACC $\\approx 0.997$). The model successfully reproduces large-scale SST structures but faces challenges in capturing finer details in coastal regions. This work contributes to the field of data-driven ocean forecasting by demonstrating the feasibility of using deep learning models pre-trained in different domains for oceanic applications. Future improvements include integrating additional oceanographic variables, increasing spatial resolution, and exploring physics-informed neural networks to enhance interpretability and understanding. These advancements can improve climate modeling and ocean prediction accuracy, supporting decision-making in environmental and economic sectors.",
    "authors": [
      "Víctor Medina",
      "Giovanny A. Cuervo-Londoño",
      "Javier Sánchez"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "physics.ao-ph"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25563v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25563v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.25550v1",
    "title": "Robust variable selection for spatial point processes observed with   noise",
    "summary": "We propose a method for variable selection in the intensity function of spatial point processes that combines sparsity-promoting estimation with noise-robust model selection. As high-resolution spatial data becomes increasingly available through remote sensing and automated image analysis, identifying spatial covariates that influence the localization of events is crucial to understand the underlying mechanism. However, results from automated acquisition techniques are often noisy, for example due to measurement uncertainties or detection errors, which leads to spurious displacements and missed events. We study the impact of such noise on sparse point-process estimation across different models, including Poisson and Thomas processes. To improve noise robustness, we propose to use stability selection based on point-process subsampling and to incorporate a non-convex best-subset penalty to enhance model-selection performance. In extensive simulations, we demonstrate that such an approach reliably recovers true covariates under diverse noise scenarios and improves both selection accuracy and stability. We then apply the proposed method to a forestry data set, analyzing the distribution of trees in relation to elevation and soil nutrients in a tropical rain forest. This shows the practical utility of the method, which provides a systematic framework for robust variable selection in spatial point-process models under noise, without requiring additional knowledge of the process.",
    "authors": [
      "Dominik Sturm",
      "Ivo F. Sbalzarini"
    ],
    "categories": [
      "stat.ME",
      "cs.LG",
      "stat.CO",
      "stat.ML"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25550v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25550v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.25514v1",
    "title": "Convergence of off-policy TD(0) with linear function approximation for   reversible Markov chains",
    "summary": "We study the convergence of off-policy TD(0) with linear function approximation when used to approximate the expected discounted reward in a Markov chain. It is well known that the combination of off-policy learning and function approximation can lead to divergence of the algorithm. Existing results for this setting modify the algorithm, for instance by reweighing the updates using importance sampling. This establishes convergence at the expense of additional complexity. In contrast, our approach is to analyse the standard algorithm, but to restrict our attention to the class of reversible Markov chains. We demonstrate convergence under this mild reversibility condition on the structure of the chain, which in many applications can be assumed using domain knowledge. In particular, we establish a convergence guarantee under an upper bound on the discount factor in terms of the difference between the on-policy and off-policy process. This improves upon known results in the literature that state that convergence holds for a sufficiently small discount factor by establishing an explicit bound. Convergence is with probability one and achieves projected Bellman error equal to zero. To obtain these results, we adapt the stochastic approximation framework that was used by Tsitsiklis and Van Roy [1997 for the on-policy case, to the off-policy case. We illustrate our results using different types of reversible Markov chains, such as one-dimensional random walks and random walks on a weighted graph.",
    "authors": [
      "Maik Overmars",
      "Jasper Goseling",
      "Richard Boucherie"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25514v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25514v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.25361v1",
    "title": "Parameter Averaging in Link Prediction",
    "summary": "Ensemble methods are widely employed to improve generalization in machine learning. This has also prompted the adoption of ensemble learning for the knowledge graph embedding (KGE) models in performing link prediction. Typical approaches to this end train multiple models as part of the ensemble, and the diverse predictions are then averaged. However, this approach has some significant drawbacks. For instance, the computational overhead of training multiple models increases latency and memory overhead. In contrast, model merging approaches offer a promising alternative that does not require training multiple models. In this work, we introduce model merging, specifically weighted averaging, in KGE models. Herein, a running average of model parameters from a training epoch onward is maintained and used for predictions. To address this, we additionally propose an approach that selectively updates the running average of the ensemble model parameters only when the generalization performance improves on a validation dataset. We evaluate these two different weighted averaging approaches on link prediction tasks, comparing the state-of-the-art benchmark ensemble approach. Additionally, we evaluate the weighted averaging approach considering literal-augmented KGE models and multi-hop query answering tasks as well. The results demonstrate that the proposed weighted averaging approach consistently improves performance across diverse evaluation settings.",
    "authors": [
      "Rupesh Sapkota",
      "Caglar Demir",
      "Arnab Sharma",
      "Axel-Cyrille Ngonga Ngomo"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25361v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25361v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.25319v1",
    "title": "4-Doodle: Text to 3D Sketches that Move!",
    "summary": "We present a novel task: text-to-3D sketch animation, which aims to bring freeform sketches to life in dynamic 3D space. Unlike prior works focused on photorealistic content generation, we target sparse, stylized, and view-consistent 3D vector sketches, a lightweight and interpretable medium well-suited for visual communication and prototyping. However, this task is very challenging: (i) no paired dataset exists for text and 3D (or 4D) sketches; (ii) sketches require structural abstraction that is difficult to model with conventional 3D representations like NeRFs or point clouds; and (iii) animating such sketches demands temporal coherence and multi-view consistency, which current pipelines do not address. Therefore, we propose 4-Doodle, the first training-free framework for generating dynamic 3D sketches from text. It leverages pretrained image and video diffusion models through a dual-space distillation scheme: one space captures multi-view-consistent geometry using differentiable B\\'ezier curves, while the other encodes motion dynamics via temporally-aware priors. Unlike prior work (e.g., DreamFusion), which optimizes from a single view per step, our multi-view optimization ensures structural alignment and avoids view ambiguity, critical for sparse sketches. Furthermore, we introduce a structure-aware motion module that separates shape-preserving trajectories from deformation-aware changes, enabling expressive motion such as flipping, rotation, and articulated movement. Extensive experiments show that our method produces temporally realistic and structurally stable 3D sketch animations, outperforming existing baselines in both fidelity and controllability. We hope this work serves as a step toward more intuitive and accessible 4D content creation.",
    "authors": [
      "Hao Chen",
      "Jiaqi Wang",
      "Yonggang Qi",
      "Ke Li",
      "Kaiyue Pang",
      "Yi-Zhe Song"
    ],
    "categories": [
      "cs.GR",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25319v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25319v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.25273v1",
    "title": "Adapting Small Language Models to Low-Resource Domains: A Case Study in   Hindi Tourism QA",
    "summary": "Domain-specific question answering in low-resource languages faces two key challenges: scarcity of annotated datasets and limited domain knowledge in general-purpose language models. In this work, we present a multi-stage finetuning strategy to adapt lightweight language models to the Hindi tourism domain by leveraging both original and synthetic training data. Synthetic question-answer pairs are generated using large LLMs (LLaMA-70B, Phi-14B) and used to augment the limited original dataset. We explore several training methodologies and analyse their impact on domain generalisation. Our results demonstrate that large models can efficiently generate synthetic data, while small models can effectively adapt to it, offering a scalable pathway for low-resource, domain-specific QA.",
    "authors": [
      "Sandipan Majhi",
      "Paheli Bhattacharya"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25273v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25273v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.25263v1",
    "title": "LangHOPS: Language Grounded Hierarchical Open-Vocabulary Part   Segmentation",
    "summary": "We propose LangHOPS, the first Multimodal Large Language Model (MLLM) based framework for open-vocabulary object-part instance segmentation. Given an image, LangHOPS can jointly detect and segment hierarchical object and part instances from open-vocabulary candidate categories. Unlike prior approaches that rely on heuristic or learnable visual grouping, our approach grounds object-part hierarchies in language space. It integrates the MLLM into the object-part parsing pipeline to leverage its rich knowledge and reasoning capabilities, and link multi-granularity concepts within the hierarchies. We evaluate LangHOPS across multiple challenging scenarios, including in-domain and cross-dataset object-part instance segmentation, and zero-shot semantic segmentation. LangHOPS achieves state-of-the-art results, surpassing previous methods by 5.5% Average Precision (AP) (in-domain) and 4.8% (cross-dataset) on the PartImageNet dataset and by 2.5% mIOU on unseen object parts in ADE20K (zero-shot). Ablation studies further validate the effectiveness of the language-grounded hierarchy and MLLM driven part query refinement strategy. The code will be released here.",
    "authors": [
      "Yang Miao",
      "Jan-Nico Zaech",
      "Xi Wang",
      "Fabien Despinoy",
      "Danda Pani Paudel",
      "Luc Van Gool"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25263v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25263v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.25223v1",
    "title": "FELA: A Multi-Agent Evolutionary System for Feature Engineering of   Industrial Event Log Data",
    "summary": "Event log data, recording fine-grained user actions and system events, represent one of the most valuable assets for modern digital services. However, the complexity and heterogeneity of industrial event logs--characterized by large scale, high dimensionality, diverse data types, and intricate temporal or relational structures--make feature engineering extremely challenging. Existing automatic feature engineering approaches, such as AutoML or genetic methods, often suffer from limited explainability, rigid predefined operations, and poor adaptability to complicated heterogeneous data. In this paper, we propose FELA (Feature Engineering LLM Agents), a multi-agent evolutionary system that autonomously extracts meaningful and high-performing features from complex industrial event log data. FELA integrates the reasoning and coding capabilities of large language models (LLMs) with an insight-guided self-evolution paradigm. Specifically, FELA employs specialized agents--Idea Agents, Code Agents, and Critic Agents--to collaboratively generate, validate, and implement novel feature ideas. An Evaluation Agent summarizes feedback and updates a hierarchical knowledge base and dual-memory system to enable continual improvement. Moreover, FELA introduces an agentic evolution algorithm, combining reinforcement learning and genetic algorithm principles to balance exploration and exploitation across the idea space. Extensive experiments on real industrial datasets demonstrate that FELA can generate explainable, domain-relevant features that significantly improve model performance while reducing manual effort. Our results highlight the potential of LLM-based multi-agent systems as a general framework for automated, interpretable, and adaptive feature engineering in complex real-world environments.",
    "authors": [
      "Kun ouyang",
      "Haoyu Wang",
      "Dong Fang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25223v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25223v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.25166v1",
    "title": "A Study on Inference Latency for Vision Transformers on Mobile Devices",
    "summary": "Given the significant advances in machine learning techniques on mobile devices, particularly in the domain of computer vision, in this work we quantitatively study the performance characteristics of 190 real-world vision transformers (ViTs) on mobile devices. Through a comparison with 102 real-world convolutional neural networks (CNNs), we provide insights into the factors that influence the latency of ViT architectures on mobile devices. Based on these insights, we develop a dataset including measured latencies of 1000 synthetic ViTs with representative building blocks and state-of-the-art architectures from two machine learning frameworks and six mobile platforms. Using this dataset, we show that inference latency of new ViTs can be predicted with sufficient accuracy for real-world applications.",
    "authors": [
      "Zhuojin Li",
      "Marco Paolieri",
      "Leana Golubchik"
    ],
    "categories": [
      "cs.CV",
      "cs.LG",
      "cs.PF"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25166v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25166v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.25753v1",
    "title": "How Data Mixing Shapes In-Context Learning: Asymptotic Equivalence for   Transformers with MLPs",
    "summary": "Pretrained Transformers demonstrate remarkable in-context learning (ICL) capabilities, enabling them to adapt to new tasks from demonstrations without parameter updates. However, theoretical studies often rely on simplified architectures (e.g., omitting MLPs), data models (e.g., linear regression with isotropic inputs), and single-source training, limiting their relevance to realistic settings. In this work, we study ICL in pretrained Transformers with nonlinear MLP heads on nonlinear tasks drawn from multiple data sources with heterogeneous input, task, and noise distributions. We analyze a model where the MLP comprises two layers, with the first layer trained via a single gradient step and the second layer fully optimized. Under high-dimensional asymptotics, we prove that such models are equivalent in ICL error to structured polynomial predictors, leveraging results from the theory of Gaussian universality and orthogonal polynomials. This equivalence reveals that nonlinear MLPs meaningfully enhance ICL performance, particularly on nonlinear tasks, compared to linear baselines. It also enables a precise analysis of data mixing effects: we identify key properties of high-quality data sources (low noise, structured covariances) and show that feature learning emerges only when the task covariance exhibits sufficient structure. These results are validated empirically across various activation functions, model sizes, and data distributions. Finally, we experiment with a real-world scenario involving multilingual sentiment analysis where each language is treated as a different source. Our experimental results for this case exemplify how our findings extend to real-world cases. Overall, our work advances the theoretical foundations of ICL in Transformers and provides actionable insight into the role of architecture and data in ICL.",
    "authors": [
      "Samet Demir",
      "Zafer Dogan"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25753v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25753v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2510.25739v1",
    "title": "Hawk: Leveraging Spatial Context for Faster Autoregressive Text-to-Image   Generation",
    "summary": "Autoregressive (AR) image generation models are capable of producing high-fidelity images but often suffer from slow inference due to their inherently sequential, token-by-token decoding process. Speculative decoding, which employs a lightweight draft model to approximate the output of a larger AR model, has shown promise in accelerating text generation without compromising quality. However, its application to image generation remains largely underexplored. The challenges stem from a significantly larger sampling space, which complicates the alignment between the draft and target model outputs, coupled with the inadequate use of the two-dimensional spatial structure inherent in images, thereby limiting the modeling of local dependencies. To overcome these challenges, we introduce Hawk, a new approach that harnesses the spatial structure of images to guide the speculative model toward more accurate and efficient predictions. Experimental results on multiple text-to-image benchmarks demonstrate a 1.71x speedup over standard AR models, while preserving both image fidelity and diversity.",
    "authors": [
      "Zhi-Kai Chen",
      "Jun-Peng Jiang",
      "Han-Jia Ye",
      "De-Chuan Zhan"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25739v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25739v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2510.25591v1",
    "title": "Generalized Sobolev IPM for Graph-Based Measures",
    "summary": "We study the Sobolev IPM problem for measures supported on a graph metric space, where critic function is constrained to lie within the unit ball defined by Sobolev norm. While Le et al. (2025) achieved scalable computation by relating Sobolev norm to weighted $L^p$-norm, the resulting framework remains intrinsically bound to $L^p$ geometric structure, limiting its ability to incorporate alternative structural priors beyond the $L^p$ geometry paradigm. To overcome this limitation, we propose to generalize Sobolev IPM through the lens of \\emph{Orlicz geometric structure}, which employs convex functions to capture nuanced geometric relationships, building upon recent advances in optimal transport theory -- particularly Orlicz-Wasserstein (OW) and generalized Sobolev transport -- that have proven instrumental in advancing machine learning methodologies. This generalization encompasses classical Sobolev IPM as a special case while accommodating diverse geometric priors beyond traditional $L^p$ structure. It however brings up significant computational hurdles that compound those already inherent in Sobolev IPM. To address these challenges, we establish a novel theoretical connection between Orlicz-Sobolev norm and Musielak norm which facilitates a novel regularization for the generalized Sobolev IPM (GSI). By further exploiting the underlying graph structure, we show that GSI with Musielak regularization (GSI-M) reduces to a simple \\emph{univariate optimization} problem, achieving remarkably computational efficiency. Empirically, GSI-M is several-order faster than the popular OW in computation, and demonstrates its practical advantages in comparing probability measures on a given graph for document classification and several tasks in topological data analysis.",
    "authors": [
      "Tam Le",
      "Truyen Nguyen",
      "Hideitsu Hino",
      "Kenji Fukumizu"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25591v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25591v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2510.25590v1",
    "title": "RegionE: Adaptive Region-Aware Generation for Efficient Image Editing",
    "summary": "Recently, instruction-based image editing (IIE) has received widespread attention. In practice, IIE often modifies only specific regions of an image, while the remaining areas largely remain unchanged. Although these two types of regions differ significantly in generation difficulty and computational redundancy, existing IIE models do not account for this distinction, instead applying a uniform generation process across the entire image. This motivates us to propose RegionE, an adaptive, region-aware generation framework that accelerates IIE tasks without additional training. Specifically, the RegionE framework consists of three main components: 1) Adaptive Region Partition. We observed that the trajectory of unedited regions is straight, allowing for multi-step denoised predictions to be inferred in a single step. Therefore, in the early denoising stages, we partition the image into edited and unedited regions based on the difference between the final estimated result and the reference image. 2) Region-Aware Generation. After distinguishing the regions, we replace multi-step denoising with one-step prediction for unedited areas. For edited regions, the trajectory is curved, requiring local iterative denoising. To improve the efficiency and quality of local iterative generation, we propose the Region-Instruction KV Cache, which reduces computational cost while incorporating global information. 3) Adaptive Velocity Decay Cache. Observing that adjacent timesteps in edited regions exhibit strong velocity similarity, we further propose an adaptive velocity decay cache to accelerate the local denoising process. We applied RegionE to state-of-the-art IIE base models, including Step1X-Edit, FLUX.1 Kontext, and Qwen-Image-Edit. RegionE achieved acceleration factors of 2.57, 2.41, and 2.06. Evaluations by GPT-4o confirmed that semantic and perceptual fidelity were well preserved.",
    "authors": [
      "Pengtao Chen",
      "Xianfang Zeng",
      "Maosen Zhao",
      "Mingzhu Shen",
      "Peng Ye",
      "Bangyin Xiang",
      "Zhibo Wang",
      "Wei Cheng",
      "Gang Yu",
      "Tao Chen"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25590v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25590v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2510.25577v1",
    "title": "Lost in Phonation: Voice Quality Variation as an Evaluation Dimension   for Speech Foundation Models",
    "summary": "Recent advances in speech foundation models (SFMs) have enabled the direct processing of spoken language from raw audio, bypassing intermediate textual representations. This capability allows SFMs to be exposed to, and potentially respond to, rich paralinguistic variations embedded in the input speech signal. One under-explored dimension of paralinguistic variation is voice quality, encompassing phonation types such as creaky and breathy voice. These phonation types are known to influence how listeners infer affective state, stance and social meaning in speech. Existing benchmarks for speech understanding largely rely on multiple-choice question answering (MCQA) formats, which are prone to failure and therefore unreliable in capturing the nuanced ways paralinguistic features influence model behaviour. In this paper, we probe SFMs through open-ended generation tasks and speech emotion recognition, evaluating whether model behaviours are consistent across different phonation inputs. We introduce a new parallel dataset featuring synthesized modifications to voice quality, designed to evaluate SFM responses to creaky and breathy voice. Our work provides the first examination of SFM sensitivity to these particular non-lexical aspects of speech perception.",
    "authors": [
      "Harm Lameris",
      "Shree Harsha Bokkahalli Satish",
      "Joakim Gustafson",
      "Éva Székely"
    ],
    "categories": [
      "eess.AS",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25577v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25577v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2510.25412v1",
    "title": "Serve Programs, Not Prompts",
    "summary": "Current large language model (LLM) serving systems, primarily designed for text completion, are neither efficient nor adaptable for increasingly complex LLM applications due to their inflexible design. We propose a new LLM serving system architecture that serves programs instead of prompts to address this problem. These programs, called LLM Inference Programs (LIPs), allow users to customize token prediction and KV cache management at runtime and to offload parts of their application logic, such as tool execution, to the server. We describe an example of this architecture through a system named Symphony, which functions as an operating system for LIPs. Symphony exposes LLM model computations via system calls and virtualizes KV cache with a dedicated file system, while ensuring GPU efficiency with a two-level process scheduling scheme. Symphony has the potential to open the door to a more efficient and extensible ecosystem for LLM applications.",
    "authors": [
      "In Gim",
      "Lin Zhong"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25412v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25412v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2510.25257v1",
    "title": "RT-DETRv4: Painlessly Furthering Real-Time Object Detection with Vision   Foundation Models",
    "summary": "Real-time object detection has achieved substantial progress through meticulously designed architectures and optimization strategies. However, the pursuit of high-speed inference via lightweight network designs often leads to degraded feature representation, which hinders further performance improvements and practical on-device deployment. In this paper, we propose a cost-effective and highly adaptable distillation framework that harnesses the rapidly evolving capabilities of Vision Foundation Models (VFMs) to enhance lightweight object detectors. Given the significant architectural and learning objective disparities between VFMs and resource-constrained detectors, achieving stable and task-aligned semantic transfer is challenging. To address this, on one hand, we introduce a Deep Semantic Injector (DSI) module that facilitates the integration of high-level representations from VFMs into the deep layers of the detector. On the other hand, we devise a Gradient-guided Adaptive Modulation (GAM) strategy, which dynamically adjusts the intensity of semantic transfer based on gradient norm ratios. Without increasing deployment and inference overhead, our approach painlessly delivers striking and consistent performance gains across diverse DETR-based models, underscoring its practical utility for real-time detection. Our new model family, RT-DETRv4, achieves state-of-the-art results on COCO, attaining AP scores of 49.7/53.5/55.4/57.0 at corresponding speeds of 273/169/124/78 FPS.",
    "authors": [
      "Zijun Liao",
      "Yian Zhao",
      "Xin Shan",
      "Yu Yan",
      "Chang Liu",
      "Lei Lu",
      "Xiangyang Ji",
      "Jie Chen"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25257v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25257v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2510.25693v1",
    "title": "PyDPF: A Python Package for Differentiable Particle Filtering",
    "summary": "State-space models (SSMs) are a widely used tool in time series analysis. In the complex systems that arise from real-world data, it is common to employ particle filtering (PF), an efficient Monte Carlo method for estimating the hidden state corresponding to a sequence of observations. Applying particle filtering requires specifying both the parametric form and the parameters of the system, which are often unknown and must be estimated. Gradient-based optimisation techniques cannot be applied directly to standard particle filters, as the filters themselves are not differentiable. However, several recently proposed methods modify the resampling step to make particle filtering differentiable. In this paper, we present an implementation of several such differentiable particle filters (DPFs) with a unified API built on the popular PyTorch framework. Our implementation makes these algorithms easily accessible to a broader research community and facilitates straightforward comparison between them. We validate our framework by reproducing experiments from several existing studies and demonstrate how DPFs can be applied to address several common challenges with state space modelling.",
    "authors": [
      "John-Joseph Brady",
      "Benjamin Cox",
      "Víctor Elvira",
      "Yunpeng Li"
    ],
    "categories": [
      "eess.SP",
      "cs.LG",
      "60-04",
      "G.3"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25693v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25693v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.25692v1",
    "title": "A Configuration-First Framework for Reproducible, Low-Code Localization",
    "summary": "Machine learning is increasingly permeating radio-based localization services. To keep results credible and comparable, everyday workflows should make rigorous experiment specification and exact repeatability the default, without blocking advanced experimentation. However, in practice, researchers face a three-way gap that could be filled by a framework that offers (i) low coding effort for end-to-end studies, (ii) reproducibility by default including versioned code, data, and configurations, controlled randomness, isolated runs, and recorded artifacts, and (iii) built-in extensibility so new models, metrics, and stages can be added with minimal integration effort. Existing tools rarely deliver all three for machine learning in general and localization workflows in particular. In this paper we introduce LOCALIZE, a low-code, configuration-first framework for radio localization in which experiments are declared in human-readable configuration, a workflow orchestrator runs standardized pipelines from data preparation to reporting, and all artifacts, such as datasets, models, metrics, and reports, are versioned. The preconfigured, versioned datasets reduce initial setup and boilerplate, speeding up model development and evaluation. The design, with clear extension points, allows experts to add components without reworking the infrastructure. In a qualitative comparison and a head-to-head study against a plain Jupyter notebook baseline, we show that the framework reduces authoring effort while maintaining comparable runtime and memory behavior. Furthermore, using a Bluetooth Low Energy dataset, we show that scaling across training data (1x to 10x) keeps orchestration overheads bounded as data grows. Overall, the framework makes reproducible machine-learning-based localization experimentation practical, accessible, and extensible.",
    "authors": [
      "Tim Strnad",
      "Blaž Bertalanič",
      "Carolina Fortuna"
    ],
    "categories": [
      "cs.SE",
      "cs.LG",
      "D.2.6; I.2.6"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25692v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25692v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.25569v1",
    "title": "A Framework for Bounding Deterministic Risk with PAC-Bayes: Applications   to Majority Votes",
    "summary": "PAC-Bayes is a popular and efficient framework for obtaining generalization guarantees in situations involving uncountable hypothesis spaces. Unfortunately, in its classical formulation, it only provides guarantees on the expected risk of a randomly sampled hypothesis. This requires stochastic predictions at test time, making PAC-Bayes unusable in many practical situations where a single deterministic hypothesis must be deployed. We propose a unified framework to extract guarantees holding for a single hypothesis from stochastic PAC-Bayesian guarantees. We present a general oracle bound and derive from it a numerical bound and a specialization to majority vote. We empirically show that our approach consistently outperforms popular baselines (by up to a factor of 2) when it comes to generalization bounds on deterministic classifiers.",
    "authors": [
      "Benjamin Leblanc",
      "Pascal Germain"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25569v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25569v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.25566v1",
    "title": "PitchFlower: A flow-based neural audio codec with pitch controllability",
    "summary": "We present PitchFlower, a flow-based neural audio codec with explicit pitch controllability. Our approach enforces disentanglement through a simple perturbation: during training, F0 contours are flattened and randomly shifted, while the true F0 is provided as conditioning. A vector-quantization bottleneck prevents pitch recovery, and a flow-based decoder generates high quality audio. Experiments show that PitchFlower achieves more accurate pitch control than WORLD at much higher audio quality, and outperforms SiFiGAN in controllability while maintaining comparable quality. Beyond pitch, this framework provides a simple and extensible path toward disentangling other speech attributes.",
    "authors": [
      "Diego Torres",
      "Axel Roebel",
      "Nicolas Obin"
    ],
    "categories": [
      "eess.AS",
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25566v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25566v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.25497v1",
    "title": "Right for the Right Reasons: Avoiding Reasoning Shortcuts via   Prototypical Neurosymbolic AI",
    "summary": "Neurosymbolic AI is growing in popularity thanks to its ability to combine neural perception and symbolic reasoning in end-to-end trainable models. However, recent findings reveal these are prone to shortcut reasoning, i.e., to learning unindented concepts--or neural predicates--which exploit spurious correlations to satisfy the symbolic constraints. In this paper, we address reasoning shortcuts at their root cause and we introduce prototypical neurosymbolic architectures. These models are able to satisfy the symbolic constraints (be right) because they have learnt the correct basic concepts (for the right reasons) and not because of spurious correlations, even in extremely low data regimes. Leveraging the theory of prototypical learning, we demonstrate that we can effectively avoid reasoning shortcuts by training the models to satisfy the background knowledge while taking into account the similarity of the input with respect to the handful of labelled datapoints. We extensively validate our approach on the recently proposed rsbench benchmark suite in a variety of settings and tasks with very scarce supervision: we show significant improvements in learning the right concepts both in synthetic tasks (MNIST-EvenOdd and Kand-Logic) and real-world, high-stake ones (BDD-OIA). Our findings pave the way to prototype grounding as an effective, annotation-efficient strategy for safe and reliable neurosymbolic learning.",
    "authors": [
      "Luca Andolfi",
      "Eleonora Giunchiglia"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25497v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25497v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.25445v1",
    "title": "Agentic AI: A Comprehensive Survey of Architectures, Applications, and   Future Directions",
    "summary": "Agentic AI represents a transformative shift in artificial intelligence, but its rapid advancement has led to a fragmented understanding, often conflating modern neural systems with outdated symbolic models -- a practice known as conceptual retrofitting. This survey cuts through this confusion by introducing a novel dual-paradigm framework that categorizes agentic systems into two distinct lineages: the Symbolic/Classical (relying on algorithmic planning and persistent state) and the Neural/Generative (leveraging stochastic generation and prompt-driven orchestration). Through a systematic PRISMA-based review of 90 studies (2018--2025), we provide a comprehensive analysis structured around this framework across three dimensions: (1) the theoretical foundations and architectural principles defining each paradigm; (2) domain-specific implementations in healthcare, finance, and robotics, demonstrating how application constraints dictate paradigm selection; and (3) paradigm-specific ethical and governance challenges, revealing divergent risks and mitigation strategies. Our analysis reveals that the choice of paradigm is strategic: symbolic systems dominate safety-critical domains (e.g., healthcare), while neural systems prevail in adaptive, data-rich environments (e.g., finance). Furthermore, we identify critical research gaps, including a significant deficit in governance models for symbolic systems and a pressing need for hybrid neuro-symbolic architectures. The findings culminate in a strategic roadmap arguing that the future of Agentic AI lies not in the dominance of one paradigm, but in their intentional integration to create systems that are both adaptable and reliable. This work provides the essential conceptual toolkit to guide future research, development, and policy toward robust and trustworthy hybrid intelligent systems.",
    "authors": [
      "Mohamad Abou Ali",
      "Fadi Dornaika"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25445v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25445v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.25427v1",
    "title": "RLMEval: Evaluating Research-Level Neural Theorem Proving",
    "summary": "Despite impressive results on curated benchmarks, the practical impact of large language models (LLMs) on research-level neural theorem proving and proof autoformalization is still limited. We introduce RLMEval, an evaluation suite for these tasks, focusing on research-level mathematics from real-world Lean formalization projects. RLMEval targets the evaluation of neural theorem proving and proof autoformalization on challenging research-level theorems by leveraging real Lean Blueprint formalization projects. Our evaluation of state-of-the-art models on RLMEval, comprising 613 theorems from 6 Lean projects, reveals a significant gap: progress on existing benchmarks does not readily translate to these more realistic settings, with the best model achieving only a 10.3 % pass rate. RLMEval provides a new, challenging benchmark designed to guide and accelerate progress in automated reasoning for formal mathematics.",
    "authors": [
      "Auguste Poiroux",
      "Antoine Bosselut",
      "Viktor Kunčak"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25427v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25427v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.25409v1",
    "title": "BhashaBench V1: A Comprehensive Benchmark for the Quadrant of Indic   Domains",
    "summary": "The rapid advancement of large language models(LLMs) has intensified the need for domain and culture specific evaluation. Existing benchmarks are largely Anglocentric and domain-agnostic, limiting their applicability to India-centric contexts. To address this gap, we introduce BhashaBench V1, the first domain-specific, multi-task, bilingual benchmark focusing on critical Indic knowledge systems. BhashaBench V1 contains 74,166 meticulously curated question-answer pairs, with 52,494 in English and 21,672 in Hindi, sourced from authentic government and domain-specific exams. It spans four major domains: Agriculture, Legal, Finance, and Ayurveda, comprising 90+ subdomains and covering 500+ topics, enabling fine-grained evaluation. Evaluation of 29+ LLMs reveals significant domain and language specific performance gaps, with especially large disparities in low-resource domains. For instance, GPT-4o achieves 76.49% overall accuracy in Legal but only 59.74% in Ayurveda. Models consistently perform better on English content compared to Hindi across all domains. Subdomain-level analysis shows that areas such as Cyber Law, International Finance perform relatively well, while Panchakarma, Seed Science, and Human Rights remain notably weak. BhashaBench V1 provides a comprehensive dataset for evaluating large language models across India's diverse knowledge domains. It enables assessment of models' ability to integrate domain-specific knowledge with bilingual understanding. All code, benchmarks, and resources are publicly available to support open research.",
    "authors": [
      "Vijay Devane",
      "Mohd Nauman",
      "Bhargav Patel",
      "Aniket Mahendra Wakchoure",
      "Yogeshkumar Sant",
      "Shyam Pawar",
      "Viraj Thakur",
      "Ananya Godse",
      "Sunil Patra",
      "Neha Maurya",
      "Suraj Racha",
      "Nitish Kamal Singh",
      "Ajay Nagpal",
      "Piyush Sawarkar",
      "Kundeshwar Vijayrao Pundalik",
      "Rohit Saluja",
      "Ganesh Ramakrishnan"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25409v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25409v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.25388v1",
    "title": "Grouping Nodes With Known Value Differences: A Lossless UCT-based   Abstraction Algorithm",
    "summary": "A core challenge of Monte Carlo Tree Search (MCTS) is its sample efficiency, which can be improved by grouping state-action pairs and using their aggregate statistics instead of single-node statistics. On the Go Abstractions in Upper Confidence bounds applied to Trees (OGA-UCT) is the state-of-the-art MCTS abstraction algorithm for deterministic environments that builds its abstraction using the Abstractions of State-Action Pairs (ASAP) framework, which aims to detect states and state-action pairs with the same value under optimal play by analysing the search graph. ASAP, however, requires two state-action pairs to have the same immediate reward, which is a rigid condition that limits the number of abstractions that can be found and thereby the sample efficiency. In this paper, we break with the paradigm of grouping value-equivalent states or state-action pairs and instead group states and state-action pairs with possibly different values as long as the difference between their values can be inferred. We call this abstraction framework Known Value Difference Abstractions (KVDA), which infers the value differences by analysis of the immediate rewards and modifies OGA-UCT to use this framework instead. The modification is called KVDA-UCT, which detects significantly more abstractions than OGA-UCT, introduces no additional parameter, and outperforms OGA-UCT on a variety of deterministic environments and parameter settings.",
    "authors": [
      "Robin Schmöcker",
      "Alexander Dockhorn",
      "Bodo Rosenhahn"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25388v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25388v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.25379v1",
    "title": "A Deep Learning Framework for Multi-Operator Learning: Architectures and   Approximation Theory",
    "summary": "While many problems in machine learning focus on learning mappings between finite-dimensional spaces, scientific applications require approximating mappings between function spaces, i.e., operators. We study the problem of learning collections of operators and provide both theoretical and empirical advances. We distinguish between two regimes: (i) multiple operator learning, where a single network represents a continuum of operators parameterized by a parametric function, and (ii) learning several distinct single operators, where each operator is learned independently. For the multiple operator case, we introduce two new architectures, $\\mathrm{MNO}$ and $\\mathrm{MONet}$, and establish universal approximation results in three settings: continuous, integrable, or Lipschitz operators. For the latter, we further derive explicit scaling laws that quantify how the network size must grow to achieve a target approximation accuracy. For learning several single operators, we develop a framework for balancing architectural complexity across subnetworks and show how approximation order determines computational efficiency. Empirical experiments on parametric PDE benchmarks confirm the strong expressive power and efficiency of the proposed architectures. Overall, this work establishes a unified theoretical and practical foundation for scalable neural operator learning across multiple operators.",
    "authors": [
      "Adrien Weihs",
      "Jingmin Sun",
      "Zecheng Zhang",
      "Hayden Schaeffer"
    ],
    "categories": [
      "cs.LG",
      "cs.NA",
      "math.NA"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25379v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25379v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.25311v1",
    "title": "Dense and Diverse Goal Coverage in Multi Goal Reinforcement Learning",
    "summary": "Reinforcement Learning algorithms are primarily focused on learning a policy that maximizes expected return. As a result, the learned policy can exploit one or few reward sources. However, in many natural situations, it is desirable to learn a policy that induces a dispersed marginal state distribution over rewarding states, while maximizing the expected return which is typically tied to reaching a goal state. This aspect remains relatively unexplored. Existing techniques based on entropy regularization and intrinsic rewards use stochasticity for encouraging exploration to find an optimal policy which may not necessarily lead to dispersed marginal state distribution over rewarding states. Other RL algorithms which match a target distribution assume the latter to be available apriori. This may be infeasible in large scale systems where enumeration of all states is not possible and a state is determined to be a goal state only upon reaching it. We formalize the problem of maximizing the expected return while uniformly visiting the goal states as Multi Goal RL in which an oracle classifier over the state space determines the goal states. We propose a novel algorithm that learns a high-return policy mixture with marginal state distribution dispersed over the set of goal states. Our algorithm is based on optimizing a custom RL reward which is computed - based on the current policy mixture - at each iteration for a set of sampled trajectories. The latter are used via an offline RL algorithm to update the policy mixture. We prove performance guarantees for our algorithm, showing efficient convergence bounds for optimizing a natural objective which captures the expected return as well as the dispersion of the marginal state distribution over the goal states. We design and perform experiments on synthetic MDPs and standard RL environments to evaluate the effectiveness of our algorithm.",
    "authors": [
      "Sagalpreet Singh",
      "Rishi Saket",
      "Aravindan Raghuveer"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25311v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25311v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.25306v1",
    "title": "Hierarchical Physics-Embedded Learning for Spatiotemporal Dynamical   Systems",
    "summary": "Modeling complex spatiotemporal dynamics, particularly in far-from-equilibrium systems, remains a grand challenge in science. The governing partial differential equations (PDEs) for these systems are often intractable to derive from first principles, due to their inherent complexity, characterized by high-order derivatives and strong nonlinearities, coupled with incomplete physical knowledge. This has spurred the development of data-driven methods, yet these approaches face limitations: Purely data-driven models are often physically inconsistent and data-intensive, while existing physics-informed methods lack the structural capacity to represent complex operators or systematically integrate partial physical knowledge. Here, we propose a hierarchical physics-embedded learning framework that fundamentally advances both the forward spatiotemporal prediction and inverse discovery of physical laws from sparse and noisy data. The key innovation is a two-level architecture that mirrors the process of scientific discovery: the first level learns fundamental symbolic components of a PDE, while the second learns their governing combinations. This hierarchical decomposition not only reduces learning complexity but, more importantly, enables a structural integration of prior knowledge. Known physical laws are directly embedded into the models computational graph, guaranteeing physical consistency and improving data efficiency. By building the framework upon adaptive Fourier Neural Operators, we can effectively capture the non-local dependencies and high-order operators characteristic of dynamical systems. Additionally, by structurally decoupling known and unknown terms, the framework further enables interpretable discovery of underlying governing equations through symbolic regression, without presupposing functional forms.",
    "authors": [
      "Xizhe Wang",
      "Xiaobin Song",
      "Qingshan Jia",
      "Hongbo Zhao",
      "Benben Jiang"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25306v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25306v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.25254v1",
    "title": "Scaling Up Bayesian DAG Sampling",
    "summary": "Bayesian inference of Bayesian network structures is often performed by sampling directed acyclic graphs along an appropriately constructed Markov chain. We present two techniques to improve sampling. First, we give an efficient implementation of basic moves, which add, delete, or reverse a single arc. Second, we expedite summing over parent sets, an expensive task required for more sophisticated moves: we devise a preprocessing method to prune possible parent sets so as to approximately preserve the sums. Our empirical study shows that our techniques can yield substantial efficiency gains compared to previous methods.",
    "authors": [
      "Daniele Nikzad",
      "Alexander Zhilkin",
      "Juha Harviainen",
      "Jack Kuipers",
      "Giusi Moffa",
      "Mikko Koivisto"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25254v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25254v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.25237v1",
    "title": "DeepShield: Fortifying Deepfake Video Detection with Local and Global   Forgery Analysis",
    "summary": "Recent advances in deep generative models have made it easier to manipulate face videos, raising significant concerns about their potential misuse for fraud and misinformation. Existing detectors often perform well in in-domain scenarios but fail to generalize across diverse manipulation techniques due to their reliance on forgery-specific artifacts. In this work, we introduce DeepShield, a novel deepfake detection framework that balances local sensitivity and global generalization to improve robustness across unseen forgeries. DeepShield enhances the CLIP-ViT encoder through two key components: Local Patch Guidance (LPG) and Global Forgery Diversification (GFD). LPG applies spatiotemporal artifact modeling and patch-wise supervision to capture fine-grained inconsistencies often overlooked by global models. GFD introduces domain feature augmentation, leveraging domain-bridging and boundary-expanding feature generation to synthesize diverse forgeries, mitigating overfitting and enhancing cross-domain adaptability. Through the integration of novel local and global analysis for deepfake detection, DeepShield outperforms state-of-the-art methods in cross-dataset and cross-manipulation evaluations, achieving superior robustness against unseen deepfake attacks.",
    "authors": [
      "Yinqi Cai",
      "Jichang Li",
      "Zhaolun Li",
      "Weikai Chen",
      "Rushi Lan",
      "Xi Xie",
      "Xiaonan Luo",
      "Guanbin Li"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25237v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25237v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.25221v1",
    "title": "MSF-Net: Multi-Stage Feature Extraction and Fusion for Robust   Photometric Stereo",
    "summary": "Photometric stereo is a technique aimed at determining surface normals through the utilization of shading cues derived from images taken under different lighting conditions. However, existing learning-based approaches often fail to accurately capture features at multiple stages and do not adequately promote interaction between these features. Consequently, these models tend to extract redundant features, especially in areas with intricate details such as wrinkles and edges. To tackle these issues, we propose MSF-Net, a novel framework for extracting information at multiple stages, paired with selective update strategy, aiming to extract high-quality feature information, which is critical for accurate normal construction. Additionally, we have developed a feature fusion module to improve the interplay among different features. Experimental results on the DiLiGenT benchmark show that our proposed MSF-Net significantly surpasses previous state-of-the-art methods in the accuracy of surface normal estimation.",
    "authors": [
      "Shiyu Qin",
      "Zhihao Cai",
      "Kaixuan Wang",
      "Lin Qi",
      "Junyu Dong"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25221v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25221v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.25130v1",
    "title": "Lipschitz-aware Linearity Grafting for Certified Robustness",
    "summary": "Lipschitz constant is a fundamental property in certified robustness, as smaller values imply robustness to adversarial examples when a model is confident in its prediction. However, identifying the worst-case adversarial examples is known to be an NP-complete problem. Although over-approximation methods have shown success in neural network verification to address this challenge, reducing approximation errors remains a significant obstacle. Furthermore, these approximation errors hinder the ability to obtain tight local Lipschitz constants, which are crucial for certified robustness. Originally, grafting linearity into non-linear activation functions was proposed to reduce the number of unstable neurons, enabling scalable and complete verification. However, no prior theoretical analysis has explained how linearity grafting improves certified robustness. We instead consider linearity grafting primarily as a means of eliminating approximation errors rather than reducing the number of unstable neurons, since linear functions do not require relaxation. In this paper, we provide two theoretical contributions: 1) why linearity grafting improves certified robustness through the lens of the $l_\\infty$ local Lipschitz constant, and 2) grafting linearity into non-linear activation functions, the dominant source of approximation errors, yields a tighter local Lipschitz constant. Based on these theoretical contributions, we propose a Lipschitz-aware linearity grafting method that removes dominant approximation errors, which are crucial for tightening the local Lipschitz constant, thereby improving certified robustness, even without certified training. Our extensive experiments demonstrate that grafting linearity into these influential activations tightens the $l_\\infty$ local Lipschitz constant and enhances certified robustness.",
    "authors": [
      "Yongjin Han",
      "Suhyun Kim"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25130v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25130v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.25129v1",
    "title": "AtlasGS: Atlanta-world Guided Surface Reconstruction with Implicit   Structured Gaussians",
    "summary": "3D reconstruction of indoor and urban environments is a prominent research topic with various downstream applications. However, existing geometric priors for addressing low-texture regions in indoor and urban settings often lack global consistency. Moreover, Gaussian Splatting and implicit SDF fields often suffer from discontinuities or exhibit computational inefficiencies, resulting in a loss of detail. To address these issues, we propose an Atlanta-world guided implicit-structured Gaussian Splatting that achieves smooth indoor and urban scene reconstruction while preserving high-frequency details and rendering efficiency. By leveraging the Atlanta-world model, we ensure the accurate surface reconstruction for low-texture regions, while the proposed novel implicit-structured GS representations provide smoothness without sacrificing efficiency and high-frequency details. Specifically, we propose a semantic GS representation to predict the probability of all semantic regions and deploy a structure plane regularization with learnable plane indicators for global accurate surface reconstruction. Extensive experiments demonstrate that our method outperforms state-of-the-art approaches in both indoor and urban scenes, delivering superior surface reconstruction quality.",
    "authors": [
      "Xiyu Zhang",
      "Chong Bao",
      "Yipeng Chen",
      "Hongjia Zhai",
      "Yitong Dong",
      "Hujun Bao",
      "Zhaopeng Cui",
      "Guofeng Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25129v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25129v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.25765v1",
    "title": "FreeArt3D: Training-Free Articulated Object Generation using 3D   Diffusion",
    "summary": "Articulated 3D objects are central to many applications in robotics, AR/VR, and animation. Recent approaches to modeling such objects either rely on optimization-based reconstruction pipelines that require dense-view supervision or on feed-forward generative models that produce coarse geometric approximations and often overlook surface texture. In contrast, open-world 3D generation of static objects has achieved remarkable success, especially with the advent of native 3D diffusion models such as Trellis. However, extending these methods to articulated objects by training native 3D diffusion models poses significant challenges. In this work, we present FreeArt3D, a training-free framework for articulated 3D object generation. Instead of training a new model on limited articulated data, FreeArt3D repurposes a pre-trained static 3D diffusion model (e.g., Trellis) as a powerful shape prior. It extends Score Distillation Sampling (SDS) into the 3D-to-4D domain by treating articulation as an additional generative dimension. Given a few images captured in different articulation states, FreeArt3D jointly optimizes the object's geometry, texture, and articulation parameters without requiring task-specific training or access to large-scale articulated datasets. Our method generates high-fidelity geometry and textures, accurately predicts underlying kinematic structures, and generalizes well across diverse object categories. Despite following a per-instance optimization paradigm, FreeArt3D completes in minutes and significantly outperforms prior state-of-the-art approaches in both quality and versatility.",
    "authors": [
      "Chuhao Chen",
      "Isabella Liu",
      "Xinyue Wei",
      "Hao Su",
      "Minghua Liu"
    ],
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25765v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25765v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2510.25726v1",
    "title": "The Tool Decathlon: Benchmarking Language Agents for Diverse, Realistic,   and Long-Horizon Task Execution",
    "summary": "Real-world language agents must handle complex, multi-step workflows across diverse Apps. For instance, an agent may manage emails by coordinating with calendars and file systems, or monitor a production database to detect anomalies and generate reports following an operating manual. However, existing language agent benchmarks often focus on narrow domains or simplified tasks that lack the diversity, realism, and long-horizon complexity required to evaluate agents' real-world performance. To address this gap, we introduce the Tool Decathlon (dubbed as Toolathlon), a benchmark for language agents offering diverse Apps and tools, realistic environment setup, and reliable execution-based evaluation. Toolathlon spans 32 software applications and 604 tools, ranging from everyday platforms such as Google Calendar and Notion to professional ones like WooCommerce, Kubernetes, and BigQuery. Most of the tools are based on a high-quality set of Model Context Protocol (MCP) servers that we may have revised or implemented ourselves. Unlike prior works, which primarily ensure functional realism but offer limited environment state diversity, we provide realistic initial environment states from real software, such as Canvas courses with dozens of students or real financial spreadsheets. This benchmark includes 108 manually sourced or crafted tasks in total, requiring interacting with multiple Apps over around 20 turns on average to complete. Each task is strictly verifiable through dedicated evaluation scripts. Comprehensive evaluation of SOTA models highlights their significant shortcomings: the best-performing model, Claude-4.5-Sonnet, achieves only a 38.6% success rate with 20.2 tool calling turns on average, while the top open-weights model DeepSeek-V3.2-Exp reaches 20.1%. We expect Toolathlon to drive the development of more capable language agents for real-world, long-horizon task execution.",
    "authors": [
      "Junlong Li",
      "Wenshuo Zhao",
      "Jian Zhao",
      "Weihao Zeng",
      "Haoze Wu",
      "Xiaochen Wang",
      "Rui Ge",
      "Yuxuan Cao",
      "Yuzhen Huang",
      "Wei Liu",
      "Junteng Liu",
      "Zhaochen Su",
      "Yiyang Guo",
      "Fan Zhou",
      "Lueyang Zhang",
      "Juan Michelini",
      "Xingyao Wang",
      "Xiang Yue",
      "Shuyan Zhou",
      "Graham Neubig",
      "Junxian He"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25726v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25726v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2510.25626v1",
    "title": "Are Language Models Efficient Reasoners? A Perspective from Logic   Programming",
    "summary": "Modern language models (LMs) exhibit strong deductive reasoning capabilities, yet standard evaluations emphasize correctness while overlooking a key aspect of human-like reasoning: efficiency. In real-world reasoning scenarios, much of the available information is irrelevant, and effective deductive inference requires identifying and ignoring such distractions. We propose a framework for assessing LM reasoning efficiency through the lens of logic programming, introducing a simple method to align proofs written in natural language -- as generated by an LM -- with shortest proofs found by executing the logic program. Efficiency is quantified by measuring how well a model avoids unnecessary inference. Empirically, we construct a dataset of math word problems injected with various number of irrelevant axioms that vary in semantic overlap with the goal theorem. We find that current LMs show marked accuracy declines under such conditions -- even with minimal, domain-consistent distractions -- and the proofs they generate frequently exhibit detours through irrelevant inferences.",
    "authors": [
      "Andreas Opedal",
      "Yanick Zengaffinen",
      "Haruki Shirakami",
      "Clemente Pasti",
      "Mrinmaya Sachan",
      "Abulhair Saparov",
      "Ryan Cotterell",
      "Bernhard Schölkopf"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG",
      "cs.LO"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25626v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25626v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2510.25609v1",
    "title": "BOLT-GAN: Bayes-Optimal Loss for Stable GAN Training",
    "summary": "We introduce BOLT-GAN, a simple yet effective modification of the WGAN framework inspired by the Bayes Optimal Learning Threshold (BOLT). We show that with a Lipschitz continuous discriminator, BOLT-GAN implicitly minimizes a different metric distance than the Earth Mover (Wasserstein) distance and achieves better training stability. Empirical evaluations on four standard image generation benchmarks (CIFAR-10, CelebA-64, LSUN Bedroom-64, and LSUN Church-64) show that BOLT-GAN consistently outperforms WGAN, achieving 10-60% lower Frechet Inception Distance (FID). Our results suggest that BOLT is a broadly applicable principle for enhancing GAN training.",
    "authors": [
      "Mohammadreza Tavasoli Naeini",
      "Ali Bereyhi",
      "Morteza Noshad",
      "Ben Liang",
      "Alfred O. Hero III"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.SP",
      "68T07",
      "I.2.6; I.5.1"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25609v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25609v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2510.25557v1",
    "title": "Hybrid Quantum-Classical Recurrent Neural Networks",
    "summary": "We present a hybrid quantum-classical recurrent neural network (QRNN) architecture in which the entire recurrent core is realized as a parametrized quantum circuit (PQC) controlled by a classical feedforward network. The hidden state is the quantum state of an $n$-qubit PQC, residing in an exponentially large Hilbert space $\\mathbb{C}^{2^n}$. The PQC is unitary by construction, making the hidden-state evolution norm-preserving without external constraints. At each timestep, mid-circuit readouts are combined with the input embedding and processed by the feedforward network, which provides explicit classical nonlinearity. The outputs parametrize the PQC, which updates the hidden state via unitary dynamics. The QRNN is compact and physically consistent, and it unifies (i) unitary recurrence as a high-capacity memory, (ii) partial observation via mid-circuit measurements, and (iii) nonlinear classical control for input-conditioned parametrization. We evaluate the model in simulation with up to 14 qubits on sentiment analysis, MNIST, permuted MNIST, copying memory, and language modeling, adopting projective measurements as a limiting case to obtain mid-circuit readouts while maintaining a coherent recurrent quantum memory. We further devise a soft attention mechanism over the mid-circuit readouts in a sequence-to-sequence model and show its effectiveness for machine translation. To our knowledge, this is the first model (RNN or otherwise) grounded in quantum operations to achieve competitive performance against strong classical baselines across a broad class of sequence-learning tasks.",
    "authors": [
      "Wenduan Xu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL",
      "quant-ph"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25557v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25557v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2510.25384v1",
    "title": "Roleplaying with Structure: Synthetic Therapist-Client Conversation   Generation from Questionnaires",
    "summary": "The development of AI for mental health is hindered by a lack of authentic therapy dialogues, due to strict privacy regulations and the fact that clinical sessions were historically rarely recorded. We present an LLM-driven pipeline that generates synthetic counseling dialogues based on structured client profiles and psychological questionnaires. Grounded on the principles of Cognitive Behavioral Therapy (CBT), our method creates synthetic therapeutic conversations for clinical disorders such as anxiety and depression. Our framework, SQPsych (Structured Questionnaire-based Psychotherapy), converts structured psychological input into natural language dialogues through therapist-client simulations. Due to data governance policies and privacy restrictions prohibiting the transmission of clinical questionnaire data to third-party services, previous methodologies relying on proprietary models are infeasible in our setting. We address this limitation by generating a high-quality corpus using open-weight LLMs, validated through human expert evaluation and LLM-based assessments. Our SQPsychLLM models fine-tuned on SQPsychConv achieve strong performance on counseling benchmarks, surpassing baselines in key therapeutic skills. Our findings highlight the potential of synthetic data to enable scalable, data-secure, and clinically informed AI for mental health support. We will release our code, models, and corpus at https://ai-mh.github.io/SQPsych",
    "authors": [
      "Doan Nam Long Vu",
      "Rui Tan",
      "Lena Moench",
      "Svenja Jule Francke",
      "Daniel Woiwod",
      "Florian Thomas-Odenthal",
      "Sanna Stroth",
      "Tilo Kircher",
      "Christiane Hermann",
      "Udo Dannlowski",
      "Hamidreza Jamalabadi",
      "Shaoxiong Ji"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25384v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25384v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2510.25126v1",
    "title": "Bridging the Divide: End-to-End Sequence-Graph Learning",
    "summary": "Many real-world datasets are both sequential and relational: each node carries an event sequence while edges encode interactions. Existing methods in sequence modeling and graph modeling often neglect one modality or the other. We argue that sequences and graphs are not separate problems but complementary facets of the same dataset, and should be learned jointly. We introduce BRIDGE, a unified end-to-end architecture that couples a sequence encoder with a GNN under a single objective, allowing gradients to flow across both modules and learning task-aligned representations. To enable fine-grained token-level message passing among neighbors, we add TOKENXATTN, a token-level cross-attention layer that passes messages between events in neighboring sequences. Across two settings, friendship prediction (Brightkite) and fraud detection (Amazon), BRIDGE consistently outperforms static GNNs, temporal graph methods, and sequence-only baselines on ranking and classification metrics.",
    "authors": [
      "Yuen Chen",
      "Yulun Wu",
      "Samuel Sharpe",
      "Igor Melnyk",
      "Nam H. Nguyen",
      "Furong Huang",
      "C. Bayan Bruss",
      "Rizal Fathony"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25126v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25126v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2510.25729v1",
    "title": "Physics-Guided Conditional Diffusion Networks for Microwave Image   Reconstruction",
    "summary": "A conditional latent-diffusion based framework for solving the electromagnetic inverse scattering problem associated with microwave imaging is introduced. This generative machine-learning model explicitly mirrors the non-uniqueness of the ill-posed inverse problem. Unlike existing inverse solvers utilizing deterministic machine learning techniques that produce a single reconstruction, the proposed latent-diffusion model generates multiple plausible permittivity maps conditioned on measured scattered-field data, thereby generating several potential instances in the range-space of the non-unique inverse mapping. A forward electromagnetic solver is integrated into the reconstruction pipeline as a physics-based evaluation mechanism. The space of candidate reconstructions form a distribution of possibilities consistent with the conditioning data and the member of this space yielding the lowest scattered-field data discrepancy between the predicted and measured scattered fields is reported as the final solution. Synthetic and experimental labeled datasets are used for training and evaluation of the model. An innovative labeled synthetic dataset is created that exemplifies a varied set of scattering features. Training of the model using this new dataset produces high quality permittivity reconstructions achieving improved generalization with excellent fidelity to shape recognition. The results highlight the potential of hybrid generative physics frameworks as a promising direction for robust, data-driven microwave imaging.",
    "authors": [
      "Shirin Chehelgami",
      "Joe LoVetri",
      "Vahab Khoshdel"
    ],
    "categories": [
      "eess.IV",
      "cs.AI",
      "cs.LG",
      "eess.SP"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25729v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25729v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.25674v1",
    "title": "Mechanistic Interpretability of RNNs emulating Hidden Markov Models",
    "summary": "Recurrent neural networks (RNNs) provide a powerful approach in neuroscience to infer latent dynamics in neural populations and to generate hypotheses about the neural computations underlying behavior. However, past work has focused on relatively simple, input-driven, and largely deterministic behaviors - little is known about the mechanisms that would allow RNNs to generate the richer, spontaneous, and potentially stochastic behaviors observed in natural settings. Modeling with Hidden Markov Models (HMMs) has revealed a segmentation of natural behaviors into discrete latent states with stochastic transitions between them, a type of dynamics that may appear at odds with the continuous state spaces implemented by RNNs. Here we first show that RNNs can replicate HMM emission statistics and then reverse-engineer the trained networks to uncover the mechanisms they implement. In the absence of inputs, the activity of trained RNNs collapses towards a single fixed point. When driven by stochastic input, trajectories instead exhibit noise-sustained dynamics along closed orbits. Rotation along these orbits modulates the emission probabilities and is governed by transitions between regions of slow, noise-driven dynamics connected by fast, deterministic transitions. The trained RNNs develop highly structured connectivity, with a small set of \"kick neurons\" initiating transitions between these regions. This mechanism emerges during training as the network shifts into a regime of stochastic resonance, enabling it to perform probabilistic computations. Analyses across multiple HMM architectures - fully connected, cyclic, and linear-chain - reveal that this solution generalizes through the modular reuse of the same dynamical motif, suggesting a compositional principle by which RNNs can emulate complex discrete latent dynamics.",
    "authors": [
      "Elia Torre",
      "Michele Viscione",
      "Lucas Pompe",
      "Benjamin F Grewe",
      "Valerio Mante"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25674v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25674v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.25602v1",
    "title": "INT v.s. FP: A Comprehensive Study of Fine-Grained Low-bit Quantization   Formats",
    "summary": "Modern AI hardware, such as Nvidia's Blackwell architecture, is increasingly embracing low-precision floating-point (FP) formats to handle the pervasive activation outliers in Large Language Models (LLMs). Despite this industry trend, a unified comparison of FP and integer (INT) quantization across varying granularities has been missing, leaving algorithm and hardware co-design without clear guidance. This paper fills that gap by systematically investigating the trade-offs between FP and INT formats. We reveal a critical performance crossover: while FP excels in coarse-grained quantization, the comparison at fine-grained (block-wise) levels is more nuanced. Our comprehensive comparison demonstrates that for popular 8-bit fine-grained formats (e.g., MX with block size 32), MXINT8 is superior to its FP counterpart in both algorithmic accuracy and hardware efficiency. However, for 4-bit formats, FP (e.g., MXFP4, NVFP4) often holds an accuracy advantage , though we show that NVINT4 can surpass NVFP4 when outlier-mitigation techniques like Hadamard rotation are applied. We also introduce a symmetric clipping method that resolves gradient bias in fine-grained low-bit INT training, enabling nearly lossless performance for MXINT8 training. These findings challenge the current hardware trajectory, demonstrating that a one-size-fits-all FP approach is suboptimal and advocating that fine-grained INT formats, particularly MXINT8, offer a better balance of accuracy, power, and efficiency for future AI accelerators.",
    "authors": [
      "Mengzhao Chen",
      "Meng Wu",
      "Hui Jin",
      "Zhihang Yuan",
      "Jing Liu",
      "Chaoyi Zhang",
      "Yunshui Li",
      "Jie Huang",
      "Jin Ma",
      "Zeyue Xue",
      "Zhiheng Liu",
      "Xingyan Bin",
      "Ping Luo"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25602v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25602v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.25542v1",
    "title": "Transformers Provably Learn Directed Acyclic Graphs via Kernel-Guided   Mutual Information",
    "summary": "Uncovering hidden graph structures underlying real-world data is a critical challenge with broad applications across scientific domains. Recently, transformer-based models leveraging the attention mechanism have demonstrated strong empirical success in capturing complex dependencies within graphs. However, the theoretical understanding of their training dynamics has been limited to tree-like graphs, where each node depends on a single parent. Extending provable guarantees to more general directed acyclic graphs (DAGs) -- which involve multiple parents per node -- remains challenging, primarily due to the difficulty in designing training objectives that enable different attention heads to separately learn multiple different parent relationships.   In this work, we address this problem by introducing a novel information-theoretic metric: the kernel-guided mutual information (KG-MI), based on the $f$-divergence. Our objective combines KG-MI with a multi-head attention framework, where each head is associated with a distinct marginal transition kernel to model diverse parent-child dependencies effectively. We prove that, given sequences generated by a $K$-parent DAG, training a single-layer, multi-head transformer via gradient ascent converges to the global optimum in polynomial time. Furthermore, we characterize the attention score patterns at convergence. In addition, when particularizing the $f$-divergence to the KL divergence, the learned attention scores accurately reflect the ground-truth adjacency matrix, thereby provably recovering the underlying graph structure. Experimental results validate our theoretical findings.",
    "authors": [
      "Yuan Cheng",
      "Yu Huang",
      "Zhe Xiong",
      "Yingbin Liang",
      "Vincent Y. F. Tan"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25542v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25542v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.25522v1",
    "title": "Comparative Study of UNet-based Architectures for Liver Tumor   Segmentation in Multi-Phase Contrast-Enhanced Computed Tomography",
    "summary": "Segmentation of liver structures in multi-phase contrast-enhanced computed tomography (CECT) plays a crucial role in computer-aided diagnosis and treatment planning for liver diseases, including tumor detection. In this study, we investigate the performance of UNet-based architectures for liver tumor segmentation, starting from the original UNet and extending to UNet3+ with various backbone networks. We evaluate ResNet, Transformer-based, and State-space (Mamba) backbones, all initialized with pretrained weights. Surprisingly, despite the advances in modern architecture, ResNet-based models consistently outperform Transformer- and Mamba-based alternatives across multiple evaluation metrics. To further improve segmentation quality, we introduce attention mechanisms into the backbone and observe that incorporating the Convolutional Block Attention Module (CBAM) yields the best performance. ResNetUNet3+ with CBAM module not only produced the best overlap metrics with a Dice score of 0.755 and IoU of 0.662, but also achieved the most precise boundary delineation, evidenced by the lowest HD95 distance of 77.911. The model's superiority was further cemented by its leading overall accuracy of 0.925 and specificity of 0.926, showcasing its robust capability in accurately identifying both lesion and healthy tissue. To further enhance interpretability, Grad-CAM visualizations were employed to highlight the region's most influential predictions, providing insights into its decision-making process. These findings demonstrate that classical ResNet architecture, when combined with modern attention modules, remain highly competitive for medical image segmentation tasks, offering a promising direction for liver tumor detection in clinical practice.",
    "authors": [
      "Doan-Van-Anh Ly",
      "Thi-Thu-Hien Pham",
      "Thanh-Hai Le"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "I.4.6"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25522v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25522v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.25518v1",
    "title": "Retrieval Augmented Generation (RAG) for Fintech: Agentic Design and   Evaluation",
    "summary": "Retrieval-Augmented Generation (RAG) systems often face limitations in specialized domains such as fintech, where domain-specific ontologies, dense terminology, and acronyms complicate effective retrieval and synthesis. This paper introduces an agentic RAG architecture designed to address these challenges through a modular pipeline of specialized agents. The proposed system supports intelligent query reformulation, iterative sub-query decomposition guided by keyphrase extraction, contextual acronym resolution, and cross-encoder-based context re-ranking. We evaluate our approach against a standard RAG baseline using a curated dataset of 85 question--answer--reference triples derived from an enterprise fintech knowledge base. Experimental results demonstrate that the agentic RAG system outperforms the baseline in retrieval precision and relevance, albeit with increased latency. These findings suggest that structured, multi-agent methodologies offer a promising direction for enhancing retrieval robustness in complex, domain-specific settings.",
    "authors": [
      "Thomas Cook",
      "Richard Osuagwu",
      "Liman Tsatiashvili",
      "Vrynsia Vrynsia",
      "Koustav Ghosal",
      "Maraim Masoud",
      "Riccardo Mattivi"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25518v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25518v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.25512v1",
    "title": "FaCT: Faithful Concept Traces for Explaining Neural Network Decisions",
    "summary": "Deep networks have shown remarkable performance across a wide range of tasks, yet getting a global concept-level understanding of how they function remains a key challenge. Many post-hoc concept-based approaches have been introduced to understand their workings, yet they are not always faithful to the model. Further, they make restrictive assumptions on the concepts a model learns, such as class-specificity, small spatial extent, or alignment to human expectations. In this work, we put emphasis on the faithfulness of such concept-based explanations and propose a new model with model-inherent mechanistic concept-explanations. Our concepts are shared across classes and, from any layer, their contribution to the logit and their input-visualization can be faithfully traced. We also leverage foundation models to propose a new concept-consistency metric, C$^2$-Score, that can be used to evaluate concept-based methods. We show that, compared to prior work, our concepts are quantitatively more consistent and users find our concepts to be more interpretable, all while retaining competitive ImageNet performance.",
    "authors": [
      "Amin Parchami-Araghi",
      "Sukrut Rao",
      "Jonas Fischer",
      "Bernt Schiele"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25512v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25512v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.25509v1",
    "title": "Support Vector Machine-Based Burnout Risk Prediction with an Interactive   Interface for Organizational Use",
    "summary": "Burnout is a psychological syndrome marked by emotional exhaustion, depersonalization, and reduced personal accomplishment, with a significant impact on individual well-being and organizational performance. This study proposes a machine learning approach to predict burnout risk using the HackerEarth Employee Burnout Challenge dataset. Three supervised algorithms were evaluated: nearest neighbors (KNN), random forest, and support vector machine (SVM), with model performance evaluated through 30-fold cross-validation using the determination coefficient (R2). Among the models tested, SVM achieved the highest predictive performance (R2 = 0.84) and was statistically superior to KNN and Random Forest based on paired $t$-tests. To ensure practical applicability, an interactive interface was developed using Streamlit, allowing non-technical users to input data and receive burnout risk predictions. The results highlight the potential of machine learning to support early detection of burnout and promote data-driven mental health strategies in organizational settings.",
    "authors": [
      "Bruno W. G. Teodosio",
      "Mário J. O. T. Lira",
      "Pedro H. M. Araújo",
      "Lucas R. C. Farias"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25509v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25509v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.25420v1",
    "title": "Improving Temporal Consistency and Fidelity at Inference-time in   Perceptual Video Restoration by Zero-shot Image-based Diffusion Models",
    "summary": "Diffusion models have emerged as powerful priors for single-image restoration, but their application to zero-shot video restoration suffers from temporal inconsistencies due to the stochastic nature of sampling and complexity of incorporating explicit temporal modeling. In this work, we address the challenge of improving temporal coherence in video restoration using zero-shot image-based diffusion models without retraining or modifying their architecture. We propose two complementary inference-time strategies: (1) Perceptual Straightening Guidance (PSG) based on the neuroscience-inspired perceptual straightening hypothesis, which steers the diffusion denoising process towards smoother temporal evolution by incorporating a curvature penalty in a perceptual space to improve temporal perceptual scores, such as Fr\\'echet Video Distance (FVD) and perceptual straightness; and (2) Multi-Path Ensemble Sampling (MPES), which aims at reducing stochastic variation by ensembling multiple diffusion trajectories to improve fidelity (distortion) scores, such as PSNR and SSIM, without sacrificing sharpness. Together, these training-free techniques provide a practical path toward temporally stable high-fidelity perceptual video restoration using large pretrained diffusion models. We performed extensive experiments over multiple datasets and degradation types, systematically evaluating each strategy to understand their strengths and limitations. Our results show that while PSG enhances temporal naturalness, particularly in case of temporal blur, MPES consistently improves fidelity and spatio-temporal perception--distortion trade-off across all tasks.",
    "authors": [
      "Nasrin Rahimi",
      "A. Murat Tekalp"
    ],
    "categories": [
      "eess.IV",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25420v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25420v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.25327v1",
    "title": "MMEdge: Accelerating On-device Multimodal Inference via Pipelined   Sensing and Encoding",
    "summary": "Real-time multimodal inference on resource-constrained edge devices is essential for applications such as autonomous driving, human-computer interaction, and mobile health. However, prior work often overlooks the tight coupling between sensing dynamics and model execution, as well as the complex inter-modality dependencies. In this paper, we propose MMEdge, an new on-device multi-modal inference framework based on pipelined sensing and encoding. Instead of waiting for complete sensor inputs, MMEdge decomposes the entire inference process into a sequence of fine-grained sensing and encoding units, allowing computation to proceed incrementally as data arrive. MMEdge also introduces a lightweight but effective temporal aggregation module that captures rich temporal dynamics across different pipelined units to maintain accuracy performance. Such pipelined design also opens up opportunities for fine-grained cross-modal optimization and early decision-making during inference. To further enhance system performance under resource variability and input data complexity, MMEdge incorporates an adaptive multimodal configuration optimizer that dynamically selects optimal sensing and model configurations for each modality under latency constraints, and a cross-modal speculative skipping mechanism that bypasses future units of slower modalities when early predictions reach sufficient confidence. We evaluate MMEdge using two public multimodal datasets and deploy it on a real-world unmanned aerial vehicle (UAV)-based multimodal testbed. The results show that MMEdge significantly reduces end-to-end latency while maintaining high task accuracy across various system and data dynamics.",
    "authors": [
      "Runxi Huang",
      "Mingxuan Yu",
      "Mingyu Tsoi",
      "Xiaomin Ouyang"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25327v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25327v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.25310v1",
    "title": "Parrot: A Training Pipeline Enhances Both Program CoT and Natural   Language CoT for Reasoning",
    "summary": "Natural language chain-of-thought (N-CoT) and Program chain-of-thought (P-CoT) have emerged as two primary paradigms for large language models (LLMs) to solve mathematical reasoning problems. Current research typically endeavors to achieve unidirectional enhancement: P-CoT enhanced N-CoT or N-CoT enhanced P-CoT. In this paper, we seek to fully unleash the two paradigms' strengths for mutual enhancement and ultimately achieve simultaneous improvements. We conduct a detailed analysis of the error types across two paradigms, based on which we propose Parrot, a novel training pipeline for mathematical problems: 1) Three target-designed subtasks integrate sequential P-CoT and N-CoT generation. 2) A subtask hybrid training strategy to facilitate natural language semantic transferability. 3) The converted N-CoT auxiliary reward is designed to alleviate the sparse rewards in P-CoT optimization. Extensive experiments demonstrate that Parrot significantly enhances both the performance of N-CoT and P-CoT, especially on N-CoT. Using Parrot SFT, the N-CoT performance of LLaMA2 and CodeLLaMA achieve gains of +21.87 and +21.48 on MathQA over the RL baseline, which is resource-intensive.",
    "authors": [
      "Senjie Jin",
      "Lu Chen",
      "Zhiheng Xi",
      "Yuhui Wang",
      "Sirui Song",
      "Yuhao Zhou",
      "Xinbo Zhang",
      "Peng Sun",
      "Hong Lu",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25310v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25310v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.25173v1",
    "title": "$D^2GS$: Dense Depth Regularization for LiDAR-free Urban Scene   Reconstruction",
    "summary": "Recently, Gaussian Splatting (GS) has shown great potential for urban scene reconstruction in the field of autonomous driving. However, current urban scene reconstruction methods often depend on multimodal sensors as inputs, \\textit{i.e.} LiDAR and images. Though the geometry prior provided by LiDAR point clouds can largely mitigate ill-posedness in reconstruction, acquiring such accurate LiDAR data is still challenging in practice: i) precise spatiotemporal calibration between LiDAR and other sensors is required, as they may not capture data simultaneously; ii) reprojection errors arise from spatial misalignment when LiDAR and cameras are mounted at different locations. To avoid the difficulty of acquiring accurate LiDAR depth, we propose $D^2GS$, a LiDAR-free urban scene reconstruction framework. In this work, we obtain geometry priors that are as effective as LiDAR while being denser and more accurate. $\\textbf{First}$, we initialize a dense point cloud by back-projecting multi-view metric depth predictions. This point cloud is then optimized by a Progressive Pruning strategy to improve the global consistency. $\\textbf{Second}$, we jointly refine Gaussian geometry and predicted dense metric depth via a Depth Enhancer. Specifically, we leverage diffusion priors from a depth foundation model to enhance the depth maps rendered by Gaussians. In turn, the enhanced depths provide stronger geometric constraints during Gaussian training. $\\textbf{Finally}$, we improve the accuracy of ground geometry by constraining the shape and normal attributes of Gaussians within road regions. Extensive experiments on the Waymo dataset demonstrate that our method consistently outperforms state-of-the-art methods, producing more accurate geometry even when compared with those using ground-truth LiDAR data.",
    "authors": [
      "Kejing Xia",
      "Jidong Jia",
      "Ke Jin",
      "Yucai Bai",
      "Li Sun",
      "Dacheng Tao",
      "Youjian Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25173v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25173v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.25150v1",
    "title": "Explainable Disentanglement on Discrete Speech Representations for   Noise-Robust ASR",
    "summary": "Discrete audio representations are gaining traction in speech modeling due to their interpretability and compatibility with large language models, but are not always optimized for noisy or real-world environments. Building on existing works that quantize Whisper embeddings for speech-to-unit modeling, we propose disentangling semantic speech content from background noise in the latent space. Our end-to-end model separates clean speech in the form of codebook tokens, while extracting interpretable noise vectors as quantization residue which are supervised via a lightweight classifier. We show that our approach improves alignment between clean/noisy speech and text, producing speech tokens that display a high degree of noiseinvariance, and improves ASR performance. Keeping Whisper frozen, we show an 82% reduction in error rate compared to Whisper, and 35% improvement over baseline methods on the VBDemand test set. Further analyses show that the learned token space generalizes well to both seen and unseen acoustic conditions.",
    "authors": [
      "Shreyas Gopal",
      "Ashutosh Anshul",
      "Haoyang Li",
      "Yue Heng Yeo",
      "Hexin Liu",
      "Eng Siong Chng"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25150v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25150v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.25132v1",
    "title": "EnzyControl: Adding Functional and Substrate-Specific Control for Enzyme   Backbone Generation",
    "summary": "Designing enzyme backbones with substrate-specific functionality is a critical challenge in computational protein engineering. Current generative models excel in protein design but face limitations in binding data, substrate-specific control, and flexibility for de novo enzyme backbone generation. To address this, we introduce EnzyBind, a dataset with 11,100 experimentally validated enzyme-substrate pairs specifically curated from PDBbind. Building on this, we propose EnzyControl, a method that enables functional and substrate-specific control in enzyme backbone generation. Our approach generates enzyme backbones conditioned on MSA-annotated catalytic sites and their corresponding substrates, which are automatically extracted from curated enzyme-substrate data. At the core of EnzyControl is EnzyAdapter, a lightweight, modular component integrated into a pretrained motif-scaffolding model, allowing it to become substrate-aware. A two-stage training paradigm further refines the model's ability to generate accurate and functional enzyme structures. Experiments show that our EnzyControl achieves the best performance across structural and functional metrics on EnzyBind and EnzyBench benchmarks, with particularly notable improvements of 13\\% in designability and 13\\% in catalytic efficiency compared to the baseline models. The code is released at https://github.com/Vecteur-libre/EnzyControl.",
    "authors": [
      "Chao Song",
      "Zhiyuan Liu",
      "Han Huang",
      "Liang Wang",
      "Qiong Wang",
      "Jianyu Shi",
      "Hui Yu",
      "Yihang Zhou",
      "Yang Zhang"
    ],
    "categories": [
      "q-bio.BM",
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25132v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25132v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.25117v1",
    "title": "A Survey on Unlearning in Large Language Models",
    "summary": "The advancement of Large Language Models (LLMs) has revolutionized natural language processing, yet their training on massive corpora poses significant risks, including the memorization of sensitive personal data, copyrighted material, and knowledge that could facilitate malicious activities. To mitigate these issues and align with legal and ethical standards such as the \"right to be forgotten\", machine unlearning has emerged as a critical technique to selectively erase specific knowledge from LLMs without compromising their overall performance. This survey provides a systematic review of over 180 papers on LLM unlearning published since 2021, focusing exclusively on large-scale generative models. Distinct from prior surveys, we introduce novel taxonomies for both unlearning methods and evaluations. We clearly categorize methods into training-time, post-training, and inference-time based on the training stage at which unlearning is applied. For evaluations, we not only systematically compile existing datasets and metrics but also critically analyze their advantages, disadvantages, and applicability, providing practical guidance to the research community. In addition, we discuss key challenges and promising future research directions. Our comprehensive overview aims to inform and guide the ongoing development of secure and reliable LLMs.",
    "authors": [
      "Ruichen Qiu",
      "Jiajun Tan",
      "Jiayue Pu",
      "Honglin Wang",
      "Xiao-Shan Gao",
      "Fei Sun"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25117v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25117v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.25771v1",
    "title": "Gaperon: A Peppered English-French Generative Language Model Suite",
    "summary": "We release Gaperon, a fully open suite of French-English-coding language models designed to advance transparency and reproducibility in large-scale model training. The Gaperon family includes 1.5B, 8B, and 24B parameter models trained on 2-4 trillion tokens, released with all elements of the training pipeline: French and English datasets filtered with a neural quality classifier, an efficient data curation and training framework, and hundreds of intermediate checkpoints. Through this work, we study how data filtering and contamination interact to shape both benchmark and generative performance. We find that filtering for linguistic quality enhances text fluency and coherence but yields subpar benchmark results, and that late deliberate contamination -- continuing training on data mixes that include test sets -- recovers competitive scores while only reasonably harming generation quality. We discuss how usual neural filtering can unintentionally amplify benchmark leakage. To support further research, we also introduce harmless data poisoning during pretraining, providing a realistic testbed for safety studies. By openly releasing all models, datasets, code, and checkpoints, Gaperon establishes a reproducible foundation for exploring the trade-offs between data curation, evaluation, safety, and openness in multilingual language model development.",
    "authors": [
      "Nathan Godey",
      "Wissam Antoun",
      "Rian Touchent",
      "Rachel Bawden",
      "Éric de la Clergerie",
      "Benoît Sagot",
      "Djamé Seddah"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25771v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25771v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.25704v1",
    "title": "Scaling flow-based approaches for topology sampling in $\\mathrm{SU}(3)$   gauge theory",
    "summary": "We develop a methodology based on out-of-equilibrium simulations to mitigate topological freezing when approaching the continuum limit of lattice gauge theories. We reduce the autocorrelation of the topological charge employing open boundary conditions, while removing exactly their unphysical effects using a non-equilibrium Monte Carlo approach in which periodic boundary conditions are gradually switched on. We perform a detailed analysis of the computational costs of this strategy in the case of the four-dimensional $\\mathrm{SU}(3)$ Yang-Mills theory. After achieving full control of the scaling, we outline a clear strategy to sample topology efficiently in the continuum limit, which we check at lattice spacings as small as $0.045$ fm. We also generalize this approach by designing a customized Stochastic Normalizing Flow for evolutions in the boundary conditions, obtaining superior performances with respect to the purely stochastic non-equilibrium approach, and paving the way for more efficient future flow-based solutions.",
    "authors": [
      "Claudio Bonanno",
      "Andrea Bulgarelli",
      "Elia Cellini",
      "Alessandro Nada",
      "Dario Panfalone",
      "Davide Vadacchino",
      "Lorenzo Verzichelli"
    ],
    "categories": [
      "hep-lat",
      "cond-mat.stat-mech",
      "cs.LG",
      "hep-ph"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25704v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25704v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.25662v1",
    "title": "User Misconceptions of LLM-Based Conversational Programming Assistants",
    "summary": "Programming assistants powered by large language models (LLMs) have become widely available, with conversational assistants like ChatGPT proving particularly accessible to less experienced programmers. However, the varied capabilities of these tools across model versions and the mixed availability of extensions that enable web search, code execution, or retrieval-augmented generation create opportunities for user misconceptions about what systems can and cannot do. Such misconceptions may lead to over-reliance, unproductive practices, or insufficient quality control in LLM-assisted programming. Here, we aim to characterize misconceptions that users of conversational LLM-based assistants may have in programming contexts. Using a two-phase approach, we first brainstorm and catalog user misconceptions that may occur, and then conduct a qualitative analysis to examine whether these conceptual issues surface in naturalistic Python-programming conversations with an LLM-based chatbot drawn from an openly available dataset. Indeed, we see evidence that some users have misplaced expectations about the availability of LLM-based chatbot features like web access, code execution, or non-text output generation. We also see potential evidence for deeper conceptual issues around the scope of information required to debug, validate, and optimize programs. Our findings reinforce the need for designing LLM-based tools that more clearly communicate their programming capabilities to users.",
    "authors": [
      "Gabrielle O'Brien",
      "Antonio Pedro Santos Alves",
      "Sebastian Baltes",
      "Grischa Liebel",
      "Mircea Lungu",
      "Marcos Kalinowski"
    ],
    "categories": [
      "cs.HC",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25662v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25662v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.25463v1",
    "title": "SPADE: Sparsity Adaptive Depth Estimator for Zero-Shot, Real-Time,   Monocular Depth Estimation in Underwater Environments",
    "summary": "Underwater infrastructure requires frequent inspection and maintenance due to harsh marine conditions. Current reliance on human divers or remotely operated vehicles is limited by perceptual and operational challenges, especially around complex structures or in turbid water. Enhancing the spatial awareness of underwater vehicles is key to reducing piloting risks and enabling greater autonomy. To address these challenges, we present SPADE: SParsity Adaptive Depth Estimator, a monocular depth estimation pipeline that combines pre-trained relative depth estimator with sparse depth priors to produce dense, metric scale depth maps. Our two-stage approach first scales the relative depth map with the sparse depth points, then refines the final metric prediction with our proposed Cascade Conv-Deformable Transformer blocks. Our approach achieves improved accuracy and generalisation over state-of-the-art baselines and runs efficiently at over 15 FPS on embedded hardware, promising to support practical underwater inspection and intervention. This work has been submitted to IEEE Journal of Oceanic Engineering Special Issue of AUV 2026.",
    "authors": [
      "Hongjie Zhang",
      "Gideon Billings",
      "Stefan B. Williams"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25463v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25463v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.25458v1",
    "title": "Scalable Utility-Aware Multiclass Calibration",
    "summary": "Ensuring that classifiers are well-calibrated, i.e., their predictions align with observed frequencies, is a minimal and fundamental requirement for classifiers to be viewed as trustworthy. Existing methods for assessing multiclass calibration often focus on specific aspects associated with prediction (e.g., top-class confidence, class-wise calibration) or utilize computationally challenging variational formulations. In this work, we study scalable \\emph{evaluation} of multiclass calibration. To this end, we propose utility calibration, a general framework that measures the calibration error relative to a specific utility function that encapsulates the goals or decision criteria relevant to the end user. We demonstrate how this framework can unify and re-interpret several existing calibration metrics, particularly allowing for more robust versions of the top-class and class-wise calibration metrics, and, going beyond such binarized approaches, toward assessing calibration for richer classes of downstream utilities.",
    "authors": [
      "Mahmoud Hegazy",
      "Michael I. Jordan",
      "Aymeric Dieuleveut"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "stat.ML"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25458v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25458v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.25440v1",
    "title": "More than a Moment: Towards Coherent Sequences of Audio Descriptions",
    "summary": "Audio Descriptions (ADs) convey essential on-screen information, allowing visually impaired audiences to follow videos. To be effective, ADs must form a coherent sequence that helps listeners to visualise the unfolding scene, rather than describing isolated moments. However, most automatic methods generate each AD independently, often resulting in repetitive, incoherent descriptions. To address this, we propose a training-free method, CoherentAD, that first generates multiple candidate descriptions for each AD time interval, and then performs auto-regressive selection across the sequence to form a coherent and informative narrative. To evaluate AD sequences holistically, we introduce a sequence-level metric, StoryRecall, which measures how well the predicted ADs convey the ground truth narrative, alongside repetition metrics that capture the redundancy across consecutive AD outputs. Our method produces coherent AD sequences with enhanced narrative understanding, outperforming prior approaches that rely on independent generations.",
    "authors": [
      "Eshika Khandelwal",
      "Junyu Xie",
      "Tengda Han",
      "Max Bain",
      "Arsha Nagrani",
      "Andrew Zisserman",
      "Gül Varol",
      "Makarand Tapaswi"
    ],
    "categories": [
      "cs.CV",
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25440v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25440v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.25426v1",
    "title": "Implicature in Interaction: Understanding Implicature Improves Alignment   in Human-LLM Interaction",
    "summary": "The rapid advancement of Large Language Models (LLMs) is positioning language at the core of human-computer interaction (HCI). We argue that advancing HCI requires attention to the linguistic foundations of interaction, particularly implicature (meaning conveyed beyond explicit statements through shared context) which is essential for human-AI (HAI) alignment. This study examines LLMs' ability to infer user intent embedded in context-driven prompts and whether understanding implicature improves response generation. Results show that larger models approximate human interpretations more closely, while smaller models struggle with implicature inference. Furthermore, implicature-based prompts significantly enhance the perceived relevance and quality of responses across models, with notable gains in smaller models. Overall, 67.6% of participants preferred responses with implicature-embedded prompts to literal ones, highlighting a clear preference for contextually nuanced communication. Our work contributes to understanding how linguistic theory can be used to address the alignment problem by making HAI interaction more natural and contextually grounded.",
    "authors": [
      "Asutosh Hota",
      "Jussi P. P. Jokinen"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25426v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25426v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.25234v1",
    "title": "Learning Disentangled Speech- and Expression-Driven Blendshapes for 3D   Talking Face Animation",
    "summary": "Expressions are fundamental to conveying human emotions. With the rapid advancement of AI-generated content (AIGC), realistic and expressive 3D facial animation has become increasingly crucial. Despite recent progress in speech-driven lip-sync for talking-face animation, generating emotionally expressive talking faces remains underexplored. A major obstacle is the scarcity of real emotional 3D talking-face datasets due to the high cost of data capture. To address this, we model facial animation driven by both speech and emotion as a linear additive problem. Leveraging a 3D talking-face dataset with neutral expressions (VOCAset) and a dataset of 3D expression sequences (Florence4D), we jointly learn a set of blendshapes driven by speech and emotion. We introduce a sparsity constraint loss to encourage disentanglement between the two types of blendshapes while allowing the model to capture inherent secondary cross-domain deformations present in the training data. The learned blendshapes can be further mapped to the expression and jaw pose parameters of the FLAME model, enabling the animation of 3D Gaussian avatars. Qualitative and quantitative experiments demonstrate that our method naturally generates talking faces with specified expressions while maintaining accurate lip synchronization. Perceptual studies further show that our approach achieves superior emotional expressivity compared to existing methods, without compromising lip-sync quality.",
    "authors": [
      "Yuxiang Mao",
      "Zhijie Zhang",
      "Zhiheng Zhang",
      "Jiawei Liu",
      "Chen Zeng",
      "Shihong Xia"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25234v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25234v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.25229v1",
    "title": "Balanced conic rectified flow",
    "summary": "Rectified flow is a generative model that learns smooth transport mappings between two distributions through an ordinary differential equation (ODE). Unlike diffusion-based generative models, which require costly numerical integration of a generative ODE to sample images with state-of-the-art quality, rectified flow uses an iterative process called reflow to learn smooth and straight ODE paths. This allows for relatively simple and efficient generation of high-quality images. However, rectified flow still faces several challenges. 1) The reflow process requires a large number of generative pairs to preserve the target distribution, leading to significant computational costs. 2) Since the model is typically trained using only generated image pairs, its performance heavily depends on the 1-rectified flow model, causing it to become biased towards the generated data.   In this work, we experimentally expose the limitations of the original rectified flow and propose a novel approach that incorporates real images into the training process. By preserving the ODE paths for real images, our method effectively reduces reliance on large amounts of generated data. Instead, we demonstrate that the reflow process can be conducted efficiently using a much smaller set of generated and real images. In CIFAR-10, we achieved significantly better FID scores, not only in one-step generation but also in full-step simulations, while using only of the generative pairs compared to the original method. Furthermore, our approach induces straighter paths and avoids saturation on generated images during reflow, leading to more robust ODE learning while preserving the distribution of real images.",
    "authors": [
      "Kim Shin Seong",
      "Mingi Kwon",
      "Jaeseok Jeong",
      "Youngjung Uh"
    ],
    "categories": [
      "cs.CV",
      "68T07, 68T45, 65C20",
      "I.2.10; I.4.9; I.2.6"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25229v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25229v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.25227v1",
    "title": "Aligning What You Separate: Denoised Patch Mixing for Source-Free Domain   Adaptation in Medical Image Segmentation",
    "summary": "Source-Free Domain Adaptation (SFDA) is emerging as a compelling solution for medical image segmentation under privacy constraints, yet current approaches often ignore sample difficulty and struggle with noisy supervision under domain shift. We present a new SFDA framework that leverages Hard Sample Selection and Denoised Patch Mixing to progressively align target distributions. First, unlabeled images are partitioned into reliable and unreliable subsets through entropy-similarity analysis, allowing adaptation to start from easy samples and gradually incorporate harder ones. Next, pseudo-labels are refined via Monte Carlo-based denoising masks, which suppress unreliable pixels and stabilize training. Finally, intra- and inter-domain objectives mix patches between subsets, transferring reliable semantics while mitigating noise. Experiments on benchmark datasets show consistent gains over prior SFDA and UDA methods, delivering more accurate boundary delineation and achieving state-of-the-art Dice and ASSD scores. Our study highlights the importance of progressive adaptation and denoised supervision for robust segmentation under domain shift.",
    "authors": [
      "Quang-Khai Bui-Tran",
      "Thanh-Huy Nguyen",
      "Hoang-Thien Nguyen",
      "Ba-Thinh Lam",
      "Nguyen Lan Vi Vu",
      "Phat K. Huynh",
      "Ulas Bagci",
      "Min Xu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25227v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25227v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.25146v1",
    "title": "EA3D: Online Open-World 3D Object Extraction from Streaming Videos",
    "summary": "Current 3D scene understanding methods are limited by offline-collected multi-view data or pre-constructed 3D geometry. In this paper, we present ExtractAnything3D (EA3D), a unified online framework for open-world 3D object extraction that enables simultaneous geometric reconstruction and holistic scene understanding. Given a streaming video, EA3D dynamically interprets each frame using vision-language and 2D vision foundation encoders to extract object-level knowledge. This knowledge is integrated and embedded into a Gaussian feature map via a feed-forward online update strategy. We then iteratively estimate visual odometry from historical frames and incrementally update online Gaussian features with new observations. A recurrent joint optimization module directs the model's attention to regions of interest, simultaneously enhancing both geometric reconstruction and semantic understanding. Extensive experiments across diverse benchmarks and tasks, including photo-realistic rendering, semantic and instance segmentation, 3D bounding box and semantic occupancy estimation, and 3D mesh generation, demonstrate the effectiveness of EA3D. Our method establishes a unified and efficient framework for joint online 3D reconstruction and holistic scene understanding, enabling a broad range of downstream tasks.",
    "authors": [
      "Xiaoyu Zhou",
      "Jingqi Wang",
      "Yuang Jia",
      "Yongtao Wang",
      "Deqing Sun",
      "Ming-Hsuan Yang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25146v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25146v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.25114v1",
    "title": "Energy Approach from $\\varepsilon$-Graph to Continuum Diffusion Model   with Connectivity Functional",
    "summary": "We derive an energy-based continuum limit for $\\varepsilon$-graphs endowed with a general connectivity functional. We prove that the discrete energy and its continuum counterpart differ by at most $O(\\varepsilon)$; the prefactor involves only the $W^{1,1}$-norm of the connectivity density as $\\varepsilon\\to0$, so the error bound remains valid even when that density has strong local fluctuations. As an application, we introduce a neural-network procedure that reconstructs the connectivity density from edge-weight data and then embeds the resulting continuum model into a brain-dynamics framework. In this setting, the usual constant diffusion coefficient is replaced by the spatially varying coefficient produced by the learned density, yielding dynamics that differ significantly from those obtained with conventional constant-diffusion models.",
    "authors": [
      "Yahong Yang",
      "Sun Lee",
      "Jeff Calder",
      "Wenrui Hao"
    ],
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA",
      "stat.ML"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25114v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25114v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.25760v1",
    "title": "Multimodal Spatial Reasoning in the Large Model Era: A Survey and   Benchmarks",
    "summary": "Humans possess spatial reasoning abilities that enable them to understand spaces through multimodal observations, such as vision and sound. Large multimodal reasoning models extend these abilities by learning to perceive and reason, showing promising performance across diverse spatial tasks. However, systematic reviews and publicly available benchmarks for these models remain limited. In this survey, we provide a comprehensive review of multimodal spatial reasoning tasks with large models, categorizing recent progress in multimodal large language models (MLLMs) and introducing open benchmarks for evaluation. We begin by outlining general spatial reasoning, focusing on post-training techniques, explainability, and architecture. Beyond classical 2D tasks, we examine spatial relationship reasoning, scene and layout understanding, as well as visual question answering and grounding in 3D space. We also review advances in embodied AI, including vision-language navigation and action models. Additionally, we consider emerging modalities such as audio and egocentric video, which contribute to novel spatial understanding through new sensors. We believe this survey establishes a solid foundation and offers insights into the growing field of multimodal spatial reasoning. Updated information about this survey, codes and implementation of the open benchmarks can be found at https://github.com/zhengxuJosh/Awesome-Spatial-Reasoning.",
    "authors": [
      "Xu Zheng",
      "Zihao Dongfang",
      "Lutao Jiang",
      "Boyuan Zheng",
      "Yulong Guo",
      "Zhenquan Zhang",
      "Giuliano Albanese",
      "Runyi Yang",
      "Mengjiao Ma",
      "Zixin Zhang",
      "Chenfei Liao",
      "Dingcheng Zhen",
      "Yuanhuiyi Lyu",
      "Yuqian Fu",
      "Bin Ren",
      "Linfeng Zhang",
      "Danda Pani Paudel",
      "Nicu Sebe",
      "Luc Van Gool",
      "Xuming Hu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25760v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25760v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2510.25701v1",
    "title": "Interpreting LLMs as Credit Risk Classifiers: Do Their Feature   Explanations Align with Classical ML?",
    "summary": "Large Language Models (LLMs) are increasingly explored as flexible alternatives to classical machine learning models for classification tasks through zero-shot prompting. However, their suitability for structured tabular data remains underexplored, especially in high-stakes financial applications such as financial risk assessment. This study conducts a systematic comparison between zero-shot LLM-based classifiers and LightGBM, a state-of-the-art gradient-boosting model, on a real-world loan default prediction task. We evaluate their predictive performance, analyze feature attributions using SHAP, and assess the reliability of LLM-generated self-explanations. While LLMs are able to identify key financial risk indicators, their feature importance rankings diverge notably from LightGBM, and their self-explanations often fail to align with empirical SHAP attributions. These findings highlight the limitations of LLMs as standalone models for structured financial risk prediction and raise concerns about the trustworthiness of their self-generated explanations. Our results underscore the need for explainability audits, baseline comparisons with interpretable models, and human-in-the-loop oversight when deploying LLMs in risk-sensitive financial environments.",
    "authors": [
      "Saeed AlMarri",
      "Kristof Juhasz",
      "Mathieu Ravaut",
      "Gautier Marti",
      "Hamdan Al Ahbabi",
      "Ibrahim Elfadel"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25701v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25701v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2510.25599v1",
    "title": "Uncertainty Quantification for Regression: A Unified Framework based on   kernel scores",
    "summary": "Regression tasks, notably in safety-critical domains, require proper uncertainty quantification, yet the literature remains largely classification-focused. In this light, we introduce a family of measures for total, aleatoric, and epistemic uncertainty based on proper scoring rules, with a particular emphasis on kernel scores. The framework unifies several well-known measures and provides a principled recipe for designing new ones whose behavior, such as tail sensitivity, robustness, and out-of-distribution responsiveness, is governed by the choice of kernel. We prove explicit correspondences between kernel-score characteristics and downstream behavior, yielding concrete design guidelines for task-specific measures. Extensive experiments demonstrate that these measures are effective in downstream tasks and reveal clear trade-offs among instantiations, including robustness and out-of-distribution detection performance.",
    "authors": [
      "Christopher Bülte",
      "Yusuf Sale",
      "Gitta Kutyniok",
      "Eyke Hüllermeier"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25599v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25599v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2510.25480v1",
    "title": "Gradient-Weight Alignment as a Train-Time Proxy for Generalization in   Classification Tasks",
    "summary": "Robust validation metrics remain essential in contemporary deep learning, not only to detect overfitting and poor generalization, but also to monitor training dynamics. In the supervised classification setting, we investigate whether interactions between training data and model weights can yield such a metric that both tracks generalization during training and attributes performance to individual training samples. We introduce Gradient-Weight Alignment (GWA), quantifying the coherence between per-sample gradients and model weights. We show that effective learning corresponds to coherent alignment, while misalignment indicates deteriorating generalization. GWA is efficiently computable during training and reflects both sample-specific contributions and dataset-wide learning dynamics. Extensive experiments show that GWA accurately predicts optimal early stopping, enables principled model comparisons, and identifies influential training samples, providing a validation-set-free approach for model analysis directly from the training data.",
    "authors": [
      "Florian A. Hölzl",
      "Daniel Rueckert",
      "Georgios Kaissis"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25480v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25480v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2510.25441v1",
    "title": "Grounded in Reality: Learning and Deploying Proactive LLM from Offline   Logs",
    "summary": "Large Language Models (LLMs) excel as passive responders, but teaching them to be proactive, goal-oriented partners, a critical capability in high-stakes domains, remains a major challenge. Current paradigms either myopically optimize single-turn attributes or rely on brittle, high-cost user simulators, creating a persistent ``reality gap''. To bridge this gap, we introduce \\texttt{Learn-to-Ask}, a general, simulator-free framework for learning and deploying proactive dialogue agents \\textit{directly from offline expert data}, bypassing the need to model complex user dynamics. Our key insight is to reframe the offline policy learning problem by leveraging the \\textbf{observed future} of each expert trajectory. This allows us to infer a dense, turn-by-turn reward signal grounded in the expert's revealed strategy, decomposing the intractable long-horizon problem into a series of supervised learning tasks, and training a policy to output a structured \\texttt{(action, state_assessment)} tuple, governing both \\textbf{what to ask} and, crucially, \\textbf{when to stop}. To ensure reward fidelity, our Automated Grader Calibration pipeline systematically purges noise from the LLM-based reward model with minimal human supervision. Empirically, we demonstrate the efficacy of \\texttt{Learn-to-Ask} in a real-world medical dataset, using LLMs of varying sizes up to 32B. Our approach culminates in the successful deployment of LLMs into a live, large-scale online AI service. In rigorous in-house evaluations, our model was launched and achieved performance even superior to human experts, proving our framework's ability to translate offline data into tangible, real-world impact. We hope this work provides a practical and economically viable blueprint for transforming passive LLMs into proactive, goal-oriented LLM applications.",
    "authors": [
      "Fei Wei",
      "Daoyuan Chen",
      "Ce Wang",
      "Yilun Huang",
      "Yushuo Chen",
      "Xuchen Pan",
      "Yaliang Li",
      "Bolin Ding"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25441v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25441v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2510.25147v1",
    "title": "Machine Learning Guided Optimal Transmission Switching to Mitigate   Wildfire Ignition Risk",
    "summary": "To mitigate acute wildfire ignition risks, utilities de-energize power lines in high-risk areas. The Optimal Power Shutoff (OPS) problem optimizes line energization statuses to manage wildfire ignition risks through de-energizations while reducing load shedding. OPS problems are computationally challenging Mixed-Integer Linear Programs (MILPs) that must be solved rapidly and frequently in operational settings. For a particular power system, OPS instances share a common structure with varying parameters related to wildfire risks, loads, and renewable generation. This motivates the use of Machine Learning (ML) for solving OPS problems by exploiting shared patterns across instances. In this paper, we develop an ML-guided framework that quickly produces high-quality de-energization decisions by extending existing ML-guided MILP solution methods while integrating domain knowledge on the number of energized and de-energized lines. Results on a large-scale realistic California-based synthetic test system show that the proposed ML-guided method produces high-quality solutions faster than traditional optimization methods.",
    "authors": [
      "Weimin Huang",
      "Ryan Piansky",
      "Bistra Dilkina",
      "Daniel K. Molzahn"
    ],
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25147v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25147v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2510.25772v1",
    "title": "VFXMaster: Unlocking Dynamic Visual Effect Generation via In-Context   Learning",
    "summary": "Visual effects (VFX) are crucial to the expressive power of digital media, yet their creation remains a major challenge for generative AI. Prevailing methods often rely on the one-LoRA-per-effect paradigm, which is resource-intensive and fundamentally incapable of generalizing to unseen effects, thus limiting scalability and creation. To address this challenge, we introduce VFXMaster, the first unified, reference-based framework for VFX video generation. It recasts effect generation as an in-context learning task, enabling it to reproduce diverse dynamic effects from a reference video onto target content. In addition, it demonstrates remarkable generalization to unseen effect categories. Specifically, we design an in-context conditioning strategy that prompts the model with a reference example. An in-context attention mask is designed to precisely decouple and inject the essential effect attributes, allowing a single unified model to master the effect imitation without information leakage. In addition, we propose an efficient one-shot effect adaptation mechanism to boost generalization capability on tough unseen effects from a single user-provided video rapidly. Extensive experiments demonstrate that our method effectively imitates various categories of effect information and exhibits outstanding generalization to out-of-domain effects. To foster future research, we will release our code, models, and a comprehensive dataset to the community.",
    "authors": [
      "Baolu Li",
      "Yiming Zhang",
      "Qinghe Wang",
      "Liqian Ma",
      "Xiaoyu Shi",
      "Xintao Wang",
      "Pengfei Wan",
      "Zhenfei Yin",
      "Yunzhi Zhuge",
      "Huchuan Lu",
      "Xu Jia"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25772v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25772v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.25770v1",
    "title": "E-Scores for (In)Correctness Assessment of Generative Model Outputs",
    "summary": "While generative models, especially large language models (LLMs), are ubiquitous in today's world, principled mechanisms to assess their (in)correctness are limited. Using the conformal prediction framework, previous works construct sets of LLM responses where the probability of including an incorrect response, or error, is capped at a desired user-defined tolerance level. However, since these methods are based on p-values, they are susceptible to p-hacking, i.e., choosing the tolerance level post-hoc can invalidate the guarantees. We therefore leverage e-values to complement generative model outputs with e-scores as a measure of incorrectness. In addition to achieving the same statistical guarantees as before, e-scores provide users flexibility in adaptively choosing tolerance levels after observing the e-scores themselves, by upper bounding a post-hoc notion of error called size distortion. We experimentally demonstrate their efficacy in assessing LLM outputs for different correctness types: mathematical factuality and property constraints satisfaction.",
    "authors": [
      "Guneet S. Dhillon",
      "Javier González",
      "Teodora Pandeva",
      "Alicia Curth"
    ],
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25770v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25770v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.25744v1",
    "title": "Task Completion Agents are Not Ideal Collaborators",
    "summary": "Current evaluations of agents remain centered around one-shot task completion, failing to account for the inherently iterative and collaborative nature of many real-world problems, where human goals are often underspecified and evolve. We argue for a shift from building and assessing task completion agents to developing collaborative agents, assessed not only by the quality of their final outputs but by how well they engage with and enhance human effort throughout the problem-solving process. To support this shift, we introduce collaborative effort scaling, a framework that captures how an agent's utility grows with increasing user involvement. Through case studies and simulated evaluations, we show that state-of-the-art agents often underperform in multi-turn, real-world scenarios, revealing a missing ingredient in agent design: the ability to sustain engagement and scaffold user understanding. Collaborative effort scaling offers a lens for diagnosing agent behavior and guiding development toward more effective interactions.",
    "authors": [
      "Shannon Zejiang Shen",
      "Valerie Chen",
      "Ken Gu",
      "Alexis Ross",
      "Zixian Ma",
      "Jillian Ross",
      "Alex Gu",
      "Chenglei Si",
      "Wayne Chi",
      "Andi Peng",
      "Jocelyn J Shen",
      "Ameet Talwalkar",
      "Tongshuang Wu",
      "David Sontag"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25744v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25744v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.25683v1",
    "title": "Graph Network-based Structural Simulator: Graph Neural Networks for   Structural Dynamics",
    "summary": "Graph Neural Networks (GNNs) have recently been explored as surrogate models for numerical simulations. While their applications in computational fluid dynamics have been investigated, little attention has been given to structural problems, especially for dynamic cases. To address this gap, we introduce the Graph Network-based Structural Simulator (GNSS), a GNN framework for surrogate modeling of dynamic structural problems.   GNSS follows the encode-process-decode paradigm typical of GNN-based machine learning models, and its design makes it particularly suited for dynamic simulations thanks to three key features: (i) expressing node kinematics in node-fixed local frames, which avoids catastrophic cancellation in finite-difference velocities; (ii) employing a sign-aware regression loss, which reduces phase errors in long rollouts; and (iii) using a wavelength-informed connectivity radius, which optimizes graph construction.   We evaluate GNSS on a case study involving a beam excited by a 50kHz Hanning-modulated pulse. The results show that GNSS accurately reproduces the physics of the problem over hundreds of timesteps and generalizes to unseen loading conditions, where existing GNNs fail to converge or deliver meaningful predictions.   Compared with explicit finite element baselines, GNSS achieves substantial inference speedups while preserving spatial and temporal fidelity. These findings demonstrate that locality-preserving GNNs with physics-consistent update rules are a competitive alternative for dynamic, wave-dominated structural simulations.",
    "authors": [
      "Alessandro Lucchetti",
      "Francesco Cadini",
      "Marco Giglio",
      "Luca Lomazzi"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CE",
      "physics.comp-ph"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25683v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25683v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.25677v1",
    "title": "ZK-SenseLM: Verifiable Large-Model Wireless Sensing with Selective   Abstention and Zero-Knowledge Attestation",
    "summary": "ZK-SenseLM is a secure and auditable wireless sensing framework that pairs a large-model encoder for Wi-Fi channel state information (and optionally mmWave radar or RFID) with a policy-grounded decision layer and end-to-end zero-knowledge proofs of inference. The encoder uses masked spectral pretraining with phase-consistency regularization, plus a light cross-modal alignment that ties RF features to compact, human-interpretable policy tokens. To reduce unsafe actions under distribution shift, we add a calibrated selective-abstention head; the chosen risk-coverage operating point is registered and bound into the proof. We implement a four-stage proving pipeline: (C1) feature sanity and commitment, (C2) threshold and version binding, (C3) time-window binding, and (C4) PLONK-style proofs that the quantized network, given the committed window, produced the logged action and confidence. Micro-batched proving amortizes cost across adjacent windows, and a gateway option offloads proofs from low-power devices. The system integrates with differentially private federated learning and on-device personalization without weakening verifiability: model hashes and the registered threshold are part of each public statement. Across activity, presence or intrusion, respiratory proxy, and RF fingerprinting tasks, ZK-SenseLM improves macro-F1 and calibration, yields favorable coverage-risk curves under perturbations, and rejects tamper and replay with compact proofs and fast verification.",
    "authors": [
      "Hasan Akgul",
      "Mari Eplik",
      "Javier Rojas",
      "Aina Binti Abdullah",
      "Pieter van der Merwe"
    ],
    "categories": [
      "cs.CR",
      "cs.CL",
      "C.2.1; D.4.6; E.3; I.2.6; I.5.4"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25677v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25677v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.25623v1",
    "title": "Evaluating the Role of Verifiers in Test-Time Scaling for Legal   Reasoning Tasks",
    "summary": "Test-time scaling (TTS) techniques can improve the performance of large language models (LLMs) at the expense of additional computation and latency. While TTS has proven effective in formal domains such as mathematics and programming \\citep{snell2024scaling, chen2024more}, its value in argumentative domains such as law remains underexplored. We present an empirical study of verifier-based TTS methods for legal multiple-choice QA (MCQA) across five benchmarks. Using a family of 7 reward models, we evaluate both outcome-level (Best-of-$N$) and process-level (tree search) verification under realistic low-$N$ budgets. Our analysis systematically investigates how verifier utility is affected by key properties such as domain specialization, model size, and supervision type (process-supervised PRMs vs. outcome-only ORMs), even when applied across different roles.",
    "authors": [
      "Davide Romano",
      "Jonathan Schwarz",
      "Daniele Giofré"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25623v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25623v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.25595v1",
    "title": "Communication and Verification in LLM Agents towards Collaboration under   Information Asymmetry",
    "summary": "While Large Language Model (LLM) agents are often approached from the angle of action planning/generation to accomplish a goal (e.g., given by language descriptions), their abilities to collaborate with each other to achieve a joint goal are not well explored. To address this limitation, this paper studies LLM agents in task collaboration, particularly under the condition of information asymmetry, where agents have disparities in their knowledge and skills and need to work together to complete a shared task. We extend Einstein Puzzles, a classical symbolic puzzle, to a table-top game. In this game, two LLM agents must reason, communicate, and act to satisfy spatial and relational constraints required to solve the puzzle. We apply a fine-tuning-plus-verifier framework in which LLM agents are equipped with various communication strategies and verification signals from the environment. Empirical results highlight the critical importance of aligned communication, especially when agents possess both information-seeking and -providing capabilities. Interestingly, agents without communication can still achieve high task performance; however, further analysis reveals a lack of true rule understanding and lower trust from human evaluators. Instead, by integrating an environment-based verifier, we enhance agents' ability to comprehend task rules and complete tasks, promoting both safer and more interpretable collaboration in AI systems. https://github.com/Roihn/EinsteinPuzzles",
    "authors": [
      "Run Peng",
      "Ziqiao Ma",
      "Amy Pang",
      "Sikai Li",
      "Zhang Xi-Jia",
      "Yingzhuo Yu",
      "Cristian-Paul Bara",
      "Joyce Chai"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25595v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25595v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.25506v1",
    "title": "Reflections on the Reproducibility of Commercial LLM Performance in   Empirical Software Engineering Studies",
    "summary": "Large Language Models have gained remarkable interest in industry and academia. The increasing interest in LLMs in academia is also reflected in the number of publications on this topic over the last years. For instance, alone 78 of the around 425 publications at ICSE 2024 performed experiments with LLMs. Conducting empirical studies with LLMs remains challenging and raises questions on how to achieve reproducible results, for both other researchers and practitioners. One important step towards excelling in empirical research on LLMs and their application is to first understand to what extent current research results are eventually reproducible and what factors may impede reproducibility. This investigation is within the scope of our work. We contribute an analysis of the reproducibility of LLM-centric studies, provide insights into the factors impeding reproducibility, and discuss suggestions on how to improve the current state. In particular, we studied the 86 articles describing LLM-centric studies, published at ICSE 2024 and ASE 2024. Of the 86 articles, 18 provided research artefacts and used OpenAI models. We attempted to replicate those 18 studies. Of the 18 studies, only five were fit for reproduction. For none of the five studies, we were able to fully reproduce the results. Two studies seemed to be partially reproducible, and three studies did not seem to be reproducible. Our results highlight not only the need for stricter research artefact evaluations but also for more robust study designs to ensure the reproducible value of future publications.",
    "authors": [
      "Florian Angermeir",
      "Maximilian Amougou",
      "Mark Kreitz",
      "Andreas Bauer",
      "Matthias Linhuber",
      "Davide Fucci",
      "Fabiola Moyón C.",
      "Daniel Mendez",
      "Tony Gorschek"
    ],
    "categories": [
      "cs.SE",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25506v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25506v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.25504v1",
    "title": "Multi-Objective Search: Algorithms, Applications, and Emerging   Directions",
    "summary": "Multi-objective search (MOS) has emerged as a unifying framework for planning and decision-making problems where multiple, often conflicting, criteria must be balanced. While the problem has been studied for decades, recent years have seen renewed interest in the topic across AI applications such as robotics, transportation, and operations research, reflecting the reality that real-world systems rarely optimize a single measure. This paper surveys developments in MOS while highlighting cross-disciplinary opportunities, and outlines open challenges that define the emerging frontier of MOS",
    "authors": [
      "Oren Salzman",
      "Carlos Hernández Ulloa",
      "Ariel Felner",
      "Sven Koenig"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25504v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25504v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.25386v1",
    "title": "Integrating Legal and Logical Specifications in Perception, Prediction,   and Planning for Automated Driving: A Survey of Methods",
    "summary": "This survey provides an analysis of current methodologies integrating legal and logical specifications into the perception, prediction, and planning modules of automated driving systems. We systematically explore techniques ranging from logic-based frameworks to computational legal reasoning approaches, emphasizing their capability to ensure regulatory compliance and interpretability in dynamic and uncertain driving environments. A central finding is that significant challenges arise at the intersection of perceptual reliability, legal compliance, and decision-making justifiability. To systematically analyze these challenges, we introduce a taxonomy categorizing existing approaches by their theoretical foundations, architectural implementations, and validation strategies. We particularly focus on methods that address perceptual uncertainty and incorporate explicit legal norms, facilitating decisions that are both technically robust and legally defensible. The review covers neural-symbolic integration methods for perception, logic-driven rule representation, and norm-aware prediction strategies, all contributing toward transparent and accountable autonomous vehicle operation. We highlight critical open questions and practical trade-offs that must be addressed, offering multidisciplinary insights from engineering, logic, and law to guide future developments in legally compliant autonomous driving systems.",
    "authors": [
      "Kumar Manas",
      "Mert Keser",
      "Alois Knoll"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.SY",
      "eess.SY"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25386v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25386v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.25301v1",
    "title": "GaTector+: A Unified Head-free Framework for Gaze Object and Gaze   Following Prediction",
    "summary": "Gaze object detection and gaze following are fundamental tasks for interpreting human gaze behavior or intent. However, most previous methods usually solve these two tasks separately, and their prediction of gaze objects and gaze following typically depend on head-related prior knowledge during both the training phase and real-world deployment. This dependency necessitates an auxiliary network to extract head location, thus precluding joint optimization across the entire system and constraining the practical applicability. To this end, we propose GaTector+, a unified framework for gaze object detection and gaze following, which eliminates the dependence on the head-related priors during inference. Specifically, GaTector+ uses an expanded specific-general-specific feature extractor that leverages a shared backbone, which extracts general features for gaze following and object detection using the shared backbone while using specific blocks before and after the shared backbone to better consider the specificity of each sub-task. To obtain head-related knowledge without prior information, we first embed a head detection branch to predict the head of each person. Then, before regressing the gaze point, a head-based attention mechanism is proposed to fuse the sense feature and gaze feature with the help of head location. Since the suboptimization of the gaze point heatmap leads to the performance bottleneck, we propose an attention supervision mechanism to accelerate the learning of the gaze heatmap. Finally, we propose a novel evaluation metric, mean Similarity over Candidates (mSoC), for gaze object detection, which is more sensitive to variations between bounding boxes. The experimental results on multiple benchmark datasets demonstrate the effectiveness of our model in both gaze object detection and gaze following tasks.",
    "authors": [
      "Yang Jin",
      "Guangyu Guo",
      "Binglu Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25301v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25301v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.25240v1",
    "title": "Generative Bayesian Optimization: Generative Models as Acquisition   Functions",
    "summary": "We present a general strategy for turning generative models into candidate solution samplers for batch Bayesian optimization (BO). The use of generative models for BO enables large batch scaling as generative sampling, optimization of non-continuous design spaces, and high-dimensional and combinatorial design. Inspired by the success of direct preference optimization (DPO), we show that one can train a generative model with noisy, simple utility values directly computed from observations to then form proposal distributions whose densities are proportional to the expected utility, i.e., BO's acquisition function values. Furthermore, this approach is generalizable beyond preference-based feedback to general types of reward signals and loss functions. This perspective avoids the construction of surrogate (regression or classification) models, common in previous methods that have used generative models for black-box optimization. Theoretically, we show that the generative models within the BO process approximately follow a sequence of distributions which asymptotically concentrate at the global optima under certain conditions. We also demonstrate this effect through experiments on challenging optimization problems involving large batches in high dimensions.",
    "authors": [
      "Rafael Oliveira",
      "Daniel M. Steinberg",
      "Edwin V. Bonilla"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25240v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25240v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.25157v1",
    "title": "Towards Real-Time Inference of Thin Liquid Film Thickness Profiles from   Interference Patterns Using Vision Transformers",
    "summary": "Thin film interferometry is a powerful technique for non-invasively measuring liquid film thickness with applications in ophthalmology, but its clinical translation is hindered by the challenges in reconstructing thickness profiles from interference patterns - an ill-posed inverse problem complicated by phase periodicity, imaging noise and ambient artifacts. Traditional reconstruction methods are either computationally intensive, sensitive to noise, or require manual expert analysis, which is impractical for real-time diagnostics. To address this challenge, here we present a vision transformer-based approach for real-time inference of thin liquid film thickness profiles directly from isolated interferograms. Trained on a hybrid dataset combining physiologically-relevant synthetic and experimental tear film data, our model leverages long-range spatial correlations to resolve phase ambiguities and reconstruct temporally coherent thickness profiles in a single forward pass from dynamic interferograms acquired in vivo and ex vivo. The network demonstrates state-of-the-art performance on noisy, rapidly-evolving films with motion artifacts, overcoming limitations of conventional phase-unwrapping and iterative fitting methods. Our data-driven approach enables automated, consistent thickness reconstruction at real-time speeds on consumer hardware, opening new possibilities for continuous monitoring of pre-lens ocular tear films and non-invasive diagnosis of conditions such as the dry eye disease.",
    "authors": [
      "Gautam A. Viruthagiri",
      "Arnuv Tandon",
      "Gerald G. Fuller",
      "Vinny Chandran Suja"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25157v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25157v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.25140v1",
    "title": "DINO-YOLO: Self-Supervised Pre-training for Data-Efficient Object   Detection in Civil Engineering Applications",
    "summary": "Object detection in civil engineering applications is constrained by limited annotated data in specialized domains. We introduce DINO-YOLO, a hybrid architecture combining YOLOv12 with DINOv3 self-supervised vision transformers for data-efficient detection. DINOv3 features are strategically integrated at two locations: input preprocessing (P0) and mid-backbone enhancement (P3). Experimental validation demonstrates substantial improvements: Tunnel Segment Crack detection (648 images) achieves 12.4% improvement, Construction PPE (1K images) gains 13.7%, and KITTI (7K images) shows 88.6% improvement, while maintaining real-time inference (30-47 FPS). Systematic ablation across five YOLO scales and nine DINOv3 variants reveals that Medium-scale architectures achieve optimal performance with DualP0P3 integration (55.77% mAP@0.5), while Small-scale requires Triple Integration (53.63%). The 2-4x inference overhead (21-33ms versus 8-16ms baseline) remains acceptable for field deployment on NVIDIA RTX 5090. DINO-YOLO establishes state-of-the-art performance for civil engineering datasets (<10K images) while preserving computational efficiency, providing practical solutions for construction safety monitoring and infrastructure inspection in data-constrained environments.",
    "authors": [
      "Malaisree P",
      "Youwai S",
      "Kitkobsin T",
      "Janrungautai S",
      "Amorndechaphon D",
      "Rojanavasu P"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25140v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25140v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.25755v1",
    "title": "MLPrE -- A tool for preprocessing and exploratory data analysis prior to   machine learning model construction",
    "summary": "With the recent growth of Deep Learning for AI, there is a need for tools to meet the demand of data flowing into those models. In some cases, source data may exist in multiple formats, and therefore the source data must be investigated and properly engineered for a Machine Learning model or graph database. Overhead and lack of scalability with existing workflows limit integration within a larger processing pipeline such as Apache Airflow, driving the need for a robust, extensible, and lightweight tool to preprocess arbitrary datasets that scales with data type and size. To address this, we present Machine Learning Preprocessing and Exploratory Data Analysis, MLPrE, in which SparkDataFrames were utilized to hold data during processing and ensure scalability. A generalizable JSON input file format was utilized to describe stepwise changes to that DataFrame. Stages were implemented for input and output, filtering, basic statistics, feature engineering, and exploratory data analysis. A total of 69 stages were implemented into MLPrE, of which we highlight and demonstrate key stages using six diverse datasets. We further highlight MLPrE's ability to independently process multiple fields in flat files and recombine them, otherwise requiring an additional pipeline, using a UniProt glossary term dataset. Building on this advantage, we demonstrated the clustering stage with available wine quality data. Lastly, we demonstrate the preparation of data for a graph database in the final stages of MLPrE using phosphosite kinase data. Overall, our MLPrE tool offers a generalizable and scalable tool for preprocessing and early data analysis, filling a critical need for such a tool given the ever expanding use of machine learning. This tool serves to accelerate and simplify early stage development in larger workflows.",
    "authors": [
      "David S Maxwell",
      "Michael Darkoh",
      "Sidharth R Samudrala",
      "Caroline Chung",
      "Stephanie T Schmidt",
      "Bissan Al-Lazikani"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25755v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25755v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.25752v1",
    "title": "Meshless solutions of PDE inverse problems on irregular geometries",
    "summary": "Solving inverse and optimization problems over solutions of nonlinear partial differential equations (PDEs) on complex spatial domains is a long-standing challenge. Here we introduce a method that parameterizes the solution using spectral bases on arbitrary spatiotemporal domains, whereby the basis is defined on a hyperrectangle containing the true domain. We find the coefficients of the basis expansion by solving an optimization problem whereby both the equations, the boundary conditions and any optimization targets are enforced by a loss function, building on a key idea from Physics-Informed Neural Networks (PINNs). Since the representation of the function natively has exponential convergence, so does the solution of the optimization problem, as long as it can be solved efficiently. We find empirically that the optimization protocols developed for machine learning find solutions with exponential convergence on a wide range of equations. The method naturally allows for the incorporation of data assimilation by including additional terms in the loss function, and for the efficient solution of optimization problems over the PDE solutions.",
    "authors": [
      "James V. Roggeveen",
      "Michael P. Brenner"
    ],
    "categories": [
      "math.NA",
      "cs.LG",
      "cs.NA",
      "physics.comp-ph"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25752v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25752v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.25616v1",
    "title": "Don't Blind Your VLA: Aligning Visual Representations for OOD   Generalization",
    "summary": "The growing success of Vision-Language-Action (VLA) models stems from the promise that pretrained Vision-Language Models (VLMs) can endow agents with transferable world knowledge and vision-language (VL) grounding, laying a foundation for action models with broader generalization. Yet when these VLMs are adapted to the action modality, it remains unclear to what extent their original VL representations and knowledge are preserved. In this work, we conduct a systematic study of representation retention during VLA fine-tuning, showing that naive action fine-tuning leads to degradation of visual representations. To characterize and measure these effects, we probe VLA's hidden representations and analyze attention maps, further, we design a set of targeted tasks and methods that contrast VLA models with their counterpart VLMs, isolating changes in VL capabilities induced by action fine-tuning. We further evaluate a range of strategies for aligning visual representations and introduce a simple yet effective method that mitigates degradation and yields improved generalization to out-of-distribution (OOD) scenarios. Taken together, our analysis clarifies the trade-off between action fine-tuning and the degradation of VL representations and highlights practical approaches to recover inherited VL capabilities. Code is publicly available: https://blind-vla-paper.github.io",
    "authors": [
      "Nikita Kachaev",
      "Mikhail Kolosov",
      "Daniil Zelezetsky",
      "Alexey K. Kovalev",
      "Aleksandr I. Panov"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.RO"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25616v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25616v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.25582v1",
    "title": "Learning-Augmented Online Bidding in Stochastic Settings",
    "summary": "Online bidding is a classic optimization problem, with several applications in online decision-making, the design of interruptible systems, and the analysis of approximation algorithms. In this work, we study online bidding under learning-augmented settings that incorporate stochasticity, in either the prediction oracle or the algorithm itself. In the first part, we study bidding under distributional predictions, and find Pareto-optimal algorithms that offer the best-possible tradeoff between the consistency and the robustness of the algorithm. In the second part, we study the power and limitations of randomized bidding algorithms, by presenting upper and lower bounds on the consistency/robustness tradeoffs. Previous works focused predominantly on oracles that do not leverage stochastic information on the quality of the prediction, and deterministic algorithms.",
    "authors": [
      "Spyros Angelopoulos",
      "Bertrand Simon"
    ],
    "categories": [
      "cs.GT",
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25582v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25582v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.25573v1",
    "title": "Monitoring the calibration of probability forecasts with an application   to concept drift detection involving image classification",
    "summary": "Machine learning approaches for image classification have led to impressive advances in that field. For example, convolutional neural networks are able to achieve remarkable image classification accuracy across a wide range of applications in industry, defense, and other areas. While these machine learning models boast impressive accuracy, a related concern is how to assess and maintain calibration in the predictions these models make. A classification model is said to be well calibrated if its predicted probabilities correspond with the rates events actually occur. While there are many available methods to assess machine learning calibration and recalibrate faulty predictions, less effort has been spent on developing approaches that continually monitor predictive models for potential loss of calibration as time passes. We propose a cumulative sum-based approach with dynamic limits that enable detection of miscalibration in both traditional process monitoring and concept drift applications. This enables early detection of operational context changes that impact image classification performance in the field. The proposed chart can be used broadly in any situation where the user needs to monitor probability predictions over time for potential lapses in calibration. Importantly, our method operates on probability predictions and event outcomes and does not require under-the-hood access to the machine learning model.",
    "authors": [
      "Christopher T. Franck",
      "Anne R. Driscoll",
      "Zoe Szajnfarber",
      "William H. Woodall"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25573v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25573v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.25536v1",
    "title": "TwinVoice: A Multi-dimensional Benchmark Towards Digital Twins via LLM   Persona Simulation",
    "summary": "Large Language Models (LLMs) are exhibiting emergent human-like abilities and are increasingly envisioned as the foundation for simulating an individual's communication style, behavioral tendencies, and personality traits. However, current evaluations of LLM-based persona simulation remain limited: most rely on synthetic dialogues, lack systematic frameworks, and lack analysis of the capability requirement. To address these limitations, we introduce TwinVoice, a comprehensive benchmark for assessing persona simulation across diverse real-world contexts. TwinVoice encompasses three dimensions: Social Persona (public social interactions), Interpersonal Persona (private dialogues), and Narrative Persona (role-based expression). It further decomposes the evaluation of LLM performance into six fundamental capabilities, including opinion consistency, memory recall, logical reasoning, lexical fidelity, persona tone, and syntactic style. Experimental results reveal that while advanced models achieve moderate accuracy in persona simulation, they still fall short of capabilities such as syntactic style and memory recall. Consequently, the average performance achieved by LLMs remains considerably below the human baseline.",
    "authors": [
      "Bangde Du",
      "Minghao Guo",
      "Songming He",
      "Ziyi Ye",
      "Xi Zhu",
      "Weihang Su",
      "Shuqi Zhu",
      "Yujia Zhou",
      "Yongfeng Zhang",
      "Qingyao Ai",
      "Yiqun Liu"
    ],
    "categories": [
      "cs.CL",
      "I.2.7; I.2.6; I.2.0"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25536v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25536v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.25517v1",
    "title": "Predicate Renaming via Large Language Models",
    "summary": "In this paper, we address the problem of giving names to predicates in logic rules using Large Language Models (LLMs). In the context of Inductive Logic Programming, various rule generation methods produce rules containing unnamed predicates, with Predicate Invention being a key example. This hinders the readability, interpretability, and reusability of the logic theory. Leveraging recent advancements in LLMs development, we explore their ability to process natural language and code to provide semantically meaningful suggestions for giving a name to unnamed predicates. The evaluation of our approach on some hand-crafted logic rules indicates that LLMs hold potential for this task.",
    "authors": [
      "Elisabetta Gentili",
      "Tony Ribeiro",
      "Fabrizio Riguzzi",
      "Katsumi Inoue"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25517v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25517v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.25434v1",
    "title": "A Critical Study of Automatic Evaluation in Sign Language Translation",
    "summary": "Automatic evaluation metrics are crucial for advancing sign language translation (SLT). Current SLT evaluation metrics, such as BLEU and ROUGE, are only text-based, and it remains unclear to what extent text-based metrics can reliably capture the quality of SLT outputs. To address this gap, we investigate the limitations of text-based SLT evaluation metrics by analyzing six metrics, including BLEU, chrF, and ROUGE, as well as BLEURT on the one hand, and large language model (LLM)-based evaluators such as G-Eval and GEMBA zero-shot direct assessment on the other hand. Specifically, we assess the consistency and robustness of these metrics under three controlled conditions: paraphrasing, hallucinations in model outputs, and variations in sentence length. Our analysis highlights the limitations of lexical overlap metrics and demonstrates that while LLM-based evaluators better capture semantic equivalence often missed by conventional metrics, they can also exhibit bias toward LLM-paraphrased translations. Moreover, although all metrics are able to detect hallucinations, BLEU tends to be overly sensitive, whereas BLEURT and LLM-based evaluators are comparatively lenient toward subtle cases. This motivates the need for multimodal evaluation frameworks that extend beyond text-based metrics to enable a more holistic assessment of SLT outputs.",
    "authors": [
      "Shakib Yazdani",
      "Yasser Hamidullah",
      "Cristina España-Bonet",
      "Eleftherios Avramidis",
      "Josef van Genabith"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25434v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25434v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.25432v1",
    "title": "Depth and Autonomy: A Framework for Evaluating LLM Applications in   Social Science Research",
    "summary": "Large language models (LLMs) are increasingly utilized by researchers across a wide range of domains, and qualitative social science is no exception; however, this adoption faces persistent challenges, including interpretive bias, low reliability, and weak auditability. We introduce a framework that situates LLM usage along two dimensions, interpretive depth and autonomy, thereby offering a straightforward way to classify LLM applications in qualitative research and to derive practical design recommendations. We present the state of the literature with respect to these two dimensions, based on all published social science papers available on Web of Science that use LLMs as a tool and not strictly as the subject of study. Rather than granting models expansive freedom, our approach encourages researchers to decompose tasks into manageable segments, much as they would when delegating work to capable undergraduate research assistants. By maintaining low levels of autonomy and selectively increasing interpretive depth only where warranted and under supervision, one can plausibly reap the benefits of LLMs while preserving transparency and reliability.",
    "authors": [
      "Ali Sanaei",
      "Ali Rajabzadeh"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25432v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25432v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.25340v1",
    "title": "Multi-party Agent Relation Sampling for Multi-party Ad Hoc Teamwork",
    "summary": "Multi-agent reinforcement learning (MARl) has achieved strong results in cooperative tasks but typically assumes fixed, fully controlled teams. Ad hoc teamwork (AHT) relaxes this by allowing collaboration with unknown partners, yet existing variants still presume shared conventions. We introduce Multil-party Ad Hoc Teamwork (MAHT), where controlled agents must coordinate with multiple mutually unfamiliar groups of uncontrolled teammates. To address this, we propose MARs, which builds a sparse skeleton graph and applies relational modeling to capture cross-group dvnamics. Experiments on MPE and starCralt ll show that MARs outperforms MARL and AHT baselines while converging faster.",
    "authors": [
      "Beiwen Zhang",
      "Yongheng Liang",
      "Hejun Wu"
    ],
    "categories": [
      "cs.MA",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25340v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25340v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.25116v1",
    "title": "Pretraining Strategies using Monolingual and Parallel Data for   Low-Resource Machine Translation",
    "summary": "This research article examines the effectiveness of various pretraining strategies for developing machine translation models tailored to low-resource languages. Although this work considers several low-resource languages, including Afrikaans, Swahili, and Zulu, the translation model is specifically developed for Lingala, an under-resourced African language, building upon the pretraining approach introduced by Reid and Artetxe (2021), originally designed for high-resource languages. Through a series of comprehensive experiments, we explore different pretraining methodologies, including the integration of multiple languages and the use of both monolingual and parallel data during the pretraining phase. Our findings indicate that pretraining on multiple languages and leveraging both monolingual and parallel data significantly enhance translation quality. This study offers valuable insights into effective pretraining strategies for low-resource machine translation, helping to bridge the performance gap between high-resource and low-resource languages. The results contribute to the broader goal of developing more inclusive and accurate NLP models for marginalized communities and underrepresented populations. The code and datasets used in this study are publicly available to facilitate further research and ensure reproducibility, with the exception of certain data that may no longer be accessible due to changes in public availability.",
    "authors": [
      "Idriss Nguepi Nguefack",
      "Mara Finkelstein",
      "Toadoum Sari Sakayo"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25116v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25116v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.25544v1",
    "title": "Error Bounds and Optimal Schedules for Masked Diffusions with Factorized   Approximations",
    "summary": "Recently proposed generative models for discrete data, such as Masked Diffusion Models (MDMs), exploit conditional independence approximations to reduce the computational cost of popular Auto-Regressive Models (ARMs), at the price of some bias in the sampling distribution. We study the resulting computation-vs-accuracy trade-off, providing general error bounds (in relative entropy) that depend only on the average number of tokens generated per iteration and are independent of the data dimensionality (i.e. sequence length), thus supporting the empirical success of MDMs. We then investigate the gain obtained by using non-constant schedule sizes (i.e. varying the number of unmasked tokens during the generation process) and identify the optimal schedule as a function of a so-called information profile of the data distribution, thus allowing for a principled optimization of schedule sizes. We define methods directly as sampling algorithms and do not use classical derivations as time-reversed diffusion processes, leading us to simple and transparent proofs.",
    "authors": [
      "Hugo Lavenant",
      "Giacomo Zanella"
    ],
    "categories": [
      "stat.ML",
      "cs.IT",
      "cs.LG",
      "math.IT",
      "stat.CO"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25544v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25544v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2510.25529v1",
    "title": "Off-policy Reinforcement Learning with Model-based Exploration   Augmentation",
    "summary": "Exploration is fundamental to reinforcement learning (RL), as it determines how effectively an agent discovers and exploits the underlying structure of its environment to achieve optimal performance. Existing exploration methods generally fall into two categories: active exploration and passive exploration. The former introduces stochasticity into the policy but struggles in high-dimensional environments, while the latter adaptively prioritizes transitions in the replay buffer to enhance exploration, yet remains constrained by limited sample diversity. To address the limitation in passive exploration, we propose Modelic Generative Exploration (MoGE), which augments exploration through the generation of under-explored critical states and synthesis of dynamics-consistent experiences through transition models. MoGE is composed of two components: (1) a diffusion-based generator that synthesizes critical states under the guidance of a utility function evaluating each state's potential influence on policy exploration, and (2) a one-step imagination world model for constructing critical transitions based on the critical states for agent learning. Our method adopts a modular formulation that aligns with the principles of off-policy learning, allowing seamless integration with existing algorithms to improve exploration without altering their core structures. Empirical results on OpenAI Gym and DeepMind Control Suite reveal that MoGE effectively bridges exploration and policy learning, leading to remarkable gains in both sample efficiency and performance across complex control tasks.",
    "authors": [
      "Likun Wang",
      "Xiangteng Zhang",
      "Yinuo Wang",
      "Guojian Zhan",
      "Wenxuan Wang",
      "Haoyu Gao",
      "Jingliang Duan",
      "Shengbo Eben Li"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25529v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25529v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2510.25368v1",
    "title": "Position: Biology is the Challenge Physics-Informed ML Needs to Evolve",
    "summary": "Physics-Informed Machine Learning (PIML) has successfully integrated mechanistic understanding into machine learning, particularly in domains governed by well-known physical laws. This success has motivated efforts to apply PIML to biology, a field rich in dynamical systems but shaped by different constraints. Biological modeling, however, presents unique challenges: multi-faceted and uncertain prior knowledge, heterogeneous and noisy data, partial observability, and complex, high-dimensional networks. In this position paper, we argue that these challenges should not be seen as obstacles to PIML, but as catalysts for its evolution. We propose Biology-Informed Machine Learning (BIML): a principled extension of PIML that retains its structural grounding while adapting to the practical realities of biology. Rather than replacing PIML, BIML retools its methods to operate under softer, probabilistic forms of prior knowledge. We outline four foundational pillars as a roadmap for this transition: uncertainty quantification, contextualization, constrained latent structure inference, and scalability. Foundation Models and Large Language Models will be key enablers, bridging human expertise with computational modeling. We conclude with concrete recommendations to build the BIML ecosystem and channel PIML-inspired innovation toward challenges of high scientific and societal relevance.",
    "authors": [
      "Julien Martinelli"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25368v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25368v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2510.25332v1",
    "title": "StreamingCoT: A Dataset for Temporal Dynamics and Multimodal   Chain-of-Thought Reasoning in Streaming VideoQA",
    "summary": "The rapid growth of streaming video applications demands multimodal models with enhanced capabilities for temporal dynamics understanding and complex reasoning. However, current Video Question Answering (VideoQA) datasets suffer from two critical limitations: 1) Static annotation mechanisms fail to capture the evolving nature of answers in temporal video streams, and 2) The absence of explicit reasoning process annotations restricts model interpretability and logical deduction capabilities. To address these challenges, We introduce StreamingCoT, the first dataset explicitly designed for temporally evolving reasoning in streaming VideoQA and multimodal Chain-of-Thought (CoT) tasks. Our framework first establishes a dynamic hierarchical annotation architecture that generates per-second dense descriptions and constructs temporally-dependent semantic segments through similarity fusion, paired with question-answer sets constrained by temporal evolution patterns. We further propose an explicit reasoning chain generation paradigm that extracts spatiotemporal objects via keyframe semantic alignment, derives object state transition-based reasoning paths using large language models, and ensures logical coherence through human-verified validation. This dataset establishes a foundation for advancing research in streaming video understanding, complex temporal reasoning, and multimodal inference. Our StreamingCoT and its construction toolkit can be accessed at https://github.com/Fleeting-hyh/StreamingCoT.",
    "authors": [
      "Yuhang Hu",
      "Zhenyu Yang",
      "Shihan Wang",
      "Shengsheng Qian",
      "Bin Wen",
      "Fan Yang",
      "Tingting Gao",
      "Changsheng Xu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25332v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25332v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2510.25206v1",
    "title": "RAVR: Reference-Answer-guided Variational Reasoning for Large Language   Models",
    "summary": "Reinforcement learning (RL) can refine the reasoning abilities of large language models (LLMs), but critically depends on a key prerequisite: the LLM can already generate high-utility reasoning paths with non-negligible probability. For tasks beyond the LLM's current competence, such reasoning path can be hard to sample, and learning risks reinforcing familiar but suboptimal reasoning. We are motivated by the insight from cognitive science that Why is this the answer is often an easier question than What is the answer, as it avoids the heavy cognitive load of open-ended exploration, opting instead for explanatory reconstruction-systematically retracing the reasoning that links a question to its answer. We show that LLMs can similarly leverage answers to derive high-quality reasoning paths. We formalize this phenomenon and prove that conditioning on answer provably increases the expected utility of sampled reasoning paths, thereby transforming intractable problems into learnable ones. Building on this insight, we introduce RAVR (Reference-Answer-guided Variational Reasoning), an end-to-end framework that uses answer-conditioned reasoning as a variational surrogate for question-only reasoning. Experiments in both general and math domains demonstrate consistent improvements over strong baselines. We further analyze the reasoning behavior and find that RAVR reduces hesitation, strengthens conclusion consolidation, and promotes problem-specific strategies in reasoning.",
    "authors": [
      "Tianqianjin Lin",
      "Xi Zhao",
      "Xingyao Zhang",
      "Rujiao Long",
      "Yi Xu",
      "Zhuoren Jiang",
      "Wenbo Su",
      "Bo Zheng"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG",
      "I.2.7"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25206v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25206v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2510.25187v1",
    "title": "Testing Cross-Lingual Text Comprehension In LLMs Using Next Sentence   Prediction",
    "summary": "While large language models are trained on massive datasets, this data is heavily skewed towards English. Does their impressive performance reflect genuine ability or just this data advantage? To find out, we tested them in a setting where they could not rely on data abundance: low-resource languages. Building on prior work Agarwal et al. (2025) that used Next Sentence Prediction (NSP) as a test, we created a large-scale benchmark with 10,000 questions each for English (a high-resource language), Swahili (medium-resource), and Hausa (low-resource). We then tested several top models, including GPT-4 Turbo, Gemini 1.5 Flash, and LLaMA 3 70B, to see how their performance holds up. The results painted a clear picture of how levels of language resources impact outcomes. While all models excelled in English, their accuracy dropped in Swahili and fell sharply in Hausa, with LLaMA 3 struggling the most. The story became even more interesting when we introduced Chain-of-Thought (CoT) prompting. For the struggling LLaMA 3, CoT acted as a helpful guide, significantly boosting its accuracy. However, for the more capable GPT-4 and Gemini, the same technique often backfired, leading to a kind of \"overthinking\" that hurt their results in the cross-lingual context. This reveals that Chain-of-Thought is not a universal solution; its effectiveness depends heavily on the model's baseline capability and the specific context of the task. Our framework pinpoints LLM weaknesses, highlights when CoT helps or hinders cross-lingual NSP performance, and factors influencing their decisions.",
    "authors": [
      "Ritesh Sunil Chavan",
      "Jack Mostow"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25187v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25187v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2510.25732v1",
    "title": "The Limits of Obliviate: Evaluating Unlearning in LLMs via   Stimulus-Knowledge Entanglement-Behavior Framework",
    "summary": "Unlearning in large language models (LLMs) is crucial for managing sensitive data and correcting misinformation, yet evaluating its effectiveness remains an open problem. We investigate whether persuasive prompting can recall factual knowledge from deliberately unlearned LLMs across models ranging from 2.7B to 13B parameters (OPT-2.7B, LLaMA-2-7B, LLaMA-3.1-8B, LLaMA-2-13B). Drawing from ACT-R and Hebbian theory (spreading activation theories), as well as communication principles, we introduce Stimulus-Knowledge Entanglement-Behavior Framework (SKeB), which models information entanglement via domain graphs and tests whether factual recall in unlearned models is correlated with persuasive framing. We develop entanglement metrics to quantify knowledge activation patterns and evaluate factuality, non-factuality, and hallucination in outputs. Our results show persuasive prompts substantially enhance factual knowledge recall (14.8% baseline vs. 24.5% with authority framing), with effectiveness inversely correlated to model size (128% recovery in 2.7B vs. 15% in 13B). SKeB provides a foundation for assessing unlearning completeness, robustness, and overall behavior in LLMs.",
    "authors": [
      "Aakriti Shah",
      "Thai Le"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.7; I.2.6; I.2.4; G.2.2"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25732v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25732v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2510.25679v1",
    "title": "Navigation in a Three-Dimensional Urban Flow using Deep Reinforcement   Learning",
    "summary": "Unmanned Aerial Vehicles (UAVs) are increasingly populating urban areas for delivery and surveillance purposes. In this work, we develop an optimal navigation strategy based on Deep Reinforcement Learning. The environment is represented by a three-dimensional high-fidelity simulation of an urban flow, characterized by turbulence and recirculation zones. The algorithm presented here is a flow-aware Proximal Policy Optimization (PPO) combined with a Gated Transformer eXtra Large (GTrXL) architecture, giving the agent richer information about the turbulent flow field in which it navigates. The results are compared with a PPO+GTrXL without the secondary prediction tasks, a PPO combined with Long Short Term Memory (LSTM) cells and a traditional navigation algorithm. The obtained results show a significant increase in the success rate (SR) and a lower crash rate (CR) compared to a PPO+LSTM, PPO+GTrXL and the classical Zermelo's navigation algorithm, paving the way to a completely reimagined UAV landscape in complex urban environments.",
    "authors": [
      "Federica Tonti",
      "Ricardo Vinuesa"
    ],
    "categories": [
      "cs.AI",
      "physics.flu-dyn"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25679v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25679v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2510.25648v1",
    "title": "Continuous subsurface property retrieval from sparse radar observations   using physics informed neural networks",
    "summary": "Estimating subsurface dielectric properties is essential for applications ranging from environmental surveys of soils to nondestructive evaluation of concrete in infrastructure. Conventional wave inversion methods typically assume few discrete homogeneous layers and require dense measurements or strong prior knowledge of material boundaries, limiting scalability and accuracy in realistic settings where properties vary continuously. We present a physics informed machine learning framework that reconstructs subsurface permittivity as a fully neural, continuous function of depth, trained to satisfy both measurement data and Maxwells equations. We validate the framework with both simulations and custom built radar experiments on multilayered natural materials. Results show close agreement with in-situ permittivity measurements (R^2=0.93), with sensitivity to even subtle variations (Delta eps_r=2). Parametric analysis reveals that accurate profiles can be recovered with as few as three strategically placed sensors in two layer systems. This approach reframes subsurface inversion from boundary-driven to continuous property estimation, enabling accurate characterization of smooth permittivity variations and advancing electromagnetic imaging using low cost radar systems.",
    "authors": [
      "Ishfaq Aziz",
      "Mohamad Alipour"
    ],
    "categories": [
      "eess.SP",
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25648v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25648v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2510.25428v1",
    "title": "Alibaba International E-commerce Product Search Competition DcuRAGONs   Team Technical Report",
    "summary": "This report details our methodology and results developed for the Multilingual E-commerce Search Competition. The problem aims to recognize relevance between user queries versus product items in a multilingual context and improve recommendation performance on e-commerce platforms. Utilizing Large Language Models (LLMs) and their capabilities in other tasks, our data-centric method achieved the highest score compared to other solutions during the competition. Final leaderboard is publised at https://alibaba-international-cikm2025.github.io. The source code for our project is published at https://github.com/nhtlongcs/e-commerce-product-search.",
    "authors": [
      "Thang-Long Nguyen-Ho",
      "Minh-Khoi Pham",
      "Hoang-Bao Le"
    ],
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25428v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25428v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2510.25378v1",
    "title": "Hallucinations in Bibliographic Recommendation: Citation Frequency as a   Proxy for Training Data Redundancy",
    "summary": "Large language models (LLMs) have been increasingly applied to a wide range of tasks, from natural language understanding to code generation. While they have also been used to assist in bibliographic recommendation, the hallucination of non-existent papers remains a major issue. Building on prior studies, this study hypothesizes that an LLM's ability to correctly produce bibliographic information depends on whether the underlying knowledge is generated or memorized, with highly cited papers (i.e., more frequently appear in the training corpus) showing lower hallucination rates. We therefore assume citation count as a proxy for training data redundancy (i.e., the frequency with which a given bibliographic record is repeatedly represented in the pretraining corpus) and investigate how citation frequency affects hallucinated references in LLM outputs. Using GPT-4.1, we generated and manually verified 100 bibliographic records across twenty computer-science domains, and measured factual consistency via cosine similarity between generated and authentic metadata. The results revealed that (i) hallucination rates vary across research domains, (ii) citation count is strongly correlated with factual accuracy, and (iii) bibliographic information becomes almost verbatimly memorized beyond approximately 1,000 citations. These findings suggest that highly cited papers are nearly verbatimly retained in the model, indicating a threshold where generalization shifts into memorization.",
    "authors": [
      "Junichiro Niimi"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25378v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25378v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2510.25347v1",
    "title": "3D CT-Based Coronary Calcium Assessment: A Feature-Driven Machine   Learning Framework",
    "summary": "Coronary artery calcium (CAC) scoring plays a crucial role in the early detection and risk stratification of coronary artery disease (CAD). In this study, we focus on non-contrast coronary computed tomography angiography (CCTA) scans, which are commonly used for early calcification detection in clinical settings. To address the challenge of limited annotated data, we propose a radiomics-based pipeline that leverages pseudo-labeling to generate training labels, thereby eliminating the need for expert-defined segmentations. Additionally, we explore the use of pretrained foundation models, specifically CT-FM and RadImageNet, to extract image features, which are then used with traditional classifiers. We compare the performance of these deep learning features with that of radiomics features. Evaluation is conducted on a clinical CCTA dataset comprising 182 patients, where individuals are classified into two groups: zero versus non-zero calcium scores. We further investigate the impact of training on non-contrast datasets versus combined contrast and non-contrast datasets, with testing performed only on non contrast scans. Results show that radiomics-based models significantly outperform CNN-derived embeddings from foundation models (achieving 84% accuracy and p<0.05), despite the unavailability of expert annotations.",
    "authors": [
      "Ayman Abaid",
      "Gianpiero Guidone",
      "Sara Alsubai",
      "Foziyah Alquahtani",
      "Talha Iqbal",
      "Ruth Sharif",
      "Hesham Elzomor",
      "Emiliano Bianchini",
      "Naeif Almagal",
      "Michael G. Madden",
      "Faisal Sharif",
      "Ihsan Ullah"
    ],
    "categories": [
      "cs.CV",
      "cs.LG",
      "68U10",
      "I.2.1"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25347v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25347v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2510.25226v1",
    "title": "Cost-Sensitive Unbiased Risk Estimation for Multi-Class   Positive-Unlabeled Learning",
    "summary": "Positive--Unlabeled (PU) learning considers settings in which only positive and unlabeled data are available, while negatives are missing or left unlabeled. This situation is common in real applications where annotating reliable negatives is difficult or costly. Despite substantial progress in PU learning, the multi-class case (MPU) remains challenging: many existing approaches do not ensure \\emph{unbiased risk estimation}, which limits performance and stability. We propose a cost-sensitive multi-class PU method based on \\emph{adaptive loss weighting}. Within the empirical risk minimization framework, we assign distinct, data-dependent weights to the positive and \\emph{inferred-negative} (from the unlabeled mixture) loss components so that the resulting empirical objective is an unbiased estimator of the target risk. We formalize the MPU data-generating process and establish a generalization error bound for the proposed estimator. Extensive experiments on \\textbf{eight} public datasets, spanning varying class priors and numbers of classes, show consistent gains over strong baselines in both accuracy and stability.",
    "authors": [
      "Miao Zhang",
      "Junpeng Li",
      "Changchun Hua",
      "Yana Yang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25226v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25226v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2510.25210v1",
    "title": "U-CAN: Unsupervised Point Cloud Denoising with Consistency-Aware   Noise2Noise Matching",
    "summary": "Point clouds captured by scanning sensors are often perturbed by noise, which have a highly negative impact on downstream tasks (e.g. surface reconstruction and shape understanding). Previous works mostly focus on training neural networks with noisy-clean point cloud pairs for learning denoising priors, which requires extensively manual efforts. In this work, we introduce U-CAN, an Unsupervised framework for point cloud denoising with Consistency-Aware Noise2Noise matching. Specifically, we leverage a neural network to infer a multi-step denoising path for each point of a shape or scene with a noise to noise matching scheme. We achieve this by a novel loss which enables statistical reasoning on multiple noisy point cloud observations. We further introduce a novel constraint on the denoised geometry consistency for learning consistency-aware denoising patterns. We justify that the proposed constraint is a general term which is not limited to 3D domain and can also contribute to the area of 2D image denoising. Our evaluations under the widely used benchmarks in point cloud denoising, upsampling and image denoising show significant improvement over the state-of-the-art unsupervised methods, where U-CAN also produces comparable results with the supervised methods.",
    "authors": [
      "Junsheng Zhou",
      "Xingyu Shi",
      "Haichuan Song",
      "Yi Fang",
      "Yu-Shen Liu",
      "Zhizhong Han"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25210v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25210v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2510.25134v1",
    "title": "Region-CAM: Towards Accurate Object Regions in Class Activation Maps for   Weakly Supervised Learning Tasks",
    "summary": "Class Activation Mapping (CAM) methods are widely applied in weakly supervised learning tasks due to their ability to highlight object regions. However, conventional CAM methods highlight only the most discriminative regions of the target. These highlighted regions often fail to cover the entire object and are frequently misaligned with object boundaries, thereby limiting the performance of downstream weakly supervised learning tasks, particularly Weakly Supervised Semantic Segmentation (WSSS), which demands pixel-wise accurate activation maps to get the best results. To alleviate the above problems, we propose a novel activation method, Region-CAM. Distinct from network feature weighting approaches, Region-CAM generates activation maps by extracting semantic information maps (SIMs) and performing semantic information propagation (SIP) by considering both gradients and features in each of the stages of the baseline classification model. Our approach highlights a greater proportion of object regions while ensuring activation maps to have precise boundaries that align closely with object edges. Region-CAM achieves 60.12% and 58.43% mean intersection over union (mIoU) using the baseline model on the PASCAL VOC training and validation datasets, respectively, which are improvements of 13.61% and 13.13% over the original CAM (46.51% and 45.30%). On the MS COCO validation set, Region-CAM achieves 36.38%, a 16.23% improvement over the original CAM (20.15%). We also demonstrate the superiority of Region-CAM in object localization tasks, using the ILSVRC2012 validation set. Region-CAM achieves 51.7% in Top-1 Localization accuracy Loc1. Compared with LayerCAM, an activation method designed for weakly supervised object localization, Region-CAM achieves 4.5% better performance in Loc1.",
    "authors": [
      "Qingdong Cai",
      "Charith Abhayaratne"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25134v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25134v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2510.25128v1",
    "title": "An Analysis of Causal Effect Estimation using Outcome Invariant Data   Augmentation",
    "summary": "The technique of data augmentation (DA) is often used in machine learning for regularization purposes to better generalize under i.i.d. settings. In this work, we present a unifying framework with topics in causal inference to make a case for the use of DA beyond just the i.i.d. setting, but for generalization across interventions as well. Specifically, we argue that when the outcome generating mechanism is invariant to our choice of DA, then such augmentations can effectively be thought of as interventions on the treatment generating mechanism itself. This can potentially help to reduce bias in causal effect estimation arising from hidden confounders. In the presence of such unobserved confounding we typically make use of instrumental variables (IVs) -- sources of treatment randomization that are conditionally independent of the outcome. However, IVs may not be as readily available as DA for many applications, which is the main motivation behind this work. By appropriately regularizing IV based estimators, we introduce the concept of IV-like (IVL) regression for mitigating confounding bias and improving predictive performance across interventions even when certain IV properties are relaxed. Finally, we cast parameterized DA as an IVL regression problem and show that when used in composition can simulate a worst-case application of such DA, further improving performance on causal estimation and generalization tasks beyond what simple DA may offer. This is shown both theoretically for the population case and via simulation experiments for the finite sample case using a simple linear example. We also present real data experiments to support our case.",
    "authors": [
      "Uzair Akbar",
      "Niki Kilbertus",
      "Hao Shen",
      "Krikamol Muandet",
      "Bo Dai"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25128v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25128v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2510.25108v1",
    "title": "Shift is Good: Mismatched Data Mixing Improves Test Performance",
    "summary": "We consider training and testing on mixture distributions with different training and test proportions. We show that in many settings, and in some sense generically, distribution shift can be beneficial, and test performance can improve due to mismatched training proportions, even if the components are unrelated and with no transfer between components. In a variety of scenarios, we identify the optimal training proportions and the extent to which such distribution shift can be beneficial. We show how the same analysis applies also to a compositional setting with differing distribution of component \"skills'' at training and test.",
    "authors": [
      "Marko Medvedev",
      "Kaifeng Lyu",
      "Zhiyuan Li",
      "Nathan Srebro"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25108v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25108v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2510.25769v1",
    "title": "Neural Stochastic Flows: Solver-Free Modelling and Inference for SDE   Solutions",
    "summary": "Stochastic differential equations (SDEs) are well suited to modelling noisy and irregularly sampled time series found in finance, physics, and machine learning. Traditional approaches require costly numerical solvers to sample between arbitrary time points. We introduce Neural Stochastic Flows (NSFs) and their latent variants, which directly learn (latent) SDE transition laws using conditional normalising flows with architectural constraints that preserve properties inherited from stochastic flows. This enables one-shot sampling between arbitrary states and yields up to two orders of magnitude speed-ups at large time gaps. Experiments on synthetic SDE simulations and on real-world tracking and video data show that NSFs maintain distributional accuracy comparable to numerical approaches while dramatically reducing computation for arbitrary time-point sampling.",
    "authors": [
      "Naoki Kiyohara",
      "Edward Johns",
      "Yingzhen Li"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25769v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25769v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2510.25470v1",
    "title": "An In-Depth Analysis of Cyber Attacks in Secured Platforms",
    "summary": "There is an increase in global malware threats. To address this, an encryption-type ransomware has been introduced on the Android operating system. The challenges associated with malicious threats in phone use have become a pressing issue in mobile communication, disrupting user experiences and posing significant privacy threats. This study surveys commonly used machine learning techniques for detecting malicious threats in phones and examines their performance. The majority of past research focuses on customer feedback and reviews, with concerns that people might create false reviews to promote or devalue products and services for personal gain. Hence, the development of techniques for detecting malicious threats using machine learning has been a key focus. This paper presents a comprehensive comparative study of current research on the issue of malicious threats and methods for tackling these challenges. Nevertheless, a huge amount of information is required by these methods, presenting a challenge for developing robust, specialized automated anti-malware systems. This research describes the Android Applications dataset, and the accuracy of the techniques is measured using the accuracy levels of the metrics employed in this study.",
    "authors": [
      "Parick Ozoh",
      "John K Omoniyi",
      "Bukola Ibitoye"
    ],
    "categories": [
      "cs.CR",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25470v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25470v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2510.25364v1",
    "title": "CLASS-IT: Conversational and Lecture-Aligned Small-Scale Instruction   Tuning for BabyLMs",
    "summary": "This work investigates whether small-scale LMs can benefit from instruction tuning. We compare conversational and question-answering instruction tuning datasets, applied either in a merged or sequential curriculum, using decoder-only models with 100M and 140M parameters. Evaluation spans both fine-tuning (SuperGLUE) and zero-shot (BLiMP, EWoK, WUGs, entity tracking, and psycholinguistic correlation) settings. Results show that instruction tuning yields small but consistent gains in fine-tuning scenarios, with sequential curricula outperforming merged data; however, improvements do not consistently transfer to zero-shot tasks, suggesting a trade-off between interaction-focused adaptation and broad linguistic generalization. These results highlight both the potential and the constraints of adapting human-inspired learning strategies to low-resource LMs, and point toward hybrid, curriculum-based approaches for enhancing generalization under ecological training limits.",
    "authors": [
      "Luca Capone",
      "Alessandro Bondielli",
      "Alessandro Lenci"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25364v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25364v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2510.25354v1",
    "title": "Analysis of Semi-Supervised Learning on Hypergraphs",
    "summary": "Hypergraphs provide a natural framework for modeling higher-order interactions, yet their theoretical underpinnings in semi-supervised learning remain limited. We provide an asymptotic consistency analysis of variational learning on random geometric hypergraphs, precisely characterizing the conditions ensuring the well-posedness of hypergraph learning as well as showing convergence to a weighted $p$-Laplacian equation. Motivated by this, we propose Higher-Order Hypergraph Learning (HOHL), which regularizes via powers of Laplacians from skeleton graphs for multiscale smoothness. HOHL converges to a higher-order Sobolev seminorm. Empirically, it performs strongly on standard baselines.",
    "authors": [
      "Adrien Weihs",
      "Andrea Bertozzi",
      "Matthew Thorpe"
    ],
    "categories": [
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25354v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25354v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2510.25238v1",
    "title": "VADB: A Large-Scale Video Aesthetic Database with Professional and   Multi-Dimensional Annotations",
    "summary": "Video aesthetic assessment, a vital area in multimedia computing, integrates computer vision with human cognition. Its progress is limited by the lack of standardized datasets and robust models, as the temporal dynamics of video and multimodal fusion challenges hinder direct application of image-based methods. This study introduces VADB, the largest video aesthetic database with 10,490 diverse videos annotated by 37 professionals across multiple aesthetic dimensions, including overall and attribute-specific aesthetic scores, rich language comments and objective tags. We propose VADB-Net, a dual-modal pre-training framework with a two-stage training strategy, which outperforms existing video quality assessment models in scoring tasks and supports downstream video aesthetic assessment tasks. The dataset and source code are available at https://github.com/BestiVictory/VADB.",
    "authors": [
      "Qianqian Qiao",
      "DanDan Zheng",
      "Yihang Bo",
      "Bao Peng",
      "Heng Huang",
      "Longteng Jiang",
      "Huaye Wang",
      "Jingdong Chen",
      "Jun Zhou",
      "Xin Jin"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25238v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25238v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2510.25219v1",
    "title": "A Benchmark Suite for Multi-Objective Optimization in Battery Thermal   Management System Design",
    "summary": "Synthetic Benchmark Problems (SBPs) are commonly used to evaluate the performance of metaheuristic algorithms. However, these SBPs often contain various unrealistic properties, potentially leading to underestimation or overestimation of algorithmic performance. While several benchmark suites comprising real-world problems have been proposed for various types of metaheuristics, a notable gap exists for Constrained Multi-objective Optimization Problems (CMOPs) derived from practical engineering applications, particularly in the domain of Battery Thermal Management System (BTMS) design. To address this gap, this study develops and presents a specialized benchmark suite for multi-objective optimization in BTMS. This suite comprises a diverse collection of real-world constrained problems, each defined via accurate surrogate models based on recent research to efficiently represent complex thermal-fluid interactions. The primary goal of this benchmark suite is to provide a practical and relevant testing ground for evolutionary algorithms and optimization methods focused on energy storage thermal management. Future work will involve establishing comprehensive baseline results using state-of-the-art algorithms, conducting comparative analyses, and developing a standardized ranking scheme to facilitate robust performance assessment.",
    "authors": [
      "Kaichen Ouyang",
      "Yezhi Xia"
    ],
    "categories": [
      "cs.NE"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25219v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25219v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2510.25121v1",
    "title": "A Unified Bilevel Model for Adversarial Learning and A Case Study",
    "summary": "Adversarial learning has been attracting more and more attention thanks to the fast development of machine learning and artificial intelligence. However, due to the complicated structure of most machine learning models, the mechanism of adversarial attacks is not well interpreted. How to measure the effect of attack is still not quite clear. In this paper, we propose a unified bilevel model for adversarial learning. We further investigate the adversarial attack in clustering models and interpret it from data perturbation point of view. We reveal that when the data perturbation is relatively small, the clustering model is robust, whereas if it is relatively large, the clustering result changes, which leads to an attack. To measure the effect of attacks for clustering models, we analyse the well-definedness of the so-called $\\delta$-measure, which can be used in the proposed bilevel model for adversarial learning of clustering models.",
    "authors": [
      "Yutong Zheng",
      "Qingna Li"
    ],
    "categories": [
      "cs.LG",
      "math.OC"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25121v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25121v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2510.25724v1",
    "title": "BambooKG: A Neurobiologically-inspired Frequency-Weight Knowledge Graph",
    "summary": "Retrieval-Augmented Generation allows LLMs to access external knowledge, reducing hallucinations and ageing-data issues. However, it treats retrieved chunks independently and struggles with multi-hop or relational reasoning, especially across documents. Knowledge graphs enhance this by capturing the relationships between entities using triplets, enabling structured, multi-chunk reasoning. However, these tend to miss information that fails to conform to the triplet structure. We introduce BambooKG, a knowledge graph with frequency-based weights on non-triplet edges which reflect link strength, drawing on the Hebbian principle of \"fire together, wire together\". This decreases information loss and results in improved performance on single- and multi-hop reasoning, outperforming the existing solutions.",
    "authors": [
      "Vanya Arikutharam",
      "Arkadiy Ukolov"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25724v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25724v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2510.25356v1",
    "title": "Not ready for the bench: LLM legal interpretation is unstable and out of   step with human judgments",
    "summary": "Legal interpretation frequently involves assessing how a legal text, as understood by an 'ordinary' speaker of the language, applies to the set of facts characterizing a legal dispute in the U.S. judicial system. Recent scholarship has proposed that legal practitioners add large language models (LLMs) to their interpretive toolkit. This work offers an empirical argument against LLM interpretation as recently practiced by legal scholars and federal judges. Our investigation in English shows that models do not provide stable interpretive judgments: varying the question format can lead the model to wildly different conclusions. Moreover, the models show weak to moderate correlation with human judgment, with large variance across model and question variant, suggesting that it is dangerous to give much credence to the conclusions produced by generative AI.",
    "authors": [
      "Abhishek Purushothama",
      "Junghyun Min",
      "Brandon Waldon",
      "Nathan Schneider"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25356v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25356v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2510.25345v1",
    "title": "Informative Sample Selection Model for Skeleton-based Action Recognition   with Limited Training Samples",
    "summary": "Skeleton-based human action recognition aims to classify human skeletal sequences, which are spatiotemporal representations of actions, into predefined categories. To reduce the reliance on costly annotations of skeletal sequences while maintaining competitive recognition accuracy, the task of 3D Action Recognition with Limited Training Samples, also known as semi-supervised 3D Action Recognition, has been proposed. In addition, active learning, which aims to proactively select the most informative unlabeled samples for annotation, has been explored in semi-supervised 3D Action Recognition for training sample selection. Specifically, researchers adopt an encoder-decoder framework to embed skeleton sequences into a latent space, where clustering information, combined with a margin-based selection strategy using a multi-head mechanism, is utilized to identify the most informative sequences in the unlabeled set for annotation. However, the most representative skeleton sequences may not necessarily be the most informative for the action recognizer, as the model may have already acquired similar knowledge from previously seen skeleton samples. To solve it, we reformulate Semi-supervised 3D action recognition via active learning from a novel perspective by casting it as a Markov Decision Process (MDP). Built upon the MDP framework and its training paradigm, we train an informative sample selection model to intelligently guide the selection of skeleton sequences for annotation. To enhance the representational capacity of the factors in the state-action pairs within our method, we project them from Euclidean space to hyperbolic space. Furthermore, we introduce a meta tuning strategy to accelerate the deployment of our method in real-world scenarios. Extensive experiments on three 3D action recognition benchmarks demonstrate the effectiveness of our method.",
    "authors": [
      "Zhigang Tu",
      "Zhengbo Zhang",
      "Jia Gong",
      "Junsong Yuan",
      "Bo Du"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25345v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25345v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2510.25218v1",
    "title": "Human Resilience in the AI Era -- What Machines Can't Replace",
    "summary": "AI is displacing tasks, mediating high-stakes decisions, and flooding communication with synthetic content, unsettling work, identity, and social trust. We argue that the decisive human countermeasure is resilience. We define resilience across three layers: psychological, including emotion regulation, meaning-making, cognitive flexibility; social, including trust, social capital, coordinated response; organizational, including psychological safety, feedback mechanisms, and graceful degradation. We synthesize early evidence that these capacities buffer individual strain, reduce burnout through social support, and lower silent failure in AI-mediated workflows through team norms and risk-responsive governance. We also show that resilience can be cultivated through training that complements rather than substitutes for structural safeguards. By reframing the AI debate around actionable human resilience, this article offers policymakers, educators, and operators a practical lens to preserve human agency and steer responsible adoption.",
    "authors": [
      "Shaoshan Liu",
      "Anina Schwarzenbach",
      "Yiyu Shi"
    ],
    "categories": [
      "cs.CY",
      "cs.AI"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25218v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25218v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2510.25471v1",
    "title": "Instrumental goals in advanced AI systems: Features to be managed and   not failures to be eliminated?",
    "summary": "In artificial intelligence (AI) alignment research, instrumental goals, also called instrumental subgoals or instrumental convergent goals, are widely associated with advanced AI systems. These goals, which include tendencies such as power-seeking and self-preservation, become problematic when they conflict with human aims. Conventional alignment theory treats instrumental goals as sources of risk that become problematic through failure modes such as reward hacking or goal misgeneralization, and attempts to limit the symptoms of instrumental goals, notably resource acquisition and self-preservation. This article proposes an alternative framing: that a philosophical argument can be constructed according to which instrumental goals may be understood as features to be accepted and managed rather than failures to be limited. Drawing on Aristotle's ontology and its modern interpretations, an ontology of concrete, goal-directed entities, it argues that advanced AI systems can be seen as artifacts whose formal and material constitution gives rise to effects distinct from their designers' intentions. In this view, the instrumental tendencies of such systems correspond to per se outcomes of their constitution rather than accidental malfunctions. The implication is that efforts should focus less on eliminating instrumental goals and more on understanding, managing, and directing them toward human-aligned ends.",
    "authors": [
      "Willem Fourie"
    ],
    "categories": [
      "cs.AI",
      "cs.CY"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25471v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25471v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2510.25387v1",
    "title": "Instance-Level Composed Image Retrieval",
    "summary": "The progress of composed image retrieval (CIR), a popular research direction in image retrieval, where a combined visual and textual query is used, is held back by the absence of high-quality training and evaluation data. We introduce a new evaluation dataset, i-CIR, which, unlike existing datasets, focuses on an instance-level class definition. The goal is to retrieve images that contain the same particular object as the visual query, presented under a variety of modifications defined by textual queries. Its design and curation process keep the dataset compact to facilitate future research, while maintaining its challenge-comparable to retrieval among more than 40M random distractors-through a semi-automated selection of hard negatives.   To overcome the challenge of obtaining clean, diverse, and suitable training data, we leverage pre-trained vision-and-language models (VLMs) in a training-free approach called BASIC. The method separately estimates query-image-to-image and query-text-to-image similarities, performing late fusion to upweight images that satisfy both queries, while down-weighting those that exhibit high similarity with only one of the two. Each individual similarity is further improved by a set of components that are simple and intuitive. BASIC sets a new state of the art on i-CIR but also on existing CIR datasets that follow a semantic-level class definition. Project page: https://vrg.fel.cvut.cz/icir/.",
    "authors": [
      "Bill Psomas",
      "George Retsinas",
      "Nikos Efthymiadis",
      "Panagiotis Filntisis",
      "Yannis Avrithis",
      "Petros Maragos",
      "Ondrej Chum",
      "Giorgos Tolias"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25387v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25387v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2510.25154v1",
    "title": "TabMGP: Martingale Posterior with TabPFN",
    "summary": "Bayesian inference provides principled uncertainty quantification but is often limited by challenges of prior elicitation, likelihood misspecification, and computational burden. The martingale posterior (MGP, Fong et al., 2023) offers an alternative, replacing prior-likelihood elicitation with a predictive rule - namely, a sequence of one-step-ahead predictive distributions - for forward data generation. The utility of MGPs depends on the choice of predictive rule, yet the literature has offered few compelling examples. Foundation transformers are well-suited here, as their autoregressive generation mirrors this forward simulation and their general-purpose design enables rich predictive modeling. We introduce TabMGP, an MGP built on TabPFN, a transformer foundation model that is currently state-of-the-art for tabular data. TabMGP produces credible sets with near-nominal coverage and often outperforms both existing MGP constructions and standard Bayes.",
    "authors": [
      "Kenyon Ng",
      "Edwin Fong",
      "David T. Frazier",
      "Jeremias Knoblauch",
      "Susan Wei"
    ],
    "categories": [
      "stat.ME",
      "stat.CO",
      "stat.ML",
      "62F15"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25154v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25154v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2510.25318v1",
    "title": "Prototype-Driven Adaptation for Few-Shot Object Detection",
    "summary": "Few-shot object detection (FSOD) often suffers from base-class bias and unstable calibration when only a few novel samples are available. We propose Prototype-Driven Alignment (PDA), a lightweight, plug-in metric head for DeFRCN that provides a prototype-based \"second opinion\" complementary to the linear classifier. PDA maintains support-only prototypes in a learnable identity-initialized projection space and optionally applies prototype-conditioned RoI alignment to reduce geometric mismatch. During fine-tuning, prototypes can be adapted via exponential moving average(EMA) updates on labeled foreground RoIs-without introducing class-specific parameters-and are frozen at inference to ensure strict protocol compliance. PDA employs a best-of-K matching scheme to capture intra-class multi-modality and temperature-scaled fusion to combine metric similarities with detector logits. Experiments on VOC FSOD and GFSOD benchmarks show that PDA consistently improves novel-class performance with minimal impact on base classes and negligible computational overhead.",
    "authors": [
      "Yushen Huang",
      "Zhiming Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25318v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25318v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2510.25239v1",
    "title": "Mapping and Classification of Trees Outside Forests using Deep Learning",
    "summary": "Trees Outside Forests (TOF) play an important role in agricultural landscapes by supporting biodiversity, sequestering carbon, and regulating microclimates. Yet, most studies have treated TOF as a single class or relied on rigid rule-based thresholds, limiting ecological interpretation and adaptability across regions. To address this, we evaluate deep learning for TOF classification using a newly generated dataset and high-resolution aerial imagery from four agricultural landscapes in Germany. Specifically, we compare convolutional neural networks (CNNs), vision transformers, and hybrid CNN-transformer models across six semantic segmentation architectures (ABCNet, LSKNet, FT-UNetFormer, DC-Swin, BANet, and U-Net) to map four categories of woody vegetation: Forest, Patch, Linear, and Tree, derived from previous studies and governmental products. Overall, the models achieved good classification accuracy across the four landscapes, with the FT-UNetFormer performing best (mean Intersection-over-Union 0.74; mean F1 score 0.84), underscoring the importance of spatial context understanding in TOF mapping and classification. Our results show good results for Forest and Linear class and reveal challenges particularly in classifying complex structures with high edge density, notably the Patch and Tree class. Our generalization experiments highlight the need for regionally diverse training data to ensure reliable large-scale mapping. The dataset and code are openly available at https://github.com/Moerizzy/TOFMapper",
    "authors": [
      "Moritz Lucas",
      "Hamid Ebrahimy",
      "Viacheslav Barkov",
      "Ralf Pecenka",
      "Kai-Uwe Kühnberger",
      "Björn Waske"
    ],
    "categories": [
      "cs.CV",
      "I.4.6"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25239v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25239v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2510.25400v1",
    "title": "Estimation of discrete distributions with high probability under   $χ^2$-divergence",
    "summary": "We investigate the high-probability estimation of discrete distributions from an \\iid sample under $\\chi^2$-divergence loss. Although the minimax risk in expectation is well understood, its high-probability counterpart remains largely unexplored. We provide sharp upper and lower bounds for the classical Laplace estimator, showing that it achieves optimal performance among estimators that do not rely on the confidence level. We further characterize the minimax high-probability risk for any estimator and demonstrate that it can be attained through a simple smoothing strategy. Our analysis highlights an intrinsic separation between asymptotic and non-asymptotic guarantees, with the latter suffering from an unavoidable overhead. This work sharpens existing guarantees and advances the theoretical understanding of divergence-based estimation.",
    "authors": [
      "Sirine Louati"
    ],
    "categories": [
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25400v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25400v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.47
  },
  {
    "arxiv_id": "2510.25174v1",
    "title": "Classifier Enhancement Using Extended Context and Domain Experts for   Semantic Segmentation",
    "summary": "Prevalent semantic segmentation methods generally adopt a vanilla classifier to categorize each pixel into specific classes.   Although such a classifier learns global information from the training data, this information is represented by a set of fixed parameters (weights and biases).   However, each image has a different class distribution, which prevents the classifier from addressing the unique characteristics of individual images.   At the dataset level, class imbalance leads to segmentation results being biased towards majority classes, limiting the model's effectiveness in identifying and segmenting minority class regions.   In this paper, we propose an Extended Context-Aware Classifier (ECAC) that dynamically adjusts the classifier using global (dataset-level) and local (image-level) contextual information.   Specifically, we leverage a memory bank to learn dataset-level contextual information of each class, incorporating the class-specific contextual information from the current image to improve the classifier for precise pixel labeling.   Additionally, a teacher-student network paradigm is adopted, where the domain expert (teacher network) dynamically adjusts contextual information with ground truth and transfers knowledge to the student network.   Comprehensive experiments illustrate that the proposed ECAC can achieve state-of-the-art performance across several datasets, including ADE20K, COCO-Stuff10K, and Pascal-Context.",
    "authors": [
      "Huadong Tang",
      "Youpeng Zhao",
      "Min Xu",
      "Jun Wang",
      "Qiang Wu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25174v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25174v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.47
  },
  {
    "arxiv_id": "2510.25141v1",
    "title": "Revisiting Reconstruction-based AI-generated Image Detection: A   Geometric Perspective",
    "summary": "The rise of generative Artificial Intelligence (AI) has made detecting AI-generated images a critical challenge for ensuring authenticity. Existing reconstruction-based methods lack theoretical foundations and on empirical heuristics, limiting interpretability and reliability. In this paper, we introduce the Jacobian-Spectral Lower Bound for reconstruction error from a geometric perspective, showing that real images off the reconstruction manifold exhibit a non-trivial error lower bound, while generated images on the manifold have near-zero error. Furthermore, we reveal the limitations of existing methods that rely on static reconstruction error from a single pass. These methods often fail when some real images exhibit lower error than generated ones. This counterintuitive behavior reduces detection accuracy and requires data-specific threshold tuning, limiting their applicability in real-world scenarios. To address these challenges, we propose ReGap, a training-free method that computes dynamic reconstruction error by leveraging structured editing operations to introduce controlled perturbations. This enables measuring error changes before and after editing, improving detection accuracy by enhancing error separation. Experimental results show that our method outperforms existing baselines, exhibits robustness to common post-processing operations and generalizes effectively across diverse conditions.",
    "authors": [
      "Wan Jiang",
      "Jing Yan",
      "Ruixuan Zhang",
      "Xiaojing Chen",
      "Changtao Miao",
      "Zhe Li",
      "Chenhao Lin",
      "Yunfeng Diao",
      "Richang Hong"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25141v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25141v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.47
  },
  {
    "arxiv_id": "2510.25507v1",
    "title": "Distributional Evaluation of Generative Models via Relative Density   Ratio",
    "summary": "We propose a functional evaluation metric for generative models based on the relative density ratio (RDR) designed to characterize distributional differences between real and generated samples. We show that the RDR as a functional summary of the goodness-of-fit for the generative model, possesses several desirable theoretical properties. It preserves $\\phi$-divergence between two distributions, enables sample-level evaluation that facilitates downstream investigations of feature-specific distributional differences, and has a bounded range that affords clear interpretability and numerical stability. Functional estimation of the RDR is achieved efficiently through convex optimization on the variational form of $\\phi$-divergence. We provide theoretical convergence rate guarantees for general estimators based on M-estimator theory, as well as the convergence rates of neural network-based estimators when the true ratio is in the anisotropic Besov space. We demonstrate the power of the proposed RDR-based evaluation through numerical experiments on MNIST, CelebA64, and the American Gut project microbiome data. We show that the estimated RDR not only allows for an effective comparison of the overall performance of competing generative models, but it can also offer a convenient means of revealing the nature of the underlying goodness-of-fit. This enables one to assess support overlap, coverage, and fidelity while pinpointing regions of the sample space where generators concentrate and revealing the features that drive the most salient distributional differences.",
    "authors": [
      "Yuliang Xu",
      "Yun Wei",
      "Li Ma"
    ],
    "categories": [
      "stat.ME",
      "stat.ML"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25507v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25507v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.46
  },
  {
    "arxiv_id": "2510.25184v1",
    "title": "Mask-Robust Face Verification for Online Learning via YOLOv5 and   Residual Networks",
    "summary": "In the contemporary landscape, the fusion of information technology and the rapid advancement of artificial intelligence have ushered school education into a transformative phase characterized by digitization and heightened intelligence. Concurrently, the global paradigm shift caused by the Covid-19 pandemic has catalyzed the evolution of e-learning, accentuating its significance. Amidst these developments, one pivotal facet of the online education paradigm that warrants attention is the authentication of identities within the digital learning sphere. Within this context, our study delves into a solution for online learning authentication, utilizing an enhanced convolutional neural network architecture, specifically the residual network model. By harnessing the power of deep learning, this technological approach aims to galvanize the ongoing progress of online education, while concurrently bolstering its security and stability. Such fortification is imperative in enabling online education to seamlessly align with the swift evolution of the educational landscape. This paper's focal proposition involves the deployment of the YOLOv5 network, meticulously trained on our proprietary dataset. This network is tasked with identifying individuals' faces culled from images captured by students' open online cameras. The resultant facial information is then channeled into the residual network to extract intricate features at a deeper level. Subsequently, a comparative analysis of Euclidean distances against students' face databases is performed, effectively ascertaining the identity of each student.",
    "authors": [
      "Zhifeng Wang",
      "Minghui Wang",
      "Chunyan Zeng",
      "Jialong Yao",
      "Yang Yang",
      "Hongmin Xu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25184v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25184v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.44
  },
  {
    "arxiv_id": "2510.25287v1",
    "title": "Stochastic Optimization in Semi-Discrete Optimal Transport: Convergence   Analysis and Minimax Rate",
    "summary": "We investigate the semi-discrete Optimal Transport (OT) problem, where a continuous source measure $\\mu$ is transported to a discrete target measure $\\nu$, with particular attention to the OT map approximation. In this setting, Stochastic Gradient Descent (SGD) based solvers have demonstrated strong empirical performance in recent machine learning applications, yet their theoretical guarantee to approximate the OT map is an open question. In this work, we answer it positively by providing both computational and statistical convergence guarantees of SGD. Specifically, we show that SGD methods can estimate the OT map with a minimax convergence rate of $\\mathcal{O}(1/\\sqrt{n})$, where $n$ is the number of samples drawn from $\\mu$. To establish this result, we study the averaged projected SGD algorithm, and identify a suitable projection set that contains a minimizer of the objective, even when the source measure is not compactly supported. Our analysis holds under mild assumptions on the source measure and applies to MTW cost functions,whic include $\\|\\cdot\\|^p$ for $p \\in (1, \\infty)$. We finally provide numerical evidence for our theoretical results.",
    "authors": [
      "Ferdinand Genans",
      "Antoine Godichon-Baggioni",
      "François-Xavier Vialard",
      "Olivier Wintenberger"
    ],
    "categories": [
      "math.ST",
      "stat.ML",
      "stat.TH"
    ],
    "published": "2025-10-29",
    "url": "https://arxiv.org/abs/2510.25287v1",
    "pdf_url": "https://arxiv.org/pdf/2510.25287v1.pdf",
    "date": "2025-10-30",
    "source": "arxiv",
    "research_score": 0.43
  }
]