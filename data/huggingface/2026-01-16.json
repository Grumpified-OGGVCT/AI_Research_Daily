[
  {
    "model_id": "gpjt/1xrtx3090m24-fineweb-edu-2x",
    "author": "unknown",
    "title": "gpjt/1xrtx3090m24-fineweb-edu-2x",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "gpjtgpt2",
      "text-generation",
      "gpjt-llm-from-scratch",
      "custom_code",
      "dataset:HuggingFaceFW/fineweb-edu",
      "license:apache-2.0",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-16T19:57:57.000Z",
    "last_modified": "2026-01-16T20:00:10.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/gpjt/1xrtx3090m24-fineweb-edu-2x",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.5
  },
  {
    "model_id": "koutch/paper_llama_llama3.1-8b_train_sft_train_para",
    "author": "unknown",
    "title": "koutch/paper_llama_llama3.1-8b_train_sft_train_para",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "text-generation-inference",
      "unsloth",
      "conversational",
      "en",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-16T20:10:49.000Z",
    "last_modified": "2026-01-16T20:18:12.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/koutch/paper_llama_llama3.1-8b_train_sft_train_para",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Birma/zarma_tts_full_16bit_v1",
    "author": "unknown",
    "title": "Birma/zarma_tts_full_16bit_v1",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "text-generation-inference",
      "unsloth",
      "conversational",
      "en",
      "base_model:unsloth/orpheus-3b-0.1-ft",
      "base_model:finetune:unsloth/orpheus-3b-0.1-ft",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-16T20:06:38.000Z",
    "last_modified": "2026-01-16T20:16:50.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Birma/zarma_tts_full_16bit_v1",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "koutch/paper_llama_llama3.1-8b_train_sft_train_no_think",
    "author": "unknown",
    "title": "koutch/paper_llama_llama3.1-8b_train_sft_train_no_think",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "text-generation-inference",
      "unsloth",
      "conversational",
      "en",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-16T20:15:23.000Z",
    "last_modified": "2026-01-16T20:15:28.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/koutch/paper_llama_llama3.1-8b_train_sft_train_no_think",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold7",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold7",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-16T20:13:43.000Z",
    "last_modified": "2026-01-16T20:15:24.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold7",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "WhoIsShe/DarkSapling-7B-v2.0-MNN",
    "author": "unknown",
    "title": "WhoIsShe/DarkSapling-7B-v2.0-MNN",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "mnn",
      "on-device",
      "android",
      "ios",
      "quantization",
      "int4",
      "text-generation",
      "llama2",
      "en",
      "base_model:WhoIsShe/DarkSapling-7B-v2.0-MNN",
      "base_model:finetune:WhoIsShe/DarkSapling-7B-v2.0-MNN",
      "license:other",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "mnn",
    "created_at": "2026-01-16T20:14:36.000Z",
    "last_modified": "2026-01-16T20:15:24.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/WhoIsShe/DarkSapling-7B-v2.0-MNN",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Shekswess/tiny-think-sft-math-stem-loss-dft-bf16-lr5e-5-e2-bs8",
    "author": "unknown",
    "title": "Shekswess/tiny-think-sft-math-stem-loss-dft-bf16-lr5e-5-e2-bs8",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama4_text",
      "text-generation",
      "generated_from_trainer",
      "trl",
      "sft",
      "conversational",
      "base_model:facebook/MobileLLM-R1-140M-base",
      "base_model:finetune:facebook/MobileLLM-R1-140M-base",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-16T18:17:55.000Z",
    "last_modified": "2026-01-16T20:13:10.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Shekswess/tiny-think-sft-math-stem-loss-dft-bf16-lr5e-5-e2-bs8",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "LLM-course/chess-player-v2bis",
    "author": "unknown",
    "title": "LLM-course/chess-player-v2bis",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "chess_transformer",
      "text-generation",
      "chess",
      "llm-course",
      "chess-challenge",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-16T20:12:34.000Z",
    "last_modified": "2026-01-16T20:12:37.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/LLM-course/chess-player-v2bis",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "AdoCleanCode/llasa_stage2_trained_multilingual_stage2",
    "author": "unknown",
    "title": "AdoCleanCode/llasa_stage2_trained_multilingual_stage2",
    "downloads": 17,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "conversational",
      "arxiv:1910.09700",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-16T00:01:51.000Z",
    "last_modified": "2026-01-16T20:11:44.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/AdoCleanCode/llasa_stage2_trained_multilingual_stage2",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "katya228/xinyuan-llm-14b-0428-heretic-psychology-gguf-q4_0",
    "author": "unknown",
    "title": "katya228/xinyuan-llm-14b-0428-heretic-psychology-gguf-q4_0",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "heretic",
      "psychology",
      "text-generation",
      "license:apache-2.0",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "",
    "created_at": "2026-01-16T20:01:33.000Z",
    "last_modified": "2026-01-16T20:11:40.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/katya228/xinyuan-llm-14b-0428-heretic-psychology-gguf-q4_0",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "koutch/paper_smol_3.json_train_dpo_v1_train_no_think",
    "author": "unknown",
    "title": "koutch/paper_smol_3.json_train_dpo_v1_train_no_think",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "smollm3",
      "text-generation",
      "text-generation-inference",
      "unsloth",
      "conversational",
      "en",
      "base_model:unsloth/SmolLM3-3B",
      "base_model:finetune:unsloth/SmolLM3-3B",
      "license:apache-2.0",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-16T20:08:01.000Z",
    "last_modified": "2026-01-16T20:10:18.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/koutch/paper_smol_3.json_train_dpo_v1_train_no_think",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold6",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold6",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-16T20:07:44.000Z",
    "last_modified": "2026-01-16T20:09:28.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold6",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "LLM-course/chess-player-v2",
    "author": "unknown",
    "title": "LLM-course/chess-player-v2",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "chess_transformer",
      "text-generation",
      "chess",
      "llm-course",
      "chess-challenge",
      "license:mit",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-16T19:57:19.000Z",
    "last_modified": "2026-01-16T20:07:13.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/LLM-course/chess-player-v2",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "Ba2han/model-muontest-sft",
    "author": "unknown",
    "title": "Ba2han/model-muontest-sft",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "llama",
      "text-generation",
      "generated_from_trainer",
      "unsloth",
      "trl",
      "sft",
      "conversational",
      "base_model:Ba2han/model-short-muontest-wsd",
      "base_model:finetune:Ba2han/model-short-muontest-wsd",
      "text-generation-inference",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-generation",
    "library": "transformers",
    "created_at": "2026-01-16T19:20:51.000Z",
    "last_modified": "2026-01-16T20:04:52.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/Ba2han/model-muontest-sft",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  },
  {
    "model_id": "arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold5",
    "author": "unknown",
    "title": "arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold5",
    "downloads": 0,
    "likes": 0,
    "tags": [
      "transformers",
      "safetensors",
      "xlm-roberta",
      "text-classification",
      "arxiv:1910.09700",
      "endpoints_compatible",
      "region:us"
    ],
    "pipeline_tag": "text-classification",
    "library": "transformers",
    "created_at": "2026-01-16T20:00:26.000Z",
    "last_modified": "2026-01-16T20:01:56.000Z",
    "days_since_creation": 0,
    "url": "https://huggingface.co/arthurbittencourt/january-llm_paraphrase-xlm-roberta-twitter_topics_0_a-fold5",
    "date": "2026-01-16",
    "source": "huggingface_model",
    "type": "model",
    "research_score": 0.4
  }
]