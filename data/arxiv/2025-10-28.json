[
  {
    "arxiv_id": "2510.23429v1",
    "title": "MiCADangelo: Fine-Grained Reconstruction of Constrained CAD Models from   3D Scans",
    "summary": "Computer-Aided Design (CAD) plays a foundational role in modern manufacturing and product development, often requiring designers to modify or build upon existing models. Converting 3D scans into parametric CAD representations--a process known as CAD reverse engineering--remains a significant challenge due to the high precision and structural complexity of CAD models. Existing deep learning-based approaches typically fall into two categories: bottom-up, geometry-driven methods, which often fail to produce fully parametric outputs, and top-down strategies, which tend to overlook fine-grained geometric details. Moreover, current methods neglect an essential aspect of CAD modeling: sketch-level constraints. In this work, we introduce a novel approach to CAD reverse engineering inspired by how human designers manually perform the task. Our method leverages multi-plane cross-sections to extract 2D patterns and capture fine parametric details more effectively. It enables the reconstruction of detailed and editable CAD models, outperforming state-of-the-art methods and, for the first time, incorporating sketch constraints directly into the reconstruction process.",
    "authors": [
      "Ahmet Serdar Karadeniz",
      "Dimitrios Mallis",
      "Danila Rukhovich",
      "Kseniya Cherenkova",
      "Anis Kacem",
      "Djamila Aouada"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23429v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23429v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.82
  },
  {
    "arxiv_id": "2510.23438v1",
    "title": "Coresets for Clustering Under Stochastic Noise",
    "summary": "We study the problem of constructing coresets for $(k, z)$-clustering when the input dataset is corrupted by stochastic noise drawn from a known distribution. In this setting, evaluating the quality of a coreset is inherently challenging, as the true underlying dataset is unobserved. To address this, we investigate coreset construction using surrogate error metrics that are tractable and provably related to the true clustering cost. We analyze a traditional metric from prior work and introduce a new error metric that more closely aligns with the true cost. Although our metric is defined independently of the noise distribution, it enables approximation guarantees that scale with the noise level. We design a coreset construction algorithm based on this metric and show that, under mild assumptions on the data and noise, enforcing an $\\varepsilon$-bound under our metric yields smaller coresets and tighter guarantees on the true clustering cost than those obtained via classical metrics. In particular, we prove that the coreset size can improve by a factor of up to $\\mathrm{poly}(k)$, where $n$ is the dataset size. Experiments on real-world datasets support our theoretical findings and demonstrate the practical advantages of our approach.",
    "authors": [
      "Lingxiao Huang",
      "Zhize Li",
      "Nisheeth K. Vishnoi",
      "Runkai Yang",
      "Haoyu Zhao"
    ],
    "categories": [
      "cs.LG",
      "cs.CG",
      "cs.DS",
      "stat.ML"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23438v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23438v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.81
  },
  {
    "arxiv_id": "2510.23053v1",
    "title": "AirFed: Federated Graph-Enhanced Multi-Agent Reinforcement Learning for   Multi-UAV Cooperative Mobile Edge Computing",
    "summary": "Multiple Unmanned Aerial Vehicles (UAVs) cooperative Mobile Edge Computing (MEC) systems face critical challenges in coordinating trajectory planning, task offloading, and resource allocation while ensuring Quality of Service (QoS) under dynamic and uncertain environments. Existing approaches suffer from limited scalability, slow convergence, and inefficient knowledge sharing among UAVs, particularly when handling large-scale IoT device deployments with stringent deadline constraints. This paper proposes AirFed, a novel federated graph-enhanced multi-agent reinforcement learning framework that addresses these challenges through three key innovations. First, we design dual-layer dynamic Graph Attention Networks (GATs) that explicitly model spatial-temporal dependencies among UAVs and IoT devices, capturing both service relationships and collaborative interactions within the network topology. Second, we develop a dual-Actor single-Critic architecture that jointly optimizes continuous trajectory control and discrete task offloading decisions. Third, we propose a reputation-based decentralized federated learning mechanism with gradient-sensitive adaptive quantization, enabling efficient and robust knowledge sharing across heterogeneous UAVs. Extensive experiments demonstrate that AirFed achieves 42.9% reduction in weighted cost compared to state-of-the-art baselines, attains over 99% deadline satisfaction and 94.2% IoT device coverage rate, and reduces communication overhead by 54.5%. Scalability analysis confirms robust performance across varying UAV numbers, IoT device densities, and system scales, validating AirFed's practical applicability for large-scale UAV-MEC deployments.",
    "authors": [
      "Zhiyu Wang",
      "Suman Raj",
      "Rajkumar Buyya"
    ],
    "categories": [
      "cs.LG",
      "cs.DC"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23053v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23053v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.8
  },
  {
    "arxiv_id": "2510.23273v1",
    "title": "A Novel Framework for Multi-Modal Protein Representation Learning",
    "summary": "Accurate protein function prediction requires integrating heterogeneous intrinsic signals (e.g., sequence and structure) with noisy extrinsic contexts (e.g., protein-protein interactions and GO term annotations). However, two key challenges hinder effective fusion: (i) cross-modal distributional mismatch among embeddings produced by pre-trained intrinsic encoders, and (ii) noisy relational graphs of extrinsic data that degrade GNN-based information aggregation. We propose Diffused and Aligned Multi-modal Protein Embedding (DAMPE), a unified framework that addresses these through two core mechanisms. First, we propose Optimal Transport (OT)-based representation alignment that establishes correspondence between intrinsic embedding spaces of different modalities, effectively mitigating cross-modal heterogeneity. Second, we develop a Conditional Graph Generation (CGG)-based information fusion method, where a condition encoder fuses the aligned intrinsic embeddings to provide informative cues for graph reconstruction. Meanwhile, our theoretical analysis implies that the CGG objective drives this condition encoder to absorb graph-aware knowledge into its produced protein representations. Empirically, DAMPE outperforms or matches state-of-the-art methods such as DPFunc on standard GO benchmarks, achieving AUPR gains of 0.002-0.013 pp and Fmax gains 0.004-0.007 pp. Ablation studies further show that OT-based alignment contributes 0.043-0.064 pp AUPR, while CGG-based fusion adds 0.005-0.111 pp Fmax. Overall, DAMPE offers a scalable and theoretically grounded approach for robust multi-modal protein representation learning, substantially enhancing protein function prediction.",
    "authors": [
      "Runjie Zheng",
      "Zhen Wang",
      "Anjie Qiao",
      "Jiancong Xie",
      "Jiahua Rao",
      "Yuedong Yang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "q-bio.QM"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23273v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23273v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.79
  },
  {
    "arxiv_id": "2510.23272v1",
    "title": "Code Aesthetics with Agentic Reward Feedback",
    "summary": "Large Language Models (LLMs) have become valuable assistants for developers in code-related tasks. While LLMs excel at traditional programming tasks such as code generation and bug fixing, they struggle with visually-oriented coding tasks, often producing suboptimal aesthetics. In this paper, we introduce a new pipeline to enhance the aesthetic quality of LLM-generated code. We first construct AesCode-358K, a large-scale instruction-tuning dataset focused on code aesthetics. Next, we propose agentic reward feedback, a multi-agent system that evaluates executability, static aesthetics, and interactive aesthetics. Building on this, we develop GRPO-AR, which integrates these signals into the GRPO algorithm for joint optimization of functionality and code aesthetics. Finally, we develop OpenDesign, a benchmark for assessing code aesthetics. Experimental results show that combining supervised fine-tuning on AesCode-358K with reinforcement learning using agentic reward feedback significantly improves performance on OpenDesign and also enhances results on existing benchmarks such as PandasPlotBench. Notably, our AesCoder-4B surpasses GPT-4o and GPT-4.1, and achieves performance comparable to large open-source models with 480B-685B parameters, underscoring the effectiveness of our approach.",
    "authors": [
      "Bang Xiao",
      "Lingjie Jiang",
      "Shaohan Huang",
      "Tengchao Lv",
      "Yupan Huang",
      "Xun Wu",
      "Lei Cui",
      "Furu Wei"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23272v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23272v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.79
  },
  {
    "arxiv_id": "2510.23151v1",
    "title": "AG-Fusion: adaptive gated multimodal fusion for 3d object detection in   complex scenes",
    "summary": "Multimodal camera-LiDAR fusion technology has found extensive application in 3D object detection, demonstrating encouraging performance. However, existing methods exhibit significant performance degradation in challenging scenarios characterized by sensor degradation or environmental disturbances. We propose a novel Adaptive Gated Fusion (AG-Fusion) approach that selectively integrates cross-modal knowledge by identifying reliable patterns for robust detection in complex scenes. Specifically, we first project features from each modality into a unified BEV space and enhance them using a window-based attention mechanism. Subsequently, an adaptive gated fusion module based on cross-modal attention is designed to integrate these features into reliable BEV representations robust to challenging environments. Furthermore, we construct a new dataset named Excavator3D (E3D) focusing on challenging excavator operation scenarios to benchmark performance in complex conditions. Our method not only achieves competitive performance on the standard KITTI dataset with 93.92% accuracy, but also significantly outperforms the baseline by 24.88% on the challenging E3D dataset, demonstrating superior robustness to unreliable modal information in complex industrial scenes.",
    "authors": [
      "Sixian Liu",
      "Chen Xu",
      "Qiang Wang",
      "Donghai Shi",
      "Yiwen Li"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23151v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23151v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.79
  },
  {
    "arxiv_id": "2510.23494v1",
    "title": "Yesnt: Are Diffusion Relighting Models Ready for Capture Stage   Compositing? A Hybrid Alternative to Bridge the Gap",
    "summary": "Volumetric video relighting is essential for bringing captured performances into virtual worlds, but current approaches struggle to deliver temporally stable, production-ready results. Diffusion-based intrinsic decomposition methods show promise for single frames, yet suffer from stochastic noise and instability when extended to sequences, while video diffusion models remain constrained by memory and scale. We propose a hybrid relighting framework that combines diffusion-derived material priors with temporal regularization and physically motivated rendering. Our method aggregates multiple stochastic estimates of per-frame material properties into temporally consistent shading components, using optical-flow-guided regularization. For indirect effects such as shadows and reflections, we extract a mesh proxy from Gaussian Opacity Fields and render it within a standard graphics pipeline. Experiments on real and synthetic captures show that this hybrid strategy achieves substantially more stable relighting across sequences than diffusion-only baselines, while scaling beyond the clip lengths feasible for video diffusion. These results indicate that hybrid approaches, which balance learned priors with physically grounded constraints, are a practical step toward production-ready volumetric video relighting.",
    "authors": [
      "Elisabeth Jüttner",
      "Leona Krath",
      "Stefan Korfhage",
      "Hannah Dröge",
      "Matthias B. Hullin",
      "Markus Plack"
    ],
    "categories": [
      "cs.CV",
      "cs.GR"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23494v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23494v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2510.23482v1",
    "title": "On the Faithfulness of Visual Thinking: Measurement and Enhancement",
    "summary": "Recent large vision-language models (LVLMs) can generate vision-text multimodal chain-of-thought (MCoT) traces after reinforcement fine-tuning (RFT). However, we observe that the visual information incorporated in MCoT is often inaccurate, though still yield correct answers, indicating a lack of faithfulness in the MCoT reasoning process. We attribute this unfaithfulness to the RL reward in RFT, which solely incentivizes the format of interleaved vision-text cues, ie, it encourages the model to incorporate visual information into its text reasoning steps without considering the correctness of the visual information. In this paper, we first probe the faithfulness of MCoT by measuring how much the prediction changes when its visual and textual thoughts are intervened. Surprisingly, the model's predictions remain nearly unchanged under visual intervention but change significantly under textual intervention, indicating that the visual evidence is largely ignored. To further analyze visual information, we introduce an automated LVLM-based evaluation metric that quantifies the faithfulness of visual cues from two perspectives: reliability and sufficiency. Our evaluation reveals that the visual information in current MCoT traces is simultaneously unreliable and insufficient. To address this issue, we propose a novel MCoT learning strategy termed Sufficient-Component Cause Model (SCCM) learning. This approach encourages the MCoT to generate sufficient yet minimal visual components that are independently capable of leading to correct answers. We note that the proposed SCCM is annotation-free and compatible with various RFT for MCoT in a plug-and-play manner. Empirical results demonstrate that SCCM consistently improves the visual faithfulness across a suite of fine-grained perception and reasoning benchmarks. Code is available at https://github.com/EugeneLiu01/Faithful_Thinking_with_Image.",
    "authors": [
      "Zujing Liu",
      "Junwen Pan",
      "Qi She",
      "Yuan Gao",
      "Guisong Xia"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23482v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23482v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2510.23181v1",
    "title": "Physics-informed diffusion models for extrapolating crystal structures   beyond known motifs",
    "summary": "Discovering materials with previously unreported crystal frameworks is key to achieving transformative functionality. Generative artificial intelligence offers a scalable means to propose candidate crystal structures, however existing approaches mainly reproduce decorated variants of established motifs rather than uncover new configurations. Here we develop a physics-informed diffusion method, supported by chemically grounded validation protocol, which embeds descriptors of compactness and local environment diversity to balance physical plausibility with structural novelty. Conditioning on these metrics improves generative performance across architectures, increasing the fraction of structures outside 100 most common prototypes up to 67%. When crystal structure prediction (CSP) is seeded with generative structures, most candidates (97%) are reconstructed by CSP, yielding 145 (66%) low-energy frameworks not matching any known prototypes. These results show that while generative models are not substitutes for CSP, their chemically informed, diversity-guided outputs can enhance CSP efficiency, establishing a practical generative-CSP synergy for discovery-oriented exploration of chemical space.",
    "authors": [
      "Andrij Vasylenko",
      "Federico Ottomano",
      "Christopher M. Collins",
      "Rahul Savani",
      "Matthew S. Dyer",
      "Matthew J. Rosseinsky"
    ],
    "categories": [
      "cond-mat.mtrl-sci",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23181v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23181v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2510.23150v1",
    "title": "Revisiting the Structure of Trend Premia: When Diversification Hides   Redundancy",
    "summary": "Recent work has emphasized the diversification benefits of combining trend signals across multiple horizons, with the medium-term window-typically six months to one year-long viewed as the \"sweet spot\" of trend-following. This paper revisits this conventional view by reallocating exposure dynamically across horizons using a Bayesian optimization framework designed to learn the optimal weights assigned to each trend horizon at the asset level. The common practice of equal weighting implicitly assumes that all assets benefit equally from all horizons; we show that this assumption is both theoretically and empirically suboptimal. We first optimize the horizon-level weights at the asset level to maximize the informativeness of trend signals before applying Bayesian graphical models-with sparsity and turnover control-to allocate dynamically across assets. The key finding is that the medium-term band contributes little incremental performance or diversification once short- and long-term components are included. Removing the 125-day layer improves Sharpe ratios and drawdown efficiency while maintaining benchmark correlation. We then rationalize this outcome through a minimum-variance formulation, showing that the medium-term horizon largely overlaps with its neighboring horizons. The resulting \"barbell\" structure-combining short- and long-term trends-captures most of the performance while reducing model complexity. This result challenges the common belief that more horizons always improve diversification and suggests that some forms of time-scale diversification may conceal unnecessary redundancy in trend premia.",
    "authors": [
      "Alban Etiennea",
      "Jean-Jacques Ohana",
      "Eric Benhamou",
      "Béatrice Guez",
      "Ethan Setrouk",
      "Thomas Jacquot"
    ],
    "categories": [
      "q-fin.PR",
      "q-fin.PM",
      "q-fin.RM",
      "q-fin.TR",
      "stat.ML"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23150v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23150v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2510.23141v1",
    "title": "Treble10: A high-quality dataset for far-field speech recognition,   dereverberation, and enhancement",
    "summary": "Accurate far-field speech datasets are critical for tasks such as automatic speech recognition (ASR), dereverberation, speech enhancement, and source separation. However, current datasets are limited by the trade-off between acoustic realism and scalability. Measured corpora provide faithful physics but are expensive, low-coverage, and rarely include paired clean and reverberant data. In contrast, most simulation-based datasets rely on simplified geometrical acoustics, thus failing to reproduce key physical phenomena like diffraction, scattering, and interference that govern sound propagation in complex environments. We introduce Treble10, a large-scale, physically accurate room-acoustic dataset. Treble10 contains over 3000 broadband room impulse responses (RIRs) simulated in 10 fully furnished real-world rooms, using a hybrid simulation paradigm implemented in the Treble SDK that combines a wave-based and geometrical acoustics solver. The dataset provides six complementary subsets, spanning mono, 8th-order Ambisonics, and 6-channel device RIRs, as well as pre-convolved reverberant speech scenes paired with LibriSpeech utterances. All signals are simulated at 32 kHz, accurately modelling low-frequency wave effects and high-frequency reflections. Treble10 bridges the realism gap between measurement and simulation, enabling reproducible, physically grounded evaluation and large-scale data augmentation for far-field speech tasks. The dataset is openly available via the Hugging Face Hub, and is intended as both a benchmark and a template for next-generation simulation-driven audio research.",
    "authors": [
      "Sarabeth S. Mullins",
      "Georg Götz",
      "Eric Bezzam",
      "Steven Zheng",
      "Daniel Gert Nielsen"
    ],
    "categories": [
      "eess.AS",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23141v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23141v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.76
  },
  {
    "arxiv_id": "2510.23325v1",
    "title": "Multitask Multimodal Self-Supervised Learning for Medical Images",
    "summary": "This thesis works to address a pivotal challenge in medical image analysis: the reliance on extensive labeled datasets, which are often limited due to the need for expert annotation and constrained by privacy and legal issues. By focusing on the development of self-supervised learning techniques and domain adaptation methods, this research aims to circumvent these limitations, presenting a novel approach to enhance the utility and efficacy of deep learning in medical imaging.   Central to this thesis is the development of the Medformer, an innovative neural network architecture designed for multitask learning and deep domain adaptation. This model is adept at pre-training on diverse medical image datasets, handling varying sizes and modalities, and is equipped with a dynamic input-output adaptation mechanism. This enables efficient processing and integration of a wide range of medical image types, from 2D X-rays to complex 3D MRIs, thus mitigating the dependency on large labeled datasets.   Further, the thesis explores the current state of self-supervised learning in medical imaging. It introduces novel pretext tasks that are capable of extracting meaningful information from unlabeled data, significantly advancing the model's interpretative abilities. This approach is validated through rigorous experimentation, including the use of the MedMNIST dataset, demonstrating the model's proficiency in learning generalized features applicable to various downstream tasks.   In summary, this thesis contributes to the advancement of medical image analysis by offering a scalable, adaptable framework that reduces reliance on labeled data. It paves the way for more accurate, efficient diagnostic tools in healthcare, signifying a major step forward in the application of deep learning in medical imaging.",
    "authors": [
      "Cristian Simionescu"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23325v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23325v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.75
  },
  {
    "arxiv_id": "2510.23596v1",
    "title": "Think Twice: Branch-and-Rethink Reasoning Reward Model",
    "summary": "Large language models (LLMs) increasingly rely on thinking models that externalize intermediate steps and allocate extra test-time compute, with think-twice strategies showing that a deliberate second pass can elicit stronger reasoning. In contrast, most reward models (RMs) still compress many quality dimensions into a single scalar in one shot, a design that induces judgment diffusion: attention spreads across evaluation criteria, yielding diluted focus and shallow analysis. We introduce branch-and-rethink (BR-RM), a two-turn RM that transfers the think-twice principle to reward modeling. Turn 1 performs adaptive branching, selecting a small set of instance-critical dimensions (such as factuality and safety) and sketching concise, evidence-seeking hypotheses. Turn 2 executes branch-conditioned rethinking, a targeted reread that tests those hypotheses and scrutinizes only what matters most. We train with GRPO-style reinforcement learning over structured two-turn traces using a simple binary outcome reward with strict format checks, making the approach compatible with standard RLHF pipelines. By converting all-at-oncescoringintofocused, second-lookreasoning, BR-RMreducesjudgmentdiffusionandimproves sensitivity to subtle yet consequential errors while remaining practical and scalable. Experimental results demonstrate that our model achieves state-of-the-art performance on three challenging reward modeling benchmarks across diverse domains. The code and the model will be released soon.",
    "authors": [
      "Yizhu Jiao",
      "Jiaqi Zeng",
      "Julien Veron Vialard",
      "Oleksii Kuchaiev",
      "Jiawei Han",
      "Olivier Delalleau"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23596v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23596v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2510.23503v1",
    "title": "Bayes-Split-Edge: Bayesian Optimization for Constrained Collaborative   Inference in Wireless Edge Systems",
    "summary": "Mobile edge devices (e.g., AR/VR headsets) typically need to complete timely inference tasks while operating with limited on-board computing and energy resources. In this paper, we investigate the problem of collaborative inference in wireless edge networks, where energy-constrained edge devices aim to complete inference tasks within given deadlines. These tasks are carried out using neural networks, and the edge device seeks to optimize inference performance under energy and delay constraints. The inference process can be split between the edge device and an edge server, thereby achieving collaborative inference over wireless networks. We formulate an inference utility optimization problem subject to energy and delay constraints, and propose a novel solution called Bayes-Split-Edge, which leverages Bayesian optimization for collaborative split inference over wireless edge networks. Our solution jointly optimizes the transmission power and the neural network split point. The Bayes-Split-Edge framework incorporates a novel hybrid acquisition function that balances inference task utility, sample efficiency, and constraint violation penalties. We evaluate our approach using the VGG19 model on the ImageNet-Mini dataset, and Resnet101 on Tiny-ImageNet, and real-world mMobile wireless channel datasets. Numerical results demonstrate that Bayes-Split-Edge achieves up to 2.4x reduction in evaluation cost compared to standard Bayesian optimization and achieves near-linear convergence. It also outperforms several baselines, including CMA-ES, DIRECT, exhaustive search, and Proximal Policy Optimization (PPO), while matching exhaustive search performance under tight constraints. These results confirm that the proposed framework provides a sample-efficient solution requiring maximum 20 function evaluations and constraint-aware optimization for wireless split inference in edge computing systems.",
    "authors": [
      "Fatemeh Zahra Safaeipour",
      "Jacob Chakareski",
      "Morteza Hashemi"
    ],
    "categories": [
      "cs.DC",
      "cs.LG",
      "eess.SP"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23503v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23503v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2510.23362v1",
    "title": "Robust Non-negative Proximal Gradient Algorithm for Inverse Problems",
    "summary": "Proximal gradient algorithms (PGA), while foundational for inverse problems like image reconstruction, often yield unstable convergence and suboptimal solutions by violating the critical non-negativity constraint. We identify the gradient descent step as the root cause of this issue, which introduces negative values and induces high sensitivity to hyperparameters. To overcome these limitations, we propose a novel multiplicative update proximal gradient algorithm (SSO-PGA) with convergence guarantees, which is designed for robustness in non-negative inverse problems. Our key innovation lies in superseding the gradient descent step with a learnable sigmoid-based operator, which inherently enforces non-negativity and boundedness by transforming traditional subtractive updates into multiplicative ones. This design, augmented by a sliding parameter for enhanced stability and convergence, not only improves robustness but also boosts expressive capacity and noise immunity. We further formulate a degradation model for multi-modal restoration and derive its SSO-PGA-based optimization algorithm, which is then unfolded into a deep network to marry the interpretability of optimization with the power of deep learning. Extensive numerical and real-world experiments demonstrate that our method significantly surpasses traditional PGA and other state-of-the-art algorithms, ensuring superior performance and stability.",
    "authors": [
      "Hanzhang Wang",
      "Zonglin Liu",
      "Jingyi Xu",
      "Chenyang Wang",
      "Zhiwei Zhong",
      "Qiangqiang Shen"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23362v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23362v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2510.23217v1",
    "title": "Process Reward Models for Sentence-Level Verification of LVLM Radiology   Reports",
    "summary": "Automating radiology report generation with Large Vision-Language Models (LVLMs) holds great potential, yet these models often produce clinically critical hallucinations, posing serious risks. Existing hallucination detection methods frequently lack the necessary sentence-level granularity or robust generalization across different LVLM generators. We introduce a novel approach: a sentence-level Process Reward Model (PRM) adapted for this vision-language task. Our PRM predicts the factual correctness of each generated sentence, conditioned on clinical context and preceding text. When fine-tuned on MIMIC-CXR with weakly-supervised labels, a lightweight 0.5B-parameter PRM outperforms existing verification techniques, demonstrating, for instance, relative improvements of 7.5% in Matthews Correlation Coefficient and 1.8% in AUROC over strong white-box baselines on outputs from one LVLM. Unlike methods reliant on internal model states, our PRM demonstrates strong generalization to an unseen LVLM. We further show its practical utility: PRM scores effectively filter low-quality reports, improving F1-CheXbert scores by 4.5% (when discarding the worst 10% of reports). Moreover, when guiding a novel weighted best-of-N selection process on the MIMIC-CXR test set, our PRM show relative improvements in clinical metrics of 7.4% for F1-CheXbert and 0.6% for BERTScore. These results demonstrate that a lightweight, context-aware PRM provides a model-agnostic safety layer for clinical LVLMs without access to internal activations",
    "authors": [
      "Alois Thomas",
      "Maya Varma",
      "Jean-Benoit Delbrouck",
      "Curtis P. Langlotz"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23217v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23217v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2510.23156v1",
    "title": "Enabling Vibration-Based Gesture Recognition on Everyday Furniture via   Energy-Efficient FPGA Implementation of 1D Convolutional Networks",
    "summary": "The growing demand for smart home interfaces has increased interest in non-intrusive sensing methods like vibration-based gesture recognition. While prior studies demonstrated feasibility, they often rely on complex preprocessing and large Neural Networks (NNs) requiring costly high-performance hardware, resulting in high energy usage and limited real-world deployability. This study proposes an energy-efficient solution deploying compact NNs on low-power Field-Programmable Gate Arrays (FPGAs) to enable real-time gesture recognition with competitive accuracy. We adopt a series of optimizations: (1) We replace complex spectral preprocessing with raw waveform input, eliminating complex on-board preprocessing while reducing input size by 21x without sacrificing accuracy. (2) We design two lightweight architectures (1D-CNN and 1D-SepCNN) tailored for embedded FPGAs, reducing parameters from 369 million to as few as 216 while maintaining comparable accuracy. (3) With integer-only quantization and automated RTL generation, we achieve seamless FPGA deployment. A ping-pong buffering mechanism in 1D-SepCNN further improves deployability under tight memory constraints. (4) We extend a hardware-aware search framework to support constraint-driven model configuration selection, considering accuracy, deployability, latency, and energy consumption. Evaluated on two swipe-direction datasets with multiple users and ordinary tables, our approach achieves low-latency, energy-efficient inference on the AMD Spartan-7 XC7S25 FPGA. Under the PS data splitting setting, the selected 6-bit 1D-CNN reaches 0.970 average accuracy across users with 9.22 ms latency. The chosen 8-bit 1D-SepCNN further reduces latency to 6.83 ms (over 53x CPU speedup) with slightly lower accuracy (0.949). Both consume under 1.2 mJ per inference, demonstrating suitability for long-term edge operation.",
    "authors": [
      "Koki Shibata",
      "Tianheng Ling",
      "Chao Qian",
      "Tomokazu Matsui",
      "Hirohiko Suwa",
      "Keiichi Yasumoto",
      "Gregor Schiele"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23156v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23156v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.73
  },
  {
    "arxiv_id": "2510.23396v1",
    "title": "EMTSF:Extraordinary Mixture of SOTA Models for Time Series Forecasting",
    "summary": "The immense success of the Transformer architecture   in Natural Language Processing has led to its adoption in Time Se ries Forecasting (TSF), where superior performance has been shown.   However, a recent important paper questioned their effectiveness by   demonstrating that a simple single layer linear model outperforms   Transformer-based models. This was soon shown to be not as valid,   by a better transformer-based model termed PatchTST. More re cently, TimeLLM demonstrated even better results by repurposing a   Large Language Model (LLM) for the TSF domain. Again, a follow   up paper challenged this by demonstrating that removing the LLM   component or replacing it with a basic attention layer in fact yields   better performance. One of the challenges in forecasting is the fact   that TSF data favors the more recent past, and is sometimes subject   to unpredictable events. Based upon these recent insights in TSF, we   propose a strong Mixture of Experts (MoE) framework. Our method   combines the state-of-the-art (SOTA) models including xLSTM, en hanced Linear, PatchTST, and minGRU, among others. This set of   complimentary and diverse models for TSF are integrated in a Trans former based MoE gating network. Our proposed model outperforms   all existing TSF models on standard benchmarks, surpassing even the   latest approaches based on MoE frameworks.",
    "authors": [
      "Musleh Alharthi",
      "Kaleel Mahmood",
      "Sarosh Patel",
      "Ausif Mahmood"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23396v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23396v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2510.23163v1",
    "title": "Beyond Direct Generation: A Decomposed Approach to Well-Crafted   Screenwriting with LLMs",
    "summary": "The screenplay serves as the foundation for television production, defining narrative structure, character development, and dialogue. While Large Language Models (LLMs) show great potential in creative writing, direct end-to-end generation approaches often fail to produce well-crafted screenplays. We argue this failure stems from forcing a single model to simultaneously master two disparate capabilities: creative narrative construction and rigid format adherence. The resulting outputs may mimic superficial style but lack the deep structural integrity and storytelling substance required for professional use. To enable LLMs to generate high-quality screenplays, we introduce Dual-Stage Refinement (DSR), a decomposed framework that decouples creative narrative generation from format conversion. The first stage transforms a brief outline into rich, novel-style prose. The second stage refines this narrative into a professionally formatted screenplay. This separation enables the model to specialize in one distinct capability at each stage. A key challenge in implementing DSR is the scarcity of paired outline-to-novel training data. We address this through hybrid data synthesis: reverse synthesis deconstructs existing screenplays into structured inputs, while forward synthesis leverages these inputs to generate high-quality narrative texts as training targets. Blind evaluations by professional screenwriters show that DSR achieves a 75% win rate against strong baselines like Gemini-2.5-Pro and reaches 82.7% of human-level performance. Our work demonstrates that decomposed generation architecture with tailored data synthesis effectively specializes LLMs in complex creative domains.",
    "authors": [
      "Hang Lei",
      "Shengyi Zong",
      "Zhaoyan Li",
      "Ziren Zhou",
      "Hao Liu"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "I.2.0"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23163v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23163v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2510.23112v1",
    "title": "GroupSHAP-Guided Integration of Financial News Keywords and Technical   Indicators for Stock Price Prediction",
    "summary": "Recent advances in finance-specific language models such as FinBERT have enabled the quantification of public sentiment into index-based measures, yet compressing diverse linguistic signals into single metrics overlooks contextual nuances and limits interpretability. To address this limitation, explainable AI techniques, particularly SHAP (SHapley Additive Explanations), have been employed to identify influential features. However, SHAP's computational cost grows exponentially with input features, making it impractical for large-scale text-based financial data. This study introduces a GRU-based forecasting framework enhanced with GroupSHAP, which quantifies contributions of semantically related keyword groups rather than individual tokens, substantially reducing computational burden while preserving interpretability. We employed FinBERT to embed news articles from 2015 to 2024, clustered them into coherent semantic groups, and applied GroupSHAP to measure each group's contribution to stock price movements. The resulting group-level SHAP variables across multiple topics were used as input features for the prediction model. Empirical results from one-day-ahead forecasting of the S&P 500 index throughout 2024 demonstrate that our approach achieves a 32.2% reduction in MAE and a 40.5% reduction in RMSE compared with benchmark models without the GroupSHAP mechanism. This research presents the first application of GroupSHAP in news-driven financial forecasting, showing that grouped sentiment representations simultaneously enhance interpretability and predictive performance.",
    "authors": [
      "Minjoo Kim",
      "Jinwoong Kim",
      "Sangjin Park"
    ],
    "categories": [
      "cs.CE",
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23112v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23112v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.72
  },
  {
    "arxiv_id": "2510.23595v1",
    "title": "Multi-Agent Evolve: LLM Self-Improve through Co-evolution",
    "summary": "Reinforcement Learning (RL) has demonstrated significant potential in enhancing the reasoning capabilities of large language models (LLMs). However, the success of RL for LLMs heavily relies on human-curated datasets and verifiable rewards, which limit their scalability and generality. Recent Self-Play RL methods, inspired by the success of the paradigm in games and Go, aim to enhance LLM reasoning capabilities without human-annotated data. However, their methods primarily depend on a grounded environment for feedback (e.g., a Python interpreter or a game engine); extending them to general domains remains challenging. To address these challenges, we propose Multi-Agent Evolve (MAE), a framework that enables LLMs to self-evolve in solving diverse tasks, including mathematics, reasoning, and general knowledge Q&A. The core design of MAE is based on a triplet of interacting agents (Proposer, Solver, Judge) that are instantiated from a single LLM, and applies reinforcement learning to optimize their behaviors. The Proposer generates questions, the Solver attempts solutions, and the Judge evaluates both while co-evolving. Experiments on Qwen2.5-3B-Instruct demonstrate that MAE achieves an average improvement of 4.54% on multiple benchmarks. These results highlight MAE as a scalable, data-efficient method for enhancing the general reasoning abilities of LLMs with minimal reliance on human-curated supervision.",
    "authors": [
      "Yixing Chen",
      "Yiding Wang",
      "Siqi Zhu",
      "Haofei Yu",
      "Tao Feng",
      "Muhan Zhan",
      "Mostofa Patwary",
      "Jiaxuan You"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23595v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23595v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2510.23090v1",
    "title": "MAP4TS: A Multi-Aspect Prompting Framework for Time-Series Forecasting   with Large Language Models",
    "summary": "Recent advances have investigated the use of pretrained large language models (LLMs) for time-series forecasting by aligning numerical inputs with LLM embedding spaces. However, existing multimodal approaches often overlook the distinct statistical properties and temporal dependencies that are fundamental to time-series data. To bridge this gap, we propose MAP4TS, a novel Multi-Aspect Prompting Framework that explicitly incorporates classical time-series analysis into the prompt design. Our framework introduces four specialized prompt components: a Global Domain Prompt that conveys dataset-level context, a Local Domain Prompt that encodes recent trends and series-specific behaviors, and a pair of Statistical and Temporal Prompts that embed handcrafted insights derived from autocorrelation (ACF), partial autocorrelation (PACF), and Fourier analysis. Multi-Aspect Prompts are combined with raw time-series embeddings and passed through a cross-modality alignment module to produce unified representations, which are then processed by an LLM and projected for final forecasting. Extensive experiments across eight diverse datasets show that MAP4TS consistently outperforms state-of-the-art LLM-based methods. Our ablation studies further reveal that prompt-aware designs significantly enhance performance stability and that GPT-2 backbones, when paired with structured prompts, outperform larger models like LLaMA in long-term forecasting tasks.",
    "authors": [
      "Suchan Lee",
      "Jihoon Choi",
      "Sohyeon Lee",
      "Minseok Song",
      "Bong-Gyu Jang",
      "Hwanjo Yu",
      "Soyeon Caren Han"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23090v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23090v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.71
  },
  {
    "arxiv_id": "2510.23576v1",
    "title": "UrbanVLA: A Vision-Language-Action Model for Urban Micromobility",
    "summary": "Urban micromobility applications, such as delivery robots, demand reliable navigation across large-scale urban environments while following long-horizon route instructions. This task is particularly challenging due to the dynamic and unstructured nature of real-world city areas, yet most existing navigation methods remain tailored to short-scale and controllable scenarios. Effective urban micromobility requires two complementary levels of navigation skills: low-level capabilities such as point-goal reaching and obstacle avoidance, and high-level capabilities, such as route-visual alignment. To this end, we propose UrbanVLA, a route-conditioned Vision-Language-Action (VLA) framework designed for scalable urban navigation. Our method explicitly aligns noisy route waypoints with visual observations during execution, and subsequently plans trajectories to drive the robot. To enable UrbanVLA to master both levels of navigation, we employ a two-stage training pipeline. The process begins with Supervised Fine-Tuning (SFT) using simulated environments and trajectories parsed from web videos. This is followed by Reinforcement Fine-Tuning (RFT) on a mixture of simulation and real-world data, which enhances the model's safety and adaptability in real-world settings. Experiments demonstrate that UrbanVLA surpasses strong baselines by more than 55% in the SocialNav task on MetaUrban. Furthermore, UrbanVLA achieves reliable real-world navigation, showcasing both scalability to large-scale urban environments and robustness against real-world uncertainties.",
    "authors": [
      "Anqi Li",
      "Zhiyong Wang",
      "Jiazhao Zhang",
      "Minghan Li",
      "Yunpeng Qi",
      "Zhibo Chen",
      "Zhizheng Zhang",
      "He Wang"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23576v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23576v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2510.23535v1",
    "title": "Sequential Multi-Agent Dynamic Algorithm Configuration",
    "summary": "Dynamic algorithm configuration (DAC) is a recent trend in automated machine learning, which can dynamically adjust the algorithm's configuration during the execution process and relieve users from tedious trial-and-error tuning tasks. Recently, multi-agent reinforcement learning (MARL) approaches have improved the configuration of multiple heterogeneous hyperparameters, making various parameter configurations for complex algorithms possible. However, many complex algorithms have inherent inter-dependencies among multiple parameters (e.g., determining the operator type first and then the operator's parameter), which are, however, not considered in previous approaches, thus leading to sub-optimal results. In this paper, we propose the sequential multi-agent DAC (Seq-MADAC) framework to address this issue by considering the inherent inter-dependencies of multiple parameters. Specifically, we propose a sequential advantage decomposition network, which can leverage action-order information through sequential advantage decomposition. Experiments from synthetic functions to the configuration of multi-objective optimization algorithms demonstrate Seq-MADAC's superior performance over state-of-the-art MARL methods and show strong generalization across problem classes. Seq-MADAC establishes a new paradigm for the widespread dependency-aware automated algorithm configuration. Our code is available at https://github.com/lamda-bbo/seq-madac.",
    "authors": [
      "Chen Lu",
      "Ke Xue",
      "Lei Yuan",
      "Yao Wang",
      "Yaoyuan Wang",
      "Sheng Fu",
      "Chao Qian"
    ],
    "categories": [
      "cs.LG",
      "cs.NE"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23535v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23535v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2510.23409v1",
    "title": "Eigen-Value: Efficient Domain-Robust Data Valuation via Eigenvalue-Based   Approach",
    "summary": "Data valuation has become central in the era of data-centric AI. It drives efficient training pipelines and enables objective pricing in data markets by assigning a numeric value to each data point. Most existing data valuation methods estimate the effect of removing individual data points by evaluating changes in model validation performance under in-distribution (ID) settings, as opposed to out-of-distribution (OOD) scenarios where data follow different patterns. Since ID and OOD data behave differently, data valuation methods based on ID loss often fail to generalize to OOD settings, particularly when the validation set contains no OOD data. Furthermore, although OOD-aware methods exist, they involve heavy computational costs, which hinder practical deployment. To address these challenges, we introduce \\emph{Eigen-Value} (EV), a plug-and-play data valuation framework for OOD robustness that uses only an ID data subset, including during validation. EV provides a new spectral approximation of domain discrepancy, which is the gap of loss between ID and OOD using ratios of eigenvalues of ID data's covariance matrix. EV then estimates the marginal contribution of each data point to this discrepancy via perturbation theory, alleviating the computational burden. Subsequently, EV plugs into ID loss-based methods by adding an EV term without any additional training loop. We demonstrate that EV achieves improved OOD robustness and stable value rankings across real-world datasets, while remaining computationally lightweight. These results indicate that EV is practical for large-scale settings with domain shift, offering an efficient path to OOD-robust data valuation.",
    "authors": [
      "Youngjun Choi",
      "Joonseong Kang",
      "Sungjun Lim",
      "Kyungwoo Song"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23409v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23409v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2510.23327v1",
    "title": "GRAD: Real-Time Gated Recurrent Anomaly Detection in Autonomous Vehicle   Sensors Using Reinforced EMA and Multi-Stage Sliding Window Techniques",
    "summary": "This paper introduces GRAD, a real-time anomaly detection method for autonomous vehicle sensors that integrates statistical analysis and deep learning to ensure the reliability of sensor data. The proposed approach combines the Reinforced Exponential Moving Average (REMA), which adapts smoothing factors and thresholding for outlier detection, with the Multi-Stage Sliding Window (MS-SW) technique for capturing both short- and long-term patterns. These features are processed using a lightweight Gated Recurrent Unit (GRU) model, which detects and classifies anomalies based on bias types, while a recovery module restores damaged sensor data to ensure continuous system operation. GRAD has a lightweight architecture consisting of two layers of GRU with a limited number of neurons that make it appropriate for real-time applications while maintaining high detection accuracy. The GRAD framework achieved remarkable performance in anomaly detection and classification. The model demonstrated an overall F1-score of 97.6% for abnormal data and 99.4% for normal data, signifying its high accuracy in distinguishing between normal and anomalous sensor data. Regarding the anomaly classification, GRAD successfully categorized different anomaly types with high precision, enabling the recovery module to accurately restore damaged sensor data. Relative to analogous studies, GRAD surpasses current models by attaining a balance between elevated detection accuracy and diminished computational expense. These results demonstrate GRAD's potential as a reliable and efficient solution for real-time anomaly detection in autonomous vehicle systems, guaranteeing safe vehicle operation with minimal computational overhead.",
    "authors": [
      "Mohammad Hossein Jafari Naeimi",
      "Ali Norouzi",
      "Athena Abdi"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23327v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23327v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2510.23216v1",
    "title": "Human-Like Goalkeeping in a Realistic Football Simulation: a   Sample-Efficient Reinforcement Learning Approach",
    "summary": "While several high profile video games have served as testbeds for Deep Reinforcement Learning (DRL), this technique has rarely been employed by the game industry for crafting authentic AI behaviors. Previous research focuses on training super-human agents with large models, which is impractical for game studios with limited resources aiming for human-like agents. This paper proposes a sample-efficient DRL method tailored for training and fine-tuning agents in industrial settings such as the video game industry. Our method improves sample efficiency of value-based DRL by leveraging pre-collected data and increasing network plasticity. We evaluate our method training a goalkeeper agent in EA SPORTS FC 25, one of the best-selling football simulations today. Our agent outperforms the game's built-in AI by 10% in ball saving rate. Ablation studies show that our method trains agents 50% faster compared to standard DRL methods. Finally, qualitative evaluation from domain experts indicates that our approach creates more human-like gameplay compared to hand-crafted agents. As a testimony of the impact of the approach, the method is intended to replace the hand-crafted counterpart in next iterations of the series.",
    "authors": [
      "Alessandro Sestini",
      "Joakim Bergdahl",
      "Jean-Philippe Barrette-LaPierre",
      "Florian Fuchs",
      "Brady Chen",
      "Micheal Jones",
      "Linus Gisslén"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23216v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23216v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2510.23051v1",
    "title": "SwiftTS: A Swift Selection Framework for Time Series Pre-trained Models   via Multi-task Meta-Learning",
    "summary": "Pre-trained models exhibit strong generalization to various downstream tasks. However, given the numerous models available in the model hub, identifying the most suitable one by individually fine-tuning is time-consuming. In this paper, we propose \\textbf{SwiftTS}, a swift selection framework for time series pre-trained models. To avoid expensive forward propagation through all candidates, SwiftTS adopts a learning-guided approach that leverages historical dataset-model performance pairs across diverse horizons to predict model performance on unseen datasets. It employs a lightweight dual-encoder architecture that embeds time series and candidate models with rich characteristics, computing patchwise compatibility scores between data and model embeddings for efficient selection. To further enhance the generalization across datasets and horizons, we introduce a horizon-adaptive expert composition module that dynamically adjusts expert weights, and the transferable cross-task learning with cross-dataset and cross-horizon task sampling to enhance out-of-distribution (OOD) robustness. Extensive experiments on 14 downstream datasets and 8 pre-trained models demonstrate that SwiftTS achieves state-of-the-art performance in time series pre-trained model selection.",
    "authors": [
      "Tengxue Zhang",
      "Biao Ouyang",
      "Yang Shu",
      "Xinyang Chen",
      "Chenjuan Guo",
      "Bin Yang"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23051v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23051v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.7
  },
  {
    "arxiv_id": "2510.23605v1",
    "title": "Track, Inpaint, Resplat: Subject-driven 3D and 4D Generation with   Progressive Texture Infilling",
    "summary": "Current 3D/4D generation methods are usually optimized for photorealism, efficiency, and aesthetics. However, they often fail to preserve the semantic identity of the subject across different viewpoints. Adapting generation methods with one or few images of a specific subject (also known as Personalization or Subject-driven generation) allows generating visual content that align with the identity of the subject. However, personalized 3D/4D generation is still largely underexplored. In this work, we introduce TIRE (Track, Inpaint, REsplat), a novel method for subject-driven 3D/4D generation. It takes an initial 3D asset produced by an existing 3D generative model as input and uses video tracking to identify the regions that need to be modified. Then, we adopt a subject-driven 2D inpainting model for progressively infilling the identified regions. Finally, we resplat the modified 2D multi-view observations back to 3D while still maintaining consistency. Extensive experiments demonstrate that our approach significantly improves identity preservation in 3D/4D generation compared to state-of-the-art methods. Our project website is available at https://zsh2000.github.io/track-inpaint-resplat.github.io/.",
    "authors": [
      "Shuhong Zheng",
      "Ashkan Mirzaei",
      "Igor Gilitschenski"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.GR",
      "cs.LG",
      "cs.RO"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23605v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23605v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2510.23601v1",
    "title": "Alita-G: Self-Evolving Generative Agent for Agent Generation",
    "summary": "Large language models (LLMs) have been shown to perform better when scaffolded into agents with memory, tools, and feedback. Beyond this, self-evolving agents have emerged, but current work largely limits adaptation to prompt rewriting or failure retries. Therefore, we present ALITA-G, a self-evolution framework that transforms a general-purpose agent into a domain expert by systematically generating, abstracting, and curating Model Context Protocol (MCP) tools. In this framework, a generalist agent executes a curated suite of target-domain tasks and synthesizes candidate MCPs from successful trajectories. These are then abstracted to parameterized primitives and consolidated into an MCP Box. At inference time, ALITA-G performs retrieval-augmented MCP selection with the help of each tool's descriptions and use cases, before executing an agent equipped with the MCP Executor. Across several benchmarks GAIA, PathVQA, and Humanity's Last Exam, ALITA-G attains strong gains while reducing computation costs. On GAIA validation, it achieves 83.03% pass@1 and 89.09% pass@3, establishing a new state-of-the-art result while reducing mean tokens per example by approximately 15% relative to a strong baseline agent. ALITA-G thus provides a principled pathway from generalist capability to reusable, domain-specific competence, improving both accuracy and efficiency on complex reasoning tasks.",
    "authors": [
      "Jiahao Qiu",
      "Xuan Qi",
      "Hongru Wang",
      "Xinzhe Juan",
      "Yimin Wang",
      "Zelin Zhao",
      "Jiayi Geng",
      "Jiacheng Guo",
      "Peihang Li",
      "Jingzhe Shi",
      "Shilong Liu",
      "Mengdi Wang"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23601v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23601v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2510.23506v1",
    "title": "Emotion-Coherent Reasoning for Multimodal LLMs via Emotional Rationale   Verifier",
    "summary": "The recent advancement of Multimodal Large Language Models (MLLMs) is transforming human-computer interaction (HCI) from surface-level exchanges into more nuanced and emotionally intelligent communication. To realize this shift, emotion understanding becomes essential allowing systems to capture subtle cues underlying user intent. Furthermore, providing faithful explanations for predicted emotions is crucial to ensure interpretability and build user trust. However, current MLLM-based methods often generate emotion explanations that diverge from the target labels and sometimes even contradict their own predicted emotions. This inconsistency poses a critical risk for misunderstanding and erodes reliability in interactive settings. To address this, we propose a novel approach: the Emotional Rationale Verifier (ERV) and an Explanation Reward. Our method guides the model to produce reasoning that is explicitly consistent with the target emotion during multimodal emotion recognition without modifying the model architecture or requiring additional paired video-description annotations. Our method significantly improves faithful explanation-prediction consistency and explanation emotion accuracy on the MAFW and DFEW datasets. Through extensive experiments and human evaluations, we show that our approach not only enhances alignment between explanation and prediction but also empowers MLLMs to deliver emotionally coherent, trustworthy interactions, marking a key step toward truly human-like HCI systems.",
    "authors": [
      "Hyeongseop Rha",
      "Jeong Hun Yeo",
      "Yeonju Kim",
      "Yong Man Ro"
    ],
    "categories": [
      "cs.AI",
      "cs.HC"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23506v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23506v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2510.23382v1",
    "title": "An Efficient Remote Sensing Super Resolution Method Exploring Diffusion   Priors and Multi-Modal Constraints for Crop Type Mapping",
    "summary": "Super resolution offers a way to harness medium even lowresolution but historically valuable remote sensing image archives. Generative models, especially diffusion models, have recently been applied to remote sensing super resolution (RSSR), yet several challenges exist. First, diffusion models are effective but require expensive training from scratch resources and have slow inference speeds. Second, current methods have limited utilization of auxiliary information as real-world constraints to reconstruct scientifically realistic images. Finally, most current methods lack evaluation on downstream tasks. In this study, we present a efficient LSSR framework for RSSR, supported by a new multimodal dataset of paired 30 m Landsat 8 and 10 m Sentinel 2 imagery. Built on frozen pretrained Stable Diffusion, LSSR integrates crossmodal attention with auxiliary knowledge (Digital Elevation Model, land cover, month) and Synthetic Aperture Radar guidance, enhanced by adapters and a tailored Fourier NDVI loss to balance spatial details and spectral fidelity. Extensive experiments demonstrate that LSSR significantly improves crop boundary delineation and recovery, achieving state-of-the-art performance with Peak Signal-to-Noise Ratio/Structural Similarity Index Measure of 32.63/0.84 (RGB) and 23.99/0.78 (IR), and the lowest NDVI Mean Squared Error (0.042), while maintaining efficient inference (0.39 sec/image). Moreover, LSSR transfers effectively to NASA Harmonized Landsat and Sentinel (HLS) super resolution, yielding more reliable crop classification (F1: 0.86) than Sentinel-2 (F1: 0.85). These results highlight the potential of RSSR to advance precision agriculture.",
    "authors": [
      "Songxi Yang",
      "Tang Sui",
      "Qunying Huang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23382v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23382v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2510.23221v1",
    "title": "Accelerating IC Thermal Simulation Data Generation via Block Krylov and   Operator Action",
    "summary": "Recent advances in data-driven approaches, such as neural operators (NOs), have shown substantial efficacy in reducing the solution time for integrated circuit (IC) thermal simulations. However, a limitation of these approaches is requiring a large amount of high-fidelity training data, such as chip parameters and temperature distributions, thereby incurring significant computational costs. To address this challenge, we propose a novel algorithm for the generation of IC thermal simulation data, named block Krylov and operator action (BlocKOA), which simultaneously accelerates the data generation process and enhances the precision of generated data. BlocKOA is specifically designed for IC applications. Initially, we use the block Krylov algorithm based on the structure of the heat equation to quickly obtain a few basic solutions. Then we combine them to get numerous temperature distributions that satisfy the physical constraints. Finally, we apply heat operators on these functions to determine the heat source distributions, efficiently generating precise data points. Theoretical analysis shows that the time complexity of BlocKOA is one order lower than the existing method. Experimental results further validate its efficiency, showing that BlocKOA achieves a 420-fold speedup in generating thermal simulation data for 5000 chips with varying physical parameters and IC structures. Even with just 4% of the generation time, data-driven approaches trained on the data generated by BlocKOA exhibits comparable performance to that using the existing method.",
    "authors": [
      "Hong Wang",
      "Wenkai Yang",
      "Jie Wang",
      "Huanshuo Dong",
      "Zijie Geng",
      "Zhen Huang",
      "Depeng Xie",
      "Zhezheng Hao",
      "Hande Dong"
    ],
    "categories": [
      "cs.AI",
      "physics.comp-ph"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23221v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23221v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.69
  },
  {
    "arxiv_id": "2510.23472v1",
    "title": "BBOPlace-Bench: Benchmarking Black-Box Optimization for Chip Placement",
    "summary": "Chip placement is a vital stage in modern chip design as it has a substantial impact on the subsequent processes and the overall quality of the final chip. The use of black-box optimization (BBO) for chip placement has a history of several decades. However, early efforts were limited by immature problem formulations and inefficient algorithm designs. Recent progress has shown the effectiveness and efficiency of BBO for chip placement, proving its potential to achieve state-of-the-art results. Despite these advancements, the field lacks a unified, BBO-specific benchmark for thoroughly assessing various problem formulations and BBO algorithms. To fill this gap, we propose BBOPlace-Bench, the first benchmark designed specifically for evaluating and developing BBO algorithms for chip placement tasks. It integrates three problem formulations of BBO for chip placement, and offers a modular, decoupled, and flexible framework that enables users to seamlessly implement, test, and compare their own algorithms. BBOPlace-Bench integrates a wide variety of existing BBO algorithms, including simulated annealing (SA), evolutionary algorithms (EAs), and Bayesian optimization (BO). Experimental results show that the problem formulations of mask-guided optimization and hyperparameter optimization exhibit superior performance than the sequence pair problem formulation, while EAs demonstrate better overall performance than SA and BO, especially in high-dimensional search spaces, and also achieve state-of-the-art performance compared to the mainstream chip placement methods. BBOPlace-Bench not only facilitates the development of efficient BBO-driven solutions for chip placement but also broadens the practical application scenarios (which are urgently needed) for the BBO community. The code of BBOPlace-Bench is available at https://github.com/lamda-bbo/BBOPlace-Bench.",
    "authors": [
      "Ke Xue",
      "Ruo-Tong Chen",
      "Rong-Xi Tan",
      "Xi Lin",
      "Yunqi Shi",
      "Siyuan Xu",
      "Mingxuan Yuan",
      "Chao Qian"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.AR",
      "cs.NE"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23472v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23472v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2510.23444v1",
    "title": "FRBNet: Revisiting Low-Light Vision through Frequency-Domain Radial   Basis Network",
    "summary": "Low-light vision remains a fundamental challenge in computer vision due to severe illumination degradation, which significantly affects the performance of downstream tasks such as detection and segmentation. While recent state-of-the-art methods have improved performance through invariant feature learning modules, they still fall short due to incomplete modeling of low-light conditions. Therefore, we revisit low-light image formation and extend the classical Lambertian model to better characterize low-light conditions. By shifting our analysis to the frequency domain, we theoretically prove that the frequency-domain channel ratio can be leveraged to extract illumination-invariant features via a structured filtering process. We then propose a novel and end-to-end trainable module named \\textbf{F}requency-domain \\textbf{R}adial \\textbf{B}asis \\textbf{Net}work (\\textbf{FRBNet}), which integrates the frequency-domain channel ratio operation with a learnable frequency domain filter for the overall illumination-invariant feature enhancement. As a plug-and-play module, FRBNet can be integrated into existing networks for low-light downstream tasks without modifying loss functions. Extensive experiments across various downstream tasks demonstrate that FRBNet achieves superior performance, including +2.2 mAP for dark object detection and +2.9 mIoU for nighttime segmentation. Code is available at: https://github.com/Sing-Forevet/FRBNet.",
    "authors": [
      "Fangtong Sun",
      "Congyu Li",
      "Ke Yang",
      "Yuchen Pan",
      "Hanwen Yu",
      "Xichuan Zhang",
      "Yiying Li"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23444v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23444v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2510.23416v1",
    "title": "Quality-controlled registration of urban MLS point clouds reducing drift   effects by adaptive fragmentation",
    "summary": "This study presents a novel workflow designed to efficiently and accurately register large-scale mobile laser scanning (MLS) point clouds to a target model point cloud in urban street scenarios. This workflow specifically targets the complexities inherent in urban environments and adeptly addresses the challenges of integrating point clouds that vary in density, noise characteristics, and occlusion scenarios, which are common in bustling city centers. Two methodological advancements are introduced. First, the proposed Semi-sphere Check (SSC) preprocessing technique optimally fragments MLS trajectory data by identifying mutually orthogonal planar surfaces. This step reduces the impact of MLS drift on the accuracy of the entire point cloud registration, while ensuring sufficient geometric features within each fragment to avoid local minima. Second, we propose Planar Voxel-based Generalized Iterative Closest Point (PV-GICP), a fine registration method that selectively utilizes planar surfaces within voxel partitions. This pre-process strategy not only improves registration accuracy but also reduces computation time by more than 50% compared to conventional point-to-plane ICP methods. Experiments on real-world datasets from Munich's inner city demonstrate that our workflow achieves sub-0.01 m average registration accuracy while significantly shortening processing times. The results underscore the potential of the proposed methods to advance automated 3D urban modeling and updating, with direct applications in urban planning, infrastructure management, and dynamic city monitoring.",
    "authors": [
      "Marco Antonio Ortiz Rincon",
      "Yihui Yang",
      "Christoph Holst"
    ],
    "categories": [
      "cs.CV",
      "eess.SP"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23416v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23416v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2510.23341v1",
    "title": "LightKGG: Simple and Efficient Knowledge Graph Generation from Textual   Data",
    "summary": "The scarcity of high-quality knowledge graphs (KGs) remains a critical bottleneck for downstream AI applications, as existing extraction methods rely heavily on error-prone pattern-matching techniques or resource-intensive large language models (LLMs). While recent tools leverage LLMs to generate KGs, their computational demands limit accessibility for low-resource environments. Our paper introduces LightKGG, a novel framework that enables efficient KG extraction from textual data using small-scale language models (SLMs) through two key technical innovations: (1) Context-integrated Graph extraction integrates contextual information with nodes and edges into a unified graph structure, reducing the reliance on complex semantic processing while maintaining more key information; (2) Topology-enhanced relationship inference leverages the inherent topology of the extracted graph to efficiently infer relationships, enabling relationship discovery without relying on complex language understanding capabilities of LLMs. By enabling accurate KG construction with minimal hardware requirements, this work bridges the gap between automated knowledge extraction and practical deployment scenarios while introducing scientifically rigorous methods for optimizing SLM efficiency in structured NLP tasks.",
    "authors": [
      "Teng Lin"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23341v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23341v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2510.23330v1",
    "title": "The First Star-by-star $N$-body/Hydrodynamics Simulation of Our Galaxy   Coupling with a Surrogate Model",
    "summary": "A major goal of computational astrophysics is to simulate the Milky Way Galaxy with sufficient resolution down to individual stars. However, the scaling fails due to some small-scale, short-timescale phenomena, such as supernova explosions. We have developed a novel integration scheme of $N$-body/hydrodynamics simulations working with machine learning. This approach bypasses the short timesteps caused by supernova explosions using a surrogate model, thereby improving scalability. With this method, we reached 300 billion particles using 148,900 nodes, equivalent to 7,147,200 CPU cores, breaking through the billion-particle barrier currently faced by state-of-the-art simulations. This resolution allows us to perform the first star-by-star galaxy simulation, which resolves individual stars in the Milky Way Galaxy. The performance scales over $10^4$ CPU cores, an upper limit in the current state-of-the-art simulations using both A64FX and X86-64 processors and NVIDIA CUDA GPUs.",
    "authors": [
      "Keiya Hirashima",
      "Michiko S. Fujii",
      "Takayuki R. Saitoh",
      "Naoto Harada",
      "Kentaro Nomura",
      "Kohji Yoshikawa",
      "Yutaka Hirai",
      "Tetsuro Asano",
      "Kana Moriwaki",
      "Masaki Iwasawa",
      "Takashi Okamoto",
      "Junichiro Makino"
    ],
    "categories": [
      "astro-ph.GA",
      "cs.DC",
      "cs.LG",
      "physics.comp-ph"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23330v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23330v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2510.23214v1",
    "title": "AUPO - Abstracted Until Proven Otherwise: A Reward Distribution Based   Abstraction Algorithm",
    "summary": "We introduce a novel, drop-in modification to Monte Carlo Tree Search's (MCTS) decision policy that we call AUPO. Comparisons based on a range of IPPC benchmark problems show that AUPO clearly outperforms MCTS. AUPO is an automatic action abstraction algorithm that solely relies on reward distribution statistics acquired during the MCTS. Thus, unlike other automatic abstraction algorithms, AUPO requires neither access to transition probabilities nor does AUPO require a directed acyclic search graph to build its abstraction, allowing AUPO to detect symmetric actions that state-of-the-art frameworks like ASAP struggle with when the resulting symmetric states are far apart in state space. Furthermore, as AUPO only affects the decision policy, it is not mutually exclusive with other abstraction techniques that only affect the tree search.",
    "authors": [
      "Robin Schmöcker",
      "Alexander Dockhorn",
      "Bodo Rosenhahn"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23214v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23214v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2510.23208v1",
    "title": "Increasing LLM Coding Capabilities through Diverse Synthetic Coding   Tasks",
    "summary": "Large language models (LLMs) have shown impressive promise in code generation, yet their progress remains limited by the shortage of large-scale datasets that are both diverse and well-aligned with human reasoning. Most existing resources pair problems with solutions, but omit the intermediate thought process that guides coding. To close this gap, we present a scalable synthetic data generation pipeline that produces nearly 800k instruction-reasoning-code-test quadruplets. Each sample combines a task, a step-by-step reasoning trace, a working solution, and executable tests, enabling models to learn not just the what but also the how of problem solving. Our pipeline combines four key components: curated contest problems, web-mined content filtered by relevance classifiers, data expansion guided by reasoning patterns, and multi-stage execution-based validation. A genetic mutation algorithm further increases task diversity while maintaining consistency between reasoning traces and code implementations. Our key finding is that fine-tuning LLMs on this dataset yields consistent improvements on coding benchmarks. Beyond raw accuracy, reasoning-aware data can substitute for model scaling, generalize across architectures, and outperform leading open-source alternatives under identical sample budgets. Our work establishes reasoning-centered synthetic data generation as an efficient approach for advancing coding capabilities in LLMs. We publish our dataset and generation pipeline to facilitate further research.",
    "authors": [
      "Amal Abed",
      "Ivan Lukic",
      "Jörg K. H. Franke",
      "Frank Hutter"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23208v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23208v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.68
  },
  {
    "arxiv_id": "2510.23347v1",
    "title": "Macroeconomic Forecasting for the G7 countries under Uncertainty Shocks",
    "summary": "Accurate macroeconomic forecasting has become harder amid geopolitical disruptions, policy reversals, and volatile financial markets. Conventional vector autoregressions (VARs) overfit in high dimensional settings, while threshold VARs struggle with time varying interdependencies and complex parameter structures. We address these limitations by extending the Sims Zha Bayesian VAR with exogenous variables (SZBVARx) to incorporate domain-informed shrinkage and four newspaper based uncertainty shocks such as economic policy uncertainty, geopolitical risk, US equity market volatility, and US monetary policy uncertainty. The framework improves structural interpretability, mitigates dimensionality, and imposes empirically guided regularization. Using G7 data, we study spillovers from uncertainty shocks to five core variables (unemployment, real broad effective exchange rates, short term rates, oil prices, and CPI inflation), combining wavelet coherence (time frequency dynamics) with nonlinear local projections (state dependent impulse responses). Out-of-sample results at 12 and 24 month horizons show that SZBVARx outperforms 14 benchmarks, including classical VARs and leading machine learning models, as confirmed by Murphy difference diagrams, multivariate Diebold Mariano tests, and Giacomini White predictability tests. Credible Bayesian prediction intervals deliver robust uncertainty quantification for scenario analysis and risk management. The proposed SZBVARx offers G7 policymakers a transparent, well calibrated tool for modern macroeconomic forecasting under pervasive uncertainty.",
    "authors": [
      "Shovon Sengupta",
      "Sunny Kumar Singh",
      "Tanujit Chakraborty"
    ],
    "categories": [
      "econ.EM",
      "cs.LG",
      "stat.AP"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23347v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23347v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2510.23224v1",
    "title": "Accurate and Scalable Multimodal Pathology Retrieval via Attentive   Vision-Language Alignment",
    "summary": "The rapid digitization of histopathology slides has opened up new possibilities for computational tools in clinical and research workflows. Among these, content-based slide retrieval stands out, enabling pathologists to identify morphologically and semantically similar cases, thereby supporting precise diagnoses, enhancing consistency across observers, and assisting example-based education. However, effective retrieval of whole slide images (WSIs) remains challenging due to their gigapixel scale and the difficulty of capturing subtle semantic differences amid abundant irrelevant content. To overcome these challenges, we present PathSearch, a retrieval framework that unifies fine-grained attentive mosaic representations with global-wise slide embeddings aligned through vision-language contrastive learning. Trained on a corpus of 6,926 slide-report pairs, PathSearch captures both fine-grained morphological cues and high-level semantic patterns to enable accurate and flexible retrieval. The framework supports two key functionalities: (1) mosaic-based image-to-image retrieval, ensuring accurate and efficient slide research; and (2) multi-modal retrieval, where text queries can directly retrieve relevant slides. PathSearch was rigorously evaluated on four public pathology datasets and three in-house cohorts, covering tasks including anatomical site retrieval, tumor subtyping, tumor vs. non-tumor discrimination, and grading across diverse organs such as breast, lung, kidney, liver, and stomach. External results show that PathSearch outperforms traditional image-to-image retrieval frameworks. A multi-center reader study further demonstrates that PathSearch improves diagnostic accuracy, boosts confidence, and enhances inter-observer agreement among pathologists in real clinical scenarios. These results establish PathSearch as a scalable and generalizable retrieval solution for digital pathology.",
    "authors": [
      "Hongyi Wang",
      "Zhengjie Zhu",
      "Jiabo Ma",
      "Fang Wang",
      "Yue Shi",
      "Bo Luo",
      "Jili Wang",
      "Qiuyu Cai",
      "Xiuming Zhang",
      "Yen-Wei Chen",
      "Lanfen Lin",
      "Hao Chen"
    ],
    "categories": [
      "cs.CV",
      "cs.IR"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23224v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23224v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2510.23169v1",
    "title": "MATCH: Task-Driven Code Evaluation through Contrastive Learning",
    "summary": "AI-based code generation is increasingly prevalent, with GitHub Copilot estimated to generate 46% of the code on GitHub. Accurately evaluating how well generated code aligns with developer intent remains a critical challenge. Traditional evaluation methods, such as unit tests, are often unscalable and costly. Syntactic similarity metrics (e.g., BLEU, ROUGE) fail to capture code functionality, and metrics like CodeBERTScore require reference code, which is not always available. To address the gap in reference-free evaluation, with few alternatives such as ICE-Score, this paper introduces MATCH, a novel reference-free metric. MATCH uses Contrastive Learning to generate meaningful embeddings for code and natural language task descriptions, enabling similarity scoring that reflects how well generated code implements the task. We show that MATCH achieves stronger correlations with functional correctness and human preference than existing metrics across multiple programming languages.",
    "authors": [
      "Marah Ghoummaid",
      "Vladimir Tchuiev",
      "Ofek Glick",
      "Michal Moschkovitz",
      "Dotan Di Castro"
    ],
    "categories": [
      "cs.CL",
      "cs.SE"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23169v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23169v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2510.23124v1",
    "title": "DeepSalt: Bridging Laboratory and Satellite Spectra through Domain   Adaptation and Knowledge Distillation for Large-Scale Soil Salinity   Estimation",
    "summary": "Soil salinization poses a significant threat to both ecosystems and agriculture because it limits plants' ability to absorb water and, in doing so, reduces crop productivity. This phenomenon alters the soil's spectral properties, creating a measurable relationship between salinity and light reflectance that enables remote monitoring. While laboratory spectroscopy provides precise measurements, its reliance on in-situ sampling limits scalability to regional or global levels. Conversely, hyperspectral satellite imagery enables wide-area observation but lacks the fine-grained interpretability of laboratory instruments. To bridge this gap, we introduce DeepSalt, a deep-learning-based spectral transfer framework that leverages knowledge distillation and a novel Spectral Adaptation Unit to transfer high-resolution spectral insights from laboratory-based spectroscopy to satellite-based hyperspectral sensing. Our approach eliminates the need for extensive ground sampling while enabling accurate, large-scale salinity estimation, as demonstrated through comprehensive empirical benchmarks. DeepSalt achieves significant performance gains over methods without explicit domain adaptation, underscoring the impact of the proposed Spectral Adaptation Unit and the knowledge distillation strategy. The model also effectively generalized to unseen geographic regions, explaining a substantial portion of the salinity variance.",
    "authors": [
      "Rupasree Dey",
      "Abdul Matin",
      "Everett Lewark",
      "Tanjim Bin Faruk",
      "Andrei Bachinin",
      "Sam Leuthold",
      "M. Francesca Cotrufo",
      "Shrideep Pallickara",
      "Sangmi Lee Pallickara"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23124v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23124v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2510.23123v1",
    "title": "Beyond Higher Rank: Token-wise Input-Output Projections for Efficient   Low-Rank Adaptation",
    "summary": "Low-rank adaptation (LoRA) is a parameter-efficient fine-tuning (PEFT) method widely used in large language models (LLMs). LoRA essentially describes the projection of an input space into a low-dimensional output space, with the dimensionality determined by the LoRA rank. In standard LoRA, all input tokens share the same weights and undergo an identical input-output projection. This limits LoRA's ability to capture token-specific information due to the inherent semantic differences among tokens. To address this limitation, we propose Token-wise Projected Low-Rank Adaptation (TopLoRA), which dynamically adjusts LoRA weights according to the input token, thereby learning token-wise input-output projections in an end-to-end manner. Formally, the weights of TopLoRA can be expressed as $B\\Sigma_X A$, where $A$ and $B$ are low-rank matrices (as in standard LoRA), and $\\Sigma_X$ is a diagonal matrix generated from each input token $X$. Notably, TopLoRA does not increase the rank of LoRA weights but achieves more granular adaptation by learning token-wise LoRA weights (i.e., token-wise input-output projections). Extensive experiments across multiple models and datasets demonstrate that TopLoRA consistently outperforms LoRA and its variants. The code is available at https://github.com/Leopold1423/toplora-neurips25.",
    "authors": [
      "Shiwei Li",
      "Xiandi Luo",
      "Haozhao Wang",
      "Xing Tang",
      "Ziqiang Cui",
      "Dugang Liu",
      "Yuhua Li",
      "Xiuqiang He",
      "Ruixuan Li"
    ],
    "categories": [
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23123v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23123v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2510.23117v1",
    "title": "Seeing Structural Failure Before it Happens: An Image-Based   Physics-Informed Neural Network (PINN) for Spaghetti Bridge Load Prediction",
    "summary": "Physics Informed Neural Networks (PINNs) are gaining attention for their ability to embed physical laws into deep learning models, which is particularly useful in structural engineering tasks with limited data. This paper aims to explore the use of PINNs to predict the weight of small scale spaghetti bridges, a task relevant to understanding load limits and potential failure modes in simplified structural models. Our proposed framework incorporates physics-based constraints to the prediction model for improved performance. In addition to standard PINNs, we introduce a novel architecture named Physics Informed Kolmogorov Arnold Network (PIKAN), which blends universal function approximation theory with physical insights. The structural parameters provided as input to the model are collected either manually or through computer vision methods. Our dataset includes 15 real bridges, augmented to 100 samples, and our best model achieves an $R^2$ score of 0.9603 and a mean absolute error (MAE) of 10.50 units. From applied perspective, we also provide a web based interface for parameter entry and prediction. These results show that PINNs can offer reliable estimates of structural weight, even with limited data, and may help inform early stage failure analysis in lightweight bridge designs.   The complete data and code are available at https://github.com/OmerJauhar/PINNS-For-Spaghetti-Bridges.",
    "authors": [
      "Omer Jauhar Khan",
      "Sudais Khan",
      "Hafeez Anwar"
    ],
    "categories": [
      "cs.LG",
      "cs.CV",
      "65M70 (Primary), 68T07 (Secondary)",
      "I.2.6; I.4.8; G.1.8"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23117v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23117v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.67
  },
  {
    "arxiv_id": "2510.23571v1",
    "title": "RobotArena $\\infty$: Scalable Robot Benchmarking via Real-to-Sim   Translation",
    "summary": "The pursuit of robot generalists - instructable agents capable of performing diverse tasks across diverse environments - demands rigorous and scalable evaluation. Yet real-world testing of robot policies remains fundamentally constrained: it is labor-intensive, slow, unsafe at scale, and difficult to reproduce. Existing simulation benchmarks are similarly limited, as they train and test policies within the same synthetic domains and cannot assess models trained from real-world demonstrations or alternative simulation environments. As policies expand in scope and complexity, these barriers only intensify, since defining \"success\" in robotics often hinges on nuanced human judgments of execution quality. In this paper, we introduce a new benchmarking framework that overcomes these challenges by shifting VLA evaluation into large-scale simulated environments augmented with online human feedback. Leveraging advances in vision-language models, 2D-to-3D generative modeling, and differentiable rendering, our approach automatically converts video demonstrations from widely used robot datasets into simulated counterparts. Within these digital twins, we assess VLA policies using both automated VLM-guided scoring and scalable human preference judgments collected from crowdworkers, transforming human involvement from tedious scene setup, resetting, and safety supervision into lightweight preference comparisons. To measure robustness, we systematically perturb simulated environments along multiple axes, such as textures and object placements, stress-testing policy generalization under controlled variation. The result is a continuously evolving, reproducible, and scalable benchmark for real-world trained robot manipulation policies, addressing a critical missing capability in today's robotics landscape.",
    "authors": [
      "Yash Jangir",
      "Yidi Zhang",
      "Kashu Yamazaki",
      "Chenyu Zhang",
      "Kuan-Hsun Tu",
      "Tsung-Wei Ke",
      "Lei Ke",
      "Yonatan Bisk",
      "Katerina Fragkiadaki"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23571v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23571v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2510.23479v1",
    "title": "MergeMix: A Unified Augmentation Paradigm for Visual and Multi-Modal   Understanding",
    "summary": "Vision-language alignment in multi-modal large language models (MLLMs) typically relies on supervised fine-tuning (SFT) or reinforcement learning (RL). SFT is stable and efficient but requires large-scale human annotations and cannot capture subtle preferences, while RL brings in a reward signal for training, but suffers from overhead and instability. These limitations highlight a trade-off between scalability, robustness, and alignment quality. To address this, we propose MergeMix, a training-time augmentation paradigm that bridges SFT and RL. It first applies an attention-aware image mixing via token merge with more cluster representation and spatial context, and then presents a preference-driven training paradigm for MLLMs by building preference pairs with mixed images and raw images, and optimizing via SimPO loss. As a mixup augmentation, MergeMix enhances attention consistency and efficiency, surpassing other heuristic-based methods in classification. Extensive experiments demonstrate that MergeMix achieves competitive accuracy with improved efficiency, providing a scalable approach to preference alignment in classification and MLLMs.",
    "authors": [
      "Xin Jin",
      "Siyuan Li",
      "Siyong Jian",
      "Kai Yu",
      "Huan Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23479v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23479v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2510.23408v1",
    "title": "AutoStreamPipe: LLM Assisted Automatic Generation of Data Stream   Processing Pipelines",
    "summary": "Data pipelines are essential in stream processing as they enable the efficient collection, processing, and delivery of real-time data, supporting rapid data analysis. In this paper, we present AutoStreamPipe, a novel framework that employs Large Language Models (LLMs) to automate the design, generation, and deployment of stream processing pipelines. AutoStreamPipe bridges the semantic gap between high-level user intent and platform-specific implementations across distributed stream processing systems for structured multi-agent reasoning by integrating a Hypergraph of Thoughts (HGoT) as an extended version of GoT. AutoStreamPipe combines resilient execution strategies, advanced query analysis, and HGoT to deliver pipelines with good accuracy. Experimental evaluations on diverse pipelines demonstrate that AutoStreamPipe significantly reduces development time (x6.3) and error rates (x5.19), as measured by a novel Error-Free Score (EFS), compared to LLM code-generation methods.",
    "authors": [
      "Abolfazl Younesi",
      "Zahra Najafabadi Samani",
      "Thomas Fahringer"
    ],
    "categories": [
      "cs.AI",
      "cs.DC",
      "cs.ET",
      "cs.LG",
      "cs.MA"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23408v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23408v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2510.23379v1",
    "title": "Symbolic Neural Generation with Applications to Lead Discovery in Drug   Design",
    "summary": "We investigate a relatively underexplored class of hybrid neurosymbolic models integrating symbolic learning with neural reasoning to construct data generators meeting formal correctness criteria. In \\textit{Symbolic Neural Generators} (SNGs), symbolic learners examine logical specifications of feasible data from a small set of instances -- sometimes just one. Each specification in turn constrains the conditional information supplied to a neural-based generator, which rejects any instance violating the symbolic specification. Like other neurosymbolic approaches, SNG exploits the complementary strengths of symbolic and neural methods. The outcome of an SNG is a triple $(H, X, W)$, where $H$ is a symbolic description of feasible instances constructed from data, $X$ a set of generated new instances that satisfy the description, and $W$ an associated weight. We introduce a semantics for such systems, based on the construction of appropriate \\textit{base} and \\textit{fibre} partially-ordered sets combined into an overall partial order, and outline a probabilistic extension relevant to practical applications. In this extension, SNGs result from searching over a weighted partial ordering. We implement an SNG combining a restricted form of Inductive Logic Programming (ILP) with a large language model (LLM) and evaluate it on early-stage drug design. Our main interest is the description and the set of potential inhibitor molecules generated by the SNG. On benchmark problems -- where drug targets are well understood -- SNG performance is statistically comparable to state-of-the-art methods. On exploratory problems with poorly understood targets, generated molecules exhibit binding affinities on par with leading clinical candidates. Experts further find the symbolic specifications useful as preliminary filters, with several generated molecules identified as viable for synthesis and wet-lab testing.",
    "authors": [
      "Ashwin Srinivasan",
      "A Baskar",
      "Tirtharaj Dash",
      "Michael Bain",
      "Sanjay Kumar Dey",
      "Mainak Banerjee"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NE",
      "q-bio.BM",
      "I.2.6; I.2.1; J.3"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23379v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23379v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2510.23334v1",
    "title": "Adaptive Blockwise Search: Inference-Time Alignment for Large Language   Models",
    "summary": "LLM alignment remains a critical challenge. Inference-time methods provide a flexible alternative to fine-tuning, but their uniform computational effort often yields suboptimal alignment. We hypothesize that for many alignment tasks, the initial tokens of a response are disproportionately more critical. To leverage this principle, we introduce AdaSearch, a novel blockwise search strategy. It adaptively allocates a fixed computational budget using a sampling schedule, focusing search effort on these critical tokens. We apply AdaSearch to sequential decoding and introduce its tree-search counterpart, AdaBeam. Our comprehensive evaluation across eight LLMs demonstrates that AdaSearch outperforms strong Best-of-N and fine-tuning baselines. Specifically, win-rates improve by over 10% for harmlessness generation, controlled sentiment generation, and for mathematical reasoning tasks relative to Best-of-N.",
    "authors": [
      "Mohammad Atif Quamar",
      "Mohammad Areeb",
      "Nishant Sharma",
      "Ananth Shreekumar",
      "Jonathan Rosenthal",
      "Muslum Ozgur Ozmen",
      "Mikhail Kuznetsov",
      "Z. Berkay Celik"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23334v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23334v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2510.23215v1",
    "title": "Accelerating Eigenvalue Dataset Generation via Chebyshev Subspace Filter",
    "summary": "Eigenvalue problems are among the most important topics in many scientific disciplines. With the recent surge and development of machine learning, neural eigenvalue methods have attracted significant attention as a forward pass of inference requires only a tiny fraction of the computation time compared to traditional solvers. However, a key limitation is the requirement for large amounts of labeled data in training, including operators and their eigenvalues. To tackle this limitation, we propose a novel method, named Sorting Chebyshev Subspace Filter (SCSF), which significantly accelerates eigenvalue data generation by leveraging similarities between operators -- a factor overlooked by existing methods. Specifically, SCSF employs truncated fast Fourier transform sorting to group operators with similar eigenvalue distributions and constructs a Chebyshev subspace filter that leverages eigenpairs from previously solved problems to assist in solving subsequent ones, reducing redundant computations. To the best of our knowledge, SCSF is the first method to accelerate eigenvalue data generation. Experimental results show that SCSF achieves up to a $3.5\\times$ speedup compared to various numerical solvers.",
    "authors": [
      "Hong Wang",
      "Jie Wang",
      "Jian Luo",
      "huanshuo dong",
      "Yeqiu Chen",
      "Runmin Jiang",
      "Zhen huang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23215v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23215v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2510.23148v1",
    "title": "Adapting Interleaved Encoders with PPO for Language-Guided Reinforcement   Learning in BabyAI",
    "summary": "Deep reinforcement learning agents often struggle when tasks require understanding both vision and language. Conventional architectures typically isolate perception (for example, CNN-based visual encoders) from decision-making (policy networks). This separation can be inefficient, since the policy's failures do not directly help the perception module learn what is important. To address this, we implement the Perception-Decision Interleaving Transformer (PDiT) architecture introduced by Mao et al. (2023), a model that alternates between perception and decision layers within a single transformer. This interleaving allows feedback from decision-making to refine perceptual features dynamically. In addition, we integrate a contrastive loss inspired by CLIP to align textual mission embeddings with visual scene features. We evaluate the PDiT encoders on the BabyAI GoToLocal environment and find that the approach achieves more stable rewards and stronger alignment compared to a standard PPO baseline. The results suggest that interleaved transformer encoders are a promising direction for developing more integrated autonomous agents.",
    "authors": [
      "Aryan Mathur",
      "Asaduddin Ahmed"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "eess.IV",
      "I.2.6; I.2.9; I.5.4"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23148v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23148v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2510.23140v1",
    "title": "Fast Voxel-Wise Kinetic Modeling in Dynamic PET using a Physics-Informed   CycleGAN",
    "summary": "Tracer kinetic modeling serves a vital role in diagnosis, treatment planning, tracer development and oncology, but burdens practitioners with complex and invasive arterial input function estimation (AIF). We adopt a physics-informed CycleGAN showing promise in DCE-MRI quantification to dynamic PET quantification. Our experiments demonstrate sound AIF predictions and parameter maps closely resembling the reference.",
    "authors": [
      "Christian Salomonsen",
      "Samuel Kuttner",
      "Michael Kampffmeyer",
      "Robert Jenssen",
      "Kristoffer Wickstrøm",
      "Jong Chul Ye",
      "Elisabeth Wetzer"
    ],
    "categories": [
      "cs.CV",
      "q-bio.OT"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23140v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23140v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2510.23131v1",
    "title": "Corpus Frequencies in Morphological Inflection: Do They Matter?",
    "summary": "The traditional approach to morphological inflection (the task of modifying a base word (lemma) to express grammatical categories) has been, for decades, to consider lexical entries of lemma-tag-form triples uniformly, lacking any information about their frequency distribution. However, in production deployment, one might expect the user inputs to reflect a real-world distribution of frequencies in natural texts. With future deployment in mind, we explore the incorporation of corpus frequency information into the task of morphological inflection along three key dimensions during system development: (i) for train-dev-test split, we combine a lemma-disjoint approach, which evaluates the model's generalization capabilities, with a frequency-weighted strategy to better reflect the realistic distribution of items across different frequency bands in training and test sets; (ii) for evaluation, we complement the standard type accuracy (often referred to simply as accuracy), which treats all items equally regardless of frequency, with token accuracy, which assigns greater weight to frequent words and better approximates performance on running text; (iii) for training data sampling, we introduce a method novel in the context of inflection, frequency-aware training, which explicitly incorporates word frequency into the sampling process. We show that frequency-aware training outperforms uniform sampling in 26 out of 43 languages.",
    "authors": [
      "Tomáš Sourada",
      "Jana Straková"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23131v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23131v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2510.23127v1",
    "title": "Lost in Tokenization: Context as the Key to Unlocking Biomolecular   Understanding in Scientific LLMs",
    "summary": "Scientific Large Language Models (Sci-LLMs) have emerged as a promising frontier for accelerating biological discovery. However, these models face a fundamental challenge when processing raw biomolecular sequences: the tokenization dilemma. Whether treating sequences as a specialized language, risking the loss of functional motif information, or as a separate modality, introducing formidable alignment challenges, current strategies fundamentally limit their reasoning capacity. We challenge this sequence-centric paradigm by positing that a more effective strategy is to provide Sci-LLMs with high-level structured context derived from established bioinformatics tools, thereby bypassing the need to interpret low-level noisy sequence data directly. Through a systematic comparison of leading Sci-LLMs on biological reasoning tasks, we tested three input modes: sequence-only, context-only, and a combination of both. Our findings are striking: the context-only approach consistently and substantially outperforms all other modes. Even more revealing, the inclusion of the raw sequence alongside its high-level context consistently degrades performance, indicating that raw sequences act as informational noise, even for models with specialized tokenization schemes. These results suggest that the primary strength of existing Sci-LLMs lies not in their nascent ability to interpret biomolecular syntax from scratch, but in their profound capacity for reasoning over structured, human-readable knowledge. Therefore, we argue for reframing Sci-LLMs not as sequence decoders, but as powerful reasoning engines over expert knowledge. This work lays the foundation for a new class of hybrid scientific AI agents, repositioning the developmental focus from direct sequence interpretation towards high-level knowledge synthesis. The code is available at github.com/opendatalab-raise-dev/CoKE.",
    "authors": [
      "Kai Zhuang",
      "Jiawei Zhang",
      "Yumou Liu",
      "Hanqun Cao",
      "Chunbin Gu",
      "Mengdi Liu",
      "Zhangyang Gao",
      "Zitong Jerry Wang",
      "Xuanhe Zhou",
      "Pheng-Ann Heng",
      "Lijun Wu",
      "Conghui He",
      "Cheng Tan"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23127v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23127v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.66
  },
  {
    "arxiv_id": "2510.23538v1",
    "title": "JanusCoder: Towards a Foundational Visual-Programmatic Interface for   Code Intelligence",
    "summary": "The scope of neural code intelligence is rapidly expanding beyond text-based source code to encompass the rich visual outputs that programs generate. This visual dimension is critical for advanced applications like flexible content generation and precise, program-driven editing of visualizations. However, progress has been impeded by the scarcity of high-quality multimodal code data, a bottleneck stemming from challenges in synthesis and quality assessment. To address these challenges, we make contributions from both a data and modeling perspective. We first introduce a complete synthesis toolkit that leverages reciprocal synergies between data modalities to efficiently produce a large-scale, high-quality corpus spanning from standard charts to complex interactive web UIs and code-driven animations. Leveraging this toolkit, we construct JanusCode-800K, the largest multimodal code corpus to date. This powers the training of our models, JanusCoder and JanusCoderV, which establish a visual-programmatic interface for generating code from textual instructions, visual inputs, or a combination of both. Our unified model is a departure from existing approaches that build specialized models for isolated tasks. Extensive experiments on both text-centric and vision-centric coding tasks demonstrate the superior performance of the JanusCoder series, with our 7B to 14B scale models approaching or even exceeding the performance of commercial models. Furthermore, extensive analysis provides key insights into harmonizing programmatic logic with its visual expression. Our code and checkpoints will are available at https://github.com/InternLM/JanusCoder.",
    "authors": [
      "Qiushi Sun",
      "Jingyang Gong",
      "Yang Liu",
      "Qiaosheng Chen",
      "Lei Li",
      "Kai Chen",
      "Qipeng Guo",
      "Ben Kao",
      "Fei Yuan"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CV",
      "cs.SE"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23538v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23538v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2510.23524v1",
    "title": "Toward Carbon-Neutral Human AI: Rethinking Data, Computation, and   Learning Paradigms for Sustainable Intelligence",
    "summary": "The rapid advancement of Artificial Intelligence (AI) has led to unprecedented computational demands, raising significant environmental and ethical concerns. This paper critiques the prevailing reliance on large-scale, static datasets and monolithic training paradigms, advocating for a shift toward human-inspired, sustainable AI solutions. We introduce a novel framework, Human AI (HAI), which emphasizes incremental learning, carbon-aware optimization, and human-in-the-loop collaboration to enhance adaptability, efficiency, and accountability. By drawing parallels with biological cognition and leveraging dynamic architectures, HAI seeks to balance performance with ecological responsibility. We detail the theoretical foundations, system design, and operational principles that enable AI to learn continuously and contextually while minimizing carbon footprints and human annotation costs. Our approach addresses pressing challenges in active learning, continual adaptation, and energy-efficient model deployment, offering a pathway toward responsible, human-centered artificial intelligence.",
    "authors": [
      "KC Santosh",
      "Rodrigue Rizk",
      "Longwei Wang"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23524v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23524v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2510.23427v1",
    "title": "PrivacyGuard: A Modular Framework for Privacy Auditing in Machine   Learning",
    "summary": "The increasing deployment of Machine Learning (ML) models in sensitive domains motivates the need for robust, practical privacy assessment tools. PrivacyGuard is a comprehensive tool for empirical differential privacy (DP) analysis, designed to evaluate privacy risks in ML models through state-of-the-art inference attacks and advanced privacy measurement techniques. To this end, PrivacyGuard implements a diverse suite of privacy attack-- including membership inference , extraction, and reconstruction attacks -- enabling both off-the-shelf and highly configurable privacy analyses. Its modular architecture allows for the seamless integration of new attacks, and privacy metrics, supporting rapid adaptation to emerging research advances. We make PrivacyGuard available at https://github.com/facebookresearch/PrivacyGuard.",
    "authors": [
      "Luca Melis",
      "Matthew Grange",
      "Iden Kalemaj",
      "Karan Chadha",
      "Shengyuan Hu",
      "Elena Kashtelyan",
      "Will Bullock"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23427v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23427v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2510.23320v1",
    "title": "LibriConvo: Simulating Conversations from Read Literature for ASR and   Diarization",
    "summary": "We introduce LibriConvo, a simulated multi-speaker conversational dataset based on speaker-aware conversation simulation (SASC), designed to support training and evaluation of speaker diarization and automatic speech recognition (ASR) systems. Unlike prior resources that mostly rely on semantically disconnected utterances and implausible temporal gaps, LibriConvo ensures semantic coherence and realistic conversational timing. Our pipeline leverages CallHome with external VAD for reliable boundaries, applies compression to reduce unnaturally long silences, and organizes LibriTTS utterances by book to maintain contextual consistency. Acoustic realism is enhanced via a novel room impulse response selection procedure that ranks speaker-microphone configurations by spatial plausibility, balancing realism and diversity. The dataset comprises 240.1 hours across 1,496 dialogues with 830 unique speakers, split in a speaker-disjoint manner for robust evaluation. Baselines show that the sortformer model outperforms the pyannote pipeline in diarization, while a fine-tuned Fast Conformer-CTC XLarge with Serialized Output Training achieves 7.29\\% WER for ASR, surpassing zero-shot Whisper-large-v3. LibriConvo provides a valuable resource for advancing multi-speaker speech processing research with realistic conversational dynamics and controlled experimental conditions.",
    "authors": [
      "Máté Gedeon",
      "Péter Mihajlik"
    ],
    "categories": [
      "eess.AS",
      "cs.CL",
      "cs.SD"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23320v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23320v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2510.23241v1",
    "title": "Progressive Growing of Patch Size: Curriculum Learning for Accelerated   and Improved Medical Image Segmentation",
    "summary": "In this work, we introduce Progressive Growing of Patch Size, an automatic curriculum learning approach for 3D medical image segmentation. Our approach progressively increases the patch size during model training, resulting in an improved class balance for smaller patch sizes and accelerated convergence of the training process. We evaluate our curriculum approach in two settings: a resource-efficient mode and a performance mode, both regarding Dice score performance and computational costs across 15 diverse and popular 3D medical image segmentation tasks. The resource-efficient mode matches the Dice score performance of the conventional constant patch size sampling baseline with a notable reduction in training time to only 44%. The performance mode improves upon constant patch size segmentation results, achieving a statistically significant relative mean performance gain of 1.28% in Dice Score. Remarkably, across all 15 tasks, our proposed performance mode manages to surpass the constant patch size baseline in Dice Score performance, while simultaneously reducing training time to only 89%. The benefits are particularly pronounced for highly imbalanced tasks such as lesion segmentation tasks. Rigorous experiments demonstrate that our performance mode not only improves mean segmentation performance but also reduces performance variance, yielding more trustworthy model comparison. Furthermore, our findings reveal that the proposed curriculum sampling is not tied to a specific architecture but represents a broadly applicable strategy that consistently boosts performance across diverse segmentation models, including UNet, UNETR, and SwinUNETR. In summary, we show that this simple yet elegant transformation on input data substantially improves both Dice Score performance and training runtime, while being compatible across diverse segmentation backbones.",
    "authors": [
      "Stefan M. Fischer",
      "Johannes Kiechle",
      "Laura Daza",
      "Lina Felsner",
      "Richard Osuala",
      "Daniel M. Lang",
      "Karim Lekadir",
      "Jan C. Peeken",
      "Julia A. Schnabel"
    ],
    "categories": [
      "cs.CV",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23241v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23241v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.65
  },
  {
    "arxiv_id": "2510.23588v1",
    "title": "FARMER: Flow AutoRegressive Transformer over Pixels",
    "summary": "Directly modeling the explicit likelihood of the raw data distribution is key topic in the machine learning area, which achieves the scaling successes in Large Language Models by autoregressive modeling. However, continuous AR modeling over visual pixel data suffer from extremely long sequences and high-dimensional spaces. In this paper, we present FARMER, a novel end-to-end generative framework that unifies Normalizing Flows (NF) and Autoregressive (AR) models for tractable likelihood estimation and high-quality image synthesis directly from raw pixels. FARMER employs an invertible autoregressive flow to transform images into latent sequences, whose distribution is modeled implicitly by an autoregressive model. To address the redundancy and complexity in pixel-level modeling, we propose a self-supervised dimension reduction scheme that partitions NF latent channels into informative and redundant groups, enabling more effective and efficient AR modeling. Furthermore, we design a one-step distillation scheme to significantly accelerate inference speed and introduce a resampling-based classifier-free guidance algorithm to boost image generation quality. Extensive experiments demonstrate that FARMER achieves competitive performance compared to existing pixel-based generative models while providing exact likelihoods and scalable training.",
    "authors": [
      "Guangting Zheng",
      "Qinyu Zhao",
      "Tao Yang",
      "Fei Xiao",
      "Zhijie Lin",
      "Jie Wu",
      "Jiajun Deng",
      "Yanyong Zhang",
      "Rui Zhu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23588v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23588v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.23564v1",
    "title": "ReCode: Unify Plan and Action for Universal Granularity Control",
    "summary": "Real-world tasks require decisions at varying granularities, and humans excel at this by leveraging a unified cognitive representation where planning is fundamentally understood as a high-level form of action. However, current Large Language Model (LLM)-based agents lack this crucial capability to operate fluidly across decision granularities. This limitation stems from existing paradigms that enforce a rigid separation between high-level planning and low-level action, which impairs dynamic adaptability and limits generalization. We propose ReCode (Recursive Code Generation), a novel paradigm that addresses this limitation by unifying planning and action within a single code representation. In this representation, ReCode treats high-level plans as abstract placeholder functions, which the agent then recursively decomposes into finer-grained sub-functions until reaching primitive actions. This recursive approach dissolves the rigid boundary between plan and action, enabling the agent to dynamically control its decision granularity. Furthermore, the recursive structure inherently generates rich, multi-granularity training data, enabling models to learn hierarchical decision-making processes. Extensive experiments show ReCode significantly surpasses advanced baselines in inference performance and demonstrates exceptional data efficiency in training, validating our core insight that unifying planning and action through recursive code generation is a powerful and effective approach to achieving universal granularity control. The code is available at https://github.com/FoundationAgents/ReCode.",
    "authors": [
      "Zhaoyang Yu",
      "Jiayi Zhang",
      "Huixue Su",
      "Yufan Zhao",
      "Yifan Wu",
      "Mingyi Deng",
      "Jinyu Xiang",
      "Yizhang Lin",
      "Lingxiao Tang",
      "Yingchao Li",
      "Yuyu Luo",
      "Bang Liu",
      "Chenglin Wu"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23564v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23564v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.23557v1",
    "title": "Minimizing Human Intervention in Online Classification",
    "summary": "We introduce and study an online problem arising in question answering systems. In this problem, an agent must sequentially classify user-submitted queries represented by $d$-dimensional embeddings drawn i.i.d. from an unknown distribution. The agent may consult a costly human expert for the correct label, or guess on her own without receiving feedback. The goal is to minimize regret against an oracle with free expert access. When the time horizon $T$ is at least exponential in the embedding dimension $d$, one can learn the geometry of the class regions: in this regime, we propose the Conservative Hull-based Classifier (CHC), which maintains convex hulls of expert-labeled queries and calls the expert as soon as a query lands outside all known hulls. CHC attains $\\mathcal{O}(\\log^d T)$ regret in $T$ and is minimax optimal for $d=1$. Otherwise, the geometry cannot be reliably learned without additional distributional assumptions. We show that when the queries are drawn from a subgaussian mixture, for $T \\le e^d$, a Center-based Classifier (CC) achieves regret proportional to $N\\log{N}$ where $N$ is the number of labels. To bridge these regimes, we introduce the Generalized Hull-based Classifier (GHC), a practical extension of CHC that allows for more aggressive guessing via a tunable threshold parameter. Our approach is validated with experiments, notably on real-world question-answering datasets using embeddings derived from state-of-the-art large language models.",
    "authors": [
      "William Réveillard",
      "Vasileios Saketos",
      "Alexandre Proutiere",
      "Richard Combes"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23557v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23557v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.23455v1",
    "title": "SGFusion: Stochastic Geographic Gradient Fusion in Federated Learning",
    "summary": "This paper proposes Stochastic Geographic Gradient Fusion (SGFusion), a novel training algorithm to leverage the geographic information of mobile users in Federated Learning (FL). SGFusion maps the data collected by mobile devices onto geographical zones and trains one FL model per zone, which adapts well to the data and behaviors of users in that zone. SGFusion models the local data-based correlation among geographical zones as a hierarchical random graph (HRG) optimized by Markov Chain Monte Carlo sampling. At each training step, every zone fuses its local gradient with gradients derived from a small set of other zones sampled from the HRG. This approach enables knowledge fusion and sharing among geographical zones in a probabilistic and stochastic gradient fusion process with self-attention weights, such that \"more similar\" zones have \"higher probabilities\" of sharing gradients with \"larger attention weights.\" SGFusion remarkably improves model utility without introducing undue computational cost. Extensive theoretical and empirical results using a heart-rate prediction dataset collected across 6 countries show that models trained with SGFusion converge with upper-bounded expected errors and significantly improve utility in all countries compared to existing approaches without notable cost in system scalability.",
    "authors": [
      "Khoa Nguyen",
      "Khang Tran",
      "NhatHai Phan",
      "Cristian Borcea",
      "Rouming Jin",
      "Issa Khalil"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23455v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23455v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.23424v1",
    "title": "Causal Deep Q Network",
    "summary": "Deep Q Networks (DQN) have shown remarkable success in various reinforcement learning tasks. However, their reliance on associative learning often leads to the acquisition of spurious correlations, hindering their problem-solving capabilities. In this paper, we introduce a novel approach to integrate causal principles into DQNs, leveraging the PEACE (Probabilistic Easy vAriational Causal Effect) formula for estimating causal effects. By incorporating causal reasoning during training, our proposed framework enhances the DQN's understanding of the underlying causal structure of the environment, thereby mitigating the influence of confounding factors and spurious correlations. We demonstrate that integrating DQNs with causal capabilities significantly enhances their problem-solving capabilities without compromising performance. Experimental results on standard benchmark environments showcase that our approach outperforms conventional DQNs, highlighting the effectiveness of causal reasoning in reinforcement learning. Overall, our work presents a promising avenue for advancing the capabilities of deep reinforcement learning agents through principled causal inference.",
    "authors": [
      "Elouanes Khelifi",
      "Amir Saki",
      "Usef Faghihi"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23424v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23424v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.23364v1",
    "title": "ZeroFlood: A Geospatial Foundation Model for Data-Efficient Flood   Susceptibility Mapping",
    "summary": "Flood susceptibility mapping (FSM) is vital for disaster prevention but remains challenging in data-scarce regions where hydrodynamic models require dense geophysical inputs. This work introduces ZeroFlood, a geospatial foundation model framework for data-efficient FSM. The approach fine-tunes Geospatial Foundation Models (GFMs) with Thinking-in-Modality (TiM) reasoning, enabling flood prediction from basic Earth observation data such as Sentinel-1 or Sentinel-2 imagery. Using paired EO and simulated flood maps from data-rich regions, ZeroFlood bridges data availability gaps through cross-modal representation learning. Experiments with TerraMind and Prithvi GFMs show that TiM enhances model robustness, with the TerraMind-Large configuration achieving an F1 score of 67.21. The results demonstrate the feasibility of foundation-model-based FSM as a scalable and data-efficient solution for flood risk management.",
    "authors": [
      "Hyeongkyun Kim",
      "Orestis Oikonomou"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23364v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23364v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.23346v1",
    "title": "Block-Diagonal LoRA for Eliminating Communication Overhead in Tensor   Parallel LoRA Serving",
    "summary": "When serving a single base LLM with several different LoRA adapters simultaneously, the adapters cannot simply be merged with the base model's weights as the adapter swapping would create overhead and requests using different adapters could not be batched. Rather, the LoRA computations have to be separated from the base LLM computations, and in a multi-device setup the LoRA adapters can be sharded in a way that is well aligned with the base model's tensor parallel execution, as proposed in S-LoRA. However, the S-LoRA sharding strategy encounters some communication overhead, which may be small in theory, but can be large in practice. In this paper, we propose to constrain certain LoRA factors to be block-diagonal, which allows for an alternative way of sharding LoRA adapters that does not require any additional communication for the LoRA computations. We demonstrate in extensive experiments that our block-diagonal LoRA approach is similarly parameter efficient as standard LoRA (i.e., for a similar number of parameters it achieves similar downstream performance) and that it leads to significant end-to-end speed-up over S-LoRA. For example, when serving on eight A100 GPUs, we observe up to 1.79x (1.23x) end-to-end speed-up with 0.87x (1.74x) the number of adapter parameters for Llama-3.1-70B, and up to 1.63x (1.3x) end-to-end speed-up with 0.86x (1.73x) the number of adapter parameters for Llama-3.1-8B.",
    "authors": [
      "Xinyu Wang",
      "Jonas M. Kübler",
      "Kailash Budhathoki",
      "Yida Wang",
      "Matthäus Kleindessner"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23346v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23346v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.23340v1",
    "title": "Planning Ahead with RSA: Efficient Signalling in Dynamic Environments by   Projecting User Awareness across Future Timesteps",
    "summary": "Adaptive agent design offers a way to improve human-AI collaboration on time-sensitive tasks in rapidly changing environments. In such cases, to ensure the human maintains an accurate understanding of critical task elements, an assistive agent must not only identify the highest priority information but also estimate how and when this information can be communicated most effectively, given that human attention represents a zero-sum cognitive resource where focus on one message diminishes awareness of other or upcoming information. We introduce a theoretical framework for adaptive signalling which meets these challenges by using principles of rational communication, formalised as Bayesian reference resolution using the Rational Speech Act (RSA) modelling framework, to plan a sequence of messages which optimise timely alignment between user belief and a dynamic environment. The agent adapts message specificity and timing to the particulars of a user and scenario based on projections of how prior-guided interpretation of messages will influence attention to the interface and subsequent belief update, across several timesteps out to a fixed horizon. In a comparison to baseline methods, we show that this effectiveness depends crucially on combining multi-step planning with a realistic model of user awareness. As the first application of RSA for communication in a dynamic environment, and for human-AI interaction in general, we establish theoretical foundations for pragmatic communication in human-agent teams, highlighting how insights from cognitive science can be capitalised to inform the design of assistive agents.",
    "authors": [
      "Anwesha Das",
      "John Duff",
      "Jörg Hoffmann",
      "Vera Demberg"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.HC"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23340v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23340v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.23337v1",
    "title": "BaZi-Based Character Simulation Benchmark: Evaluating AI on Temporal and   Persona Reasoning",
    "summary": "Human-like virtual characters are crucial for games, storytelling, and virtual reality, yet current methods rely heavily on annotated data or handcrafted persona prompts, making it difficult to scale up and generate realistic, contextually coherent personas. We create the first QA dataset for BaZi-based persona reasoning, where real human experiences categorized into wealth, health, kinship, career, and relationships are represented as life-event questions and answers. Furthermore, we propose the first BaZi-LLM system that integrates symbolic reasoning with large language models to generate temporally dynamic and fine-grained virtual personas. Compared with mainstream LLMs such as DeepSeek-v3 and GPT-5-mini, our method achieves a 30.3%-62.6% accuracy improvement. In addition, when incorrect BaZi information is used, our model's accuracy drops by 20%-45%, showing the potential of culturally grounded symbolic-LLM integration for realistic character simulation.",
    "authors": [
      "Siyuan Zheng",
      "Pai Liu",
      "Xi Chen",
      "Jizheng Dong",
      "Sihan Jia"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23337v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23337v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.23304v1",
    "title": "CNOT Minimal Circuit Synthesis: A Reinforcement Learning Approach",
    "summary": "CNOT gates are fundamental to quantum computing, as they facilitate entanglement, a crucial resource for quantum algorithms. Certain classes of quantum circuits are constructed exclusively from CNOT gates. Given their widespread use, it is imperative to minimise the number of CNOT gates employed. This problem, known as CNOT minimisation, remains an open challenge, with its computational complexity yet to be fully characterised. In this work, we introduce a novel reinforcement learning approach to address this task. Instead of training multiple reinforcement learning agents for different circuit sizes, we use a single agent up to a fixed size $m$. Matrices of sizes different from m are preprocessed using either embedding or Gaussian striping. To assess the efficacy of our approach, we trained an agent with m = 8, and evaluated it on matrices of size n that range from 3 to 15. The results we obtained show that our method overperforms the state-of-the-art algorithm as the value of n increases.",
    "authors": [
      "Riccardo Romanello",
      "Daniele Lizzio Bosco",
      "Jacopo Cossio",
      "Dusan Sutulovic",
      "Giuseppe Serra",
      "Carla Piazza",
      "Paolo Burelli"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23304v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23304v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.23237v1",
    "title": "Robust Iterative Learning Hidden Quantum Markov Models",
    "summary": "Hidden Quantum Markov Models (HQMMs) extend classical Hidden Markov Models to the quantum domain, offering a powerful probabilistic framework for modeling sequential data with quantum coherence. However, existing HQMM learning algorithms are highly sensitive to data corruption and lack mechanisms to ensure robustness under adversarial perturbations. In this work, we introduce the Adversarially Corrupted HQMM (AC-HQMM), which formalizes robustness analysis by allowing a controlled fraction of observation sequences to be adversarially corrupted. To learn AC-HQMMs, we propose the Robust Iterative Learning Algorithm (RILA), a derivative-free method that integrates a Remove Corrupted Rows by Entropy Filtering (RCR-EF) module with an iterative stochastic resampling procedure for physically valid Kraus operator updates. RILA incorporates L1-penalized likelihood objectives to enhance stability, resist overfitting, and remain effective under non-differentiable conditions. Across multiple HQMM and HMM benchmarks, RILA demonstrates superior convergence stability, corruption resilience, and preservation of physical validity compared to existing algorithms, establishing a principled and efficient approach for robust quantum sequential learning.",
    "authors": [
      "Ning Ning"
    ],
    "categories": [
      "cs.LG",
      "quant-ph",
      "stat.CO",
      "stat.ME",
      "stat.ML"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23237v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23237v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.23074v1",
    "title": "Fast-MIA: Efficient and Scalable Membership Inference for LLMs",
    "summary": "We propose Fast-MIA (https://github.com/Nikkei/fast-mia), a Python library for efficiently evaluating membership inference attacks (MIA) against Large Language Models (LLMs). MIA against LLMs has emerged as a crucial challenge due to growing concerns over copyright, security, and data privacy, and has attracted increasing research attention. However, the progress of this research is significantly hindered by two main obstacles: (1) the high computational cost of inference in LLMs, and (2) the lack of standardized and maintained implementations of MIA methods, which makes large-scale empirical comparison difficult. To address these challenges, our library provides fast batch inference and includes implementations of representative MIA methods under a unified evaluation framework. This library supports easy implementation of reproducible benchmarks with simple configuration and extensibility. We release Fast-MIA as an open-source (Apache License 2.0) tool to support scalable and transparent research on LLMs.",
    "authors": [
      "Hiromu Takahashi",
      "Shotaro Ishihara"
    ],
    "categories": [
      "cs.CR",
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23074v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23074v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.64
  },
  {
    "arxiv_id": "2510.23449v1",
    "title": "Schrodinger Neural Network and Uncertainty Quantification: Quantum   Machine",
    "summary": "We introduce the Schrodinger Neural Network (SNN), a principled architecture for conditional density estimation and uncertainty quantification inspired by quantum mechanics. The SNN maps each input to a normalized wave function on the output domain and computes predictive probabilities via the Born rule. The SNN departs from standard parametric likelihood heads by learning complex coefficients of a spectral expansion (e . g ., Chebyshev polynomials) whose squared modulus yields the conditional density $p(y|x)=\\left| \\psi _x(y)\\right| {}^2$ with analytic normalization. This representation confers three practical advantages: positivity and exact normalization by construction, native multimodality through interference among basis modes without explicit mixture bookkeeping, and yields closed-form (or efficiently computable) functionals$-$such as moments and several calibration diagnostics$-$as quadratic forms in coefficient space. We develop the statistical and computational foundations of the SNN, including (i) training by exact maximum-likelihood with unit-sphere coefficient parameterization, (ii) physics-inspired quadratic regularizers (kinetic and potential energies) motivated by uncertainty relations between localization and spectral complexity, (iii) scalable low-rank and separable extensions for multivariate outputs, (iv) operator-based extensions that represent observables, constraints, and weak labels as self-adjoint matrices acting on the amplitude space, and (v) a comprehensive framework for evaluating multimodal predictions. The SNN provides a coherent, tractable framework to elevate probabilistic prediction from point estimates to physically inspired amplitude-based distributions.",
    "authors": [
      "M. M. Hammad"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23449v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23449v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2510.23397v1",
    "title": "VideoTG-R1: Boosting Video Temporal Grounding via Curriculum   Reinforcement Learning on Reflected Boundary Annotations",
    "summary": "Video temporal grounding (VTG) aims to locate precise segments in videos based on language queries, which is a fundamental challenge in video understanding. While recent Multimodal Large Language Models (MLLMs) have shown promise in tackling VTG through reinforcement learning (RL), they overlook the challenges arising from both the quality and difficulty of training samples. (1) Partially annotated samples. Many samples contain relevant segments beyond the annotated interval, introducing ambiguous supervision. (2) Hard-to-ground samples. Samples with poor zero-shot performance produce consistently low and indistinguishable rewards during RL training, exhibiting no clear preference among multiple outputs and thus hindering learning efficiency. To address these challenges, we propose VideoTG-R1, a novel curriculum RL framework with reflected boundary annotations, enabling data-efficient training. Specifically, we propose a Boundary Reflection Agent that utilizes MLLMs to predict query-relevant timestamps outside the annotated intervals, allowing us to identify and filter out partially annotated samples, thereby reducing ambiguity. Furthermore, we introduce a Difficulty Estimation Agent to assess the training difficulty of each sample and design a curriculum RL strategy that dynamically masks the videos of hard-to-ground samples according to the training steps, easing the training difficulty and providing clearer preference. Experiments on the VTG and grounded VideoQA tasks demonstrate the effectiveness of our method. Remarkably, with only 10% of the training samples and 21% of the computational budget, VideoTG-R1 outperforms full-data counterparts under both group relative policy optimization (GRPO) and supervised fine-tuning (SFT). The code is available at https://github.com/ldong1111/VideoTG-R1.",
    "authors": [
      "Lu Dong",
      "Haiyu Zhang",
      "Han Lin",
      "Ziang Yan",
      "Xiangyu Zeng",
      "Hongjie Zhang",
      "Yifei Huang",
      "Yi Wang",
      "Zhen-Hua Ling",
      "Limin Wang",
      "Yali Wang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23397v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23397v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2510.23264v1",
    "title": "PAHQ: Accelerating Automated Circuit Discovery through Mixed-Precision   Inference Optimization",
    "summary": "Circuit discovery, which involves identifying sparse and task-relevant subnetworks in pre-trained language models, is a cornerstone of mechanistic interpretability. Automated Circuit Discovery (ACDC) has emerged as a pivotal methodology in circuit discovery, but its application to large language models is severely limited by computational inefficiency and prohibitively high memory requirements. Although several accelerated approaches have been proposed, they primarily rely on linear approximations to ACDC, which significantly compromises analytical faithfulness. Our proposed method for accelerating automated circuit discovery, Per Attention Head Quantization (PAHQ), takes a fundamentally different approach by optimizing the efficiency of each individual patching operation. PAHQ leverages a fundamental alignment between activation patching and mixed-precision quantization (MPQ): interpretability analysis through patching essentially performs targeted ablation studies. Therefore, we can maintain high precision exclusively for investigated components while safely reducing precision elsewhere in the network. PAHQ-accelerated ACDC reduces runtime by up to 80\\% and memory consumption by up to 30\\% compared to unaccelerated ACDC while maintaining faithfulness. Importantly, our method readily integrates with existing edge-based circuit discovery techniques by modifying the attention computation mechanism. This training-free approach provides a practical and novel pathway for accelerating mechanistic interpretability methods. Our code is available at https://github.com/626619403/PAHQ.",
    "authors": [
      "Xinhai Wang",
      "Shu Yang",
      "Liangyu Wang",
      "Lin Zhang",
      "Huanyi Xie",
      "Lijie Hu",
      "Di Wang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23264v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23264v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2510.23160v1",
    "title": "ENTP: Enhancing Low-Quality SFT Data via Neural-Symbolic Text Purge-Mix",
    "summary": "Supervised Fine-Tuning (SFT) adapts pre-trained Large Language Models (LLMs) to domain-specific instructions by training on a carefully curated subset of high-quality instruction-response pairs, typically drawn from a larger dataset that often contains many low-quality or noisy samples. However, existing quality-first paradigms often overlook valuable signals in discarded low-quality data and rely on imperfect quality filters. We introduce ENTP (Enhancing low-quality SFT data via Neural-symbolic Text Purge-Mix), a framework that revitalizes low-quality corpora through symbolic purification and neural reconstruction. The symbolic module identifies and prunes noisy samples based on statistical priors, while the neural component synthesizes enriched instruction-response pairs by leveraging latent representations and model knowledge. This neural-symbolic synergy enhances data informativeness and diversity. Experiments show that ENTP-augmented datasets, constructed exclusively from low-quality data, outperform 13 established data-selection baselines across five instruction-following benchmarks, and even surpass fine-tuning on the full original dataset (approximately 300K examples). Our results highlight the untapped potential of low-quality data and underscore the importance of intelligent purification and synthesis for efficient instruction alignment.",
    "authors": [
      "Zile Yang",
      "Ling Li",
      "Na Di",
      "Jinlong Pang",
      "Yao Zhou",
      "Hao Cheng",
      "Bo Han",
      "Jiaheng Wei"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23160v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23160v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2510.23114v1",
    "title": "Flexing in 73 Languages: A Single Small Model for Multilingual   Inflection",
    "summary": "We present a compact, single-model approach to multilingual inflection, the task of generating inflected word forms from base lemmas to express grammatical categories. Our model, trained jointly on data from 73 languages, is lightweight, robust to unseen words, and outperforms monolingual baselines in most languages. This demonstrates the effectiveness of multilingual modeling for inflection and highlights its practical benefits: simplifying deployment by eliminating the need to manage and retrain dozens of separate monolingual models. In addition to the standard SIGMORPHON shared task benchmarks, we evaluate our monolingual and multilingual models on 73 Universal Dependencies (UD) treebanks, extracting lemma-tag-form triples and their frequency counts. To ensure realistic data splits, we introduce a novel frequency-weighted, lemma-disjoint train-dev-test resampling procedure. Our work addresses the lack of an open-source, general-purpose, multilingual morphological inflection system capable of handling unseen words across a wide range of languages, including Czech. All code is publicly released at: https://github.com/tomsouri/multilingual-inflection.",
    "authors": [
      "Tomáš Sourada",
      "Jana Straková"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23114v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23114v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.63
  },
  {
    "arxiv_id": "2510.23569v1",
    "title": "EgoThinker: Unveiling Egocentric Reasoning with Spatio-Temporal CoT",
    "summary": "Egocentric video reasoning centers on an unobservable agent behind the camera who dynamically shapes the environment, requiring inference of hidden intentions and recognition of fine-grained interactions. This core challenge limits current multimodal large language models MLLMs, which excel at visible event reasoning but lack embodied, first-person understanding. To bridge this gap, we introduce EgoThinker, a novel framework that endows MLLMs with robust egocentric reasoning capabilities through spatio-temporal chain-of-thought supervision and a two-stage learning curriculum. First, we introduce EgoRe-5M, a large-scale egocentric QA dataset constructed from 13M diverse egocentric video clips. This dataset features multi-minute segments annotated with detailed CoT rationales and dense hand-object grounding. Second, we employ SFT on EgoRe-5M to instill reasoning skills, followed by reinforcement fine-tuning RFT to further enhance spatio-temporal localization. Experimental results show that EgoThinker outperforms existing methods across multiple egocentric benchmarks, while achieving substantial improvements in fine-grained spatio-temporal localization tasks. Full code and data are released at https://github.com/InternRobotics/EgoThinker.",
    "authors": [
      "Baoqi Pei",
      "Yifei Huang",
      "Jilan Xu",
      "Yuping He",
      "Guo Chen",
      "Fei Wu",
      "Yu Qiao",
      "Jiangmiao Pang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23569v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23569v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.23558v1",
    "title": "ISA-Bench: Benchmarking Instruction Sensitivity for Large Audio Language   Models",
    "summary": "Large Audio Language Models (LALMs), which couple acoustic perception with large language models (LLMs) to extract and understand diverse information from audio, have attracted intense interest from both academic and industrial communities. However, existing LALMs are highly sensitive to how instructions are phrased, affecting both (i) instruction-following rates and (ii) task performance. Yet, no existing benchmarks offer a systematic and comprehensive evaluation of this sensitivity. We introduce ISA-Bench, a dynamic benchmark evaluating instruction sensitivity for LALMs along three axes: instruction description, output format, and task composition. We assess recent open-source and proprietary LALMs using ISA-Bench, profiling both compliance and accuracy under controlled instruction variations. Experimental results reveal that even state-of-the-art LALMs suffer significant instruction sensitivity, leading to degraded performance on fundamental audio understanding tasks. To mitigate this issue, we fine-tune Qwen2-Audio on a specifically constructed complex instruction-variant dataset, achieving a marked improvement in instruction-following performance. However, this also induces nontrivial catastrophic forgetting: the model loses some previously mastered task capabilities when exposed to new instruction styles. Our benchmark provides a standardized basis for assessing and improving instruction sensitivity in LALMs, underscoring the need for instruction-robust audio understanding in real-world pipelines.",
    "authors": [
      "Bohan Li",
      "Wenbin Huang",
      "Yuhang Qiu",
      "Yiwei Guo",
      "Hankun Wang",
      "Zhihan Li",
      "Jing Peng",
      "Ziyang Ma",
      "Xie Chen",
      "Kai Yu"
    ],
    "categories": [
      "cs.SD",
      "cs.CL",
      "eess.AS"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23558v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23558v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.23554v1",
    "title": "A U-Net and Transformer Pipeline for Multilingual Image Translation",
    "summary": "This paper presents an end-to-end multilingual translation pipeline that integrates a custom U-Net for text detection, the Tesseract engine for text recognition, and a from-scratch sequence-to-sequence (Seq2Seq) Transformer for Neural Machine Translation (NMT). Our approach first utilizes a U-Net model, trained on a synthetic dataset , to accurately segment and detect text regions from an image. These detected regions are then processed by Tesseract to extract the source text. This extracted text is fed into a custom Transformer model trained from scratch on a multilingual parallel corpus spanning 5 languages. Unlike systems reliant on monolithic pre-trained models, our architecture emphasizes full customization and adaptability. The system is evaluated on its text detection accuracy, text recognition quality, and translation performance via BLEU scores. The complete pipeline demonstrates promising results, validating the viability of a custom-built system for translating text directly from images.",
    "authors": [
      "Siddharth Sahay",
      "Radhika Agarwal"
    ],
    "categories": [
      "cs.LG",
      "cs.CL",
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23554v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23554v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.23473v1",
    "title": "Video-Thinker: Sparking \"Thinking with Videos\" via Reinforcement   Learning",
    "summary": "Recent advances in image reasoning methods, particularly \"Thinking with Images\", have demonstrated remarkable success in Multimodal Large Language Models (MLLMs); however, this dynamic reasoning paradigm has not yet been extended to video reasoning tasks. In this paper, we propose Video-Thinker, which empowers MLLMs to think with videos by autonomously leveraging their intrinsic \"grounding\" and \"captioning\" capabilities to generate reasoning clues throughout the inference process. To spark this capability, we construct Video-Thinker-10K, a curated dataset featuring autonomous tool usage within chain-of-thought reasoning sequences. Our training strategy begins with Supervised Fine-Tuning (SFT) to learn the reasoning format, followed by Group Relative Policy Optimization (GRPO) to strengthen this reasoning capability. Through this approach, Video-Thinker enables MLLMs to autonomously navigate grounding and captioning tasks for video reasoning, eliminating the need for constructing and calling external tools. Extensive experiments demonstrate that Video-Thinker achieves significant performance gains on both in-domain tasks and challenging out-of-domain video reasoning benchmarks, including Video-Holmes, CG-Bench-Reasoning, and VRBench. Our Video-Thinker-7B substantially outperforms existing baselines such as Video-R1 and establishes state-of-the-art performance among 7B-sized MLLMs.",
    "authors": [
      "Shijian Wang",
      "Jiarui Jin",
      "Xingjian Wang",
      "Linxin Song",
      "Runhao Fu",
      "Hecheng Wang",
      "Zongyuan Ge",
      "Yuan Lu",
      "Xuelian Cheng"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23473v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23473v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.23442v1",
    "title": "CURVETE: Curriculum Learning and Progressive Self-supervised Training   for Medical Image Classification",
    "summary": "Identifying high-quality and easily accessible annotated samples poses a notable challenge in medical image analysis. Transfer learning techniques, leveraging pre-training data, offer a flexible solution to this issue. However, the impact of fine-tuning diminishes when the dataset exhibits an irregular distribution between classes. This paper introduces a novel deep convolutional neural network, named Curriculum Learning and Progressive Self-supervised Training (CURVETE). CURVETE addresses challenges related to limited samples, enhances model generalisability, and improves overall classification performance. It achieves this by employing a curriculum learning strategy based on the granularity of sample decomposition during the training of generic unlabelled samples. Moreover, CURVETE address the challenge of irregular class distribution by incorporating a class decomposition approach in the downstream task. The proposed method undergoes evaluation on three distinct medical image datasets: brain tumour, digital knee x-ray, and Mini-DDSM datasets. We investigate the classification performance using a generic self-supervised sample decomposition approach with and without the curriculum learning component in training the pretext task. Experimental results demonstrate that the CURVETE model achieves superior performance on test sets with an accuracy of 96.60% on the brain tumour dataset, 75.60% on the digital knee x-ray dataset, and 93.35% on the Mini-DDSM dataset using the baseline ResNet-50. Furthermore, with the baseline DenseNet-121, it achieved accuracies of 95.77%, 80.36%, and 93.22% on the brain tumour, digital knee x-ray, and Mini-DDSM datasets, respectively, outperforming other training strategies.",
    "authors": [
      "Asmaa Abbas",
      "Mohamed Gaber",
      "Mohammed M. Abdelsamea"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23442v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23442v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.23205v1",
    "title": "VR-Drive: Viewpoint-Robust End-to-End Driving with Feed-Forward 3D   Gaussian Splatting",
    "summary": "End-to-end autonomous driving (E2E-AD) has emerged as a promising paradigm that unifies perception, prediction, and planning into a holistic, data-driven framework. However, achieving robustness to varying camera viewpoints, a common real-world challenge due to diverse vehicle configurations, remains an open problem. In this work, we propose VR-Drive, a novel E2E-AD framework that addresses viewpoint generalization by jointly learning 3D scene reconstruction as an auxiliary task to enable planning-aware view synthesis. Unlike prior scene-specific synthesis approaches, VR-Drive adopts a feed-forward inference strategy that supports online training-time augmentation from sparse views without additional annotations. To further improve viewpoint consistency, we introduce a viewpoint-mixed memory bank that facilitates temporal interaction across multiple viewpoints and a viewpoint-consistent distillation strategy that transfers knowledge from original to synthesized views. Trained in a fully end-to-end manner, VR-Drive effectively mitigates synthesis-induced noise and improves planning under viewpoint shifts. In addition, we release a new benchmark dataset to evaluate E2E-AD performance under novel camera viewpoints, enabling comprehensive analysis. Our results demonstrate that VR-Drive is a scalable and robust solution for the real-world deployment of end-to-end autonomous driving systems.",
    "authors": [
      "Hoonhee Cho",
      "Jae-Young Kang",
      "Giwon Lee",
      "Hyemin Yang",
      "Heejun Park",
      "Seokwoo Jung",
      "Kuk-Jin Yoon"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23205v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23205v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.23182v1",
    "title": "SI-Bench: Benchmarking Social Intelligence of Large Language Models in   Human-to-Human Conversations",
    "summary": "As large language models (LLMs) develop anthropomorphic abilities, they are increasingly being deployed as autonomous agents to interact with humans. However, evaluating their performance in realistic and complex social interactions remains a significant challenge. Most previous research built datasets through simulated agent-to-agent interactions, which fails to capture the authentic linguistic styles and relational dynamics found in real human conversations. To address this gap, we introduce SI-Bench, a novel benchmark designed to evaluate aspects of social intelligence in LLMs. Grounded in broad social science theories, SI-Bench contains 2,221 authentic multi-turn dialogues collected from a social networking application. We further selected a subset of 312 dialogues for manual annotation across 8 major models. The experiments show that SOTA models have surpassed the human expert in process reasoning under complex social situations, yet they still fall behind humans in reply quality. Moreover, introducing Chain-of-Thought (CoT) reasoning may degrade the performance of LLMs in social dialogue tasks. All datasets are openly available at https://github.com/SI-Bench/SI-Bench.git.",
    "authors": [
      "Shuai Huang",
      "Wenxuan Zhao",
      "Jun Gao"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23182v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23182v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.23145v1",
    "title": "Implicit Modeling for Transferability Estimation of Vision Foundation   Models",
    "summary": "Transferability estimation identifies the best pre-trained models for downstream tasks without incurring the high computational cost of full fine-tuning. This capability facilitates deployment and advances the pre-training and fine-tuning paradigm. However, existing methods often struggle to accurately assess transferability for emerging pre-trained models with diverse architectures, training strategies, and task alignments. In this work, we propose Implicit Transferability Modeling (ITM), a novel framework that implicitly models each model's intrinsic transferability, coupled with a Divide-and-Conquer Variational Approximation (DVA) strategy to efficiently approximate embedding space evolution. This design enables generalization across a broader range of models and downstream tasks. Extensive experiments on a comprehensive benchmark--spanning extensive training regimes and a wider variety of model types--demonstrate that ITM consistently outperforms existing methods in terms of stability, effectiveness, and efficiency.",
    "authors": [
      "Yaoyan Zheng",
      "Huiqun Wang",
      "Nan Zhou",
      "Di Huang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23145v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23145v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.23070v1",
    "title": "Quality-Aware Translation Tagging in Multilingual RAG system",
    "summary": "Multilingual Retrieval-Augmented Generation (mRAG) often retrieves English documents and translates them into the query language for low-resource settings. However, poor translation quality degrades response generation performance. Existing approaches either assume sufficient translation quality or utilize the rewriting method, which introduces factual distortion and hallucinations. To mitigate these problems, we propose Quality-Aware Translation Tagging in mRAG (QTT-RAG), which explicitly evaluates translation quality along three dimensions-semantic equivalence, grammatical accuracy, and naturalness&fluency-and attach these scores as metadata without altering the original content. We evaluate QTT-RAG against CrossRAG and DKM-RAG as baselines in two open-domain QA benchmarks (XORQA, MKQA) using six instruction-tuned LLMs ranging from 2.4B to 14B parameters, covering two low-resource languages (Korean and Finnish) and one high-resource language (Chinese). QTT-RAG outperforms the baselines by preserving factual integrity while enabling generator models to make informed decisions based on translation reliability. This approach allows for effective usage of cross-lingual documents in low-resource settings with limited native language documents, offering a practical and robust solution across multilingual domains.",
    "authors": [
      "Hoyeon Moon",
      "Byeolhee Kim",
      "Nikhil Verma"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23070v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23070v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.62
  },
  {
    "arxiv_id": "2510.23507v1",
    "title": "A Deep Latent Factor Graph Clustering with Fairness-Utility Trade-off   Perspective",
    "summary": "Fair graph clustering seeks partitions that respect network structure while maintaining proportional representation across sensitive groups, with applications spanning community detection, team formation, resource allocation, and social network analysis. Many existing approaches enforce rigid constraints or rely on multi-stage pipelines (e.g., spectral embedding followed by $k$-means), limiting trade-off control, interpretability, and scalability. We introduce \\emph{DFNMF}, an end-to-end deep nonnegative tri-factorization tailored to graphs that directly optimizes cluster assignments with a soft statistical-parity regularizer. A single parameter $\\lambda$ tunes the fairness--utility balance, while nonnegativity yields parts-based factors and transparent soft memberships. The optimization uses sparse-friendly alternating updates and scales near-linearly with the number of edges. Across synthetic and real networks, DFNMF achieves substantially higher group balance at comparable modularity, often dominating state-of-the-art baselines on the Pareto front. The code is available at https://github.com/SiamakGhodsi/DFNMF.git.",
    "authors": [
      "Siamak Ghodsi",
      "Amjad Seyedi",
      "Tai Le Quy",
      "Fariba Karimi",
      "Eirini Ntoutsi"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.IT",
      "math.IT"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23507v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23507v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2510.23451v1",
    "title": "Omni-Reward: Towards Generalist Omni-Modal Reward Modeling with   Free-Form Preferences",
    "summary": "Reward models (RMs) play a critical role in aligning AI behaviors with human preferences, yet they face two fundamental challenges: (1) Modality Imbalance, where most RMs are mainly focused on text and image modalities, offering limited support for video, audio, and other modalities; and (2) Preference Rigidity, where training on fixed binary preference pairs fails to capture the complexity and diversity of personalized preferences. To address the above challenges, we propose Omni-Reward, a step toward generalist omni-modal reward modeling with support for free-form preferences, consisting of: (1) Evaluation: We introduce Omni-RewardBench, the first omni-modal RM benchmark with free-form preferences, covering nine tasks across five modalities including text, image, video, audio, and 3D; (2) Data: We construct Omni-RewardData, a multimodal preference dataset comprising 248K general preference pairs and 69K instruction-tuning pairs for training generalist omni-modal RMs; (3) Model: We propose Omni-RewardModel, which includes both discriminative and generative RMs, and achieves strong performance on Omni-RewardBench as well as other widely used reward modeling benchmarks.",
    "authors": [
      "Zhuoran Jin",
      "Hongbang Yuan",
      "Kejian Zhu",
      "Jiachun Li",
      "Pengfei Cao",
      "Yubo Chen",
      "Kang Liu",
      "Jun Zhao"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23451v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23451v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2510.23389v1",
    "title": "Floating-Point Neural Network Verification at the Software Level",
    "summary": "The behaviour of neural network components must be proven correct before deployment in safety-critical systems. Unfortunately, existing neural network verification techniques cannot certify the absence of faults at the software level. In this paper, we show how to specify and verify that neural networks are safe, by explicitly reasoning about their floating-point implementation. In doing so, we construct NeuroCodeBench 2.0, a benchmark comprising 912 neural network verification examples that cover activation functions, common layers, and full neural networks of up to 170K parameters. Our verification suite is written in plain C and is compatible with the format of the International Competition on Software Verification (SV-COMP). Thanks to it, we can conduct the first rigorous evaluation of eight state-of-the-art software verifiers on neural network code. The results show that existing automated verification tools can correctly solve an average of 11% of our benchmark, while producing around 3% incorrect verdicts. At the same time, a historical analysis reveals that the release of our benchmark has already had a significantly positive impact on the latter.",
    "authors": [
      "Edoardo Manino",
      "Bruno Farias",
      "Rafael Sá Menezes",
      "Fedor Shmarov",
      "Lucas C. Cordeiro"
    ],
    "categories": [
      "cs.SE",
      "cs.CR",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23389v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23389v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2510.23285v1",
    "title": "Adaptive Stochastic Coefficients for Accelerating Diffusion Sampling",
    "summary": "Diffusion-based generative processes, formulated as differential equation solving, frequently balance computational speed with sample quality. Our theoretical investigation of ODE- and SDE-based solvers reveals complementary weaknesses: ODE solvers accumulate irreducible gradient error along deterministic trajectories, while SDE methods suffer from amplified discretization errors when the step budget is limited. Building upon this insight, we introduce AdaSDE, a novel single-step SDE solver that aims to unify the efficiency of ODEs with the error resilience of SDEs. Specifically, we introduce a single per-step learnable coefficient, estimated via lightweight distillation, which dynamically regulates the error correction strength to accelerate diffusion sampling. Notably, our framework can be integrated with existing solvers to enhance their capabilities. Extensive experiments demonstrate state-of-the-art performance: at 5 NFE, AdaSDE achieves FID scores of 4.18 on CIFAR-10, 8.05 on FFHQ and 6.96 on LSUN Bedroom. Codes are available in https://github.com/WLU-wry02/AdaSDE.",
    "authors": [
      "Ruoyu Wang",
      "Beier Zhu",
      "Junzhi Li",
      "Liangyu Yuan",
      "Chi Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23285v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23285v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2510.23235v1",
    "title": "Grassmanian Interpolation of Low-Pass Graph Filters: Theory and   Applications",
    "summary": "Low-pass graph filters are fundamental for signal processing on graphs and other non-Euclidean domains. However, the computation of such filters for parametric graph families can be prohibitively expensive as computation of the corresponding low-frequency subspaces, requires the repeated solution of an eigenvalue problem. We suggest a novel algorithm of low-pass graph filter interpolation based on Riemannian interpolation in normal coordinates on the Grassmann manifold. We derive an error bound estimate for the subspace interpolation and suggest two possible applications for induced parametric graph families. First, we argue that the temporal evolution of the node features may be translated to the evolving graph topology via a similarity correction to adjust the homophily degree of the network. Second, we suggest a dot product graph family induced by a given static graph which allows to infer improved message passing scheme for node classification facilitated by the filter interpolation.",
    "authors": [
      "Anton Savostianov",
      "Michael T. Schaub",
      "Benjamin Stamm"
    ],
    "categories": [
      "cs.LG",
      "cs.NA",
      "cs.SI",
      "eess.SP",
      "math.NA",
      "math.SP"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23235v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23235v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2510.23225v1",
    "title": "Through the Lens: Benchmarking Deepfake Detectors Against   Moiré-Induced Distortions",
    "summary": "Deepfake detection remains a pressing challenge, particularly in real-world settings where smartphone-captured media from digital screens often introduces Moir\\'e artifacts that can distort detection outcomes. This study systematically evaluates state-of-the-art (SOTA) deepfake detectors on Moir\\'e-affected videos, an issue that has received little attention. We collected a dataset of 12,832 videos, spanning 35.64 hours, from the Celeb-DF, DFD, DFDC, UADFV, and FF++ datasets, capturing footage under diverse real-world conditions, including varying screens, smartphones, lighting setups, and camera angles. To further examine the influence of Moir\\'e patterns on deepfake detection, we conducted additional experiments using our DeepMoir\\'eFake, referred to as (DMF) dataset and two synthetic Moir\\'e generation techniques. Across 15 top-performing detectors, our results show that Moir\\'e artifacts degrade performance by as much as 25.4%, while synthetically generated Moir\\'e patterns lead to a 21.4% drop in accuracy. Surprisingly, demoir\\'eing methods, intended as a mitigation approach, instead worsened the problem, reducing accuracy by up to 17.2%. These findings underscore the urgent need for detection models that can robustly handle Moir\\'e distortions alongside other realworld challenges, such as compression, sharpening, and blurring. By introducing the DMF dataset, we aim to drive future research toward closing the gap between controlled experiments and practical deepfake detection.",
    "authors": [
      "Razaib Tariq",
      "Minji Heo",
      "Simon S. Woo",
      "Shahroz Tariq"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23225v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23225v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.61
  },
  {
    "arxiv_id": "2510.23606v1",
    "title": "Variational Masked Diffusion Models",
    "summary": "Masked diffusion models have recently emerged as a flexible framework for discrete generative modeling. However, a key limitation of standard masked diffusion is its inability to effectively capture dependencies among tokens that are predicted concurrently, leading to degraded generation quality when dependencies among tokens are important. To explicitly model dependencies among tokens, we propose Variational Masked Diffusion (VMD), a framework that introduces latent variables into the masked diffusion process. Through controlled experiments on synthetic datasets, we demonstrate that VMD successfully learns dependencies that conventional masked diffusion fails to capture. We further validate the effectiveness of our approach on Sudoku puzzles and text datasets, where learning of dependencies among tokens improves global consistency. Across these domains, VMD enhances both generation quality and dependency awareness, highlighting the value of integrating variational inference into masked diffusion. Our code is available at: https://riccizz.github.io/VMD.",
    "authors": [
      "Yichi Zhang",
      "Alex Schwing",
      "Zhizhen Zhao"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23606v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23606v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.23590v1",
    "title": "Lightweight Robust Direct Preference Optimization",
    "summary": "Direct Preference Optimization (DPO) has become a popular method for fine-tuning large language models (LLMs) due to its stability and simplicity. However, it is also known to be sensitive to noise in the data and prone to overfitting. Recent works have proposed using distributionally robust optimization (DRO) to address potential noise and distributional shift in the data. However, these methods often suffer from excessive conservatism and high computational cost. We propose DPO-PRO (DPO with Preference Robustness), a robust fine-tuning algorithm based on DPO which accounts for uncertainty in the preference distribution through a lightweight DRO formulation. Unlike prior DRO-based variants, DPO-PRO focuses solely on uncertainty in preferences, avoiding unnecessary conservatism and incurring negligible computational overhead. We further show that DPO-PRO is equivalent to a regularized DPO objective that penalizes model overconfidence under weak preference signals. We evaluate DPO-PRO on standard alignment benchmarks and a real-world public health task. Experimental results show that our method consistently improves robustness to noisy preference signals compared to existing DPO variants.",
    "authors": [
      "Cheol Woo Kim",
      "Shresth Verma",
      "Mauricio Tec",
      "Milind Tambe"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23590v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23590v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.23544v1",
    "title": "LimRank: Less is More for Reasoning-Intensive Information Reranking",
    "summary": "Existing approaches typically rely on large-scale fine-tuning to adapt LLMs for information reranking tasks, which is computationally expensive. In this work, we demonstrate that modern LLMs can be effectively adapted using only minimal, high-quality supervision. To enable this, we design LIMRANK-SYNTHESIZER, a reusable and open-source pipeline for generating diverse, challenging, and realistic reranking examples. Using this synthetic data, we fine-tune our reranker model, LIMRANK. We evaluate LIMRANK on two challenging benchmarks, i.e., BRIGHT for reasoning-intensive retrieval and FollowIR for instruction-following retrieval. Our experiments demonstrate that LIMRANK achieves competitive performance, while being trained on less than 5% of the data typically used in prior work. Further ablation studies demonstrate the effectiveness of LIMRANK-SYNTHESIZER and the strong generalization capabilities of LIMRANK across downstream tasks, including scientific literature search and retrieval-augmented generation for knowledge-intensive problem solving.",
    "authors": [
      "Tingyu Song",
      "Yilun Zhao",
      "Siyue Zhang",
      "Chen Zhao",
      "Arman Cohan"
    ],
    "categories": [
      "cs.CL",
      "cs.IR"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23544v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23544v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.23534v1",
    "title": "Direct Debiased Machine Learning via Bregman Divergence Minimization",
    "summary": "We develop a direct debiased machine learning framework comprising Neyman targeted estimation and generalized Riesz regression. Our framework unifies Riesz regression for automatic debiased machine learning, covariate balancing, targeted maximum likelihood estimation (TMLE), and density-ratio estimation. In many problems involving causal effects or structural models, the parameters of interest depend on regression functions. Plugging regression functions estimated by machine learning methods into the identifying equations can yield poor performance because of first-stage bias. To reduce such bias, debiased machine learning employs Neyman orthogonal estimating equations. Debiased machine learning typically requires estimation of the Riesz representer and the regression function. For this problem, we develop a direct debiased machine learning framework with an end-to-end algorithm. We formulate estimation of the nuisance parameters, the regression function and the Riesz representer, as minimizing the discrepancy between Neyman orthogonal scores computed with known and unknown nuisance parameters, which we refer to as Neyman targeted estimation. Neyman targeted estimation includes Riesz representer estimation, and we measure discrepancies using the Bregman divergence. The Bregman divergence encompasses various loss functions as special cases, where the squared loss yields Riesz regression and the Kullback-Leibler divergence yields entropy balancing. We refer to this Riesz representer estimation as generalized Riesz regression. Neyman targeted estimation also yields TMLE as a special case for regression function estimation. Furthermore, for specific pairs of models and Riesz representer estimation methods, we can automatically obtain the covariate balancing property without explicitly solving the covariate balancing objective.",
    "authors": [
      "Masahiro Kato"
    ],
    "categories": [
      "econ.EM",
      "cs.LG",
      "math.ST",
      "stat.ME",
      "stat.ML",
      "stat.TH"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23534v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23534v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.23532v1",
    "title": "When No Paths Lead to Rome: Benchmarking Systematic Neural Relational   Reasoning",
    "summary": "Designing models that can learn to reason in a systematic way is an important and long-standing challenge. In recent years, a wide range of solutions have been proposed for the specific case of systematic relational reasoning, including Neuro-Symbolic approaches, variants of the Transformer architecture, and specialised Graph Neural Networks. However, existing benchmarks for systematic relational reasoning focus on an overly simplified setting, based on the assumption that reasoning can be reduced to composing relational paths. In fact, this assumption is hard-baked into the architecture of several recent models, leading to approaches that can perform well on existing benchmarks but are difficult to generalise to other settings. To support further progress in the field of systematic relational reasoning with neural networks, we introduce NoRA, a new benchmark which adds several levels of difficulty and requires models to go beyond path-based reasoning.",
    "authors": [
      "Anirban Das",
      "Irtaza Khalid",
      "Rafael Peñaloza",
      "Steven Schockaert"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23532v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23532v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.23530v1",
    "title": "Learning Linearity in Audio Consistency Autoencoders via Implicit   Regularization",
    "summary": "Audio autoencoders learn useful, compressed audio representations, but their non-linear latent spaces prevent intuitive algebraic manipulation such as mixing or scaling. We introduce a simple training methodology to induce linearity in a high-compression Consistency Autoencoder (CAE) by using data augmentation, thereby inducing homogeneity (equivariance to scalar gain) and additivity (the decoder preserves addition) without altering the model's architecture or loss function. When trained with our method, the CAE exhibits linear behavior in both the encoder and decoder while preserving reconstruction fidelity. We test the practical utility of our learned space on music source composition and separation via simple latent arithmetic. This work presents a straightforward technique for constructing structured latent spaces, enabling more intuitive and efficient audio processing.",
    "authors": [
      "Bernardo Torres",
      "Manuel Moussallam",
      "Gabriel Meseguer-Brocal"
    ],
    "categories": [
      "cs.SD",
      "cs.AI",
      "cs.LG",
      "eess.AS"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23530v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23530v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.23471v1",
    "title": "Robust Decision Making with Partially Calibrated Forecasts",
    "summary": "Calibration has emerged as a foundational goal in ``trustworthy machine learning'', in part because of its strong decision theoretic semantics. Independent of the underlying distribution, and independent of the decision maker's utility function, calibration promises that amongst all policies mapping predictions to actions, the uniformly best policy is the one that ``trusts the predictions'' and acts as if they were correct. But this is true only of \\emph{fully calibrated} forecasts, which are tractable to guarantee only for very low dimensional prediction problems. For higher dimensional prediction problems (e.g. when outcomes are multiclass), weaker forms of calibration have been studied that lack these decision theoretic properties. In this paper we study how a conservative decision maker should map predictions endowed with these weaker (``partial'') calibration guarantees to actions, in a way that is robust in a minimax sense: i.e. to maximize their expected utility in the worst case over distributions consistent with the calibration guarantees. We characterize their minimax optimal decision rule via a duality argument, and show that surprisingly, ``trusting the predictions and acting accordingly'' is recovered in this minimax sense by \\emph{decision calibration} (and any strictly stronger notion of calibration), a substantially weaker and more tractable condition than full calibration. For calibration guarantees that fall short of decision calibration, the minimax optimal decision rule is still efficiently computable, and we provide an empirical evaluation of a natural one that applies to any regression model solved to optimize squared error.",
    "authors": [
      "Shayan Kiyani",
      "Hamed Hassani",
      "George Pappas",
      "Aaron Roth"
    ],
    "categories": [
      "stat.ML",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23471v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23471v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.23469v1",
    "title": "Adaptive Dual Prompting: Hierarchical Debiasing for Fairness-aware Graph   Neural Networks",
    "summary": "In recent years, pre-training Graph Neural Networks (GNNs) through self-supervised learning on unlabeled graph data has emerged as a widely adopted paradigm in graph learning. Although the paradigm is effective for pre-training powerful GNN models, the objective gap often exists between pre-training and downstream tasks. To bridge this gap, graph prompting adapts pre-trained GNN models to specific downstream tasks with extra learnable prompts while keeping the pre-trained GNN models frozen. As recent graph prompting methods largely focus on enhancing model utility on downstream tasks, they often overlook fairness concerns when designing prompts for adaptation. In fact, pre-trained GNN models will produce discriminative node representations across demographic subgroups, as downstream graph data inherently contains biases in both node attributes and graph structures. To address this issue, we propose an Adaptive Dual Prompting (ADPrompt) framework that enhances fairness for adapting pre-trained GNN models to downstream tasks. To mitigate attribute bias, we design an Adaptive Feature Rectification module that learns customized attribute prompts to suppress sensitive information at the input layer, reducing bias at the source. Afterward, we propose an Adaptive Message Calibration module that generates structure prompts at each layer, which adjust the message from neighboring nodes to enable dynamic and soft calibration of the information flow. Finally, ADPrompt jointly optimizes the two prompting modules to adapt the pre-trained GNN while enhancing fairness. We conduct extensive experiments on four datasets with four pre-training strategies to evaluate the performance of ADPrompt. The results demonstrate that our proposed ADPrompt outperforms seven baseline methods on node classification tasks.",
    "authors": [
      "Yuhan Yang",
      "Xingbo Fu",
      "Jundong Li"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23469v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23469v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.23428v1",
    "title": "Improving Predictions of Molecular Properties with Graph Featurisation   and Heterogeneous Ensemble Models",
    "summary": "We explore a \"best-of-both\" approach to modelling molecular properties by combining learned molecular descriptors from a graph neural network (GNN) with general-purpose descriptors and a mixed ensemble of machine learning (ML) models. We introduce a MetaModel framework to aggregate predictions from a diverse set of leading ML models. We present a featurisation scheme for combining task-specific GNN-derived features with conventional molecular descriptors.   We demonstrate that our framework outperforms the cutting-edge ChemProp model on all regression datasets tested and 6 of 9 classification datasets. We further show that including the GNN features derived from ChemProp boosts the ensemble model's performance on several datasets where it otherwise would have underperformed. We conclude that to achieve optimal performance across a wide set of problems, it is vital to combine general-purpose descriptors with task-specific learned features and use a diverse set of ML models to make the predictions.",
    "authors": [
      "Michael L. Parker",
      "Samar Mahmoud",
      "Bailey Montefiore",
      "Mario Öeren",
      "Himani Tandon",
      "Charlotte Wharrick",
      "Matthew D. Segall"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23428v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23428v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.23383v1",
    "title": "One-Timestep is Enough: Achieving High-performance ANN-to-SNN Conversion   via Scale-and-Fire Neurons",
    "summary": "Spiking Neural Networks (SNNs) are gaining attention as energy-efficient alternatives to Artificial Neural Networks (ANNs), especially in resource-constrained settings. While ANN-to-SNN conversion (ANN2SNN) achieves high accuracy without end-to-end SNN training, existing methods rely on large time steps, leading to high inference latency and computational cost. In this paper, we propose a theoretical and practical framework for single-timestep ANN2SNN. We establish the Temporal-to-Spatial Equivalence Theory, proving that multi-timestep integrate-and-fire (IF) neurons can be equivalently replaced by single-timestep multi-threshold neurons (MTN). Based on this theory, we introduce the Scale-and-Fire Neuron (SFN), which enables effective single-timestep ($T=1$) spiking through adaptive scaling and firing. Furthermore, we develop the SFN-based Spiking Transformer (SFormer), a specialized instantiation of SFN within Transformer architectures, where spike patterns are aligned with attention distributions to mitigate the computational, energy, and hardware overhead of the multi-threshold design. Extensive experiments on image classification, object detection, and instance segmentation demonstrate that our method achieves state-of-the-art performance under single-timestep inference. Notably, we achieve 88.8% top-1 accuracy on ImageNet-1K at $T=1$, surpassing existing conversion methods.",
    "authors": [
      "Qiuyang Chen",
      "Huiqi Yang",
      "Qingyan Meng",
      "Zhengyu Ma"
    ],
    "categories": [
      "cs.NE"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23383v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23383v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.23261v1",
    "title": "Toward Interpretable Evaluation Measures for Time Series Segmentation",
    "summary": "Time series segmentation is a fundamental task in analyzing temporal data across various domains, from human activity recognition to energy monitoring. While numerous state-of-the-art methods have been developed to tackle this problem, the evaluation of their performance remains critically limited. Existing measures predominantly focus on change point accuracy or rely on point-based measures such as Adjusted Rand Index (ARI), which fail to capture the quality of the detected segments, ignore the nature of errors, and offer limited interpretability. In this paper, we address these shortcomings by introducing two novel evaluation measures: WARI (Weighted Adjusted Rand Index), that accounts for the position of segmentation errors, and SMS (State Matching Score), a fine-grained measure that identifies and scores four fundamental types of segmentation errors while allowing error-specific weighting. We empirically validate WARI and SMS on synthetic and real-world benchmarks, showing that they not only provide a more accurate assessment of segmentation quality but also uncover insights, such as error provenance and type, that are inaccessible with traditional measures.",
    "authors": [
      "Félix Chavelli",
      "Paul Boniol",
      "Michaël Thomazo"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23261v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23261v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.23259v1",
    "title": "GCAO: Group-driven Clustering via Gravitational Attraction and   Optimization",
    "summary": "Traditional clustering algorithms often struggle with high-dimensional and non-uniformly distributed data, where low-density boundary samples are easily disturbed by neighboring clusters, leading to unstable and distorted clustering results. To address this issue, we propose a Group-driven Clustering via Gravitational Attraction and Optimization (GCAO) algorithm. GCAO introduces a group-level optimization mechanism that aggregates low-density boundary points into collaboratively moving groups, replacing the traditional point-based contraction process. By combining local density estimation with neighborhood topology, GCAO constructs effective gravitational interactions between groups and their surroundings, enhancing boundary clarity and structural consistency. Using groups as basic motion units, a gravitational contraction strategy ensures globally stable and directionally consistent convergence. Experiments on multiple high-dimensional datasets demonstrate that GCAO outperforms 11 representative clustering methods, achieving average improvements of 37.13%, 52.08%, 44.98%, and 38.81% in NMI, ARI, Homogeneity, and ACC, respectively, while maintaining competitive efficiency and scalability. These results highlight GCAO's superiority in preserving cluster integrity, enhancing boundary separability, and ensuring robust performance on complex data distributions.",
    "authors": [
      "Qi Li",
      "Jun Wang"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23259v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23259v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.23189v1",
    "title": "DREaM: Drug-Drug Relation Extraction via Transfer Learning Method",
    "summary": "Relation extraction between drugs plays a crucial role in identifying drug drug interactions and predicting side effects. The advancement of machine learning methods in relation extraction, along with the development of large medical text databases, has enabled the low cost extraction of such relations compared to other approaches that typically require expert knowledge. However, to the best of our knowledge, there are limited datasets specifically designed for drug drug relation extraction currently available. Therefore, employing transfer learning becomes necessary to apply machine learning methods in this domain. In this study, we propose DREAM, a method that first employs a trained relation extraction model to discover relations between entities and then applies this model to a corpus of medical texts to construct an ontology of drug relationships. The extracted relations are subsequently validated using a large language model. Quantitative results indicate that the LLM agreed with 71 of the relations extracted from a subset of PubMed abstracts. Furthermore, our qualitative analysis indicates that this approach can uncover ambiguities in the medical domain, highlighting the challenges inherent in relation extraction in this field.",
    "authors": [
      "Ali Fata",
      "Hossein Rahmani",
      "Parinaz Soltanzadeh",
      "Amirhossein Derakhshan",
      "Behrouz Minaei Bidgoli"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23189v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23189v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.23083v1",
    "title": "Smaller Models, Smarter Rewards: A Two-Sided Approach to Process and   Outcome Rewards",
    "summary": "Generating high-quality code remains a challenge for Large Language Models (LLMs). For the evolution of reasoning models on this task, reward models are a necessary intermediate step. These models judge outcomes or intermediate steps. Decoder-only transformer models can be turned into reward models by introducing a regression layer and supervised fine-tuning. While it is known that reflection capabilities generally increase with the size of a model, we want to investigate whether state-of-the-art small language models like the Phi-4 family can be turned into usable reward models blending the consideration of process rewards and outcome rewards.   Targeting this goal, we construct a dataset of code samples with correctness labels derived from the APPS coding challenge benchmark. We then train a value-head model to estimate the success probability of intermediate outputs. Our evaluation shows that small LLMs are capable of serving as effective reward models or code evaluation critics, successfully identifying correct solutions among multiple candidates. Using this critic, we achieve over a 20% improvement in the search capability of the most accurate code out of multiple generations.",
    "authors": [
      "Jan Niklas Groeneveld",
      "Xi Qin",
      "Alexander Schaefer",
      "Yaad Oren"
    ],
    "categories": [
      "cs.AI",
      "cs.LG",
      "cs.SE",
      "I.2.7"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23083v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23083v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.23049v1",
    "title": "Advantage Shaping as Surrogate Reward Maximization: Unifying Pass@K   Policy Gradients",
    "summary": "This note reconciles two seemingly distinct approaches to policy gradient optimization for the Pass@K objective in reinforcement learning with verifiable rewards: (1) direct REINFORCE-style methods, and (2) advantage-shaping techniques that directly modify GRPO. We show that these are two sides of the same coin. By reverse-engineering existing advantage-shaping algorithms, we reveal that they implicitly optimize surrogate rewards. We specifically interpret practical ``hard-example up-weighting'' modifications to GRPO as reward-level regularization. Conversely, starting from surrogate reward objectives, we provide a simple recipe for deriving both existing and new advantage-shaping methods. This perspective provides a lens for RLVR policy gradient optimization beyond our original motivation of Pass@K.",
    "authors": [
      "Christos Thrampoulidis",
      "Sadegh Mahdavi",
      "Wenlong Deng"
    ],
    "categories": [
      "cs.LG",
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23049v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23049v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.6
  },
  {
    "arxiv_id": "2510.23587v1",
    "title": "A Survey of Data Agents: Emerging Paradigm or Overstated Hype?",
    "summary": "The rapid advancement of large language models (LLMs) has spurred the emergence of data agents--autonomous systems designed to orchestrate Data + AI ecosystems for tackling complex data-related tasks. However, the term \"data agent\" currently suffers from terminological ambiguity and inconsistent adoption, conflating simple query responders with sophisticated autonomous architectures. This terminological ambiguity fosters mismatched user expectations, accountability challenges, and barriers to industry growth. Inspired by the SAE J3016 standard for driving automation, this survey introduces the first systematic hierarchical taxonomy for data agents, comprising six levels that delineate and trace progressive shifts in autonomy, from manual operations (L0) to a vision of generative, fully autonomous data agents (L5), thereby clarifying capability boundaries and responsibility allocation. Through this lens, we offer a structured review of existing research arranged by increasing autonomy, encompassing specialized data agents for data management, preparation, and analysis, alongside emerging efforts toward versatile, comprehensive systems with enhanced autonomy. We further analyze critical evolutionary leaps and technical gaps for advancing data agents, especially the ongoing L2-to-L3 transition, where data agents evolve from procedural execution to autonomous orchestration. Finally, we conclude with a forward-looking roadmap, envisioning the advent of proactive, generative data agents.",
    "authors": [
      "Yizhang Zhu",
      "Liangwei Wang",
      "Chenyu Yang",
      "Xiaotian Lin",
      "Boyan Li",
      "Wei Zhou",
      "Xinyu Liu",
      "Zhangyang Peng",
      "Tianqi Luo",
      "Yu Li",
      "Chengliang Chai",
      "Chong Chen",
      "Shimin Di",
      "Ju Fan",
      "Ji Sun",
      "Nan Tang",
      "Fugee Tsung",
      "Jiannan Wang",
      "Chenglin Wu",
      "Yanwei Xu",
      "Shaolei Zhang",
      "Yong Zhang",
      "Xuanhe Zhou",
      "Guoliang Li",
      "Yuyu Luo"
    ],
    "categories": [
      "cs.DB",
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23587v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23587v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.23512v1",
    "title": "Localising under the drape: proprioception in the era of distributed   surgical robotic system",
    "summary": "Despite their mechanical sophistication, surgical robots remain blind to their surroundings. This lack of spatial awareness causes collisions, system recoveries, and workflow disruptions, issues that will intensify with the introduction of distributed robots with independent interacting arms. Existing tracking systems rely on bulky infrared cameras and reflective markers, providing only limited views of the surgical scene and adding hardware burden in crowded operating rooms. We present a marker-free proprioception method that enables precise localisation of surgical robots under their sterile draping despite associated obstruction of visual cues. Our method solely relies on lightweight stereo-RGB cameras and novel transformer-based deep learning models. It builds on the largest multi-centre spatial robotic surgery dataset to date (1.4M self-annotated images from human cadaveric and preclinical in vivo studies). By tracking the entire robot and surgical scene, rather than individual markers, our approach provides a holistic view robust to occlusions, supporting surgical scene understanding and context-aware control. We demonstrate an example of potential clinical benefits during in vivo breathing compensation with access to tissue dynamics, unobservable under state of the art tracking, and accurately locate in multi-robot systems for future intelligent interaction. In addition, and compared with existing systems, our method eliminates markers and improves tracking visibility by 25%. To our knowledge, this is the first demonstration of marker-free proprioception for fully draped surgical robots, reducing setup complexity, enhancing safety, and paving the way toward modular and autonomous robotic surgery.",
    "authors": [
      "Martin Huber",
      "Nicola A. Cavalcanti",
      "Ayoob Davoodi",
      "Ruixuan Li",
      "Christopher E. Mower",
      "Fabio Carrillo",
      "Christoph J. Laux",
      "Francois Teyssere",
      "Thibault Chandanson",
      "Antoine Harlé",
      "Elie Saghbiny",
      "Mazda Farshad",
      "Guillaume Morel",
      "Emmanuel Vander Poorten",
      "Philipp Fürnstahl",
      "Sébastien Ourselin",
      "Christos Bergeles",
      "Tom Vercauteren"
    ],
    "categories": [
      "cs.RO",
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23512v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23512v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.23497v1",
    "title": "VOLD: Reasoning Transfer from LLMs to Vision-Language Models via   On-Policy Distillation",
    "summary": "Training vision-language models (VLMs) for complex reasoning remains a challenging task, i.a. due to the scarcity of high-quality image-text reasoning data. Conversely, text-based reasoning resources are abundant and scalable, but it is still an open question how to leveraging them for VLM reasoning. To address this problem, we propose VOLD, a framework to transfer reasoning capabilities from text-only teacher models to VLM student models. To this end, VOLD combines reinforcement learning via Group Relative Policy Optimization (GRPO) with on-policy distillation, which allows the student reasoning traces to be guided by the teacher model, resulting in a significant gain over using GRPO alone. We further show that a cold-start alignment is essential for an effective transfer during the online training phase in this scenario and that without sufficient distributional alignment between teacher and student, on-policy distillation fails to provide meaningful guidance. We evaluate VOLD across diverse benchmarks including MMMU-Pro, MathVision, MathVista, and LogicVista, showing that VOLD outperforms the baseline model significantly and improves over the state of the art by a margin. Our ablation shows the importance of a cold-start alignment via SFT for on-policy distillation with a text-only teacher.",
    "authors": [
      "Walid Bousselham",
      "Hilde Kuehne",
      "Cordelia Schmid"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23497v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23497v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.23476v1",
    "title": "Human-AI Collaborative Uncertainty Quantification",
    "summary": "AI predictive systems are increasingly embedded in decision making pipelines, shaping high stakes choices once made solely by humans. Yet robust decisions under uncertainty still rely on capabilities that current AI lacks: domain knowledge not captured by data, long horizon context, and reasoning grounded in the physical world. This gap has motivated growing efforts to design collaborative frameworks that combine the complementary strengths of humans and AI. This work advances this vision by identifying the fundamental principles of Human AI collaboration within uncertainty quantification, a key component of reliable decision making. We introduce Human AI Collaborative Uncertainty Quantification, a framework that formalizes how an AI model can refine a human expert's proposed prediction set with two goals: avoiding counterfactual harm, ensuring the AI does not degrade correct human judgments, and complementarity, enabling recovery of correct outcomes the human missed. At the population level, we show that the optimal collaborative prediction set follows an intuitive two threshold structure over a single score function, extending a classical result in conformal prediction. Building on this insight, we develop practical offline and online calibration algorithms with provable distribution free finite sample guarantees. The online method adapts to distribution shifts, including human behavior evolving through interaction with AI, a phenomenon we call Human to AI Adaptation. Experiments across image classification, regression, and text based medical decision making show that collaborative prediction sets consistently outperform either agent alone, achieving higher coverage and smaller set sizes across various conditions.",
    "authors": [
      "Sima Noorani",
      "Shayan Kiyani",
      "George Pappas",
      "Hamed Hassani"
    ],
    "categories": [
      "cs.AI",
      "cs.HC",
      "stat.ML"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23476v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23476v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.23284v1",
    "title": "DCMM-SQL: Automated Data-Centric Pipeline and Multi-Model Collaboration   Training for Text-to-SQL Model",
    "summary": "Text-to-SQL tasks have gained attractive improvements since the release of ChatGPT. Among them, agent-based frameworks have been widely used in this field. However, the impact of data-centric strategies on text-to-SQL tasks has rarely been explored. In this paper, we systemically design a fully automated data-centric pipeline for text-to-SQL tasks, including \\emph{adaptive data repair}, which can automatically find and fix errors in the training dataset; and \\emph{error data augmentation}, where we specifically diffuse and enhance erroneous data predicted by the initially trained models. Meanwhile, we propose a Multi-Model collaboration training schema, aiming to train multiple models with different augmented data, enabling them to possess distinct capabilities and work together to complement each other, because it has been found that the capability of a single fine-tuned model is very limited. Furthermore, we utilize an ensemble strategy to integrate the capabilities of multiple models to solve a multiple-choice question, aiming to further improve the accuracy of text-to-SQL tasks. The experiment results and ablation study have demonstrated the effectiveness of data-centric pipeline and Multi-Model(MM) interactive iterative strategies, achieving first place in lightweight text-to-SQL models (within 70B).",
    "authors": [
      "Yuanzhen Xie",
      "Liu Ye",
      "Jiqun Chu",
      "Mochi Gao",
      "Hehuan Liu",
      "Yunzhi Tan",
      "Bo Hu",
      "Zang Li"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23284v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23284v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.23271v1",
    "title": "Mubeen AI: A Specialized Arabic Language Model for Heritage Preservation   and User Intent Understanding",
    "summary": "Mubeen is a proprietary Arabic language model developed by MASARAT SA, optimized for deep understanding of Arabic linguistics, Islamic studies, and cultural heritage. Trained on an extensive collection of authentic Arabic sources significantly expanded by digitizing historical manuscripts via a proprietary Arabic OCR engine, the model incorporates seminal scholarly works in linguistics, jurisprudence, hadith, and Quranic exegesis, alongside thousands of academic theses and peer-reviewed research papers. Conditioned through a deep linguistic engineering framework, Mubeen masters not just the meaning but the eloquence of Arabic, enabling precise understanding across classical texts, contemporary writing, and regional dialects with focus on comprehending user intent and delivering accurate, contextually relevant responses. Unlike other Arabic models relying on translated English data that often fail in intent detection or retrieval-augmented generation (RAG), Mubeen uses native Arabic sources to ensure cultural authenticity and accuracy. Its core innovation is the Practical Closure Architecture, designed to solve the \"Utility Gap Crisis\" where factually correct answers fail to resolve users' core needs, forcing them into frustrating cycles of re-prompting. By prioritizing clarity and decisive guidance, Mubeen transforms from an information repository into a decisive guide, aligning with Saudi Vision 2030. The model's architecture combines deep heritage specialization with multi-disciplinary expert modules, enabling robust performance across both cultural preservation and general knowledge domains.",
    "authors": [
      "Mohammed Aljafari",
      "Ismail Alturki",
      "Ahmed Mori",
      "Yehya Kadumi"
    ],
    "categories": [
      "cs.CL",
      "68T50 (68T50 Natural language processing)",
      "I.2.7; I.2.6; I.2.0; H.3.3"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23271v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23271v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.23199v1",
    "title": "Rate-optimal Design for Anytime Best Arm Identification",
    "summary": "We consider the best arm identification problem, where the goal is to identify the arm with the highest mean reward from a set of $K$ arms under a limited sampling budget. This problem models many practical scenarios such as A/B testing. We consider a class of algorithms for this problem, which is provably minimax optimal up to a constant factor. This idea is a generalization of existing works in fixed-budget best arm identification, which are limited to a particular choice of risk measures. Based on the framework, we propose Almost Tracking, a closed-form algorithm that has a provable guarantee on the popular risk measure $H_1$. Unlike existing algorithms, Almost Tracking does not require the total budget in advance nor does it need to discard a significant part of samples, which gives a practical advantage. Through experiments on synthetic and real-world datasets, we show that our algorithm outperforms existing anytime algorithms as well as fixed-budget algorithms.",
    "authors": [
      "Junpei Komiyama",
      "Kyoungseok Jang",
      "Junya Honda"
    ],
    "categories": [
      "stat.ML",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23199v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23199v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.23142v1",
    "title": "Rethinking GSPO: The Perplexity-Entropy Equivalence",
    "summary": "We provide a new perspective on GSPO's length-normalized importance ratios by establishing their connection to information-theoretic quantities. We show that GSPO's sequence-level weight $s(\\theta) = (\\pi_\\theta/\\pi_{\\theta_{\\text{old}}})^{1/|y|}$ can be equivalently expressed as the inverse perplexity ratio $\\text{PPL}_{\\theta_{\\text{old}}}/\\text{PPL}_\\theta$ and as the exponential cross-entropy change $\\exp(\\Delta H)$. While the perplexity-entropy relationship follows from standard definitions, this observation provides a useful lens for understanding GSPO: the algorithm weights policy gradient updates by perplexity ratios, offering an information-theoretic interpretation of the importance weights. This perspective helps explain GSPO's empirical properties, including log-domain variance reduction through geometric averaging and stability in training mixture-of-experts models. We validate the mathematical equivalences and variance predictions through controlled experiments on mathematical reasoning tasks.",
    "authors": [
      "Chi Liu"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23142v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23142v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.59
  },
  {
    "arxiv_id": "2510.23581v1",
    "title": "Lookahead Anchoring: Preserving Character Identity in Audio-Driven Human   Animation",
    "summary": "Audio-driven human animation models often suffer from identity drift during temporal autoregressive generation, where characters gradually lose their identity over time. One solution is to generate keyframes as intermediate temporal anchors that prevent degradation, but this requires an additional keyframe generation stage and can restrict natural motion dynamics. To address this, we propose Lookahead Anchoring, which leverages keyframes from future timesteps ahead of the current generation window, rather than within it. This transforms keyframes from fixed boundaries into directional beacons: the model continuously pursues these future anchors while responding to immediate audio cues, maintaining consistent identity through persistent guidance. This also enables self-keyframing, where the reference image serves as the lookahead target, eliminating the need for keyframe generation entirely. We find that the temporal lookahead distance naturally controls the balance between expressivity and consistency: larger distances allow for greater motion freedom, while smaller ones strengthen identity adherence. When applied to three recent human animation models, Lookahead Anchoring achieves superior lip synchronization, identity preservation, and visual quality, demonstrating improved temporal conditioning across several different architectures. Video results are available at the following link: https://lookahead-anchoring.github.io.",
    "authors": [
      "Junyoung Seo",
      "Rodrigo Mira",
      "Alexandros Haliassos",
      "Stella Bounareli",
      "Honglie Chen",
      "Linh Tran",
      "Seungryong Kim",
      "Zoe Landgraf",
      "Jie Shen"
    ],
    "categories": [
      "cs.CV",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23581v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23581v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2510.23536v1",
    "title": "IPQA: A Benchmark for Core Intent Identification in Personalized   Question Answering",
    "summary": "Intent identification serves as the foundation for generating appropriate responses in personalized question answering (PQA). However, existing benchmarks evaluate only response quality or retrieval performance without directly measuring intent identification capabilities. This gap is critical because without understanding which intents users prioritize, systems cannot generate responses satisfying individual information needs. To address this, we introduce the concept of core intents: intents users prioritize when selecting answers to satisfy their information needs. To evaluate these core intents, we propose IPQA, a benchmark for core Intent identification in Personalized Question Answering. Since users do not explicitly state their prioritized intents, we derive core intents from observable behavior patterns in answer selection, grounded in satisficing theory where users choose answers meeting their acceptance thresholds. We construct a dataset with various domains through systematic filtering, LLM-based annotation, and rigorous quality control combining automated verification with human validation. Experimental evaluations across state-of-the-art language models reveal that current systems struggle with core intent identification in personalized contexts. Models fail to identify core intents from user histories, with performance degrading as question complexity increases. The code and dataset will be made publicly available to facilitate future research in this direction.",
    "authors": [
      "Jieyong Kim",
      "Maryam Amirizaniani",
      "Soojin Yoon",
      "Dongha Lee"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23536v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23536v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2510.23525v1",
    "title": "DPGLA: Bridging the Gap between Synthetic and Real Data for Unsupervised   Domain Adaptation in 3D LiDAR Semantic Segmentation",
    "summary": "Annotating real-world LiDAR point clouds for use in intelligent autonomous systems is costly. To overcome this limitation, self-training-based Unsupervised Domain Adaptation (UDA) has been widely used to improve point cloud semantic segmentation by leveraging synthetic point cloud data. However, we argue that existing methods do not effectively utilize unlabeled data, as they either rely on predefined or fixed confidence thresholds, resulting in suboptimal performance. In this paper, we propose a Dynamic Pseudo-Label Filtering (DPLF) scheme to enhance real data utilization in point cloud UDA semantic segmentation. Additionally, we design a simple and efficient Prior-Guided Data Augmentation Pipeline (PG-DAP) to mitigate domain shift between synthetic and real-world point clouds. Finally, we utilize data mixing consistency loss to push the model to learn context-free representations. We implement and thoroughly evaluate our approach through extensive comparisons with state-of-the-art methods. Experiments on two challenging synthetic-to-real point cloud semantic segmentation tasks demonstrate that our approach achieves superior performance. Ablation studies confirm the effectiveness of the DPLF and PG-DAP modules. We release the code of our method in this paper.",
    "authors": [
      "Wanmeng Li",
      "Simone Mosco",
      "Daniel Fusaro",
      "Alberto Pretto"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23525v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23525v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2510.23489v1",
    "title": "Quantum Phase Classification of Rydberg Atom Systems Using   Resource-Efficient Variational Quantum Circuits and Classical Shadows",
    "summary": "Quantum phase transitions in Rydberg atom arrays present significant opportunities for studying many-body physics, yet distinguishing between different ordered phases without explicit order parameters remains challenging. We present a resource-efficient quantum machine learning approach combining classical shadow tomography with variational quantum circuits (VQCs) for binary phase classification of Z2 and Z3 ordered phases. Our pipeline processes 500 randomized measurements per 51-atom chain state, reconstructs shadow operators, performs PCA dimensionality reduction (514 features), and encodes features using angle embedding onto a 2-qubit parameterized circuit. The circuit employs RY-RZ angle encoding, strong entanglement via all-to-all CZ gates, and a minimal 2-parameter ansatz achieving depth 7. Training via simultaneous perturbation stochastic approximation (SPSA) with hinge loss converged in 120 iterations. The model achieved 100% test accuracy with perfect precision, recall, and F1 scores, demonstrating that minimal quantum resources suffice for high-accuracy phase classification. This work establishes pathways for quantum-enhanced condensed matter physics on near-term quantum devices.",
    "authors": [
      "Hemish Ahuja",
      "Samradh Bhardwaj",
      "Kirti Dhir",
      "Roman Bagdasarian",
      "Ziwoong Jang"
    ],
    "categories": [
      "quant-ph",
      "cs.LG",
      "81P68"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23489v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23489v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2510.23486v1",
    "title": "Learning to Reason Efficiently with Discounted Reinforcement Learning",
    "summary": "Large reasoning models (LRMs) often consume excessive tokens, inflating computational cost and latency. We challenge the assumption that longer responses improve accuracy. By penalizing reasoning tokens using a discounted reinforcement learning setup (interpretable as a small token cost) and analyzing Blackwell optimality in restricted policy classes, we encourage concise yet accurate reasoning. Experiments confirm our theoretical results that this approach shortens chains of thought while preserving accuracy.",
    "authors": [
      "Alex Ayoub",
      "Kavosh Asadi",
      "Dale Schuurmans",
      "Csaba Szepesvári",
      "Karim Bouyarmane"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23486v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23486v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2510.23477v1",
    "title": "MMTutorBench: The First Multimodal Benchmark for AI Math Tutoring",
    "summary": "Effective math tutoring requires not only solving problems but also diagnosing students' difficulties and guiding them step by step. While multimodal large language models (MLLMs) show promise, existing benchmarks largely overlook these tutoring skills. We introduce MMTutorBench, the first benchmark for AI math tutoring, consisting of 685 problems built around pedagogically significant key-steps. Each problem is paired with problem-specific rubrics that enable fine-grained evaluation across six dimensions, and structured into three tasks-Insight Discovery, Operation Formulation, and Operation Execution. We evaluate 12 leading MLLMs and find clear performance gaps between proprietary and open-source systems, substantial room compared to human tutors, and consistent trends across input variants: OCR pipelines degrade tutoring quality, few-shot prompting yields limited gains, and our rubric-based LLM-as-a-Judge proves highly reliable. These results highlight both the difficulty and diagnostic value of MMTutorBench for advancing AI tutoring.",
    "authors": [
      "Tengchao Yang",
      "Sichen Guo",
      "Mengzhao Jia",
      "Jiaming Su",
      "Yuanyang Liu",
      "Zhihan Zhang",
      "Meng Jiang"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23477v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23477v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2510.23319v1",
    "title": "Arabic Little STT: Arabic Children Speech Recognition Dataset",
    "summary": "The performance of Artificial Intelligence (AI) systems fundamentally depends on high-quality training data. However, low-resource languages like Arabic suffer from severe data scarcity. Moreover, the absence of child-specific speech corpora is an essential gap that poses significant challenges. To address this gap, we present our created dataset, Arabic Little STT, a dataset of Levantine Arabic child speech recorded in classrooms, containing 355 utterances from 288 children (ages 6 - 13). We further conduct a systematic assessment of Whisper, a state-of-the-art automatic speech recognition (ASR) model, on this dataset and compare its performance with adult Arabic benchmarks. Our evaluation across eight Whisper variants reveals that even the best-performing model (Large_v3) struggles significantly, achieving a 0.66 word error rate (WER) on child speech, starkly contrasting with its sub 0.20 WER on adult datasets. These results align with other research on English speech. Results highlight the critical need for dedicated child speech benchmarks and inclusive training data in ASR development. Emphasizing that such data must be governed by strict ethical and privacy frameworks to protect sensitive child information. We hope that this study provides an initial step for future work on equitable speech technologies for Arabic-speaking children. We hope that our publicly available dataset enrich the children's demographic representation in ASR datasets.",
    "authors": [
      "Mouhand Alkadri",
      "Dania Desouki",
      "Khloud Al Jallad"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.HC",
      "cs.LG",
      "cs.SD"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23319v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23319v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.58
  },
  {
    "arxiv_id": "2510.23607v1",
    "title": "Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial   Representations",
    "summary": "Humans learn abstract concepts through multisensory synergy, and once formed, such representations can often be recalled from a single modality. Inspired by this principle, we introduce Concerto, a minimalist simulation of human concept learning for spatial cognition, combining 3D intra-modal self-distillation with 2D-3D cross-modal joint embedding. Despite its simplicity, Concerto learns more coherent and informative spatial features, as demonstrated by zero-shot visualizations. It outperforms both standalone SOTA 2D and 3D self-supervised models by 14.2% and 4.8%, respectively, as well as their feature concatenation, in linear probing for 3D scene perception. With full fine-tuning, Concerto sets new SOTA results across multiple scene understanding benchmarks (e.g., 80.7% mIoU on ScanNet). We further present a variant of Concerto tailored for video-lifted point cloud spatial understanding, and a translator that linearly projects Concerto representations into CLIP's language space, enabling open-world perception. These results highlight that Concerto emerges spatial representations with superior fine-grained geometric and semantic consistency.",
    "authors": [
      "Yujia Zhang",
      "Xiaoyang Wu",
      "Yixing Lao",
      "Chengyao Wang",
      "Zhuotao Tian",
      "Naiyan Wang",
      "Hengshuang Zhao"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23607v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23607v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.23508v1",
    "title": "M4FC: a Multimodal, Multilingual, Multicultural, Multitask Real-World   Fact-Checking Dataset",
    "summary": "Existing real-world datasets for multimodal automated fact-checking have multiple limitations: they contain few instances, focus on only one or two languages and tasks, suffer from evidence leakage, or depend on external sets of news articles for sourcing true claims. To address these shortcomings, we introduce M4FC, a new real-world dataset comprising 4,982 images paired with 6,980 claims. The images, verified by professional fact-checkers from 22 organizations, represent diverse cultural and geographic contexts. Each claim is available in one or two out of ten languages. M4FC spans six multimodal fact-checking tasks: visual claim extraction, claimant intent prediction, fake detection, image contextualization, location verification, and verdict prediction. We provide baseline results for all tasks and analyze how combining intermediate tasks influence downstream verdict prediction performance. We make our dataset and code available.",
    "authors": [
      "Jiahui Geng",
      "Jonathan Tonglet",
      "Iryna Gurevych"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23508v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23508v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.23498v1",
    "title": "Mixed Precision Training of Neural ODEs",
    "summary": "Exploiting low-precision computations has become a standard strategy in deep learning to address the growing computational costs imposed by ever larger models and datasets. However, naively performing all computations in low precision can lead to roundoff errors and instabilities. Therefore, mixed precision training schemes usually store the weights in high precision and use low-precision computations only for whitelisted operations. Despite their success, these principles are currently not reliable for training continuous-time architectures such as neural ordinary differential equations (Neural ODEs). This paper presents a mixed precision training framework for neural ODEs, combining explicit ODE solvers with a custom backpropagation scheme, and demonstrates its effectiveness across a range of learning tasks. Our scheme uses low-precision computations for evaluating the velocity, parameterized by the neural network, and for storing intermediate states, while stability is provided by a custom dynamic adjoint scaling and by accumulating the solution and gradients in higher precision. These contributions address two key challenges in training neural ODE: the computational cost of repeated network evaluations and the growth of memory requirements with the number of time steps or layers. Along with the paper, we publish our extendable, open-source PyTorch package rampde, whose syntax resembles that of leading packages to provide a drop-in replacement in existing codes. We demonstrate the reliability and effectiveness of our scheme using challenging test cases and on neural ODE applications in image classification and generative models, achieving approximately 50% memory reduction and up to 2x speedup while maintaining accuracy comparable to single-precision training.",
    "authors": [
      "Elena Celledoni",
      "Brynjulf Owren",
      "Lars Ruthotto",
      "Tianjiao Nicole Yang"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.NA",
      "math.NA",
      "68T07, 65L06, 65G50",
      "I.2; G.1"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23498v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23498v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.23463v1",
    "title": "Differential Privacy as a Perk: Federated Learning over Multiple-Access   Fading Channels with a Multi-Antenna Base Station",
    "summary": "Federated Learning (FL) is a distributed learning paradigm that preserves privacy by eliminating the need to exchange raw data during training. In its prototypical edge instantiation with underlying wireless transmissions enabled by analog over-the-air computing (AirComp), referred to as \\emph{over-the-air FL (AirFL)}, the inherent channel noise plays a unique role of \\emph{frenemy} in the sense that it degrades training due to noisy global aggregation while providing a natural source of randomness for privacy-preserving mechanisms, formally quantified by \\emph{differential privacy (DP)}. It remains, nevertheless, challenging to effectively harness such channel impairments, as prior arts, under assumptions of either simple channel models or restricted types of loss functions, mostly considering (local) DP enhancement with a single-round or non-convergent bound on privacy loss. In this paper, we study AirFL over multiple-access fading channels with a multi-antenna base station (BS) subject to user-level DP requirements. Despite a recent study, which claimed in similar settings that artificial noise (AN) must be injected to ensure DP in general, we demonstrate, on the contrary, that DP can be gained as a \\emph{perk} even \\emph{without} employing any AN. Specifically, we derive a novel bound on DP that converges under general bounded-domain assumptions on model parameters, along with a convergence bound with general smooth and non-convex loss functions. Next, we optimize over receive beamforming and power allocations to characterize the optimal convergence-privacy trade-offs, which also reveal explicit conditions in which DP is achievable without compromising training. Finally, our theoretical findings are validated by extensive numerical results.",
    "authors": [
      "Hao Liang",
      "Haifeng Wen",
      "Kaishun Wu",
      "Hong Xing"
    ],
    "categories": [
      "cs.LG",
      "cs.CR",
      "stat.ML"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23463v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23463v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.23458v1",
    "title": "BrowseConf: Confidence-Guided Test-Time Scaling for Web Agents",
    "summary": "Confidence in LLMs is a useful indicator of model uncertainty and answer reliability. Existing work mainly focused on single-turn scenarios, while research on confidence in complex multi-turn interactions is limited. In this paper, we investigate whether LLM-based search agents have the ability to communicate their own confidence through verbalized confidence scores after long sequences of actions, a significantly more challenging task compared to outputting confidence in a single interaction. Experimenting on open-source agentic models, we first find that models exhibit much higher task accuracy at high confidence while having near-zero accuracy when confidence is low. Based on this observation, we propose Test-Time Scaling (TTS) methods that use confidence scores to determine answer quality, encourage the model to try again until reaching a satisfactory confidence level. Results show that our proposed methods significantly reduce token consumption while demonstrating competitive performance compared to baseline fixed budget TTS methods.",
    "authors": [
      "Litu Ou",
      "Kuan Li",
      "Huifeng Yin",
      "Liwen Zhang",
      "Zhongwang Zhang",
      "Xixi Wu",
      "Rui Ye",
      "Zile Qiao",
      "Yong Jiang",
      "Pengjun Xie",
      "Fei Huang",
      "Jingren Zhou"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23458v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23458v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.23453v1",
    "title": "What are the odds? Risk and uncertainty about AI existential risk",
    "summary": "This work is a commentary of the article \\href{https://doi.org/10.18716/ojs/phai/2025.2801}{AI Survival Stories: a Taxonomic Analysis of AI Existential Risk} by Cappelen, Goldstein, and Hawthorne. It is not just a commentary though, but a useful reminder of the philosophical limitations of \\say{linear} models of risk. The article will focus on the model employed by the authors: first, I discuss some differences between standard Swiss Cheese models and this one. I then argue that in a situation of epistemic indifference the probability of P(D) is higher than what one might first suggest, given the structural relationships between layers. I then distinguish between risk and uncertainty, and argue that any estimation of P(D) is structurally affected by two kinds of uncertainty: option uncertainty and state-space uncertainty. Incorporating these dimensions of uncertainty into our qualitative discussion on AI existential risk can provide a better understanding of the likeliness of P(D).",
    "authors": [
      "Marco Grossi"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23453v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23453v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.23410v1",
    "title": "Bid2X: Revealing Dynamics of Bidding Environment in Online Advertising   from A Foundation Model Lens",
    "summary": "Auto-bidding is crucial in facilitating online advertising by automatically providing bids for advertisers. While previous work has made great efforts to model bidding environments for better ad performance, it has limitations in generalizability across environments since these models are typically tailored for specific bidding scenarios. To this end, we approach the scenario-independent principles through a unified function that estimates the achieved effect under specific bids, such as budget consumption, gross merchandise volume (GMV), page views, etc. Then, we propose a bidding foundation model Bid2X to learn this fundamental function from data in various scenarios. Our Bid2X is built over uniform series embeddings that encode heterogeneous data through tailored embedding methods. To capture complex inter-variable and dynamic temporal dependencies in bidding data, we propose two attention mechanisms separately treating embeddings of different variables and embeddings at different times as attention tokens for representation learning. On top of the learned variable and temporal representations, a variable-aware fusion module is used to perform adaptive bidding outcome prediction. To model the unique bidding data distribution, we devise a zero-inflated projection module to incorporate the estimated non-zero probability into its value prediction, which makes up a joint optimization objective containing classification and regression. The objective is proven to converge to the zero-inflated distribution. Our model has been deployed on the ad platform in Taobao, one of the world's largest e-commerce platforms. Offline evaluation on eight datasets exhibits Bid2X's superiority compared to various baselines and its generality across different scenarios. Bid2X increased GMV by 4.65% and ROI by 2.44% in online A/B tests, paving the way for bidding foundation model in computational advertising.",
    "authors": [
      "Jiahao Ji",
      "Tianyu Wang",
      "Yeshu Li",
      "Yushen Huo",
      "Zhilin Zhang",
      "Chuan Yu",
      "Jian Xu",
      "Bo Zheng"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23410v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23410v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.23393v1",
    "title": "The Best of N Worlds: Aligning Reinforcement Learning with Best-of-N   Sampling via max@k Optimisation",
    "summary": "The application of Reinforcement Learning with Verifiable Rewards (RLVR) to mathematical and coding domains has demonstrated significant improvements in the reasoning and problem-solving abilities of Large Language Models. Despite its success in single generation problem solving, the reinforcement learning fine-tuning process may harm the model's exploration ability, as reflected in decreased diversity of generations and a resulting degradation of performance during Best-of-N sampling for large N values. In this work, we focus on optimizing the max@k metric, a continuous generalization of pass@k. We derive an unbiased on-policy gradient estimate for direct optimization of this metric. Furthermore, we extend our derivations to the off-policy updates, a common element in modern RLVR algorithms, that allows better sample efficiency. Empirically, we show that our objective effectively optimizes max@k metric in off-policy scenarios, aligning the model with the Best-of-N inference strategy.",
    "authors": [
      "Farid Bagirov",
      "Mikhail Arkhipov",
      "Ksenia Sycheva",
      "Evgeniy Glukhov",
      "Egor Bogomolov"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23393v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23393v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.23371v1",
    "title": "Towards a Generalizable AI for Materials Discovery: Validation through   Immersion Coolant Screening",
    "summary": "Artificial intelligence (AI) has emerged as a powerful accelerator of materials discovery, yet most existing models remain problem-specific, requiring additional data collection and retraining for each new property. Here we introduce and validate GATE (Geometrically Aligned Transfer Encoder) -- a generalizable AI framework that jointly learns 34 physicochemical properties spanning thermal, electrical, mechanical, and optical domains. By aligning these properties within a shared geometric space, GATE captures cross-property correlations that reduce disjoint-property bias -- a key factor causing false negatives in multi-criteria screening. To demonstrate its generalizability, GATE -- without any problem-specific reconfiguration -- was directly applied to the discovery of immersion cooling fluids for data centers, a stringent real-world challenge defined by the Open Compute Project (OCP). Screening billions of candidates, GATE identified 92,861 molecules as promising for practical deployment. Four were experimentally or literarily validated, showing strong agreement with wet-lab measurements and performance comparable to or exceeding a commercial coolant. These results establish GATE as a ready-to-use, generalizable AI platform readily applicable across diverse materials discovery tasks.",
    "authors": [
      "Hyunseung Kim",
      "Dae-Woong Jeong",
      "Changyoung Park",
      "Won-Ji Lee",
      "Ha-Eun Lee",
      "Ji-Hye Lee",
      "Rodrigo Hormazabal",
      "Sung Moon Ko",
      "Sumin Lee",
      "Soorin Yim",
      "Chanhui Lee",
      "Sehui Han",
      "Sang-Ho Cha",
      "Woohyung Lim"
    ],
    "categories": [
      "cs.LG",
      "cs.CE"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23371v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23371v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.23306v1",
    "title": "ReconViaGen: Towards Accurate Multi-view 3D Object Reconstruction via   Generation",
    "summary": "Existing multi-view 3D object reconstruction methods heavily rely on sufficient overlap between input views, where occlusions and sparse coverage in practice frequently yield severe reconstruction incompleteness. Recent advancements in diffusion-based 3D generative techniques offer the potential to address these limitations by leveraging learned generative priors to hallucinate invisible parts of objects, thereby generating plausible 3D structures. However, the stochastic nature of the inference process limits the accuracy and reliability of generation results, preventing existing reconstruction frameworks from integrating such 3D generative priors. In this work, we comprehensively analyze the reasons why diffusion-based 3D generative methods fail to achieve high consistency, including (a) the insufficiency in constructing and leveraging cross-view connections when extracting multi-view image features as conditions, and (b) the poor controllability of iterative denoising during local detail generation, which easily leads to plausible but inconsistent fine geometric and texture details with inputs. Accordingly, we propose ReconViaGen to innovatively integrate reconstruction priors into the generative framework and devise several strategies that effectively address these issues. Extensive experiments demonstrate that our ReconViaGen can reconstruct complete and accurate 3D models consistent with input views in both global structure and local details.Project page: https://jiahao620.github.io/reconviagen.",
    "authors": [
      "Jiahao Chang",
      "Chongjie Ye",
      "Yushuang Wu",
      "Yuantao Chen",
      "Yidan Zhang",
      "Zhongjin Luo",
      "Chenghong Li",
      "Yihao Zhi",
      "Xiaoguang Han"
    ],
    "categories": [
      "cs.CV",
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23306v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23306v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.23191v1",
    "title": "The Benchmarking Epistemology: Construct Validity for Evaluating Machine   Learning Models",
    "summary": "Predictive benchmarking, the evaluation of machine learning models based on predictive performance and competitive ranking, is a central epistemic practice in machine learning research and an increasingly prominent method for scientific inquiry. Yet, benchmark scores alone provide at best measurements of model performance relative to an evaluation dataset and a concrete learning problem. Drawing substantial scientific inferences from the results, say about theoretical tasks like image classification, requires additional assumptions about the theoretical structure of the learning problems, evaluation functions, and data distributions. We make these assumptions explicit by developing conditions of construct validity inspired by psychological measurement theory. We examine these assumptions in practice through three case studies, each exemplifying a typical intended inference: measuring engineering progress in computer vision with ImageNet; evaluating policy-relevant weather predictions with WeatherBench; and examining limitations of the predictability of life events with the Fragile Families Challenge. Our framework clarifies the conditions under which benchmark scores can support diverse scientific claims, bringing predictive benchmarking into perspective as an epistemological practice and a key site of conceptual and theoretical reasoning in machine learning.",
    "authors": [
      "Timo Freiesleben",
      "Sebastian Zezulka"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23191v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23191v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.23176v1",
    "title": "TARC: Time-Adaptive Robotic Control",
    "summary": "Fixed-frequency control in robotics imposes a trade-off between the efficiency of low-frequency control and the robustness of high-frequency control, a limitation not seen in adaptable biological systems. We address this with a reinforcement learning approach in which policies jointly select control actions and their application durations, enabling robots to autonomously modulate their control frequency in response to situational demands. We validate our method with zero-shot sim-to-real experiments on two distinct hardware platforms: a high-speed RC car and a quadrupedal robot. Our method matches or outperforms fixed-frequency baselines in terms of rewards while significantly reducing the control frequency and exhibiting adaptive frequency control under real-world conditions.",
    "authors": [
      "Arnav Sukhija",
      "Lenart Treven",
      "Jin Cheng",
      "Florian Dörfler",
      "Stelian Coros",
      "Andreas Krause"
    ],
    "categories": [
      "cs.RO",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23176v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23176v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.23171v1",
    "title": "Benchmarking VQE Configurations: Architectures, Initializations, and   Optimizers for Silicon Ground State Energy",
    "summary": "Quantum computing presents a promising path toward precise quantum chemical simulations, particularly for systems that challenge classical methods. This work investigates the performance of the Variational Quantum Eigensolver (VQE) in estimating the ground-state energy of the silicon atom, a relatively heavy element that poses significant computational complexity. Within a hybrid quantum-classical optimization framework, we implement VQE using a range of ansatz, including Double Excitation Gates, ParticleConservingU2, UCCSD, and k-UpCCGSD, combined with various optimizers such as gradient descent, SPSA, and ADAM. The main contribution of this work lies in a systematic methodological exploration of how these configuration choices interact to influence VQE performance, establishing a structured benchmark for selecting optimal settings in quantum chemical simulations. Key findings show that parameter initialization plays a decisive role in the algorithm's stability, and that the combination of a chemically inspired ansatz with adaptive optimization yields superior convergence and precision compared to conventional approaches.",
    "authors": [
      "Zakaria Boutakka",
      "Nouhaila Innan",
      "Muhammed Shafique",
      "Mohamed Bennai",
      "Z. Sakhi"
    ],
    "categories": [
      "quant-ph",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23171v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23171v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.23087v1",
    "title": "EndoWave: Rational-Wavelet 4D Gaussian Splatting for Endoscopic   Reconstruction",
    "summary": "In robot-assisted minimally invasive surgery, accurate 3D reconstruction from endoscopic video is vital for downstream tasks and improved outcomes. However, endoscopic scenarios present unique challenges, including photometric inconsistencies, non-rigid tissue motion, and view-dependent highlights. Most 3DGS-based methods that rely solely on appearance constraints for optimizing 3DGS are often insufficient in this context, as these dynamic visual artifacts can mislead the optimization process and lead to inaccurate reconstructions. To address these limitations, we present EndoWave, a unified spatio-temporal Gaussian Splatting framework by incorporating an optical flow-based geometric constraint and a multi-resolution rational wavelet supervision. First, we adopt a unified spatio-temporal Gaussian representation that directly optimizes primitives in a 4D domain. Second, we propose a geometric constraint derived from optical flow to enhance temporal coherence and effectively constrain the 3D structure of the scene. Third, we propose a multi-resolution rational orthogonal wavelet as a constraint, which can effectively separate the details of the endoscope and enhance the rendering performance. Extensive evaluations on two real surgical datasets, EndoNeRF and StereoMIS, demonstrate that our method EndoWave achieves state-of-the-art reconstruction quality and visual accuracy compared to the baseline method.",
    "authors": [
      "Taoyu Wu",
      "Yiyi Miao",
      "Jiaxin Guo",
      "Ziyan Chen",
      "Sihang Zhao",
      "Zhuoxiao Li",
      "Zhe Tang",
      "Baoru Huang",
      "Limin Yu"
    ],
    "categories": [
      "cs.CV",
      "cs.RO"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23087v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23087v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.23077v1",
    "title": "Think before Recommendation: Autonomous Reasoning-enhanced Recommender",
    "summary": "The core task of recommender systems is to learn user preferences from historical user-item interactions. With the rapid development of large language models (LLMs), recent research has explored leveraging the reasoning capabilities of LLMs to enhance rating prediction tasks. However, existing distillation-based methods suffer from limitations such as the teacher model's insufficient recommendation capability, costly and static supervision, and superficial transfer of reasoning ability. To address these issues, this paper proposes RecZero, a reinforcement learning (RL)-based recommendation paradigm that abandons the traditional multi-model and multi-stage distillation approach. Instead, RecZero trains a single LLM through pure RL to autonomously develop reasoning capabilities for rating prediction. RecZero consists of two key components: (1) \"Think-before-Recommendation\" prompt construction, which employs a structured reasoning template to guide the model in step-wise analysis of user interests, item features, and user-item compatibility; and (2) rule-based reward modeling, which adopts group relative policy optimization (GRPO) to compute rewards for reasoning trajectories and optimize the LLM. Additionally, the paper explores a hybrid paradigm, RecOne, which combines supervised fine-tuning with RL, initializing the model with cold-start reasoning samples and further optimizing it with RL. Experimental results demonstrate that RecZero and RecOne significantly outperform existing baseline methods on multiple benchmark datasets, validating the superiority of the RL paradigm in achieving autonomous reasoning-enhanced recommender systems.",
    "authors": [
      "Xiaoyu Kong",
      "Junguang Jiang",
      "Bin Liu",
      "Ziru Xu",
      "Han Zhu",
      "Jian Xu",
      "Bo Zheng",
      "Jiancan Wu",
      "Xiang Wang"
    ],
    "categories": [
      "cs.IR",
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23077v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23077v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.57
  },
  {
    "arxiv_id": "2510.23603v1",
    "title": "PixelRefer: A Unified Framework for Spatio-Temporal Object Referring   with Arbitrary Granularity",
    "summary": "Multimodal large language models (MLLMs) have demonstrated strong general-purpose capabilities in open-world visual comprehension. However, most existing MLLMs primarily focus on holistic, scene-level understanding, often overlooking the need for fine-grained, object-centric reasoning. In this paper, we present PixelRefer, a unified region-level MLLM framework that enables advanced fine-grained understanding over user-specified regions across both images and videos. Motivated by the observation that LLM attention predominantly focuses on object-level tokens, we propose a Scale-Adaptive Object Tokenizer (SAOT) to generate compact and semantically rich object representations from free-form regions. Our analysis reveals that global visual tokens contribute mainly in early LLM layers, inspiring the design of PixelRefer-Lite, an efficient variant that employs an Object-Centric Infusion module to pre-fuse global context into object tokens. This yields a lightweight Object-Only Framework that substantially reduces computational cost while maintaining high semantic fidelity. To facilitate fine-grained instruction tuning, we curate PixelRefer-2.2M, a high-quality object-centric instruction dataset. Extensive experiments across a range of benchmarks validate that PixelRefer achieves leading performance with fewer training samples, while PixelRefer-Lite offers competitive accuracy with notable gains in efficiency.",
    "authors": [
      "Yuqian Yuan",
      "Wenqiao Zhang",
      "Xin Li",
      "Shihao Wang",
      "Kehan Li",
      "Wentong Li",
      "Jun Xiao",
      "Lei Zhang",
      "Beng Chin Ooi"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23603v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23603v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.23550v1",
    "title": "Bayesian Nonlinear PDE Inference via Gaussian Process Collocation with   Application to the Richards Equation",
    "summary": "The estimation of unknown parameters in nonlinear partial differential equations (PDEs) offers valuable insights across a wide range of scientific domains. In this work, we focus on estimating plant root parameters in the Richards equation, which is essential for understanding the soil-plant system in agricultural studies. Since conventional methods are computationally intensive and often yield unstable estimates, we develop a new Gaussian process collocation method for efficient Bayesian inference. Unlike existing Gaussian process-based approaches, our method constructs an approximate posterior distribution using samples drawn from a Gaussian process model fitted to the observed data, which does not require any structural assumption about the underlying PDE. Further, we propose to use an importance sampling procedure to correct for the discrepancy between the approximate and true posterior distributions. As an alternative, we also devise a prior-guided Bayesian optimization algorithm leveraging the approximate posterior. Simulation studies demonstrate that our method yields robust estimates under various settings. Finally, we apply our method on a real agricultural data set and estimate the plant root parameters with uncertainty quantification.",
    "authors": [
      "Yumo Yang",
      "Anass Ben Bouazza",
      "Xuejun Dong",
      "Quan Zhou"
    ],
    "categories": [
      "stat.ME",
      "stat.AP",
      "stat.CO",
      "stat.ML"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23550v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23550v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.23515v1",
    "title": "FreeFuse: Multi-Subject LoRA Fusion via Auto Masking at Test Time",
    "summary": "This paper proposes FreeFuse, a novel training-free approach for multi-subject text-to-image generation through automatic fusion of multiple subject LoRAs. In contrast to existing methods that either focus on pre-inference LoRA weight merging or rely on segmentation models and complex techniques like noise blending to isolate LoRA outputs, our key insight is that context-aware dynamic subject masks can be automatically derived from cross-attention layer weights. Mathematical analysis shows that directly applying these masks to LoRA outputs during inference well approximates the case where the subject LoRA is integrated into the diffusion model and used individually for the masked region. FreeFuse demonstrates superior practicality and efficiency as it requires no additional training, no modification to LoRAs, no auxiliary models, and no user-defined prompt templates or region specifications. Alternatively, it only requires users to provide the LoRA activation words for seamless integration into standard workflows. Extensive experiments validate that FreeFuse outperforms existing approaches in both generation quality and usability under the multi-subject generation tasks. The project page is at https://future-item.github.io/FreeFuse/",
    "authors": [
      "Yaoli Liu",
      "Yao-Xiang Ding",
      "Kun Zhou"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23515v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23515v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.23487v1",
    "title": "Are Agents Just Automata? On the Formal Equivalence Between Agentic AI   and the Chomsky Hierarchy",
    "summary": "This paper establishes a formal equivalence between the architectural classes of modern agentic AI systems and the abstract machines of the Chomsky hierarchy. We posit that the memory architecture of an AI agent is the definitive feature determining its computational power and that it directly maps it to a corresponding class of automaton. Specifically, we demonstrate that simple reflex agents are equivalent to Finite Automata, hierarchical task-decomposition agents are equivalent to Pushdown Automata, and agents employing readable/writable memory for reflection are equivalent to TMs. This Automata-Agent Framework provides a principled methodology for right-sizing agent architectures to optimize computational efficiency and cost. More critically, it creates a direct pathway to formal verification, enables the application of mature techniques from automata theory to guarantee agent safety and predictability. By classifying agents, we can formally delineate the boundary between verifiable systems and those whose behavior is fundamentally undecidable. We address the inherent probabilistic nature of LLM-based agents by extending the framework to probabilistic automata that allow quantitative risk analysis. The paper concludes by outlining an agenda for developing static analysis tools and grammars for agentic frameworks.",
    "authors": [
      "Roham Koohestani",
      "Ziyou Li",
      "Anton Podkopaev",
      "Maliheh Izadi"
    ],
    "categories": [
      "cs.AI",
      "cs.FL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23487v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23487v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.23485v1",
    "title": "Tighter CMI-Based Generalization Bounds via Stochastic Projection and   Quantization",
    "summary": "In this paper, we leverage stochastic projection and lossy compression to establish new conditional mutual information (CMI) bounds on the generalization error of statistical learning algorithms. It is shown that these bounds are generally tighter than the existing ones. In particular, we prove that for certain problem instances for which existing MI and CMI bounds were recently shown in Attias et al. [2024] and Livni [2023] to become vacuous or fail to describe the right generalization behavior, our bounds yield suitable generalization guarantees of the order of $\\mathcal{O}(1/\\sqrt{n})$, where $n$ is the size of the training dataset. Furthermore, we use our bounds to investigate the problem of data \"memorization\" raised in those works, and which asserts that there are learning problem instances for which any learning algorithm that has good prediction there exist distributions under which the algorithm must \"memorize\" a big fraction of the training dataset. We show that for every learning algorithm, there exists an auxiliary algorithm that does not memorize and which yields comparable generalization error for any data distribution. In part, this shows that memorization is not necessary for good generalization.",
    "authors": [
      "Milad Sefidgaran",
      "Kimia Nadjahi",
      "Abdellatif Zaidi"
    ],
    "categories": [
      "stat.ML",
      "cs.IT",
      "cs.LG",
      "math.IT"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23485v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23485v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.23474v1",
    "title": "Policy-Aware Generative AI for Safe, Auditable Data Access Governance",
    "summary": "Enterprises need access decisions that satisfy least privilege, comply with regulations, and remain auditable. We present a policy aware controller that uses a large language model (LLM) to interpret natural language requests against written policies and metadata, not raw data. The system, implemented with Google Gemini~2.0 Flash, executes a six-stage reasoning framework (context interpretation, user validation, data classification, business purpose test, compliance mapping, and risk synthesis) with early hard policy gates and deny by default. It returns APPROVE, DENY, CONDITIONAL together with cited controls and a machine readable rationale. We evaluate on fourteen canonical cases across seven scenario families using a privacy preserving benchmark. Results show Exact Decision Match improving from 10/14 to 13/14 (92.9\\%) after applying policy gates, DENY recall rising to 1.00, False Approval Rate on must-deny families dropping to 0, and Functional Appropriateness and Compliance Adherence at 14/14. Expert ratings of rationale quality are high, and median latency is under one minute. These findings indicate that policy constrained LLM reasoning, combined with explicit gates and audit trails, can translate human readable policies into safe, compliant, and traceable machine decisions.",
    "authors": [
      "Shames Al Mandalawi",
      "Muzakkiruddin Ahmed Mohammed",
      "Hendrika Maclean",
      "Mert Can Cakmak",
      "John R. Talburt"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23474v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23474v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.23448v1",
    "title": "An Information-Theoretic Analysis of Out-of-Distribution Generalization   in Meta-Learning with Applications to Meta-RL",
    "summary": "In this work, we study out-of-distribution generalization in meta-learning from an information-theoretic perspective. We focus on two scenarios: (i) when the testing environment mismatches the training environment, and (ii) when the training environment is broader than the testing environment. The first corresponds to the standard distribution mismatch setting, while the second reflects a broad-to-narrow training scenario. We further formalize the generalization problem in meta-reinforcement learning and establish corresponding generalization bounds. Finally, we analyze the generalization performance of a gradient-based meta-reinforcement learning algorithm.",
    "authors": [
      "Xingtu Liu"
    ],
    "categories": [
      "cs.LG",
      "stat.ML"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23448v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23448v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.23443v1",
    "title": "A Neuro-Symbolic Multi-Agent Approach to Legal-Cybersecurity Knowledge   Integration",
    "summary": "The growing intersection of cybersecurity and law creates a complex information space where traditional legal research tools struggle to deal with nuanced connections between cases, statutes, and technical vulnerabilities. This knowledge divide hinders collaboration between legal experts and cybersecurity professionals. To address this important gap, this work provides a first step towards intelligent systems capable of navigating the increasingly intricate cyber-legal domain. We demonstrate promising initial results on multilingual tasks.",
    "authors": [
      "Chiara Bonfanti",
      "Alessandro Druetto",
      "Cataldo Basile",
      "Tharindu Ranasinghe",
      "Marcos Zampieri"
    ],
    "categories": [
      "cs.AI",
      "cs.CL",
      "cs.CR",
      "cs.MA"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23443v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23443v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.23299v1",
    "title": "MMSD3.0: A Multi-Image Benchmark for Real-World Multimodal Sarcasm   Detection",
    "summary": "Despite progress in multimodal sarcasm detection, existing datasets and methods predominantly focus on single-image scenarios, overlooking potential semantic and affective relations across multiple images. This leaves a gap in modeling cases where sarcasm is triggered by multi-image cues in real-world settings. To bridge this gap, we introduce MMSD3.0, a new benchmark composed entirely of multi-image samples curated from tweets and Amazon reviews. We further propose the Cross-Image Reasoning Model (CIRM), which performs targeted cross-image sequence modeling to capture latent inter-image connections. In addition, we introduce a relevance-guided, fine-grained cross-modal fusion mechanism based on text-image correspondence to reduce information loss during integration. We establish a comprehensive suite of strong and representative baselines and conduct extensive experiments, showing that MMSD3.0 is an effective and reliable benchmark that better reflects real-world conditions. Moreover, CIRM demonstrates state-of-the-art performance across MMSD, MMSD2.0 and MMSD3.0, validating its effectiveness in both single-image and multi-image scenarios.",
    "authors": [
      "Haochen Zhao",
      "Yuyao Kong",
      "Yongxiu Xu",
      "Gaopeng Gou",
      "Hongbo Xu",
      "Yubin Wang",
      "Haoliang Zhang"
    ],
    "categories": [
      "cs.CV",
      "cs.MM"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23299v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23299v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.23254v1",
    "title": "Provable test-time adaptivity and distributional robustness of   in-context learning",
    "summary": "We study in-context learning problems where a Transformer is pretrained on tasks drawn from a mixture distribution $\\pi=\\sum_{\\alpha\\in\\mathcal{A}} \\lambda_{\\alpha} \\pi_{\\alpha}$, called the pretraining prior, in which each mixture component $\\pi_{\\alpha}$ is a distribution on tasks of a specific difficulty level indexed by $\\alpha$. Our goal is to understand the performance of the pretrained Transformer when evaluated on a different test distribution $\\mu$, consisting of tasks of fixed difficulty $\\beta\\in\\mathcal{A}$, and with potential distribution shift relative to $\\pi_\\beta$, subject to the chi-squared divergence $\\chi^2(\\mu,\\pi_{\\beta})$ being at most $\\kappa$. In particular, we consider nonparametric regression problems with random smoothness, and multi-index models with random smoothness as well as random effective dimension. We prove that a large Transformer pretrained on sufficient data achieves the optimal rate of convergence corresponding to the difficulty level $\\beta$, uniformly over test distributions $\\mu$ in the chi-squared divergence ball. Thus, the pretrained Transformer is able to achieve faster rates of convergence on easier tasks and is robust to distribution shift at test time. Finally, we prove that even if an estimator had access to the test distribution $\\mu$, the convergence rate of its expected risk over $\\mu$ could not be faster than that of our pretrained Transformers, thereby providing a more appropriate optimality guarantee than minimax lower bounds.",
    "authors": [
      "Tianyi Ma",
      "Tengyao Wang",
      "Richard J. Samworth"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.TH",
      "62G08, 68T07"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23254v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23254v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.23184v1",
    "title": "Finding 3D Scene Analogies with Multimodal Foundation Models",
    "summary": "Connecting current observations with prior experiences helps robots adapt and plan in new, unseen 3D environments. Recently, 3D scene analogies have been proposed to connect two 3D scenes, which are smooth maps that align scene regions with common spatial relationships. These maps enable detailed transfer of trajectories or waypoints, potentially supporting demonstration transfer for imitation learning or task plan transfer across scenes. However, existing methods for the task require additional training and fixed object vocabularies. In this work, we propose to use multimodal foundation models for finding 3D scene analogies in a zero-shot, open-vocabulary setting. Central to our approach is a hybrid neural representation of scenes that consists of a sparse graph based on vision-language model features and a feature field derived from 3D shape foundation models. 3D scene analogies are then found in a coarse-to-fine manner, by first aligning the graph and refining the correspondence with feature fields. Our method can establish accurate correspondences between complex scenes, and we showcase applications in trajectory and waypoint transfer.",
    "authors": [
      "Junho Kim",
      "Young Min Kim"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23184v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23184v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.23111v1",
    "title": "Neural Emulator Superiority: When Machine Learning for PDEs Surpasses   its Training Data",
    "summary": "Neural operators or emulators for PDEs trained on data from numerical solvers are conventionally assumed to be limited by their training data's fidelity. We challenge this assumption by identifying \"emulator superiority,\" where neural networks trained purely on low-fidelity solver data can achieve higher accuracy than those solvers when evaluated against a higher-fidelity reference. Our theoretical analysis reveals how the interplay between emulator inductive biases, training objectives, and numerical error characteristics enables superior performance during multi-step rollouts. We empirically validate this finding across different PDEs using standard neural architectures, demonstrating that emulators can implicitly learn dynamics that are more regularized or exhibit more favorable error accumulation properties than their training data, potentially surpassing training data limitations and mitigating numerical artifacts. This work prompts a re-evaluation of emulator benchmarking, suggesting neural emulators might achieve greater physical fidelity than their training source within specific operational regimes. Project Page: https://tum-pbs.github.io/emulator-superiority",
    "authors": [
      "Felix Koehler",
      "Nils Thuerey"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23111v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23111v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.23081v1",
    "title": "A Survey on LLM Mid-training",
    "summary": "Recent advances in foundation models have highlighted the significant benefits of multi-stage training, with a particular emphasis on the emergence of mid-training as a vital stage that bridges pre-training and post-training. Mid-training is distinguished by its use of intermediate data and computational resources, systematically enhancing specified capabilities such as mathematics, coding, reasoning, and long-context extension, while maintaining foundational competencies. This survey provides a formal definition of mid-training for large language models (LLMs) and investigates optimization frameworks that encompass data curation, training strategies, and model architecture optimization. We analyze mainstream model implementations in the context of objective-driven interventions, illustrating how mid-training serves as a distinct and critical stage in the progressive development of LLM capabilities. By clarifying the unique contributions of mid-training, this survey offers a comprehensive taxonomy and actionable insights, supporting future research and innovation in the advancement of LLMs.",
    "authors": [
      "Chengying Tu",
      "Xuemiao Zhang",
      "Rongxiang Weng",
      "Rumei Li",
      "Chen Zhang",
      "Yang Bai",
      "Hongfei Yan",
      "Jingang Wang",
      "Xunliang Cai"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23081v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23081v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.23062v1",
    "title": "TLCD: A Deep Transfer Learning Framework for Cross-Disciplinary   Cognitive Diagnosis",
    "summary": "Driven by the dual principles of smart education and artificial intelligence technology, the online education model has rapidly emerged as an important component of the education industry. Cognitive diagnostic technology can utilize students' learning data and feedback information in educational evaluation to accurately assess their ability level at the knowledge level. However, while massive amounts of information provide abundant data resources, they also bring about complexity in feature extraction and scarcity of disciplinary data. In cross-disciplinary fields, traditional cognitive diagnostic methods still face many challenges. Given the differences in knowledge systems, cognitive structures, and data characteristics between different disciplines, this paper conducts in-depth research on neural network cognitive diagnosis and knowledge association neural network cognitive diagnosis, and proposes an innovative cross-disciplinary cognitive diagnosis method (TLCD). This method combines deep learning techniques and transfer learning strategies to enhance the performance of the model in the target discipline by utilizing the common features of the main discipline. The experimental results show that the cross-disciplinary cognitive diagnosis model based on deep learning performs better than the basic model in cross-disciplinary cognitive diagnosis tasks, and can more accurately evaluate students' learning situation.",
    "authors": [
      "Zhifeng Wang",
      "Meixin Su",
      "Yang Yang",
      "Chunyan Zeng",
      "Lizhi Ye"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23062v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23062v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.56
  },
  {
    "arxiv_id": "2510.23553v1",
    "title": "OntoPret: An Ontology for the Interpretation of Human Behavior",
    "summary": "As human machine teaming becomes central to paradigms like Industry 5.0, a critical need arises for machines to safely and effectively interpret complex human behaviors. A research gap currently exists between techno centric robotic frameworks, which often lack nuanced models of human behavior, and descriptive behavioral ontologies, which are not designed for real time, collaborative interpretation. This paper addresses this gap by presenting OntoPret, an ontology for the interpretation of human behavior. Grounded in cognitive science and a modular engineering methodology, OntoPret provides a formal, machine processable framework for classifying behaviors, including task deviations and deceptive actions. We demonstrate its adaptability across two distinct use cases manufacturing and gameplay and establish the semantic foundations necessary for advanced reasoning about human intentions.",
    "authors": [
      "Alexis Ellis",
      "Stacie Severyn",
      "Fjollë Novakazi",
      "Hadi Banaee",
      "Cogan Shimizu"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23553v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23553v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2510.23414v1",
    "title": "Symmetria: A Synthetic Dataset for Learning in Point Clouds",
    "summary": "Unlike image or text domains that benefit from an abundance of large-scale datasets, point cloud learning techniques frequently encounter limitations due to the scarcity of extensive datasets. To overcome this limitation, we present Symmetria, a formula-driven dataset that can be generated at any arbitrary scale. By construction, it ensures the absolute availability of precise ground truth, promotes data-efficient experimentation by requiring fewer samples, enables broad generalization across diverse geometric settings, and offers easy extensibility to new tasks and modalities. Using the concept of symmetry, we create shapes with known structure and high variability, enabling neural networks to learn point cloud features effectively. Our results demonstrate that this dataset is highly effective for point cloud self-supervised pre-training, yielding models with strong performance in downstream tasks such as classification and segmentation, which also show good few-shot learning capabilities. Additionally, our dataset can support fine-tuning models to classify real-world objects, highlighting our approach's practical utility and application. We also introduce a challenging task for symmetry detection and provide a benchmark for baseline comparisons. A significant advantage of our approach is the public availability of the dataset, the accompanying code, and the ability to generate very large collections, promoting further research and innovation in point cloud learning.",
    "authors": [
      "Ivan Sipiran",
      "Gustavo Santelices",
      "Lucas Oyarzún",
      "Andrea Ranieri",
      "Chiara Romanengo",
      "Silvia Biasotti",
      "Bianca Falcidieno"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23414v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23414v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2510.23395v1",
    "title": "Detecting Religious Language in Climate Discourse",
    "summary": "Religious language continues to permeate contemporary discourse, even in ostensibly secular domains such as environmental activism and climate change debates. This paper investigates how explicit and implicit forms of religious language appear in climate-related texts produced by secular and religious nongovernmental organizations (NGOs). We introduce a dual methodological approach: a rule-based model using a hierarchical tree of religious terms derived from ecotheology literature, and large language models (LLMs) operating in a zero-shot setting. Using a dataset of more than 880,000 sentences, we compare how these methods detect religious language and analyze points of agreement and divergence. The results show that the rule-based method consistently labels more sentences as religious than LLMs. These findings highlight not only the methodological challenges of computationally detecting religious language but also the broader tension over whether religious language should be defined by vocabulary alone or by contextual meaning. This study contributes to digital methods in religious studies by demonstrating both the potential and the limitations of approaches for analyzing how the sacred persists in climate discourse.",
    "authors": [
      "Evy Beijen",
      "Pien Pieterse",
      "Yusuf Çelik",
      "Willem Th. van Peursen",
      "Sandjai Bhulai",
      "Meike Morren"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23395v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23395v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2510.23384v1",
    "title": "Opinion Mining Based Entity Ranking using Fuzzy Logic Algorithmic   Approach",
    "summary": "Opinions are central to almost all human activities and are key influencers of our behaviors. In current times due to growth of social networking website and increase in number of e-commerce site huge amount of opinions are now available on web. Given a set of evaluative statements that contain opinions (or sentiments) about an Entity, opinion mining aims to extract attributes and components of the object that have been commented on in each statement and to determine whether the comments are positive, negative or neutral. While lot of research recently has been done in field of opinion mining and some of it dealing with ranking of entities based on review or opinion set, classifying opinions into finer granularity level and then ranking entities has never been done before. In this paper method for opinion mining from statements at a deeper level of granularity is proposed. This is done by using fuzzy logic reasoning, after which entities are ranked as per this information.",
    "authors": [
      "Pratik N. Kalamkar",
      "A. G. Phakatkar"
    ],
    "categories": [
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23384v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23384v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2510.23358v1",
    "title": "How AI Forecasts AI Jobs: Benchmarking LLM Predictions of Labor Market   Changes",
    "summary": "Artificial intelligence is reshaping labor markets, yet we lack tools to systematically forecast its effects on employment. This paper introduces a benchmark for evaluating how well large language models (LLMs) can anticipate changes in job demand, especially in occupations affected by AI. Existing research has shown that LLMs can extract sentiment, summarize economic reports, and emulate forecaster behavior, but little work has assessed their use for forward-looking labor prediction. Our benchmark combines two complementary datasets: a high-frequency index of sector-level job postings in the United States, and a global dataset of projected occupational changes due to AI adoption. We format these data into forecasting tasks with clear temporal splits, minimizing the risk of information leakage. We then evaluate LLMs using multiple prompting strategies, comparing task-scaffolded, persona-driven, and hybrid approaches across model families. We assess both quantitative accuracy and qualitative consistency over time. Results show that structured task prompts consistently improve forecast stability, while persona prompts offer advantages on short-term trends. However, performance varies significantly across sectors and horizons, highlighting the need for domain-aware prompting and rigorous evaluation protocols. By releasing our benchmark, we aim to support future research on labor forecasting, prompt design, and LLM-based economic reasoning. This work contributes to a growing body of research on how LLMs interact with real-world economic data, and provides a reproducible testbed for studying the limits and opportunities of AI as a forecasting tool in the context of labor markets.",
    "authors": [
      "Sheri Osborn",
      "Rohit Valecha",
      "H. Raghav Rao",
      "Dan Sass",
      "Anthony Rios"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23358v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23358v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2510.23252v1",
    "title": "Are ASR foundation models generalized enough to capture features of   regional dialects for low-resource languages?",
    "summary": "Conventional research on speech recognition modeling relies on the canonical form for most low-resource languages while automatic speech recognition (ASR) for regional dialects is treated as a fine-tuning task. To investigate the effects of dialectal variations on ASR we develop a 78-hour annotated Bengali Speech-to-Text (STT) corpus named Ben-10. Investigation from linguistic and data-driven perspectives shows that speech foundation models struggle heavily in regional dialect ASR, both in zero-shot and fine-tuned settings. We observe that all deep learning methods struggle to model speech data under dialectal variations but dialect specific model training alleviates the issue. Our dataset also serves as a out of-distribution (OOD) resource for ASR modeling under constrained resources in ASR algorithms. The dataset and code developed for this project are publicly available",
    "authors": [
      "Tawsif Tashwar Dipto",
      "Azmol Hossain",
      "Rubayet Sabbir Faruque",
      "Md. Rezuwan Hassan",
      "Kanij Fatema",
      "Tanmoy Shome",
      "Ruwad Naswan",
      "Md. Foriduzzaman Zihad",
      "Mohaymen Ul Anam",
      "Nazia Tasnim",
      "Hasan Mahmud",
      "Md Kamrul Hasan",
      "Md. Mehedi Hasan Shawon",
      "Farig Sadeque",
      "Tahsin Reasat"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23252v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23252v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2510.23149v1",
    "title": "Complexity Dependent Error Rates for Physics-informed Statistical   Learning via the Small-ball Method",
    "summary": "Physics-informed statistical learning (PISL) integrates empirical data with physical knowledge to enhance the statistical performance of estimators. While PISL methods are widely used in practice, a comprehensive theoretical understanding of how informed regularization affects statistical properties is still missing. Specifically, two fundamental questions have yet to be fully addressed: (1) what is the trade-off between considering soft penalties versus hard constraints, and (2) what is the statistical gain of incorporating physical knowledge compared to purely data-driven empirical error minimisation. In this paper, we address these questions for PISL in convex classes of functions under physical knowledge expressed as linear equations by developing appropriate complexity dependent error rates based on the small-ball method. We show that, under suitable assumptions, (1) the error rates of physics-informed estimators are comparable to those of hard constrained empirical error minimisers, differing only by constant terms, and that (2) informed penalization can effectively reduce model complexity, akin to dimensionality reduction, thereby improving learning performance. This work establishes a theoretical framework for evaluating the statistical properties of physics-informed estimators in convex classes of functions, contributing to closing the gap between statistical theory and practical PISL, with potential applications to cases not yet explored in the literature.",
    "authors": [
      "Diego Marcondes"
    ],
    "categories": [
      "stat.ML",
      "cs.LG",
      "math.ST",
      "stat.TH"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23149v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23149v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2510.23136v1",
    "title": "A method for outlier detection based on cluster analysis and visual   expert criteria",
    "summary": "Outlier detection is an important problem occurring in a wide range of areas. Outliers are the outcome of fraudulent behaviour, mechanical faults, human error, or simply natural deviations. Many data mining applications perform outlier detection, often as a preliminary step in order to filter out outliers and build more representative models. In this paper, we propose an outlier detection method based on a clustering process. The aim behind the proposal outlined in this paper is to overcome the specificity of many existing outlier detection techniques that fail to take into account the inherent dispersion of domain objects. The outlier detection method is based on four criteria designed to represent how human beings (experts in each domain) visually identify outliers within a set of objects after analysing the clusters. This has an advantage over other clustering-based outlier detection techniques that are founded on a purely numerical analysis of clusters. Our proposal has been evaluated, with satisfactory results, on data (particularly time series) from two different domains: stabilometry, a branch of medicine studying balance-related functions in human beings and electroencephalography (EEG), a neurological exploration used to diagnose nervous system disorders. To validate the proposed method, we studied method outlier detection and efficiency in terms of runtime. The results of regression analyses confirm that our proposal is useful for detecting outlier data in different domains, with a false positive rate of less than 2% and a reliability greater than 99%.",
    "authors": [
      "Juan A. Lara",
      "David Lizcano",
      "Víctor Rampérez",
      "Javier Soriano"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23136v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23136v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2510.23104v1",
    "title": "Leveraging Hierarchical Organization for Medical Multi-document   Summarization",
    "summary": "Medical multi-document summarization (MDS) is a complex task that requires effectively managing cross-document relationships. This paper investigates whether incorporating hierarchical structures in the inputs of MDS can improve a model's ability to organize and contextualize information across documents compared to traditional flat summarization methods. We investigate two ways of incorporating hierarchical organization across three large language models (LLMs), and conduct comprehensive evaluations of the resulting summaries using automated metrics, model-based metrics, and domain expert evaluation of preference, understandability, clarity, complexity, relevance, coverage, factuality, and coherence. Our results show that human experts prefer model-generated summaries over human-written summaries. Hierarchical approaches generally preserve factuality, coverage, and coherence of information, while also increasing human preference for summaries. Additionally, we examine whether simulated judgments from GPT-4 align with human judgments, finding higher agreement along more objective evaluation facets. Our findings demonstrate that hierarchical structures can improve the clarity of medical summaries generated by models while maintaining content coverage, providing a practical way to improve human preference for generated summaries.",
    "authors": [
      "Yi-Li Hsu",
      "Katelyn X. Mei",
      "Lucy Lu Wang"
    ],
    "categories": [
      "cs.CL",
      "cs.AI",
      "cs.IR"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23104v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23104v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.55
  },
  {
    "arxiv_id": "2510.23594v1",
    "title": "PRISM-Bench: A Benchmark of Puzzle-Based Visual Tasks with CoT Error   Detection",
    "summary": "We introduce \\textbf{PRISM-Bench}, a benchmark of puzzle-based visual challenges designed to evaluate not only whether models can solve problems, but how their reasoning unfolds. Unlike prior evaluations that measure only final-answer accuracy, PRISM-Bench introduces a diagnostic task: given a visual puzzle and a step-by-step chain-of-thought (CoT) containing exactly one error, models must identify the first incorrect step. This setting enables fine-grained assessment of logical consistency, error detection, and visual reasoning. The puzzles in PRISM-Bench require multi-step symbolic, geometric, and analogical reasoning, resisting shortcuts based on superficial pattern matching. Evaluations across state-of-the-art MLLMs reveal a persistent gap between fluent generation and faithful reasoning: models that produce plausible CoTs often fail to locate simple logical faults. By disentangling answer generation from reasoning verification, PRISM-Bench offers a sharper lens on multimodal reasoning competence and underscores the need for diagnostic evaluation protocols in the development of trustworthy MLLMs.",
    "authors": [
      "Yusu Qian",
      "Cheng Wan",
      "Chao Jia",
      "Yinfei Yang",
      "Qingyu Zhao",
      "Zhe Gan"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23594v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23594v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2510.23585v1",
    "title": "Hope Speech Detection in Social Media English Corpora: Performance of   Traditional and Transformer Models",
    "summary": "The identification of hope speech has become a promised NLP task, considering the need to detect motivational expressions of agency and goal-directed behaviour on social media platforms. This proposal evaluates traditional machine learning models and fine-tuned transformers for a previously split hope speech dataset as train, development and test set. On development test, a linear-kernel SVM and logistic regression both reached a macro-F1 of 0.78; SVM with RBF kernel reached 0.77, and Na\\\"ive Bayes hit 0.75. Transformer models delivered better results, the best model achieved weighted precision of 0.82, weighted recall of 0.80, weighted F1 of 0.79, macro F1 of 0.79, and 0.80 accuracy. These results suggest that while optimally configured traditional machine learning models remain agile, transformer architectures detect some subtle semantics of hope to achieve higher precision and recall in hope speech detection, suggesting that larges transformers and LLMs could perform better in small datasets.",
    "authors": [
      "Luis Ramos",
      "Hiram Calvo",
      "Olga Kolesnikova"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23585v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23585v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2510.23478v1",
    "title": "UrbanIng-V2X: A Large-Scale Multi-Vehicle, Multi-Infrastructure Dataset   Across Multiple Intersections for Cooperative Perception",
    "summary": "Recent cooperative perception datasets have played a crucial role in advancing smart mobility applications by enabling information exchange between intelligent agents, helping to overcome challenges such as occlusions and improving overall scene understanding. While some existing real-world datasets incorporate both vehicle-to-vehicle and vehicle-to-infrastructure interactions, they are typically limited to a single intersection or a single vehicle. A comprehensive perception dataset featuring multiple connected vehicles and infrastructure sensors across several intersections remains unavailable, limiting the benchmarking of algorithms in diverse traffic environments. Consequently, overfitting can occur, and models may demonstrate misleadingly high performance due to similar intersection layouts and traffic participant behavior. To address this gap, we introduce UrbanIng-V2X, the first large-scale, multi-modal dataset supporting cooperative perception involving vehicles and infrastructure sensors deployed across three urban intersections in Ingolstadt, Germany. UrbanIng-V2X consists of 34 temporally aligned and spatially calibrated sensor sequences, each lasting 20 seconds. All sequences contain recordings from one of three intersections, involving two vehicles and up to three infrastructure-mounted sensor poles operating in coordinated scenarios. In total, UrbanIng-V2X provides data from 12 vehicle-mounted RGB cameras, 2 vehicle LiDARs, 17 infrastructure thermal cameras, and 12 infrastructure LiDARs. All sequences are annotated at a frequency of 10 Hz with 3D bounding boxes spanning 13 object classes, resulting in approximately 712k annotated instances across the dataset. We provide comprehensive evaluations using state-of-the-art cooperative perception methods and publicly release the codebase, dataset, HD map, and a digital twin of the complete data collection environment.",
    "authors": [
      "Karthikeyan Chandra Sekaran",
      "Markus Geisler",
      "Dominik Rößle",
      "Adithya Mohan",
      "Daniel Cremers",
      "Wolfgang Utschick",
      "Michael Botsch",
      "Werner Huber",
      "Torsten Schön"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23478v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23478v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2510.23167v1",
    "title": "Guiding Skill Discovery with Foundation Models",
    "summary": "Learning diverse skills without hand-crafted reward functions could accelerate reinforcement learning in downstream tasks. However, existing skill discovery methods focus solely on maximizing the diversity of skills without considering human preferences, which leads to undesirable behaviors and possibly dangerous skills. For instance, a cheetah robot trained using previous methods learns to roll in all directions to maximize skill diversity, whereas we would prefer it to run without flipping or entering hazardous areas. In this work, we propose a Foundation model Guided (FoG) skill discovery method, which incorporates human intentions into skill discovery through foundation models. Specifically, FoG extracts a score function from foundation models to evaluate states based on human intentions, assigning higher values to desirable states and lower to undesirable ones. These scores are then used to re-weight the rewards of skill discovery algorithms. By optimizing the re-weighted skill discovery rewards, FoG successfully learns to eliminate undesirable behaviors, such as flipping or rolling, and to avoid hazardous areas in both state-based and pixel-based tasks. Interestingly, we show that FoG can discover skills involving behaviors that are difficult to define. Interactive visualisations are available from https://sites.google.com/view/submission-fog.",
    "authors": [
      "Zhao Yang",
      "Thomas M. Moerland",
      "Mike Preuss",
      "Aske Plaat",
      "Vincent François-Lavet",
      "Edward S. Hu"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23167v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23167v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2510.23106v1",
    "title": "Sampling from Energy distributions with Target Concrete Score Identity",
    "summary": "We introduce the Target Concrete Score Identity Sampler (TCSIS), a method for sampling from unnormalized densities on discrete state spaces by learning the reverse dynamics of a Continuous-Time Markov Chain (CTMC). Our approach builds on a forward in time CTMC with a uniform noising kernel and relies on the proposed Target Concrete Score Identity, which relates the concrete score, the ratio of marginal probabilities of two states, to a ratio of expectations of Boltzmann factors under the forward uniform diffusion kernel. This formulation enables Monte Carlo estimation of the concrete score without requiring samples from the target distribution or computation of the partition function. We approximate the concrete score with a neural network and propose two algorithms: Self-Normalized TCSIS and Unbiased TCSIS. Finally, we demonstrate the effectiveness of TCSIS on problems from statistical physics.",
    "authors": [
      "Sergei Kholkin",
      "Francisco Vargas",
      "Alexander Korotin"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23106v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23106v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2510.23052v1",
    "title": "Knocking-Heads Attention",
    "summary": "Multi-head attention (MHA) has become the cornerstone of modern large language models, enhancing representational capacity through parallel attention heads. However, increasing the number of heads inherently weakens individual head capacity, and existing attention mechanisms - whether standard MHA or its variants like grouped-query attention (GQA) and grouped-tied attention (GTA) - simply concatenate outputs from isolated heads without strong interaction. To address this limitation, we propose knocking-heads attention (KHA), which enables attention heads to \"knock\" on each other - facilitating cross-head feature-level interactions before the scaled dot-product attention. This is achieved by applying a shared, diagonally-initialized projection matrix across all heads. The diagonal initialization preserves head-specific specialization at the start of training while allowing the model to progressively learn integrated cross-head representations. KHA adds only minimal parameters and FLOPs and can be seamlessly integrated into MHA, GQA, GTA, and other attention variants. We validate KHA by training a 6.1B parameter MoE model (1.01B activated) on 1T high-quality tokens. Compared to baseline attention mechanisms, KHA brings superior and more stable training dynamics, achieving better performance across downstream tasks.",
    "authors": [
      "Zhanchao Zhou",
      "Xiaodong Chen",
      "Haoxing Chen",
      "Zhenzhong Lan",
      "Jianguo Li"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23052v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23052v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.54
  },
  {
    "arxiv_id": "2510.23504v1",
    "title": "iPac: Incorporating Intra-image Patch Context into Graph Neural Networks   for Medical Image Classification",
    "summary": "Graph neural networks have emerged as a promising paradigm for image processing, yet their performance in image classification tasks is hindered by a limited consideration of the underlying structure and relationships among visual entities. This work presents iPac, a novel approach to introduce a new graph representation of images to enhance graph neural network image classification by recognizing the importance of underlying structure and relationships in medical image classification. iPac integrates various stages, including patch partitioning, feature extraction, clustering, graph construction, and graph-based learning, into a unified network to advance graph neural network image classification. By capturing relevant features and organising them into clusters, we construct a meaningful graph representation that effectively encapsulates the semantics of the image. Experimental evaluation on diverse medical image datasets demonstrates the efficacy of iPac, exhibiting an average accuracy improvement of up to 5% over baseline methods. Our approach offers a versatile and generic solution for image classification, particularly in the realm of medical images, by leveraging the graph representation and accounting for the inherent structure and relationships among visual entities.",
    "authors": [
      "Usama Zidan",
      "Mohamed Gaber",
      "Mohammed M. Abdelsamea"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23504v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23504v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2510.23484v1",
    "title": "T-REGS: Minimum Spanning Tree Regularization for Self-Supervised   Learning",
    "summary": "Self-supervised learning (SSL) has emerged as a powerful paradigm for learning representations without labeled data, often by enforcing invariance to input transformations such as rotations or blurring. Recent studies have highlighted two pivotal properties for effective representations: (i) avoiding dimensional collapse-where the learned features occupy only a low-dimensional subspace, and (ii) enhancing uniformity of the induced distribution. In this work, we introduce T-REGS, a simple regularization framework for SSL based on the length of the Minimum Spanning Tree (MST) over the learned representation. We provide theoretical analysis demonstrating that T-REGS simultaneously mitigates dimensional collapse and promotes distribution uniformity on arbitrary compact Riemannian manifolds. Several experiments on synthetic data and on classical SSL benchmarks validate the effectiveness of our approach at enhancing representation quality.",
    "authors": [
      "Julie Mordacq",
      "David Loiseaux",
      "Vicky Kalogeiton",
      "Steve Oudot"
    ],
    "categories": [
      "cs.LG",
      "cs.CG",
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23484v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23484v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2510.23464v1",
    "title": "Evaluating Large Language Models for Stance Detection on Financial   Targets from SEC Filing Reports and Earnings Call Transcripts",
    "summary": "Financial narratives from U.S. Securities and Exchange Commission (SEC) filing reports and quarterly earnings call transcripts (ECTs) are very important for investors, auditors, and regulators. However, their length, financial jargon, and nuanced language make fine-grained analysis difficult. Prior sentiment analysis in the financial domain required a large, expensive labeled dataset, making the sentence-level stance towards specific financial targets challenging. In this work, we introduce a sentence-level corpus for stance detection focused on three core financial metrics: debt, earnings per share (EPS), and sales. The sentences were extracted from Form 10-K annual reports and ECTs, and labeled for stance (positive, negative, neutral) using the advanced ChatGPT-o3-pro model under rigorous human validation. Using this corpus, we conduct a systematic evaluation of modern large language models (LLMs) using zero-shot, few-shot, and Chain-of-Thought (CoT) prompting strategies. Our results show that few-shot with CoT prompting performs best compared to supervised baselines, and LLMs' performance varies across the SEC and ECT datasets. Our findings highlight the practical viability of leveraging LLMs for target-specific stance in the financial domain without requiring extensive labeled data.",
    "authors": [
      "Nikesh Gyawali",
      "Doina Caragea",
      "Alex Vasenkov",
      "Cornelia Caragea"
    ],
    "categories": [
      "cs.CL",
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23464v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23464v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2510.23421v1",
    "title": "Exploring Vulnerability in AI Industry",
    "summary": "The rapid ascent of Foundation Models (FMs), enabled by the Transformer architecture, drives the current AI ecosystem. Characterized by large-scale training and downstream adaptability, FMs (as GPT family) have achieved massive public adoption, fueling a turbulent market shaped by platform economics and intense investment. Assessing the vulnerability of this fast-evolving industry is critical yet challenging due to data limitations. This paper proposes a synthetic AI Vulnerability Index (AIVI) focusing on the upstream value chain for FM production, prioritizing publicly available data. We model FM output as a function of five inputs: Compute, Data, Talent, Capital, and Energy, hypothesizing that supply vulnerability in any input threatens the industry. Key vulnerabilities include compute concentration, data scarcity and legal risks, talent bottlenecks, capital intensity and strategic dependencies, as well as escalating energy demands. Acknowledging imperfect input substitutability, we propose a weighted geometrical average of aggregate subindexes, normalized using theoretical or empirical benchmarks. Despite limitations and room for improvement, this preliminary index aims to quantify systemic risks in AI's core production engine, and implicitly shed a light on the risks for downstream value chain.",
    "authors": [
      "Claudio Pirrone",
      "Stefano Fricano",
      "Gioacchino Fazio"
    ],
    "categories": [
      "econ.GN",
      "cs.AI",
      "q-fin.EC"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23421v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23421v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2510.23415v1",
    "title": "Towards Generalisable Foundation Models for 3D Brain MRI",
    "summary": "Foundation models in artificial intelligence (AI) are transforming medical imaging by enabling general-purpose feature learning from large-scale, unlabeled datasets. In this work, we introduce BrainFound, a self-supervised foundation model for brain MRI, built by extending DINO-v2, a vision transformer originally designed for 2D natural images. BrainFound adapts DINO-v2 to model full 3D brain anatomy by incorporating volumetric information from sequential MRI slices, moving beyond conventional single-slice paradigms. It supports both single- and multimodal inputs, enabling a broad range of downstream tasks, including disease detection and image segmentation, while generalising across varied imaging protocols and clinical scenarios. We show that BrainFound consistently outperforms existing self-supervised pretraining strategies and supervised baselines, particularly in label-scarce and multi-contrast settings. By integrating information from diverse 3D MRI modalities (e.g., T1, T2, FLAIR), it enhances diagnostic accuracy and reduces dependency on extensive expert annotations. This flexibility makes BrainFound a scalable and practical solution for 3D neuroimaging pipelines, with significant potential for clinical deployment and research innovation.",
    "authors": [
      "Moona Mazher",
      "Geoff J. M. Parker",
      "Daniel C. Alexander"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23415v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23415v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2510.23288v1",
    "title": "Learning from Frustration: Torsor CNNs on Graphs",
    "summary": "Most equivariant neural networks rely on a single global symmetry, limiting their use in domains where symmetries are instead local. We introduce Torsor CNNs, a framework for learning on graphs with local symmetries encoded as edge potentials-- group-valued transformations between neighboring coordinate frames. We establish that this geometric construction is fundamentally equivalent to the classical group synchronization problem, yielding: (1) a Torsor Convolutional Layer that is provably equivariant to local changes in coordinate frames, and (2) the frustration loss--a standalone geometric regularizer that encourages locally equivariant representations when added to any NN's training objective. The Torsor CNN framework unifies and generalizes several architectures--including classical CNNs and Gauge CNNs on manifolds-- by operating on arbitrary graphs without requiring a global coordinate system or smooth manifold structure. We establish the mathematical foundations of this framework and demonstrate its applicability to multi-view 3D recognition, where relative camera poses naturally define the required edge potentials.",
    "authors": [
      "Daiyuan Li",
      "Shreya Arya",
      "Robert Ghrist"
    ],
    "categories": [
      "cs.LG",
      "math.AT",
      "es: 68T07, 22E70"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23288v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23288v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2510.23278v1",
    "title": "hYOLO Model: Enhancing Object Classification with Hierarchical Context   in YOLOv8",
    "summary": "Current convolution neural network (CNN) classification methods are predominantly focused on flat classification which aims solely to identify a specified object within an image. However, real-world objects often possess a natural hierarchical organization that can significantly help classification tasks. Capturing the presence of relations between objects enables better contextual understanding as well as control over the severity of mistakes. Considering these aspects, this paper proposes an end-to-end hierarchical model for image detection and classification built upon the YOLO model family. A novel hierarchical architecture, a modified loss function, and a performance metric tailored to the hierarchical nature of the model are introduced. The proposed model is trained and evaluated on two different hierarchical categorizations of the same dataset: a systematic categorization that disregards visual similarities between objects and a categorization accounting for common visual characteristics across classes. The results illustrate how the suggested methodology addresses the inherent hierarchical structure present in real-world objects, which conventional flat classification algorithms often overlook.",
    "authors": [
      "Veska Tsenkova",
      "Peter Stanchev",
      "Daniel Petrov",
      "Deyan Lazarov"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23278v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23278v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2510.23258v1",
    "title": "Deep Active Inference with Diffusion Policy and Multiple Timescale World   Model for Real-World Exploration and Navigation",
    "summary": "Autonomous robotic navigation in real-world environments requires exploration to acquire environmental information as well as goal-directed navigation in order to reach specified targets. Active inference (AIF) based on the free-energy principle provides a unified framework for these behaviors by minimizing the expected free energy (EFE), thereby combining epistemic and extrinsic values. To realize this practically, we propose a deep AIF framework that integrates a diffusion policy as the policy model and a multiple timescale recurrent state-space model (MTRSSM) as the world model. The diffusion policy generates diverse candidate actions while the MTRSSM predicts their long-horizon consequences through latent imagination, enabling action selection that minimizes EFE. Real-world navigation experiments demonstrated that our framework achieved higher success rates and fewer collisions compared with the baselines, particularly in exploration-demanding scenarios. These results highlight how AIF based on EFE minimization can unify exploration and goal-directed navigation in real-world robotic settings.",
    "authors": [
      "Riko Yokozawa",
      "Kentaro Fujii",
      "Yuta Nomura",
      "Shingo Murata"
    ],
    "categories": [
      "cs.RO",
      "cs.AI",
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23258v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23258v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2510.23203v1",
    "title": "DecoDINO: 3D Human-Scene Contact Prediction with Semantic Classification",
    "summary": "Accurate vertex-level contact prediction between humans and surrounding objects is a prerequisite for high fidelity human object interaction models used in robotics, AR/VR, and behavioral simulation. DECO was the first in the wild estimator for this task but is limited to binary contact maps and struggles with soft surfaces, occlusions, children, and false-positive foot contacts. We address these issues and introduce DecoDINO, a three-branch network based on DECO's framework. It uses two DINOv2 ViT-g/14 encoders, class-balanced loss weighting to reduce bias, and patch-level cross-attention for improved local reasoning. Vertex features are finally passed through a lightweight MLP with a softmax to assign semantic contact labels. We also tested a vision-language model (VLM) to integrate text features, but the simpler architecture performed better and was used instead. On the DAMON benchmark, DecoDINO (i) raises the binary-contact F1 score by 7$\\%$, (ii) halves the geodesic error, and (iii) augments predictions with object-level semantic labels. Ablation studies show that LoRA fine-tuning and the dual encoders are key to these improvements. DecoDINO outperformed the challenge baseline in both tasks of the DAMON Challenge. Our code is available at https://github.com/DavidePasero/deco/tree/main.",
    "authors": [
      "Lukas Bierling",
      "Davide Pasero",
      "Fleur Dolmans",
      "Helia Ghasemi",
      "Angelo Broere"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23203v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23203v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.53
  },
  {
    "arxiv_id": "2510.23561v1",
    "title": "Revising Second Order Terms in Deep Animation Video Coding",
    "summary": "First Order Motion Model is a generative model that animates human heads based on very little motion information derived from keypoints. It is a promising solution for video communication because first it operates at very low bitrate and second its computational complexity is moderate compared to other learning based video codecs. However, it has strong limitations by design. Since it generates facial animations by warping source-images, it fails to recreate videos with strong head movements. This works concentrates on one specific kind of head movements, namely head rotations. We show that replacing the Jacobian transformations in FOMM by a global rotation helps the system to perform better on items with head-rotations while saving 40% to 80% of bitrate on P-frames. Moreover, we apply state-of-the-art normalization techniques to the discriminator to stabilize the adversarial training which is essential for generating visually appealing videos. We evaluate the performance by the learned metics LPIPS and DISTS to show the success our optimizations.",
    "authors": [
      "Konstantin Schmidt",
      "Thomas Richter"
    ],
    "categories": [
      "eess.IV",
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23561v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23561v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2510.23501v1",
    "title": "Towards Deep Physics-Informed Kolmogorov-Arnold Networks",
    "summary": "Since their introduction, Kolmogorov-Arnold Networks (KANs) have been successfully applied across several domains, with physics-informed machine learning (PIML) emerging as one of the areas where they have thrived. In the PIML setting, Chebyshev-based physics-informed KANs (cPIKANs) have become the standard due to their computational efficiency. However, like their multilayer perceptron-based counterparts, cPIKANs face significant challenges when scaled to depth, leading to training instabilities that limit their applicability to several PDE problems. To address this, we propose a basis-agnostic, Glorot-like initialization scheme that preserves activation variance and yields substantial improvements in stability and accuracy over the default initialization of cPIKANs. Inspired by the PirateNet architecture, we further introduce Residual-Gated Adaptive KANs (RGA KANs), designed to mitigate divergence in deep cPIKANs where initialization alone is not sufficient. Through empirical tests and information bottleneck analysis, we show that RGA KANs successfully traverse all training phases, unlike baseline cPIKANs, which stagnate in the diffusion phase in specific PDE settings. Evaluations on seven standard forward PDE benchmarks under a fixed training pipeline with adaptive components demonstrate that RGA KANs consistently outperform parameter-matched cPIKANs and PirateNets - often by several orders of magnitude - while remaining stable in settings where the others diverge.",
    "authors": [
      "Spyros Rigas",
      "Fotios Anagnostopoulos",
      "Michalis Papachristou",
      "Georgios Alexandridis"
    ],
    "categories": [
      "cs.LG",
      "physics.comp-ph"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23501v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23501v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2510.23295v1",
    "title": "Predicting symbolic ODEs from multiple trajectories",
    "summary": "We introduce MIO, a transformer-based model for inferring symbolic ordinary differential equations (ODEs) from multiple observed trajectories of a dynamical system. By combining multiple instance learning with transformer-based symbolic regression, the model effectively leverages repeated observations of the same system to learn more generalizable representations of the underlying dynamics. We investigate different instance aggregation strategies and show that even simple mean aggregation can substantially boost performance. MIO is evaluated on systems ranging from one to four dimensions and under varying noise levels, consistently outperforming existing baselines.",
    "authors": [
      "Yakup Emre Şahin",
      "Niki Kilbertus",
      "Sören Becker"
    ],
    "categories": [
      "cs.LG"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23295v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23295v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2510.23198v1",
    "title": "PTPP-Aware Adaptation Scaling Laws: Predicting Domain-Adaptation   Performance at Unseen Pre-Training Budgets",
    "summary": "Continual pre-training (CPT) for domain adaptation must balance target-domain gains with stability on the base domain. Existing CPT scaling laws typically assume a fixed pre-training budget, which limits their ability to forecast adaptation outcomes for models trained at different tokens-per-parameter (PTPP). We present \\emph{PTPP-aware} adaptation scaling laws that make the pre-training budget an explicit variable, enabling accurate \\emph{prediction} of adaptation loss at unseen \\ptpp. On a multilingual setup (English/Arabic $\\rightarrow$ French), PTPP-aware formulations trained on early stages (\\ptpp{}=\\{15,31\\}) predict target loss at \\ptpp{}=279 and outperform a PTPP-agnostic \\dcpt{} transfer baseline on metrics (Huber-on-log, MAE$_\\mathrm{rel}$, calibration slope); full diagnostics (RMSE, MAPE) are in the appendix. Beyond forecasting, we show a practical use case: planning replay ratios and adaptation token budgets that satisfy target and forgetting constraints under compute limits.",
    "authors": [
      "Etienne Goffinet",
      "Shane Bergsma",
      "Avraham Sheinin",
      "Natalia Vassilieva",
      "Shaheer Muhammad",
      "Preslav Nakov",
      "Gurpreet Gosal"
    ],
    "categories": [
      "cs.LG",
      "cs.AI",
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23198v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23198v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2510.23190v1",
    "title": "Evaluation of Vision-LLMs in Surveillance Video",
    "summary": "The widespread use of cameras in our society has created an overwhelming amount of video data, far exceeding the capacity for human monitoring. This presents a critical challenge for public safety and security, as the timely detection of anomalous or criminal events is crucial for effective response and prevention. The ability for an embodied agent to recognize unexpected events is fundamentally tied to its capacity for spatial reasoning. This paper investigates the spatial reasoning of vision-language models (VLMs) by framing anomalous action recognition as a zero-shot, language-grounded task, addressing the embodied perception challenge of interpreting dynamic 3D scenes from sparse 2D video. Specifically, we investigate whether small, pre-trained vision--LLMs can act as spatially-grounded, zero-shot anomaly detectors by converting video into text descriptions and scoring labels via textual entailment. We evaluate four open models on UCF-Crime and RWF-2000 under prompting and privacy-preserving conditions. Few-shot exemplars can improve accuracy for some models, but may increase false positives, and privacy filters -- especially full-body GAN transforms -- introduce inconsistencies that degrade accuracy. These results chart where current vision--LLMs succeed (simple, spatially salient events) and where they falter (noisy spatial cues, identity obfuscation). Looking forward, we outline concrete paths to strengthen spatial grounding without task-specific training: structure-aware prompts, lightweight spatial memory across clips, scene-graph or 3D-pose priors during description, and privacy methods that preserve action-relevant geometry. This positions zero-shot, language-grounded pipelines as adaptable building blocks for embodied, real-world video understanding. Our implementation for evaluating VLMs is publicly available at: https://github.com/pascalbenschopTU/VLLM_AnomalyRecognition",
    "authors": [
      "Pascal Benschop",
      "Cristian Meo",
      "Justin Dauwels",
      "Jelte P. Mense"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23190v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23190v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2510.23118v1",
    "title": "Task-Agnostic Fusion of Time Series and Imagery for Earth Observation",
    "summary": "We propose a task-agnostic framework for multimodal fusion of time series and single timestamp images, enabling cross-modal generation and robust downstream performance. Our approach explores deterministic and learned strategies for time series quantization and then leverages a masked correlation learning objective, aligning discrete image and time series tokens in a unified representation space. Instantiated in the Earth observation domain, the pretrained model generates consistent global temperature profiles from satellite imagery and is validated through counterfactual experiments. Across downstream tasks, our task-agnostic pretraining outperforms task-specific fusion by 6\\% in R$^2$ and 2\\% in RMSE on average, and exceeds baseline methods by 50\\% in R$^2$ and 12\\% in RMSE. Finally, we analyze gradient sensitivity across modalities, providing insights into model robustness. Code, data, and weights will be released under a permissive license.",
    "authors": [
      "Gianfranco Basile",
      "Johannes Jakubik",
      "Benedikt Blumenstiel",
      "Thomas Brunschwiler",
      "Juan Bernabe Moreno"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23118v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23118v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.52
  },
  {
    "arxiv_id": "2510.23574v1",
    "title": "More Than Generation: Unifying Generation and Depth Estimation via   Text-to-Image Diffusion Models",
    "summary": "Generative depth estimation methods leverage the rich visual priors stored in pre-trained text-to-image diffusion models, demonstrating astonishing zero-shot capability. However, parameter updates during training lead to catastrophic degra- dation in the image generation capability of the pre-trained model. We introduce MERGE, a unified model for image generation and depth estimation, starting from a fixed pre-trained text-to-image model. MERGE demonstrates that the pre-trained text-to-image model can do more than image generation, but also expand to depth estimation effortlessly. Specifically, MERGE introduces a play- and-plug framework that enables seamless switching between image generation and depth estimation modes through simple and pluggable converters. Meanwhile, we propose a Group Reuse Mechanism to encourage parameter reuse and im- prove the utilization of the additional learnable parameters. MERGE unleashes the powerful depth estimation capability of the pre-trained text-to-image model while preserving its original image generation ability. Compared to other unified models for image generation and depth estimation, MERGE achieves state-of- the-art performance across multiple depth estimation benchmarks. The code will be made available at https://github.com/H-EmbodVis/MERGE",
    "authors": [
      "Hongkai Lin",
      "Dingkang Liang",
      "Mingyang Du",
      "Xin Zhou",
      "Xiang Bai"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23574v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23574v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2510.23368v1",
    "title": "PlanarTrack: A high-quality and challenging benchmark for large-scale   planar object tracking",
    "summary": "Planar tracking has drawn increasing interest owing to its key roles in robotics and augmented reality. Despite recent great advancement, further development of planar tracking, particularly in the deep learning era, is largely limited compared to generic tracking due to the lack of large-scale platforms. To mitigate this, we propose PlanarTrack, a large-scale high-quality and challenging benchmark for planar tracking. Specifically, PlanarTrack consists of 1,150 sequences with over 733K frames, including 1,000 short-term and 150 new long-term videos, which enables comprehensive evaluation of short- and long-term tracking performance. All videos in PlanarTrack are recorded in unconstrained conditions from the wild, which makes PlanarTrack challenging but more realistic for real-world applications. To ensure high-quality annotations, each video frame is manually annotated by four corner points with multi-round meticulous inspection and refinement. To enhance target diversity of PlanarTrack, we only capture a unique target in one sequence, which is different from existing benchmarks. To our best knowledge, PlanarTrack is by far the largest and most diverse and challenging dataset dedicated to planar tracking. To understand performance of existing methods on PlanarTrack and to provide a comparison for future research, we evaluate 10 representative planar trackers with extensive comparison and in-depth analysis. Our evaluation reveals that, unsurprisingly, the top planar trackers heavily degrade on the challenging PlanarTrack, which indicates more efforts are required for improving planar tracking. Our data and results will be released at https://github.com/HengLan/PlanarTrack",
    "authors": [
      "Yifan Jiao",
      "Xinran Liu",
      "Xiaoqiong Liu",
      "Xiaohui Yuan",
      "Heng Fan",
      "Libo Zhang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23368v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23368v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2510.23363v1",
    "title": "Interpretable Tile-Based Classification of Paclitaxel Exposure",
    "summary": "Medical image analysis is central to drug discovery and preclinical evaluation, where scalable, objective readouts can accelerate decision-making. We address classification of paclitaxel (Taxol) exposure from phase-contrast microscopy of C6 glioma cells -- a task with subtle dose differences that challenges full-image models. We propose a simple tiling-and-aggregation pipeline that operates on local patches and combines tile outputs into an image label, achieving state-of-the-art accuracy on the benchmark dataset and improving over the published baseline by around 20 percentage points, with trends confirmed by cross-validation. To understand why tiling is effective, we further apply Grad-CAM and Score-CAM and attention analyses, which enhance model interpretability and point toward robustness-oriented directions for future medical image research. Code is released to facilitate reproduction and extension.",
    "authors": [
      "Sean Fletcher",
      "Gabby Scott",
      "Douglas Currie",
      "Xin Zhang",
      "Yuqi Song",
      "Bruce MacLeod"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23363v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23363v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2510.23057v1",
    "title": "Seq-DeepIPC: Sequential Sensing for End-to-End Control in Legged Robot   Navigation",
    "summary": "We present Seq-DeepIPC, a sequential end-to-end perception-to-control model for legged robot navigation in realworld environments. Seq-DeepIPC advances intelligent sensing for autonomous legged navigation by tightly integrating multi-modal perception (RGB-D + GNSS) with temporal fusion and control. The model jointly predicts semantic segmentation and depth estimation, giving richer spatial features for planning and control. For efficient deployment on edge devices, we use EfficientNet-B0 as the encoder, reducing computation while maintaining accuracy. Heading estimation is simplified by removing the noisy IMU and instead computing the bearing angle directly from consecutive GNSS positions. We collected a larger and more diverse dataset that includes both road and grass terrains, and validated Seq-DeepIPC on a robot dog. Comparative and ablation studies show that sequential inputs improve perception and control in our models, while other baselines do not benefit. Seq-DeepIPC achieves competitive or better results with reasonable model size; although GNSS-only heading is less reliable near tall buildings, it is robust in open areas. Overall, Seq-DeepIPC extends end-to-end navigation beyond wheeled robots to more versatile and temporally-aware systems. To support future research, we will release the codes to our GitHub repository at https://github.com/oskarnatan/Seq-DeepIPC.",
    "authors": [
      "Oskar Natan",
      "Jun Miura"
    ],
    "categories": [
      "cs.RO",
      "cs.CV",
      "cs.SY",
      "eess.IV",
      "eess.SY"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23057v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23057v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.51
  },
  {
    "arxiv_id": "2510.23578v1",
    "title": "Reduced AI Acceptance After the Generative AI Boom: Evidence From a   Two-Wave Survey Study",
    "summary": "The rapid adoption of generative artificial intelligence (GenAI) technologies has led many organizations to integrate AI into their products and services, often without considering user preferences. Yet, public attitudes toward AI use, especially in impactful decision-making scenarios, are underexplored. Using a large-scale two-wave survey study (n_wave1=1514, n_wave2=1488) representative of the Swiss population, we examine shifts in public attitudes toward AI before and after the launch of ChatGPT. We find that the GenAI boom is significantly associated with reduced public acceptance of AI (see Figure 1) and increased demand for human oversight in various decision-making contexts. The proportion of respondents finding AI \"not acceptable at all\" increased from 23% to 30%, while support for human-only decision-making rose from 18% to 26%. These shifts have amplified existing social inequalities in terms of widened educational, linguistic, and gender gaps post-boom. Our findings challenge industry assumptions about public readiness for AI deployment and highlight the critical importance of aligning technological development with evolving public preferences.",
    "authors": [
      "Joachim Baumann",
      "Aleksandra Urman",
      "Ulrich Leicht-Deobald",
      "Zachary J. Roman",
      "Anikó Hannák",
      "Markus Christen"
    ],
    "categories": [
      "cs.AI"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23578v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23578v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2510.23276v1",
    "title": "A Cocktail-Party Benchmark: Multi-Modal dataset and Comparative   Evaluation Results",
    "summary": "We introduce the task of Multi-Modal Context-Aware Recognition (MCoRec) in the ninth CHiME Challenge, which addresses the cocktail-party problem of overlapping conversations in a single-room setting using audio, visual, and contextual cues. MCoRec captures natural multi-party conversations where the recordings focus on unscripted, casual group chats, leading to extreme speech overlap of up to 100% and highly fragmented conversational turns. The task requires systems to answer the question \"Who speaks when, what, and with whom?\" by jointly transcribing each speaker's speech and clustering them into their respective conversations from audio-visual recordings. Audio-only baselines exceed 100% word error rate, whereas incorporating visual cues yields substantial 50% improvements, highlighting the importance of multi-modality. In this manuscript, we present the motivation behind the task, outline the data collection process, and report the baseline systems developed for the MCoRec.",
    "authors": [
      "Thai-Binh Nguyen",
      "Katerina Zmolikova",
      "Pingchuan Ma",
      "Ngoc Quan Pham",
      "Christian Fuegen",
      "Alexander Waibel"
    ],
    "categories": [
      "cs.CL"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23276v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23276v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2510.23240v1",
    "title": "Autoregressive Styled Text Image Generation, but Make it Reliable",
    "summary": "Generating faithful and readable styled text images (especially for Styled Handwritten Text generation - HTG) is an open problem with several possible applications across graphic design, document understanding, and image editing. A lot of research effort in this task is dedicated to developing strategies that reproduce the stylistic characteristics of a given writer, with promising results in terms of style fidelity and generalization achieved by the recently proposed Autoregressive Transformer paradigm for HTG. However, this method requires additional inputs, lacks a proper stop mechanism, and might end up in repetition loops, generating visual artifacts. In this work, we rethink the autoregressive formulation by framing HTG as a multimodal prompt-conditioned generation task, and tackle the content controllability issues by introducing special textual input tokens for better alignment with the visual ones. Moreover, we devise a Classifier-Free-Guidance-based strategy for our autoregressive model. Through extensive experimental validation, we demonstrate that our approach, dubbed Eruku, compared to previous solutions requires fewer inputs, generalizes better to unseen styles, and follows more faithfully the textual prompt, improving content adherence.",
    "authors": [
      "Carmine Zaccagnino",
      "Fabio Quattrini",
      "Vittorio Pippi",
      "Silvia Cascianelli",
      "Alessio Tonioni",
      "Rita Cucchiara"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23240v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23240v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2510.23144v1",
    "title": "DQ3D: Depth-guided Query for Transformer-Based 3D Object Detection in   Traffic Scenarios",
    "summary": "3D object detection from multi-view images in traffic scenarios has garnered significant attention in recent years. Many existing approaches rely on object queries that are generated from 3D reference points to localize objects. However, a limitation of these methods is that some reference points are often far from the target object, which can lead to false positive detections. In this paper, we propose a depth-guided query generator for 3D object detection (DQ3D) that leverages depth information and 2D detections to ensure that reference points are sampled from the surface or interior of the object. Furthermore, to address partially occluded objects in current frame, we introduce a hybrid attention mechanism that fuses historical detection results with depth-guided queries, thereby forming hybrid queries. Evaluation on the nuScenes dataset demonstrates that our method outperforms the baseline by 6.3\\% in terms of mean Average Precision (mAP) and 4.3\\% in the NuScenes Detection Score (NDS).",
    "authors": [
      "Ziyu Wang",
      "Wenhao Li",
      "Ji Wu"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23144v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23144v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.5
  },
  {
    "arxiv_id": "2510.23301v1",
    "title": "MDReID: Modality-Decoupled Learning for Any-to-Any Multi-Modal Object   Re-Identification",
    "summary": "Real-world object re-identification (ReID) systems often face modality inconsistencies, where query and gallery images come from different sensors (e.g., RGB, NIR, TIR). However, most existing methods assume modality-matched conditions, which limits their robustness and scalability in practical applications. To address this challenge, we propose MDReID, a flexible any-to-any image-level ReID framework designed to operate under both modality-matched and modality-mismatched scenarios. MDReID builds on the insight that modality information can be decomposed into two components: modality-shared features that are predictable and transferable, and modality-specific features that capture unique, modality-dependent characteristics. To effectively leverage this, MDReID introduces two key components: the Modality Decoupling Learning (MDL) and Modality-aware Metric Learning (MML). Specifically, MDL explicitly decomposes modality features into modality-shared and modality-specific representations, enabling effective retrieval in both modality-aligned and mismatched scenarios. MML, a tailored metric learning strategy, further enforces orthogonality and complementarity between the two components to enhance discriminative power across modalities. Extensive experiments conducted on three challenging multi-modality ReID benchmarks (RGBNT201, RGBNT100, MSVR310) consistently demonstrate the superiority of MDReID. Notably, MDReID achieves significant mAP improvements of 9.8\\%, 3.0\\%, and 11.5\\% in general modality-matched scenarios, and average gains of 3.4\\%, 11.8\\%, and 10.9\\% in modality-mismatched scenarios, respectively. The code is available at: \\textcolor{magenta}{https://github.com/stone96123/MDReID}.",
    "authors": [
      "Yingying Feng",
      "Jie Li",
      "Jie Hu",
      "Yukang Zhang",
      "Lei Tan",
      "Jiayi Ji"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23301v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23301v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.49
  },
  {
    "arxiv_id": "2510.23407v1",
    "title": "Multi-Task Surrogate-Assisted Search with Bayesian Competitive Knowledge   Transfer for Expensive Optimization",
    "summary": "Expensive optimization problems (EOPs) present significant challenges for traditional evolutionary optimization due to their limited evaluation calls. Although surrogate-assisted search (SAS) has become a popular paradigm for addressing EOPs, it still suffers from the cold-start issue. In response to this challenge, knowledge transfer has been gaining popularity for its ability to leverage search experience from potentially related instances, ultimately facilitating head-start optimization for more efficient decision-making. However, the curse of negative transfer persists when applying knowledge transfer to EOPs, primarily due to the inherent limitations of existing methods in assessing knowledge transferability. On the one hand, a priori transferability assessment criteria are intrinsically inaccurate due to their imprecise understandings. On the other hand, a posteriori methods often necessitate sufficient observations to make correct inferences, rendering them inefficient when applied to EOPs. Considering the above, this paper introduces a Bayesian competitive knowledge transfer (BCKT) method developed to improve multi-task SAS (MSAS) when addressing multiple EOPs simultaneously. Specifically, the transferability of knowledge is estimated from a Bayesian perspective that accommodates both prior beliefs and empirical evidence, enabling accurate competition between inner-task and inter-task solutions, ultimately leading to the adaptive use of promising solutions while effectively suppressing inferior ones. The effectiveness of our method in boosting various SAS algorithms for both multi-task and many-task problems is empirically validated, complemented by comparative studies that demonstrate its superiority over peer algorithms and its applicability to real-world scenarios. The source code of our method is available at https://github.com/XmingHsueh/MSAS-BCKT.",
    "authors": [
      "Yi Lu",
      "Xiaoming Xue",
      "Kai Zhang",
      "Liming Zhang",
      "Guodong Chen",
      "Chenming Cao",
      "Piyang Liu",
      "Kay Chen Tan"
    ],
    "categories": [
      "cs.NE"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23407v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23407v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.48
  },
  {
    "arxiv_id": "2510.23095v1",
    "title": "Revisiting Multimodal Positional Encoding in Vision-Language Models",
    "summary": "Multimodal position encoding is essential for vision-language models, yet there has been little systematic investigation into multimodal position encoding. We conduct a comprehensive analysis of multimodal Rotary Positional Embedding (RoPE) by examining its two core components: position design and frequency allocation. Through extensive experiments, we identify three key guidelines: positional coherence, full frequency utilization, and preservation of textual priors-ensuring unambiguous layout, rich representation, and faithful transfer from the pre-trained LLM. Based on these insights, we propose Multi-Head RoPE (MHRoPE) and MRoPE-Interleave (MRoPE-I), two simple and plug-and-play variants that require no architectural changes. Our methods consistently outperform existing approaches across diverse benchmarks, with significant improvements in both general and fine-grained multimodal understanding. Code will be avaliable at https://github.com/JJJYmmm/Multimodal-RoPEs.",
    "authors": [
      "Jie Huang",
      "Xuejing Liu",
      "Sibo Song",
      "Ruibing Hou",
      "Hong Chang",
      "Junyang Lin",
      "Shuai Bai"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23095v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23095v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.48
  },
  {
    "arxiv_id": "2510.23116v1",
    "title": "Residual Diffusion Bridge Model for Image Restoration",
    "summary": "Diffusion bridge models establish probabilistic paths between arbitrary paired distributions and exhibit great potential for universal image restoration. Most existing methods merely treat them as simple variants of stochastic interpolants, lacking a unified analytical perspective. Besides, they indiscriminately reconstruct images through global noise injection and removal, inevitably distorting undegraded regions due to imperfect reconstruction. To address these challenges, we propose the Residual Diffusion Bridge Model (RDBM). Specifically, we theoretically reformulate the stochastic differential equations of generalized diffusion bridge and derive the analytical formulas of its forward and reverse processes. Crucially, we leverage the residuals from given distributions to modulate the noise injection and removal, enabling adaptive restoration of degraded regions while preserving intact others. Moreover, we unravel the fundamental mathematical essence of existing bridge models, all of which are special cases of RDBM and empirically demonstrate the optimality of our proposed models. Extensive experiments are conducted to demonstrate the state-of-the-art performance of our method both qualitatively and quantitatively across diverse image restoration tasks. Code is publicly available at https://github.com/MiliLab/RDBM.",
    "authors": [
      "Hebaixu Wang",
      "Jing Zhang",
      "Haoyang Chen",
      "Haonan Guo",
      "Di Wang",
      "Jiayi Ma",
      "Bo Du"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23116v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23116v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.47
  },
  {
    "arxiv_id": "2510.23399v1",
    "title": "Color and Frequency Correction for Image Colorization",
    "summary": "The project has carried out the re-optimization of image coloring in accordance with the existing Autocolorization direction model DDColor. For the experiments on the existing weights of DDColor, we found that it has limitations in some frequency bands and the color cast problem caused by insufficient input dimension. We construct two optimization schemes and combine them, which achieves the performance improvement of indicators such as PSNR and SSIM of the images after DDColor.",
    "authors": [
      "Yun Kai Zhuang"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23399v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23399v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.46
  },
  {
    "arxiv_id": "2510.23137v1",
    "title": "Note on the Construction of Structure Tensor",
    "summary": "This note presents a theoretical discussion of two structure tensor constructions: one proposed by Bigun and Granlund 1987, and the other by Granlund and Knutsson 1995. At first glance, these approaches may appear quite different--the former is implemented by averaging outer products of gradient filter responses, while the latter constructs the tensor from weighted outer products of tune-in frequency vectors of quadrature filters. We argue that when both constructions are viewed through the common lens of Total Least Squares (TLS) line fitting to the power spectrum, they can be reconciled to a large extent, and additional benefits emerge. From this perspective, the correction term introduced in Granlund and Knutsson 1995 becomes unnecessary. Omitting it ensures that the resulting tensor remains positive semi-definite, thereby simplifying the interpretation of its eigenvalues. Furthermore, this interpretation allows fitting more than a single 0rientation to the input by reinterpreting quadrature filter responses without relying on a structure tensor. It also removes the constraint that responses must originate strictly from quadrature filters, allowing the use of alternative filter types and non-angular tessellations. These alternatives include Gabor filters--which, although not strictly quadrature, are still suitable for structure tensor construction--even when they tessellate the spectrum in a Cartesian fashion, provided they are sufficiently concentrated.",
    "authors": [
      "Josef Bigun",
      "Fernado Alonso-Fernandez"
    ],
    "categories": [
      "cs.CV",
      "math.SP"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23137v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23137v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.46
  },
  {
    "arxiv_id": "2510.23253v1",
    "title": "A Video Is Not Worth a Thousand Words",
    "summary": "As we become increasingly dependent on vision language models (VLMs) to answer questions about the world around us, there is a significant amount of research devoted to increasing both the difficulty of video question answering (VQA) datasets, and the context lengths of the models that they evaluate. The reliance on large language models as backbones has lead to concerns about potential text dominance, and the exploration of interactions between modalities is underdeveloped. How do we measure whether we're heading in the right direction, with the complexity that multi-modal models introduce? We propose a joint method of computing both feature attributions and modality scores based on Shapley values, where both the features and modalities are arbitrarily definable. Using these metrics, we compare $6$ VLM models of varying context lengths on $4$ representative datasets, focusing on multiple-choice VQA. In particular, we consider video frames and whole textual elements as equal features in the hierarchy, and the multiple-choice VQA task as an interaction between three modalities: video, question and answer. Our results demonstrate a dependence on text and show that the multiple-choice VQA task devolves into a model's ability to ignore distractors. Code available at https://github.com/sjpollard/a-video-is-not-worth-a-thousand-words.",
    "authors": [
      "Sam Pollard",
      "Michael Wray"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23253v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23253v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.45
  },
  {
    "arxiv_id": "2510.23589v1",
    "title": "InFlux: A Benchmark for Self-Calibration of Dynamic Intrinsics of Video   Cameras",
    "summary": "Accurately tracking camera intrinsics is crucial for achieving 3D understanding from 2D video. However, most 3D algorithms assume that camera intrinsics stay constant throughout a video, which is often not true for many real-world in-the-wild videos. A major obstacle in this field is a lack of dynamic camera intrinsics benchmarks--existing benchmarks typically offer limited diversity in scene content and intrinsics variation, and none provide per-frame intrinsic changes for consecutive video frames. In this paper, we present Intrinsics in Flux (InFlux), a real-world benchmark that provides per-frame ground truth intrinsics annotations for videos with dynamic intrinsics. Compared to prior benchmarks, InFlux captures a wider range of intrinsic variations and scene diversity, featuring 143K+ annotated frames from 386 high-resolution indoor and outdoor videos with dynamic camera intrinsics. To ensure accurate per-frame intrinsics, we build a comprehensive lookup table of calibration experiments and extend the Kalibr toolbox to improve its accuracy and robustness. Using our benchmark, we evaluate existing baseline methods for predicting camera intrinsics and find that most struggle to achieve accurate predictions on videos with dynamic intrinsics. For the dataset, code, videos, and submission, please visit https://influx.cs.princeton.edu/.",
    "authors": [
      "Erich Liang",
      "Roma Bhattacharjee",
      "Sreemanti Dey",
      "Rafael Moschopoulos",
      "Caitlin Wang",
      "Michel Liao",
      "Grace Tan",
      "Andrew Wang",
      "Karhan Kayan",
      "Stamatis Alexandropoulos",
      "Jia Deng"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23589v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23589v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.44
  },
  {
    "arxiv_id": "2510.23079v1",
    "title": "Strategies for Robust Deep Learning Based Deformable Registration",
    "summary": "Deep learning based deformable registration methods have become popular in recent years. However, their ability to generalize beyond training data distribution can be poor, significantly hindering their usability. LUMIR brain registration challenge for Learn2Reg 2025 aims to advance the field by evaluating the performance of the registration on contrasts and modalities different from those included in the training set. Here we describe our submission to the challenge, which proposes a very simple idea for significantly improving robustness by transforming the images into MIND feature space before feeding them into the model. In addition, a special ensembling strategy is proposed that shows a small but consistent improvement.",
    "authors": [
      "Joel Honkamaa",
      "Pekka Marttinen"
    ],
    "categories": [
      "cs.CV"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23079v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23079v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.44
  },
  {
    "arxiv_id": "2510.23197v1",
    "title": "Model-free filtering in high dimensions via projection and score-based   diffusions",
    "summary": "We consider the problem of recovering a latent signal $X$ from its noisy observation $Y$. The unknown law $\\mathbb{P}^X$ of $X$, and in particular its support $\\mathscr{M}$, are accessible only through a large sample of i.i.d.\\ observations. We further assume $\\mathscr{M}$ to be a low-dimensional submanifold of a high-dimensional Euclidean space $\\mathbb{R}^d$. As a filter or denoiser $\\widehat X$, we suggest an estimator of the metric projection $\\pi_{\\mathscr{M}}(Y)$ of $Y$ onto the manifold $\\mathscr{M}$. To compute this estimator, we study an auxiliary semiparametric model in which $Y$ is obtained by adding isotropic Laplace noise to $X$. Using score matching within a corresponding diffusion model, we obtain an estimator of the Bayesian posterior $\\mathbb{P}^{X \\mid Y}$ in this setup. Our main theoretical results show that, in the limit of high dimension $d$, this posterior $\\mathbb{P}^{X\\mid Y}$ is concentrated near the desired metric projection $\\pi_{\\mathscr{M}}(Y)$.",
    "authors": [
      "Sören Christensen",
      "Jan Kallsen",
      "Claudia Strauch",
      "Lukas Trottner"
    ],
    "categories": [
      "math.ST",
      "stat.ML",
      "stat.TH",
      "62C10, 62G20, 62G05, 60J65, 68T07"
    ],
    "published": "2025-10-27",
    "url": "https://arxiv.org/abs/2510.23197v1",
    "pdf_url": "https://arxiv.org/pdf/2510.23197v1.pdf",
    "date": "2025-10-28",
    "source": "arxiv",
    "research_score": 0.42
  }
]